# Рубежный контроль №2

Необходимо подготовить отчет по рубежному контролю и разместить его в Вашем репозитории. Вы можете использовать
титульный лист, или в начале ноутбука в текстовой ячейке указать Ваши Ф.И.О. и группу.

## Тема: Методы построения моделей машинного обучения.

Для заданного набора данных (по Вашему варианту) постройте модели классификации или регрессии (в зависимости от
конкретной задачи, рассматриваемой в наборе данных). Для построения моделей используйте методы 1 и 2 (по варианту для
Вашей группы). Оцените качество моделей на основе подходящих метрик качества (не менее двух метрик). Какие метрики
качества Вы использовали и почему? Какие выводы Вы можете сделать о качестве построенных моделей? Для построения моделей
необходимо выполнить требуемую предобработку данных: заполнение пропусков, кодирование категориальных признаков, и т.д.

## Задание

Для заданного набора данных (по Вашему варианту) постройте модели классификации или регрессии (в зависимости от
конкретной задачи, рассматриваемой в наборе данных). Для построения моделей используйте методы 1 и 2 (по варианту для
Вашей группы). Оцените качество моделей на основе подходящих метрик качества (не менее двух метрик). Какие метрики
качества Вы использовали и почему? Какие выводы Вы можете сделать о качестве построенных моделей? Для построения моделей
необходимо выполнить требуемую предобработку данных: заполнение пропусков, кодирование категориальных признаков, и т.д.

- Для студентов групп ИУ5Ц-81Б, ИУ5Ц-82Б, ИУ5Ц-83Б, ИУ5Ц-84Б номер варианта = 25 + номер в списке группы.
- При решении задач можно выбирать любое подмножество признаков из приведенного набора данных.
- Для сокращения времени построения моделей можно использовать фрагмент набора данных (например, первые 200-500 строк).
- Методы 1 и 2 для каждой группы приведены в следующей таблице:

|     Вариант № | Группа            | Метод №1                         | Метод №2            |           
|--------------:|-------------------|----------------------------------|---------------------|
| :two: :seven: | ИУ5-64Б, ИУ5Ц-84Б | Линейная/логистическая регрессия | Градиентный бустинг |

### Наборы данных:

https://www.kaggle.com/datasets/fedesoriano/company-bankruptcy-prediction/data

## Небольшое предисловие об исследовании

### Прогнозирование банкротства компаний с использованием машинного обучения

Этот проект посвящен задаче прогнозирования банкротства компаний с использованием машинного обучения. Цель - построить
модель, которая может эффективно предсказывать, обанкротится ли компания на основе ее финансовых показателей.

### Датасет

Для анализа был использован датасет "Company Bankruptcy Prediction" из репозитория UCI Machine Learning. Он содержит
данные о 6819 компаниях из Taiwan Economic Journal за период с 1999 по 2009 годы. Каждая компания описывается 96
признаками, которые представляют собой различные финансовые показатели, такие как рентабельность активов, коэффициенты
ликвидности, показатели роста и др.

Целевой признак - "Bankrupt?" - бинарный и указывает, обанкротилась ли компания (1) или нет (0).

### Анализ и предобработка данных:

- Проведена описательная статистика для изучения распределения признаков и выявления потенциальных выбросов.
- Выявлены признаки с потенциальными выбросами с помощью анализа средних значений, стандартных отклонений и
  межквартильного размаха (IQR).
- Выбросы удалены с использованием метода IQR для сохранения большей части данных.
- Оптимизировано использование памяти путем преобразования типов данных в более эффективные форматы.
- Признаки нормализованы с использованием StandardScaler для улучшения работы алгоритмов машинного обучения.

### Построение моделей:

- Обучены пять моделей классификации:
    - LogisticRegression,
    - CatBoostClassifier,
    - LGBMClassifier,
    - XGBClassifier,
    - GradientBoostingClassifier,
- Для каждой модели проведен подбор гиперпараметров с помощью GridSearchCV для поиска наилучшей конфигурации.
- Модели оценены на тестовой выборке с использованием метрик точности, полноты, F1-меры и AUC-ROC.

### Сравнение моделей:

Сравнение производительности моделей на тестовой выборке:

| Модель                     | Accuracy | Precision | Recall   | F1-Score | Время обучения [s] | Время предсказания [s] | Рейтинг  |
|----------------------------|----------|-----------|----------|----------|--------------------|------------------------|----------|
| LGBMClassifier             | 0.97561  | 0.666667  | 0.086957 | 0.153846 | 0.057874           | 0.01                   | 0.419554 |
| LogisticRegression         | 0.976164 | 0.555556  | 0.326087 | 0.410959 | 0.026165           | 0.012                  | 0.410081 |
| CatBoostClassifier         | 0.976164 | 0.6       | 0.195652 | 0.295082 | 0.232785           | 0.012                  | 0.376874 |
| XGBClassifier              | 0.97561  | 0.6       | 0.130435 | 0.214286 | 0.079355           | 0.028                  | 0.287531 |
| GradientBoostingClassifier | 0.975055 | 0.538462  | 0.152174 | 0.237288 | 1.866682           | 0.011                  | 0.121996 |

### Выводы

- LGBMClassifier показала наилучшую производительность, учитывая баланс точности, полноты и времени обучения.
- CatBoostClassifier также является хорошим вариантом, но время обучения значительно больше, что может быть существенным
  фактором при работе с большими датасетами.
- LogisticRegression проста и интерпретируема, что делает ее привлекательной для задач, где важно понимание влияния
  признаков на прогноз. Однако, она имеет более низкий recall по сравнению с моделями градиентного бустинга.
- XGBClassifier и GradientBoostingClassifier показали менее высокую производительность по сравнению с другими моделями.