{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение стоимости автомобилей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание проекта\n",
    "Сервис по продаже автомобилей с пробегом «Не бит, не крашен» разрабатывает приложение, чтобы привлечь новых клиентов. В нём можно будет узнать рыночную стоимость своего автомобиля. \n",
    "\n",
    "Построить модель, которая умеет её определять. В нашем распоряжении данные о технических характеристиках, комплектации и ценах других автомобилей.\n",
    "\n",
    "Критерии, которые важны заказчику:\n",
    "- качество предсказания;\n",
    "- время обучения модели;\n",
    "- время предсказания модели.\n",
    "\n",
    "# План по выполнению проекта\n",
    "\n",
    "Чтобы усилить исследование, не ограничивайтесь градиентным бустингом. Попробуем более простые модели — иногда они работают лучше. Эти редкие случаи легко пропустить, если всегда применять только бустинг.\n",
    "\n",
    "Поэкспериментируем и сравним характеристики моделей: время обучения, время предсказания, точность результата.\n",
    "\n",
    "Основные шаги:\n",
    "\n",
    "1. Загрузить данные, путь к файлу: `datasets/autos.csv`.\n",
    "1. Изучить данные. Заполнить пропущенные значения и обработать аномалии в столбцах. Если среди признаков имеются неинформативные, удалить их.\n",
    "1. Подготовить выборки для обучения моделей.\n",
    "1. Обучить разные модели, одна из которых — LightGBM, как минимум одна — не бустинг. Для каждой модели попробовать разные гиперпараметры.\n",
    "1. Проанализировать время обучения, время предсказания и качество моделей.\n",
    "1. Опираясь на критерии заказчика, выбрать лучшую модель, проверить её качество на тестовой выборке.\n",
    "\n",
    "Примечания:\n",
    "\n",
    "1. Для оценки качества моделей применять метрику `RMSE`.\n",
    "1. Значение метрики `RMSE` должно быть меньше `2500`.\n",
    "1. Самостоятельно освоить библиотеку LightGBM и её средствами построить модели градиентного бустинга.\n",
    "1. Время выполнения ячейки кода Jupyter Notebook можно получить специальной командой. Найти её.\n",
    "1. Модель градиентного бустинга может долго обучаться, поэтому можно изменить у неё только два-три параметра.\n",
    "1. Если перестанет работать Jupyter Notebook, можно удалить лишние переменные оператором del.\n",
    "\n",
    "`del features_train`\n",
    "\n",
    "# Описание данных\n",
    "\n",
    "Данные находятся в файле `/datasets/autos.csv`.\n",
    "\n",
    "**Признаки**: \n",
    "- `DateCrawled` — дата скачивания анкеты из базы\n",
    "- `VehicleType` — тип автомобильного кузова\n",
    "- `RegistrationYear` — год регистрации автомобиля\n",
    "- `Gearbox` — тип коробки передач\n",
    "- `Power` — мощность (л. с.)\n",
    "- `Model` — модель автомобиля\n",
    "- `Kilometer` — пробег (км)\n",
    "- `RegistrationMonth` — месяц регистрации автомобиля\n",
    "- `FuelType` — тип топлива\n",
    "- `Brand` — марка автомобиля\n",
    "- `Repaired` — была машина в ремонте или нет\n",
    "- `DateCreated` — дата создания анкеты\n",
    "- `NumberOfPictures` — количество фотографий автомобиля\n",
    "- `PostalCode` — почтовый индекс владельца анкеты (пользователя)\n",
    "- `LastSeen` — дата последней активности пользователя\n",
    "\n",
    "**Целевой признак:** \n",
    "- `Price` — цена (евро)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузим-данные\" data-toc-modified-id=\"Загрузим-данные-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Загрузим данные</a></span></li><li><span><a href=\"#Изучим-данные\" data-toc-modified-id=\"Изучим-данные-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Изучим данные</a></span></li><li><span><a href=\"#Заполним-пропущенные-значения-и-обработаем-аномалии-в-столбцах.-Если-среди-признаков-имеются-неинформативные,-то-удалим-их.\" data-toc-modified-id=\"Заполним-пропущенные-значения-и-обработаем-аномалии-в-столбцах.-Если-среди-признаков-имеются-неинформативные,-то-удалим-их.-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Заполним пропущенные значения и обработаем аномалии в столбцах. Если среди признаков имеются неинформативные, то удалим их.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Пропущенные-значения\" data-toc-modified-id=\"Пропущенные-значения-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Пропущенные значения</a></span><ul class=\"toc-item\"><li><span><a href=\"#Радикальный-метод\" data-toc-modified-id=\"Радикальный-метод-1.3.1.1\"><span class=\"toc-item-num\">1.3.1.1&nbsp;&nbsp;</span>Радикальный метод</a></span></li><li><span><a href=\"#Второй-способ---заполнение-&quot;unknown&quot;-или-медианным-значением\" data-toc-modified-id=\"Второй-способ---заполнение-&quot;unknown&quot;-или-медианным-значением-1.3.1.2\"><span class=\"toc-item-num\">1.3.1.2&nbsp;&nbsp;</span>Второй способ - заполнение <code>\"unknown\"</code> или медианным значением</a></span></li></ul></li><li><span><a href=\"#Уникальные-значения\" data-toc-modified-id=\"Уникальные-значения-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Уникальные значения</a></span></li><li><span><a href=\"#Дублирующие-значения\" data-toc-modified-id=\"Дублирующие-значения-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Дублирующие значения</a></span></li></ul></li></ul></li><li><span><a href=\"#Обучение-моделей\" data-toc-modified-id=\"Обучение-моделей-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#Прямое-кодирование---One-Hot-Encoding\" data-toc-modified-id=\"Прямое-кодирование---One-Hot-Encoding-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Прямое кодирование - One-Hot Encoding</a></span><ul class=\"toc-item\"><li><span><a href=\"#Деление-на-обучающей-и-валидационной-выборки\" data-toc-modified-id=\"Деление-на-обучающей-и-валидационной-выборки-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Деление на обучающей и валидационной выборки</a></span></li><li><span><a href=\"#LinearRegression\" data-toc-modified-id=\"LinearRegression-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>LinearRegression</a></span></li></ul></li><li><span><a href=\"#Порядковое-кодирование---OrdinalEncoder\" data-toc-modified-id=\"Порядковое-кодирование---OrdinalEncoder-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Порядковое кодирование - OrdinalEncoder</a></span><ul class=\"toc-item\"><li><span><a href=\"#Кодирование-признаков---деление-на-обучающей-и-валидационной-выборки\" data-toc-modified-id=\"Кодирование-признаков---деление-на-обучающей-и-валидационной-выборки-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Кодирование признаков - деление на обучающей и валидационной выборки</a></span></li><li><span><a href=\"#DecisionTreeRegressor\" data-toc-modified-id=\"DecisionTreeRegressor-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>DecisionTreeRegressor</a></span></li><li><span><a href=\"#RandomForestRegressor\" data-toc-modified-id=\"RandomForestRegressor-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>RandomForestRegressor</a></span></li><li><span><a href=\"#LightGBMRegressor\" data-toc-modified-id=\"LightGBMRegressor-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>LightGBMRegressor</a></span></li><li><span><a href=\"#CatBoostRegressor\" data-toc-modified-id=\"CatBoostRegressor-2.2.5\"><span class=\"toc-item-num\">2.2.5&nbsp;&nbsp;</span>CatBoostRegressor</a></span></li></ul></li><li><span><a href=\"#Масштабирование-признаков---StandardScaler\" data-toc-modified-id=\"Масштабирование-признаков---StandardScaler-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Масштабирование признаков - StandardScaler</a></span><ul class=\"toc-item\"><li><span><a href=\"#Масштабируем-One-Hot-Encoding\" data-toc-modified-id=\"Масштабируем-One-Hot-Encoding-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Масштабируем One-Hot Encoding</a></span><ul class=\"toc-item\"><li><span><a href=\"#Деление-на-обучающей-и-валидационной-выборки\" data-toc-modified-id=\"Деление-на-обучающей-и-валидационной-выборки-2.3.1.1\"><span class=\"toc-item-num\">2.3.1.1&nbsp;&nbsp;</span>Деление на обучающей и валидационной выборки</a></span></li><li><span><a href=\"#LinearRegression\" data-toc-modified-id=\"LinearRegression-2.3.1.2\"><span class=\"toc-item-num\">2.3.1.2&nbsp;&nbsp;</span>LinearRegression</a></span></li></ul></li><li><span><a href=\"#Масштабируем-OrdinalEncoder\" data-toc-modified-id=\"Масштабируем-OrdinalEncoder-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Масштабируем OrdinalEncoder</a></span><ul class=\"toc-item\"><li><span><a href=\"#Деление-на-обучающей-и-валидационной-выборки\" data-toc-modified-id=\"Деление-на-обучающей-и-валидационной-выборки-2.3.2.1\"><span class=\"toc-item-num\">2.3.2.1&nbsp;&nbsp;</span>Деление на обучающей и валидационной выборки</a></span></li><li><span><a href=\"#Кодируем-признаки\" data-toc-modified-id=\"Кодируем-признаки-2.3.2.2\"><span class=\"toc-item-num\">2.3.2.2&nbsp;&nbsp;</span>Кодируем признаки</a></span></li><li><span><a href=\"#DecisionTreeRegressor\" data-toc-modified-id=\"DecisionTreeRegressor-2.3.2.3\"><span class=\"toc-item-num\">2.3.2.3&nbsp;&nbsp;</span>DecisionTreeRegressor</a></span></li><li><span><a href=\"#RandomForestRegressor\" data-toc-modified-id=\"RandomForestRegressor-2.3.2.4\"><span class=\"toc-item-num\">2.3.2.4&nbsp;&nbsp;</span>RandomForestRegressor</a></span></li><li><span><a href=\"#LightGBMRegressor\" data-toc-modified-id=\"LightGBMRegressor-2.3.2.5\"><span class=\"toc-item-num\">2.3.2.5&nbsp;&nbsp;</span>LightGBMRegressor</a></span></li><li><span><a href=\"#CatBoostRegressor\" data-toc-modified-id=\"CatBoostRegressor-2.3.2.6\"><span class=\"toc-item-num\">2.3.2.6&nbsp;&nbsp;</span>CatBoostRegressor</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Анализ-моделей\" data-toc-modified-id=\"Анализ-моделей-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Анализ моделей</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Уведомление о завершение работы определенного ячейка (очень пригодится для машинного обучения)\n",
    "import jupyternotify\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключаем все необходимые библиотеки\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Время обучения модели\n",
    "import timeit\n",
    "from lightgbm import LGBMRegressor\n",
    "# Вызов библиотеки для отключения предупреждения\n",
    "import warnings\n",
    "\n",
    "# Разбиение на обучающую, валидационную и тестовую выборку и кроссвалидацию для повышения качеств обучения\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Конвейер\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# Масштабируемость модели\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "# и для машинного обучения разными способами (по условию мы выбираем линейную регрессию):\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем датасет\n",
    "try:\n",
    "    # С локального файла\n",
    "    try:\n",
    "        df = pd.read_csv('datasets/autos.csv')\n",
    "    except:\n",
    "        df = pd.read_csv('/datasets/autos.csv')\n",
    "except:\n",
    "    print('Отсутствует датасет. Проверьте путь файла')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354369 non-null  object\n",
      " 1   Price              354369 non-null  int64 \n",
      " 2   VehicleType        316879 non-null  object\n",
      " 3   RegistrationYear   354369 non-null  int64 \n",
      " 4   Gearbox            334536 non-null  object\n",
      " 5   Power              354369 non-null  int64 \n",
      " 6   Model              334664 non-null  object\n",
      " 7   Kilometer          354369 non-null  int64 \n",
      " 8   RegistrationMonth  354369 non-null  int64 \n",
      " 9   FuelType           321474 non-null  object\n",
      " 10  Brand              354369 non-null  object\n",
      " 11  Repaired           283215 non-null  object\n",
      " 12  DateCreated        354369 non-null  object\n",
      " 13  NumberOfPictures   354369 non-null  int64 \n",
      " 14  PostalCode         354369 non-null  int64 \n",
      " 15  LastSeen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дополнительные информация:**\n",
    "\n",
    "**Признаки**\n",
    "- `DateCrawled` — дата скачивания анкеты из базы\n",
    "- `VehicleType` — тип автомобильного кузова\n",
    "- `RegistrationYear` — год регистрации автомобиля\n",
    "- `Gearbox` — тип коробки передач\n",
    "- `Power` — мощность (л. с.)\n",
    "- `Model` — модель автомобиля\n",
    "- `Kilometer` — пробег (км)\n",
    "- `RegistrationMonth` — месяц регистрации автомобиля\n",
    "- `FuelType` — тип топлива\n",
    "- `Brand` — марка автомобиля\n",
    "- `Repaired` — была машина в ремонте или нет\n",
    "- `DateCreated` — дата создания анкеты\n",
    "- `NumberOfPictures` — количество фотографий автомобиля\n",
    "- `PostalCode` — почтовый индекс владельца анкеты (пользователя)\n",
    "- `LastSeen` — дата последней активности пользователя\n",
    "\n",
    "**Целевой признак**\n",
    "- `Price` — цена (евро)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Repaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-24 11:52:17</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-24 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>70435</td>\n",
       "      <td>2016-04-07 03:16:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-24 10:58:45</td>\n",
       "      <td>18300</td>\n",
       "      <td>coupe</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>yes</td>\n",
       "      <td>2016-03-24 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>66954</td>\n",
       "      <td>2016-04-07 01:46:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-14 12:52:21</td>\n",
       "      <td>9800</td>\n",
       "      <td>suv</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>grand</td>\n",
       "      <td>125000</td>\n",
       "      <td>8</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>jeep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>90480</td>\n",
       "      <td>2016-04-05 12:47:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-03-17 16:54:04</td>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-17 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>91074</td>\n",
       "      <td>2016-03-17 17:40:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-31 17:25:20</td>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-31 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60437</td>\n",
       "      <td>2016-04-06 10:17:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "0  2016-03-24 11:52:17    480         NaN              1993  manual      0   \n",
       "1  2016-03-24 10:58:45  18300       coupe              2011  manual    190   \n",
       "2  2016-03-14 12:52:21   9800         suv              2004    auto    163   \n",
       "3  2016-03-17 16:54:04   1500       small              2001  manual     75   \n",
       "4  2016-03-31 17:25:20   3600       small              2008  manual     69   \n",
       "\n",
       "   Model  Kilometer  RegistrationMonth  FuelType       Brand Repaired  \\\n",
       "0   golf     150000                  0    petrol  volkswagen      NaN   \n",
       "1    NaN     125000                  5  gasoline        audi      yes   \n",
       "2  grand     125000                  8  gasoline        jeep      NaN   \n",
       "3   golf     150000                  6    petrol  volkswagen       no   \n",
       "4  fabia      90000                  7  gasoline       skoda       no   \n",
       "\n",
       "           DateCreated  NumberOfPictures  PostalCode             LastSeen  \n",
       "0  2016-03-24 00:00:00                 0       70435  2016-04-07 03:16:57  \n",
       "1  2016-03-24 00:00:00                 0       66954  2016-04-07 01:46:50  \n",
       "2  2016-03-14 00:00:00                 0       90480  2016-04-05 12:47:46  \n",
       "3  2016-03-17 00:00:00                 0       91074  2016-03-17 17:40:17  \n",
       "4  2016-03-31 00:00:00                 0       60437  2016-04-06 10:17:21  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Power</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.0</td>\n",
       "      <td>354369.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4416.656776</td>\n",
       "      <td>2004.234448</td>\n",
       "      <td>110.094337</td>\n",
       "      <td>128211.172535</td>\n",
       "      <td>5.714645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50508.689087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4514.158514</td>\n",
       "      <td>90.227958</td>\n",
       "      <td>189.850405</td>\n",
       "      <td>37905.341530</td>\n",
       "      <td>3.726421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25783.096248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1067.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>125000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30165.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2700.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49413.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6400.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99998.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Price  RegistrationYear          Power      Kilometer  \\\n",
       "count  354369.000000     354369.000000  354369.000000  354369.000000   \n",
       "mean     4416.656776       2004.234448     110.094337  128211.172535   \n",
       "std      4514.158514         90.227958     189.850405   37905.341530   \n",
       "min         0.000000       1000.000000       0.000000    5000.000000   \n",
       "25%      1050.000000       1999.000000      69.000000  125000.000000   \n",
       "50%      2700.000000       2003.000000     105.000000  150000.000000   \n",
       "75%      6400.000000       2008.000000     143.000000  150000.000000   \n",
       "max     20000.000000       9999.000000   20000.000000  150000.000000   \n",
       "\n",
       "       RegistrationMonth  NumberOfPictures     PostalCode  \n",
       "count      354369.000000          354369.0  354369.000000  \n",
       "mean            5.714645               0.0   50508.689087  \n",
       "std             3.726421               0.0   25783.096248  \n",
       "min             0.000000               0.0    1067.000000  \n",
       "25%             3.000000               0.0   30165.000000  \n",
       "50%             6.000000               0.0   49413.000000  \n",
       "75%             9.000000               0.0   71083.000000  \n",
       "max            12.000000               0.0   99998.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут можно заметить странное, что в колонке \"год регистрации автомобиля\" есть 1000 и 9999. Скорее всего это аномальное значения. Также в данный момент не существуют машин, у которых мощностей двигателя больше 143 л.с. А также странно получилось, что машина выставлена в продажах бесплатно. Ну, может быть они хотят быстрее избавиться от них, а может \"ради прикола\" выставили в продажах, но все равно устраняем их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Стоимость ЕВРО')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1700x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(17, 10))\n",
    "\n",
    "axs[0].boxplot(df['RegistrationYear'])\n",
    "axs[0].set_title('RegistrationYear')\n",
    "axs[0].set_ylabel('Год')\n",
    "        \n",
    "axs[1].boxplot(df['Power'])\n",
    "axs[1].set_title('Power')\n",
    "axs[1].set_ylabel('Мощность л.с')\n",
    "\n",
    "axs[2].boxplot(df['Price'])\n",
    "axs[2].set_title('Price')\n",
    "axs[2].set_ylabel('Стоимость ЕВРО')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заполним пропущенные значения и обработаем аномалии в столбцах. Если среди признаков имеются неинформативные, то удалим их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скорпируем\n",
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем аномальные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-04-07 14:36:58'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Смотрим дату скачивания анкеты из базы и год регистрации автомобиля, \n",
    "# т.к. год регистрации автомобиля не должен позже дату скачивания анкеты\n",
    "df_clean['DateCrawled'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очистим\n",
    "# Год регистрации автомобиля\n",
    "df_clean = df_clean[df_clean['RegistrationYear'] > (df_clean.describe()['RegistrationYear']['50%'] - df_clean.describe()['RegistrationYear']['std'])]\n",
    "df_clean = df_clean[df_clean['RegistrationYear'] < 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мощность двигателя л.с\n",
    "df_clean = df_clean[df_clean['Power'] > 5]\n",
    "\n",
    "# В 2016 году шведский суперкар с названием Koenigsegg Regera имеет 1800 л.с. и двигатель у него является самым мощным в мире\n",
    "df_clean = df_clean[df_clean['Power'] < 1800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Бесплатных автомобилей устраняем \n",
    "df_clean = df_clean[df_clean['Price'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Repaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>2016-03-23 17:30:02</td>\n",
       "      <td>2</td>\n",
       "      <td>sedan</td>\n",
       "      <td>2002</td>\n",
       "      <td>auto</td>\n",
       "      <td>272</td>\n",
       "      <td>7er</td>\n",
       "      <td>5000</td>\n",
       "      <td>9</td>\n",
       "      <td>petrol</td>\n",
       "      <td>bmw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-23 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>65183</td>\n",
       "      <td>2016-03-24 21:28:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "3742  2016-03-23 17:30:02      2       sedan              2002    auto    272   \n",
       "\n",
       "     Model  Kilometer  RegistrationMonth FuelType Brand Repaired  \\\n",
       "3742   7er       5000                  9   petrol   bmw      NaN   \n",
       "\n",
       "              DateCreated  NumberOfPictures  PostalCode             LastSeen  \n",
       "3742  2016-03-23 00:00:00                 0       65183  2016-03-24 21:28:34  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Здесь можно заметить, что продается БМВ со стоимостью 2 евро)\n",
    "df_clean[df_clean.index==3742]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Power</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>295937.000000</td>\n",
       "      <td>295937.000000</td>\n",
       "      <td>295937.000000</td>\n",
       "      <td>295937.000000</td>\n",
       "      <td>295937.000000</td>\n",
       "      <td>295937.0</td>\n",
       "      <td>295937.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4865.070944</td>\n",
       "      <td>2002.823043</td>\n",
       "      <td>121.330158</td>\n",
       "      <td>128300.280127</td>\n",
       "      <td>5.996080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51241.180390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4611.936652</td>\n",
       "      <td>6.536964</td>\n",
       "      <td>60.845880</td>\n",
       "      <td>36737.164496</td>\n",
       "      <td>3.582654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25782.523619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1923.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1067.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1350.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>125000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30926.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3200.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50259.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6999.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>1799.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99998.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Price  RegistrationYear          Power      Kilometer  \\\n",
       "count  295937.000000     295937.000000  295937.000000  295937.000000   \n",
       "mean     4865.070944       2002.823043     121.330158  128300.280127   \n",
       "std      4611.936652          6.536964      60.845880   36737.164496   \n",
       "min         2.000000       1923.000000       6.000000    5000.000000   \n",
       "25%      1350.000000       1999.000000      75.000000  125000.000000   \n",
       "50%      3200.000000       2003.000000     111.000000  150000.000000   \n",
       "75%      6999.000000       2007.000000     150.000000  150000.000000   \n",
       "max     20000.000000       2016.000000    1799.000000  150000.000000   \n",
       "\n",
       "       RegistrationMonth  NumberOfPictures     PostalCode  \n",
       "count      295937.000000          295937.0  295937.000000  \n",
       "mean            5.996080               0.0   51241.180390  \n",
       "std             3.582654               0.0   25782.523619  \n",
       "min             0.000000               0.0    1067.000000  \n",
       "25%             3.000000               0.0   30926.000000  \n",
       "50%             6.000000               0.0   50259.000000  \n",
       "75%             9.000000               0.0   72108.000000  \n",
       "max            12.000000               0.0   99998.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Стоимость ЕВРО')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABXoAAANECAYAAAAOlpfmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADwF0lEQVR4nOzdeVhV9dr/8c9mI4MDKCqCikpoajmkaCKGQXocMzlo5lDHSsNMLYfI6JRpg3gc8+SU52Q2OJSE2OOUOJCUWDmQYs5BmgKaJjigIOzfH/5Yxx045ZYt8H5d17qetb7fe691L56rs/Dmu+9lslgsFgEAAAAAAAAASiwHeycAAAAAAAAAALg9FHoBAAAAAAAAoISj0AsAAAAAAAAAJRyFXgAAAAAAAAAo4Sj0AgAAAAAAAEAJR6EXAAAAAAAAAEo4Cr0AAAAAAAAAUMJR6AUAAAAAAACAEo5CLwAAAAAAAACUcBR6gbtccHCwgoOD7Z3GTVm4cKFMJpNSU1PtnQoAAAAAoAR7+umnVa9ePXunAZQoFHqBm1BQwCzYHB0dVatWLT399NM6duyYvdMrZMuWLRo/frzOnDlzR84/ceJExcbG3pFzX8+kSZNkMpn09ddfFznfrVs3ubu76/jx48WcGQCgNPjz897FxUX33nuvhg8froyMDHunBwBAicJzFSh+JovFYrF3EsDdbuHChXrmmWf01ltvydfXVxcvXtTWrVu1cOFC1atXT8nJyXJxcbkj187JyZEkOTk53fRnpk6dqoiICKWkpNyRv4BWrFhRvXv31sKFC63G8/LylJubK2dnZ5lMJptfNzc3V/7+/jp//rySk5Pl6upqzC1btkx9+vTR7Nmz9cILL9j82gCA0q+o5/23336rTz/9VHXr1lVycrLKly9v7zQBACgRbve5mpubq/z8fDk7Oxdj1kDJ5mjvBICSpGvXrmrVqpUkafDgwapWrZr+9a9/6auvvlKfPn3uyDVvpcD7V+Tn5ysnJ8cmhWqz2Syz2WyDrIpWrlw5zZ8/X+3atdPbb7+tiRMnSpLOnj2rkSNHKiAgQM8///wdu34BW/7MAAB3nz8/76tWrarp06drxYoV6tevn52zKxrPJgDA3epWn6vnz59XhQoVVK5cueJOFSjxaN0A3IagoCBJ0uHDh42xffv2qXfv3vLw8JCLi4tatWqlr776qtBnd+3apYcffliurq6qXbu23nnnHX300UeFetwW1aP3/fff1/3336/y5curSpUqatWqlRYvXixJGj9+vCIiIiRJvr6+xtdkCs5pMpk0fPhwLVq0SPfff7+cnZ21du1aSVdWAgcGBqpq1apydXWVv7+/oqOjra5tMpl0/vx5ffzxx8a5n376aUnX7tE7Z84c41o1a9bUsGHDCrWVCA4OVpMmTfTzzz8rJCRE5cuXV61atTR58mSruIJi7tSpU/Xzzz9Lkl5//XWdOHFC8+fPl4ODg86cOaORI0fKx8dHzs7Oql+/vv71r38pPz/f6lw3c783+pkBAEq/Rx55RJKUkpKiy5cv6+2335afn5+cnZ1Vr149vfbaa7p06ZIRP3r0aFWtWlVXf3FuxIgRMplM+ve//22MZWRkyGQyae7cucbYpUuX9Oabb6p+/fpydnaWj4+PXnnlFavzSzybAAAl19XP1aeffloVK1bU4cOH1a1bN1WqVEkDBgyQVHSP3vz8fM2cOVNNmzaVi4uLqlevri5dumjbtm1WcZ999pn8/f3l6uoqDw8P9e3bV0ePHi2W+wPsiRW9wG0oKGhWqVJFkrRnzx61a9dOtWrV0quvvqoKFSroiy++UGhoqL788kv9/e9/lyQdO3ZMISEhMplMioyMVIUKFfTf//73pr6S8p///EcvvviievfurZdeekkXL17Url279P3336t///4KCwvTgQMHtGTJEs2YMUPVqlWTJFWvXt04x8aNG/XFF19o+PDhqlatmvHwnDlzph577DENGDBAOTk5Wrp0qR5//HGtXLlS3bt3lyR9+umnGjx4sB588EGFh4dLkvz8/K6Z7/jx4zVhwgR17NhRQ4cO1f79+zV37lz9+OOP+u6776z+SvvHH3+oS5cuCgsLU58+fRQdHa2xY8eqadOm6tq1qxEXFRWl2NhYDRkyRO+9955mz56tiIgINW3aVBcuXNDDDz+sY8eOaciQIapTp462bNmiyMhIpaWl6b333jPOczP3e6OfGQCg9Cv4g27VqlU1ePBgffzxx+rdu7fGjBmj77//XlFRUdq7d6+WL18u6cofgmfMmKE9e/aoSZMmkqSEhAQ5ODgoISFBL774ojEmSe3bt5d05R+vjz32mL799luFh4ercePG2r17t2bMmKEDBw4U6o/PswkAUBJd/VyVpMuXL6tz58566KGHNHXq1Ou2cxg0aJAWLlyorl27avDgwbp8+bISEhK0detWY9Xwu+++qzfeeEN9+vTR4MGDdfLkSb3//vtq3769du7cqcqVK9/xewTsxgLghj766COLJMv69estJ0+etBw9etQSHR1tqV69usXZ2dly9OhRi8VisXTo0MHStGlTy8WLF43P5ufnWwIDAy0NGjQwxkaMGGExmUyWnTt3GmOnTp2yeHh4WCRZUlJSjPGHH37Y8vDDDxvHPXv2tNx///3XzXfKlCmFzlNAksXBwcGyZ8+eQnMXLlywOs7JybE0adLE8sgjj1iNV6hQwTJw4MBCny/4ORVc98SJExYnJydLp06dLHl5eUbcrFmzLJIsCxYssLpPSZZPPvnEGLt06ZLFy8vL0qtXr0LXio6OtkiyeHh4WO655x4j97fffttSoUIFy4EDB6ziX331VYvZbLYcOXLklu/3ej8zAEDpUdTzfunSpZaqVataXF1dLfHx8RZJlsGDB1t97uWXX7ZIsmzcuNFisVx5/kmyzJkzx2KxWCxnzpyxODg4WB5//HFLjRo1jM+9+OKLFg8PD0t+fr7FYrFYPv30U4uDg4MlISHB6vzz5s2zSLJ89913xhjPJgDA3e5Gz9XffvvNMnDgQIsky6uvvlro8wMHDrTUrVvXON64caNFkuXFF18sFFvwLE1NTbWYzWbLu+++azW/e/dui6OjY6FxoLShdQNwCzp27Kjq1avLx8dHvXv3VoUKFfTVV1+pdu3aOn36tDZu3Kg+ffro7Nmz+v333/X777/r1KlT6ty5sw4ePKhjx45JktauXau2bdvqgQceMM7t4eFhfEXleipXrqzffvtNP/7441++j4cfflj33XdfofGrX272xx9/KDMzU0FBQdqxY8dfus769euVk5OjkSNHysHhf/9z89xzz8nNzU2rVq2yiq9YsaKefPJJ49jJyUkPPvigfvnll0Ln7tWrl7p166bTp09r9uzZRu7Lli1TUFCQqlSpYvz/4Pfff1fHjh2Vl5enzZs3/6X7vdbPDABQ+lz9vO/bt68qVqyo5cuXa8uWLZKutGa42pgxYyTJeK5Vr15djRo1Mp453333ncxmsyIiIpSRkaGDBw9KurKi96GHHjJeYLps2TI1btxYjRo1snqGFXzFddOmTVbX5dkEACgJrvVcrVWrlhEzdOjQG57nyy+/lMlk0ptvvlloruBZGhMTo/z8fPXp08fqWerl5aUGDRoUepYCpQ2tG4BbMHv2bN17773KzMzUggULtHnzZqPdwqFDh2SxWPTGG2/ojTfeKPLzJ06cUK1atfTrr7+qbdu2hebr169/wxzGjh2r9evX68EHH1T9+vXVqVMn9e/fX+3atbvp+/D19S1yfOXKlXrnnXeUlJRk1Quw4KF5q3799VdJUsOGDa3GnZycdM899xjzBWrXrl3oWlWqVNGuXbuKPH/r1q21evVq4ys6knTw4EHt2rXLqlXF1U6cOGHs38r9XutnBgAofQqe946OjqpRo4YaNmwoBwcHLV++XA4ODoWe115eXqpcubLVcy0oKEirV6+WdKWg26pVK7Vq1UoeHh5KSEhQjRo19NNPP6l///7GZw4ePKi9e/fe1DNM4tkEACgZrvVcLeDo6KjatWvf8DyHDx9WzZo15eHhcc2YgwcPymKxqEGDBkXO84I3lHYUeoFb8OCDDxpFxdDQUD300EPq37+/9u/fb7zo6+WXX1bnzp2L/PzNFHJvpHHjxtq/f79WrlyptWvX6ssvv9ScOXM0btw4TZgw4abOcfVK1gIJCQl67LHH1L59e82ZM0fe3t4qV66cPvroI+NFb3ea2Wwuctxy1ctsbiQ/P19/+9vf9MorrxQ5f++990q69fst6mcGACidrn7eF+Vm/gD60EMP6T//+Y9++eUXJSQkKCgoSCaTSQ899JASEhJUs2ZN5efnGy92la48w5o2barp06cXeU4fHx+rY55NAICS4EbPVWdnZ6vC7+3Iz8+XyWTSmjVrivz3ZcWKFW1yHeBuRaEX+IvMZrOioqIUEhKiWbNm6dlnn5V05S+EHTt2vO5n69atq0OHDhUaL2qsKBUqVNATTzyhJ554Qjk5OQoLC9O7776ryMhIubi4/KUVuF9++aVcXFz09ddfW70U7qOPPioUe7Pnr1u3riRp//79uueee4zxnJwcpaSk3PDn9Ff4+fnp3LlzNzz3rdwvAADSledafn6+Dh48qMaNGxvjGRkZOnPmjPHck2QUcOPi4vTjjz/q1VdflXTlxWtz585VzZo1VaFCBfn7+xuf8fPz008//aQOHTr85W/TAABQWvn5+enrr7/W6dOnr7mq18/PTxaLRb6+vsYiH6AsoUcvcBuCg4P14IMP6r333pObm5uCg4P1wQcfKC0trVDsyZMnjf3OnTsrMTFRSUlJxtjp06e1aNGiG17z1KlTVsdOTk667777ZLFYlJubK+lKIViSzpw5c9P3YjabZTKZlJeXZ4ylpqYWesN3wflv5twdO3aUk5OT/v3vf1utyv3www+VmZmp7t2733R+N6tPnz5KTEzU119/XWjuzJkzunz5sqRbu18AACSpW7dukqT33nvParxgBe7VzzVfX1/VqlVLM2bMUG5urtFiKSgoSIcPH1Z0dLQCAgLk6Pi/dRd9+vTRsWPH9J///KfQtbOzs3X+/Hlb3xIAACVGr169ZLFYivwma8G/N8PCwmQ2mzVhwoRC3wy1WCyF/j0NlDas6AVuU0REhB5//HEtXLhQs2fP1kMPPaSmTZvqueee0z333KOMjAwlJibqt99+008//SRJeuWVV/TZZ5/pb3/7m0aMGKEKFSrov//9r+rUqaPTp09fdxVPp06d5OXlpXbt2qlGjRrau3evZs2ape7du6tSpUqSZKwO+uc//6m+ffuqXLly6tGjh1EALkr37t01ffp0denSRf3799eJEyc0e/Zs1a9fv1CPXH9/f61fv17Tp09XzZo15evrqzZt2hQ6Z/Xq1RUZGakJEyaoS5cueuyxx7R//37NmTNHrVu3tnrxmq1EREToq6++0qOPPqqnn35a/v7+On/+vHbv3q3o6GilpqaqWrVqt3S/AABIUvPmzTVw4EDNnz9fZ86c0cMPP6wffvhBH3/8sUJDQxUSEmIVHxQUpKVLl6pp06aqUqWKJKlly5aqUKGCDhw4YNWfV5KeeuopffHFF3r++ee1adMmtWvXTnl5edq3b5+++OILff3119f96isAAKVZSEiInnrqKf373//WwYMH1aVLF+Xn5yshIUEhISEaPny4/Pz89M477ygyMlKpqakKDQ1VpUqVlJKSouXLlys8PFwvv/yyvW8FuGMo9AK3KSwsTH5+fpo6daqee+45bdu2TRMmTNDChQt16tQpeXp6qkWLFho3bpzxGR8fH23atEkvvviiJk6cqOrVq2vYsGGqUKGCXnzxRbm4uFzzekOGDNGiRYs0ffp0nTt3TrVr19aLL76o119/3Yhp3bq13n77bc2bN09r165Vfn6+UlJSrlvofeSRR/Thhx9q0qRJGjlypHx9ffWvf/1LqamphQqf06dPV3h4uF5//XVlZ2dr4MCBRRZ6JWn8+PGqXr26Zs2apVGjRsnDw0Ph4eGaOHHiHWmEX758eX3zzTeaOHGili1bpk8++URubm669957NWHCBLm7u9/y/QIAUOC///2v7rnnHi1cuFDLly+Xl5eXIiMji3wDeEGh96GHHjLGHB0d1bZtW61fv96qP68kOTg4KDY2VjNmzNAnn3yi5cuXq3z58rrnnnv00ksv8RVUAECZ99FHH6lZs2b68MMPFRERIXd3d7Vq1UqBgYFGzKuvvqp7771XM2bMMFb/+vj4qFOnTnrsscfslTpQLEyWW3nLEYA7auTIkfrggw907ty5a76YDAAAAAAAAPgzevQCdpKdnW11fOrUKX366ad66KGHKPICAAAAAADgltC6AbCTtm3bKjg4WI0bN1ZGRoY+/PBDZWVl6Y033rB3agAAAAAAAChhKPQCdtKtWzdFR0dr/vz5MplMatmypT788EO1b9/e3qkBAAAAAACghKFHLwAAAAAAAACUcPToBQAAAAAAAIASjkIvAAAAAAAAAJRw9Oi9Sfn5+Tp+/LgqVaokk8lk73QAAHZgsVh09uxZ1axZUw4O/K30ZvEMBQDwDP1reIYCAG7lGUqh9yYdP35cPj4+9k4DAHAXOHr0qGrXrm3vNEoMnqEAgAI8Q28Nz1AAQIGbeYbatdAbFRWlmJgY7du3T66urgoMDNS//vUvNWzY0Ii5ePGixowZo6VLl+rSpUvq3Lmz5syZoxo1akiSfvrpJ02aNEnffvutfv/9d9WrV0/PP/+8XnrpJatrxcfHa/To0dqzZ498fHz0+uuv6+mnn77pXCtVqiTpyg/Vzc3t9m8eAFDiZGVlycfHx3gm4ObwDAUA8Az9a3iGAgBu5Rlq10LvN998o2HDhql169a6fPmyXnvtNXXq1Ek///yzKlSoIEkaNWqUVq1apWXLlsnd3V3Dhw9XWFiYvvvuO0nS9u3b5enpqc8++0w+Pj7asmWLwsPDZTabNXz4cElSSkqKunfvrueff16LFi3Shg0bNHjwYHl7e6tz5843lWvB12Tc3Nx4wAJAGcdXJ28Nz1AAQAGeobeGZygAoMDNPENNFovFUgy53JSTJ0/K09NT33zzjdq3b6/MzExVr15dixcvVu/evSVJ+/btU+PGjZWYmKiAgIAizzNs2DDt3btXGzdulCSNHTtWq1atUnJyshHTt29fnTlzRmvXrr2p3LKysuTu7q7MzEwesABQRvEs+Gv4uQEAeBb8NfzcAAC38iy4q7rgZ2ZmSpI8PDwkXVmtm5ubq44dOxoxjRo1Up06dZSYmHjd8xScQ5ISExOtziFJnTt3vu45Ll26pKysLKsNAAAAAAAAAO5Gd02hNz8/XyNHjlS7du3UpEkTSVJ6erqcnJxUuXJlq9gaNWooPT29yPNs2bJFn3/+ucLDw42x9PR0o6fv1efIyspSdnZ2keeJioqSu7u7sdEAHwAAAAAAAMDd6q4p9A4bNkzJyclaunTpXz5HcnKyevbsqTfffFOdOnW6rXwiIyOVmZlpbEePHr2t8wEAAAAAAADAnWLXl7EVGD58uFauXKnNmzerdu3axriXl5dycnJ05swZq1W9GRkZ8vLysjrHzz//rA4dOig8PFyvv/661ZyXl5cyMjKsxjIyMuTm5iZXV9cic3J2dpazs/Nt3hkAAAAAAAAA3Hl2XdFrsVg0fPhwLV++XBs3bpSvr6/VvL+/v8qVK6cNGzYYY/v379eRI0fUtm1bY2zPnj0KCQnRwIED9e677xa6Ttu2ba3OIUlxcXFW5wAAAAAAAACAksquK3qHDRumxYsXa8WKFapUqZLRd9fd3V2urq5yd3fXoEGDNHr0aHl4eMjNzU0jRoxQ27ZtFRAQIOlKu4ZHHnlEnTt31ujRo41zmM1mVa9eXZL0/PPPa9asWXrllVf07LPPauPGjfriiy+0atUq+9w4AAAAAAAAANiQXVf0zp07V5mZmQoODpa3t7exff7550bMjBkz9Oijj6pXr15q3769vLy8FBMTY8xHR0fr5MmT+uyzz6zO0bp1ayPG19dXq1atUlxcnJo3b65p06bpv//9rzp37lys9wsAAAAAAAAAd4LJYrFY7J1ESZCVlSV3d3dlZmbKzc3N3ukAAOyAZ8Ffw88NAMCz4K/h5wYAuJVngV1X9AIAAAAAAAAAbh+FXgAAAAAAAAAo4Sj0AgAAAAAAAEAJR6EXAAAAAAAAAEo4Cr0AAAAAAAAAUMJR6AUAAAAAAACAEo5CLwAAAAAAAACUcBR6AQAAAAAAAKCEo9ALAAAAAAAAACUchV4AAAAAAAAAKOEo9AIAAAAAAABACUehFwAAAAAAAABKOAq9AAAAAAAAAFDCUegFAAAAAAAAgBKOQi8AAAAAAAAAlHAUegEAAAAAAACghKPQCwAAAAAAAAAlHIVeAAAAAAAAACjhHO2dAAAAAFBa5eXlKSEhQWlpafL29lZQUJDMZrO90wIA4K5nMpkKjVksFjtkApQcrOgFAAAA7oCYmBjVr19fISEh6t+/v0JCQlS/fn3FxMTYOzWg1IqKilLr1q1VqVIleXp6KjQ0VPv377eKuXjxooYNG6aqVauqYsWK6tWrlzIyMqxijhw5ou7du6t8+fLy9PRURESELl++bBUTHx+vli1bytnZWfXr19fChQsL5TN79mzVq1dPLi4uatOmjX744Qeb3zNQGhVV5L3eOIArKPQCAAAANhYTE6PevXsXKh5lZGSod+/eFHuBO+Sbb77RsGHDtHXrVsXFxSk3N1edOnXS+fPnjZhRo0bp//7v/7Rs2TJ98803On78uMLCwoz5vLw8de/eXTk5OdqyZYs+/vhjLVy4UOPGjTNiUlJS1L17d4WEhCgpKUkjR47U4MGD9fXXXxsxn3/+uUaPHq0333xTO3bsUPPmzdW5c2edOHGieH4YQAl1o2IuxV7g2kwW1r3flKysLLm7uyszM1Nubm72TgcAYAc8C/4afm4oa/Ly8lSzZk2dOHFC3bt3V7du3eTq6qrs7GytXr1aq1atkqenp44fP04bB5QZ9noWnDx5Up6envrmm2/Uvn17ZWZmqnr16lq8eLF69+4tSdq3b58aN26sxMREBQQEaM2aNXr00Ud1/Phx1ahRQ5I0b948jR07VidPnpSTk5PGjh2rVatWKTk52bhW3759debMGa1du1aS1KZNG7Vu3VqzZs2SJOXn58vHx0cjRozQq6++elP58wxFWXMrRVzKWSgrbuVZQI9eoIy5cOGC9u3bd8ufy87OVmpqqurVqydXV9e/dO1GjRqpfPnyf+mzAACUFPHx8Tpx4oQaNWqkPXv2aNWqVcZcvXr11KhRI+3bt0/x8fHq0KGDHTMFSr/MzExJkoeHhyRp+/btys3NVceOHY2YRo0aqU6dOkahNzExUU2bNjWKvJLUuXNnDR06VHv27FGLFi2UmJhodY6CmJEjR0qScnJytH37dkVGRhrzDg4O6tixoxITE6+Z76VLl3Tp0iXjOCsr66/fPACgzKHQC5Qx+/btk7+/v12uvX37drVs2dIu1wYAoLjEx8dLuvLM7dGjh5YsWaImTZooOTlZEydO1P/93/8ZcRR6gTsnPz9fI0eOVLt27dSkSRNJUnp6upycnFS5cmWr2Bo1aig9Pd2IubrIWzBfMHe9mKysLGVnZ+uPP/5QXl5ekTHXW3QRFRWlCRMm3PrNAgAgCr1AmdOoUSNt3779lj+3d+9ePfnkk/rss8/UuHHjv3xtAABKu/z8fElSQECAYmNj5eDgYHXcrl07bd261YgDcGcMGzZMycnJ+vbbb+2dyk2LjIzU6NGjjeOsrCz5+PjYMSMAQElCoRcoY8qXL39bq2obN27MqlwAAK6jatWqkq60PcrOztbYsWN18OBBNWjQQP/617904cIFqzgAtjd8+HCtXLlSmzdvVu3atY1xLy8v5eTk6MyZM1arejMyMuTl5WXE/PDDD1bnK3ix4tUxRb1s0c3NTa6urjKbzTKbzUXGFJyjKM7OznJ2dr71GwYAQJKDvRMAAAAASpOCr2r/9NNPqlixombPnq1169Zp9uzZqlixonbt2mUVB8B2LBaLhg8fruXLl2vjxo3y9fW1mvf391e5cuW0YcMGY2z//v06cuSI2rZtK0lq27atdu/erRMnThgxcXFxcnNz03333WfEXH2OgpiCczg5Ocnf398qJj8/Xxs2bDBiAACwNVb0AgAAADZUq1Ytm8YBuHnDhg3T4sWLtWLFClWqVMnoqevu7i5XV1e5u7tr0KBBGj16tDw8POTm5qYRI0aobdu2CggIkCR16tRJ9913n5566ilNnjxZ6enpev311zVs2DBjte3zzz+vWbNm6ZVXXtGzzz6rjRs36osvvrB6+eLo0aM1cOBAtWrVSg8++KDee+89nT9/Xs8880zx/2AAAGUChV4AAADAhlq1amXTOAA3b+7cuZKk4OBgq/GPPvpITz/9tCRpxowZcnBwUK9evXTp0iV17txZc+bMMWLNZrNWrlypoUOHqm3btqpQoYIGDhyot956y4jx9fXVqlWrNGrUKM2cOVO1a9fWf//7X3Xu3NmIeeKJJ3Ty5EmNGzdO6enpeuCBB7R27VpW8wMA7hiTxWKx2DuJkiArK0vu7u7KzMyUm5ubvdMBit2OHTvk7++v7du306MXZRbPgr+GnxvKmiFDhmj+/PmSpK5du+ree+9Vdna2XF1ddeDAAa1Zs0aSFB4erg8++MCeqQLFhmfBX8PPDWWNyWS66VjKWSgrbuVZwIpeAAAAwIZWr14tSWrWrJni4uKMwq4kOTo6qmnTptq9e7cRBwAAANgChV4AAADgDti1a5ceffRRde3aVa6ursrOztaaNWu0cuVKe6cGAACAUohCLwAAAGBDnTt31ocffihJWrZsmVxcXIy5Z599Vq6urkYcAAAAYCsO9k4AAAAAKE0ef/xxY9/d3V1jx47VgQMHNHbsWLm7uxcZBwAAANwuVvQCAAAANnT69GljPycnR5MnT9bkyZOvGwcAAADcLlb0AgAAADbk7e0tSQoKCipyvmC8IA4AAACwBQq9AAAAgA0FBQWpXr16qly5sk6fPq127drJx8dH7dq10+nTp1W5cmX5+vpesxAMAAAA/BW0bgAAAABsyGw2a9q0aerVq5eqVq0qi8UiSTp69Khx/OWXX8psNts5UwAAAJQmrOgFAKAE2rx5s3r06KGaNWvKZDIpNjbWat5kMhW5TZkyxYipV69eoflJkyZZnWfXrl0KCgqSi4uLfHx8iuwzCqCwrVu3Srry3+LVHBwcrOYBAAAAW6HQCwBACXT+/Hk1b95cs2fPLnI+LS3NaluwYIFMJpN69eplFffWW29ZxY0YMcKYy8rKUqdOnVS3bl1t375dU6ZM0fjx4zV//vw7em9ASZeTk6MZM2aoRo0aunDhgjZt2qTFixdr06ZNOn/+vGrUqKEZM2YoJyfH3qkCAACgFKF1AwAAJVDXrl3VtWvXa857eXlZHa9YsUIhISG65557rMYrVapUKLbAokWLlJOTowULFsjJyUn333+/kpKSNH36dIWHh9/+TQCl1Jw5c3T58mW98847cnZ2VnBwsNX8W2+9pSFDhmjOnDkaOXKkXXIEAABA6cOKXgAASrmMjAytWrVKgwYNKjQ3adIkVa1aVS1atNCUKVN0+fJlYy4xMVHt27eXk5OTMda5c2ft379ff/zxxzWvd+nSJWVlZVltQFly+PBhSdKjjz5a5HzBeEEcAAAAYAsUegEAKOU+/vhjVapUSWFhYVbjL774opYuXapNmzZpyJAhmjhxol555RVjPj09XTVq1LD6TMFxenr6Na8XFRUld3d3Y/Px8bHh3QB3Pz8/P0nSypUri5wvGC+IAwAAAGyBQi8AAKXcggULNGDAALm4uFiNjx49WsHBwWrWrJmef/55TZs2Te+//74uXbp0W9eLjIxUZmamsR09evS2zgeUNC+88IIcHR31+uuvW62Sl6TLly9r3LhxcnR01AsvvGCnDAEAAFAaUegFAKAUS0hI0P79+zV48OAbxrZp00aXL19WamqqpCt9fjMyMqxiCo6v1ddXkpydneXm5ma1AWWJk5OTRo0apYyMDNWuXVvz58/X8ePHNX/+fNWuXVsZGRkaNWqUVVsUAAAA4HbxMjYAAEqxDz/8UP7+/mrevPkNY5OSkuTg4CBPT09JUtu2bfXPf/5Tubm5KleunCQpLi5ODRs2VJUqVe5o3kBJN3nyZEnSjBkzNGTIEGPc0dFRERERxjwAAABgKxR6AQAogc6dO6dDhw4ZxykpKUpKSpKHh4fq1KkjScrKytKyZcs0bdq0Qp9PTEzU999/r5CQEFWqVEmJiYkaNWqUnnzySaOI279/f02YMEGDBg3S2LFjlZycrJkzZ2rGjBnFc5NACTd58mS98847mjNnjg4fPiw/Pz+98MILrOQFAADAHUGhFwCAEmjbtm0KCQkxjkePHi1JGjhwoBYuXChJWrp0qSwWi/r161fo887Ozlq6dKnGjx+vS5cuydfXV6NGjTLOI0nu7u5at26dhg0bJn9/f1WrVk3jxo1TeHj4nb05oBRxcnLSyJEj7Z0GAAAAygAKvQAAlEDBwcGyWCzXjQkPD79mUbZly5baunXrDa/TrFkzJSQk/KUcAQAAAADFh5exAQAAAAAAAEAJR6EXAAAAAAAAAEo4Cr0AAAAAAAAAUMJR6AUAAAAAAACAEo5CLwAAAAAAAACUcI72TgAAAAAorfLy8pSQkKC0tDR5e3srKChIZrPZ3mkBAACgFGJFLwAAAHAHxMTEqH79+goJCVH//v0VEhKi+vXrKyYmxt6pAQAAoBSi0AsAAADYWExMjHr37q2MjAyr8YyMDPXu3ZtiLwAAAGyOQi8AAABgQ3l5eRo6dKgsFovy8vIKzVksFg0dOrTQHAAAAHA7KPQCAAAANhQfH68TJ05IknJzc63mCo5PnDih+Pj44k4NAAAApRiFXgAAAMCGNm7caOx7enrqP//5j9LS0vSf//xHnp6eRcYBAAAAt8vR3gkAAAAApUlKSookqVKlSvrtt9/k6HjlV+7Bgwfr6aefloeHh86ePWvEAQAAALZAoRcAAACwoYK2DdWrV5fFYlF8fLzS0tLk7e2tdu3aqXr16jp79qwRBwAAANgChV4AAADAhipWrChJ+uWXX+Tu7q7s7GxjztXV1TguiAMAAABsgR69AAAAgA0FBQUZ+5cuXbKay8nJKTIOAAAAuF0UegEAAAAbeuGFF4x9s9lsNXf18dVxAAAAwO2i0AsAAADY0Pfff2/s5+XlWc1dfXx1HAAAAHC7KPQCAAAANpSWliZJeumll+TgYP3rtslk0ksvvWQVBwAAANgChV4AAADAhry9vSVJffv21fnz5zVjxgwNHz5cM2bM0Pnz5/XEE09YxQEAAAC24GjvBAAAAIDSJCgoSPXq1dPEiRMVGxurkSNHGnP5+fmKioqSr68vL2MDAACATbGiFwAAALAhs9msadOmaeXKlQoNDVViYqLOnj2rxMREhYaGauXKlZo6dWqhF7UBAAAAt4MVvQAAAICNhYWFKTo6WmPGjFFgYKAx7uvrq+joaIWFhdkxOwAAAJRGFHoBAACAOyAsLEw9e/ZUQkKC0tLS5O3traCgIFbyAgAA4I6g0AsAAADcIWazWcHBwfZOAwAAAGUAhV4AAADgDsnLy2NFLwAAAIoFL2MDAAAA7oCYmBjVr19fISEh6t+/v0JCQlS/fn3FxMTYOzUAAACUQqzoBQAAAGwsJiZGvXv3Vvfu3RURESFXV1dlZ2drzZo16t27Ny9kAwAAgM1R6AUAAABsKC8vT2PGjJG/v7+Sk5O1cuVKY65evXry9/fXyy+/rJ49e9LGAQAAADZD6wYAAADAhhISEpSamqrt27eradOmSkxM1NmzZ5WYmKimTZtq+/btSklJUUJCgr1TBQAAQClCoRcAAACwoWPHjkmSunTpotjYWAUEBKhixYoKCAhQbGysunTpYhUHAAAA2AKFXgAAAMCGTp48KUkKCwuTg4P1r9sODg4KDQ21igMAAABsgUIvAAAAYEPVq1eXdOWFbPn5+VZz+fn5io2NtYoDAAAAbIFCLwAAAGBDtWrVkiStWbNGoaGhVj16Q0NDtWbNGqs4AAAAwBYc7Z0AAAAAUJoEBQWpXr16qlatmnbt2qXAwEBjrl69emrVqpVOnTqloKAgO2YJAACA0oZCLwAAAGBDZrNZ06ZNU+/evdW9e3dFRETI1dVV2dnZWrt2rVatWqXo6GiZzWZ7pwoAAIBShEIvAAAAYGNhYWGKjo7W6NGjtXLlSmO8Xr16io6OVlhYmB2zAwAAQGlEj14AAADgDjGZTPZOAQAAAGUEK3oBAAAAG4uJiSmydcOaNWvUu3dvVvUCAADA5ij0AgAAADaUl5enMWPGyN/fX7t377Zq3VC3bl35+/vr5ZdfVs+ePenTCwAAAJuhdQMAAABgQwkJCUpNTdW2bdvUrFkzJSYm6uzZs0pMTFSzZs20bds2paSkKCEhwd6pAgAAoBSh0AsAAADY0LFjxyRJXbt2VWxsrAICAlSxYkUFBAQoNjZWXbt2tYoDAAAAbIHWDUAJdfDgQZ09e7bYrrd3716r/1tcKlWqpAYNGhTrNQEAuB0nT56UJIWFhcnBwXpdhYODg0JDQ7VmzRojDgAAALAFCr1ACXTw4EHde++9drn2k08+WezXPHDgAMVeAECJUb16dUlXXsj27LPPWhV78/PzFRsbaxUHAAAA2AKFXqAEKljJ+9lnn6lx48bFcs3s7GylpqaqXr16cnV1LZZr7t27V08++WSxrlwGAOB21apVS5K0du1ahYaGKjIyUk2aNFFycrKioqK0du1aqzgAAADAFij0AiVY48aN1bJly2K7Xrt27YrtWgAAlFRBQUGqV6+eqlWrpt27dyswMNCY8/X1lb+/v06dOqWgoCA7ZgkAAIDShkIvAAAAYENms1nTpk1T79691b17d7388stydXVVdna21q5dq1WrVik6Olpms9neqQIAAKAUodALAAAA2FhYWJiio6M1ZswYrVy50hj39fVVdHS0wsLC7JgdAAAASiMKvQAAAMAdEBYWpk6dOumpp57S4cOH5efnp08//VQVK1a0d2oAAAAohSj0AgAAAHdAaGioVqxYYRzv3r1blSpVUs+ePRUbG2u/xAAAAFAqOdg7AQAAAKC0+XOR92orVqxQaGho8SYEAACAUo9CLwAAAGBD2dnZ1yzyFlixYoWys7OLKSMAAACUBRR6AQAAABsaMmSIse/o6KhXX31Vhw4d0quvvipHR8ci4wAAAIDbRaEXAAAAsKElS5YY++fPn1dUVJT8/PwUFRWl8+fPFxkHAAAA3C4KvQAAAIANXb58WZJUv359OTk5Wc05OTnpnnvusYoDAAAAbIFCLwAAAGBDBe0ZDh06pJycHKu5nJwc/fLLL1ZxAAAAgC1Q6AUAAABsqF+/fsZ+hQoVNHbsWB04cEBjx45VhQoViowDAAAAbheFXgAAAMCGPvjgA2P/8uXLmjx5sho2bKjJkydbtWu4Og4AAAC4XRR6AQAAABtydXVVz549rxvTs2dPubq6FlNGQNmyefNm9ejRQzVr1pTJZFJsbKzVvMlkKnKbMmWKEVOvXr1C85MmTbI6z65duxQUFCQXFxf5+Pho8uTJhXJZtmyZGjVqJBcXFzVt2lSrV6++I/cMAIBEoRcAAACwudjY2GsWe3v27Fmo8ATAds6fP6/mzZtr9uzZRc6npaVZbQsWLJDJZFKvXr2s4t566y2ruBEjRhhzWVlZ6tSpk+rWravt27drypQpGj9+vObPn2/EbNmyRf369dOgQYO0c+dOhYaGKjQ0VMnJyXfmxgEAZR5vgAAAAADugNjYWGVnZysiIkIHDx5UgwYNNGXKFFbyAndY165d1bVr12vOe3l5WR2vWLFCISEhuueee6zGK1WqVCi2wKJFi5STk6MFCxbIyclJ999/v5KSkjR9+nSFh4dLkmbOnKkuXbooIiJCkvT2228rLi5Os2bN0rx5827nFgEAKBIregEAAIA7xNXVVbNmzdLXX3+tWbNmUeQF7jIZGRlatWqVBg0aVGhu0qRJqlq1qlq0aKEpU6ZY9dhOTExU+/bt5eTkZIx17txZ+/fv1x9//GHEdOzY0eqcnTt3VmJi4h26GwBAWceKXgAAAABAmfTxxx+rUqVKCgsLsxp/8cUX1bJlS3l4eGjLli2KjIxUWlqapk+fLklKT0+Xr6+v1Wdq1KhhzFWpUkXp6enG2NUx6enp18zn0qVLunTpknGclZV1W/cHAChbKPQCAAAAAMqkBQsWaMCAAXJxcbEaHz16tLHfrFkzOTk5aciQIYqKipKzs/MdyycqKkoTJky4Y+cHAJRutG4AAAAAAJQ5CQkJ2r9/vwYPHnzD2DZt2ujy5ctKTU2VdKXPb0ZGhlVMwXFBX99rxVyr768kRUZGKjMz09iOHj16K7cEACjjKPQCAAAAAMqcDz/8UP7+/mrevPkNY5OSkuTg4CBPT09JUtu2bbV582bl5uYaMXFxcWrYsKGqVKlixGzYsMHqPHFxcWrbtu01r+Ps7Cw3NzerDQCAm0WhFwAAAABQapw7d05JSUlKSkqSJKWkpCgpKUlHjhwxYrKysrRs2bIiV/MmJibqvffe008//aRffvlFixYt0qhRo/Tkk08aRdz+/fvLyclJgwYN0p49e/T5559r5syZVi0fXnrpJa1du1bTpk3Tvn37NH78eG3btk3Dhw+/sz8AAECZRY9eAAAAAECpsW3bNoWEhBjHBcXXgQMHauHChZKkpUuXymKxqF+/foU+7+zsrKVLl2r8+PG6dOmSfH19NWrUKKsirru7u9atW6dhw4bJ399f1apV07hx4xQeHm7EBAYGavHixXr99df12muvqUGDBoqNjVWTJk3u0J0DAMo6Cr0AAADAHZKXl6eEhASlpaXJ29tbQUFBMpvN9k4LKNWCg4NlsViuGxMeHm5VlL1ay5YttXXr1htep1mzZkpISLhuzOOPP67HH3/8hucCAMAWaN0AAAAA3AExMTGqX7++QkJC1L9/f4WEhKh+/fqKiYmxd2oAAAAohSj0AgAAADYWExOj3r17q2nTpkpMTNTZs2eVmJiopk2bqnfv3hR7AQAAYHMUegEAAAAbysvL05gxY/Too48qNjZWAQEBqlixogICAhQbG6tHH31UL7/8svLy8uydKgAAAEoRevQCJZDp8kW18HKQ65kD0vHS+/ca1zMH1MLLQabLF+2dCgAANy0hIUGpqalasmSJHBysn9MODg6KjIxUYGCgEhISFBwcbJ8kAQAAUOpQ6AVKIJdzR7RjSEVp8xBps72zuXMaS9oxpKL2njsiKdDe6QAAcFPS0tIkSU2aNClyvmC8IA4AAACwBQq9QAl0sWIdtfzgnBYtWqTGjRrZO507Zu++fRowYIA+7FbH3qkAAHDTvL29JUnJyckKCAgoNJ+cnGwVBwAAANgChV6gBLI4umhner6yK98r1XzA3uncMdnp+dqZni+Lo4u9UwEA4KYFBQWpXr16mjhxomJjY63aN+Tn5ysqKkq+vr4KCgqyY5YAAAAobUpvc08AAADADsxms6ZNm6aVK1cqNDRUiYmJOnv2rBITExUaGqqVK1dq6tSpMpvN9k4VAAAApQgregEAAAAbCwsLU3R0tMaMGaPAwP/1mff19VV0dLTCwsLsmB0AAABKIwq9AAAAwB0QFhamnj17KiEhQWlpafL29lZQUBAreQEAAHBH0LoBAAAAAAAAAEo4Cr0AAADAHRATE6P69esrJCRE/fv3V0hIiOrXr6+YmBh7pwYAAIBSiEIvAAAAYGMxMTHq3bu3mjZtavUytqZNm6p3794UewEAAGBzFHoBAAAAG8rLy9OYMWP06KOPKjY2VgEBAapYsaICAgIUGxurRx99VC+//LLy8vLsnSoAAABKEQq9AAAAgA0lJCQoNTVVr732mhwcrH/ddnBwUGRkpFJSUpSQkGCnDAEAAFAaUegFAAAAbCgtLU2S1KRJkyLnC8YL4gAAAABboNALAAAA2JC3t7ckKTk5WXl5eYqPj9eSJUsUHx+vvLw8JScnW8UBAAAAtuBo7wQAAACA0iQoKEj16tXTiBEjlJGRoaNHjxpzPj4+qlGjhnx9fRUUFGTHLAEAAFDasKIXAAAAsCGz2azHH39c27ZtsyryStLRo0e1bds29e7dW2az2U4ZAgAAoDSi0AsAQAm0efNm9ejRQzVr1pTJZFJsbKzV/NNPPy2TyWS1denSxSrm9OnTGjBggNzc3FS5cmUNGjRI586ds4rZtWuXgoKC5OLiIh8fH02ePPlO3xpQ4uXl5WnWrFnXjZk1a5by8vKKKSMAAACUBRR6AQAogc6fP6/mzZtr9uzZ14zp0qWL0tLSjG3JkiVW8wMGDNCePXsUFxenlStXavPmzQoPDzfms7Ky1KlTJ9WtW1fbt2/XlClTNH78eM2fP/+O3RdQGqxbt07Z2dnG8YMPPqjx48frwQcfNMays7O1bt06e6QHAACAUooevQAAlEBdu3ZV165drxvj7OwsLy+vIuf27t2rtWvX6scff1SrVq0kSe+//766deumqVOnqmbNmlq0aJFycnK0YMECOTk56f7771dSUpKmT59uVRAGYO3qle/nz59X+fLlJUlvvvmmLly4oAoVKhhxN/rvGAAAALhZdl3RGxUVpdatW6tSpUry9PRUaGio9u/fbxVz8eJFDRs2TFWrVlXFihXVq1cvZWRkWMUcOXJE3bt3V/ny5eXp6amIiAhdvnzZKiY+Pl4tW7aUs7Oz6tevr4ULF97p2wMAwK7i4+Pl6emphg0baujQoTp16pQxl5iYqMqVKxtFXknq2LGjHBwc9P333xsx7du3l5OTkxHTuXNn7d+/X3/88cc1r3vp0iVlZWVZbUBZ8uOPP0qSmjdvbhR5C5QvX15Nmza1igMAAABswa6F3m+++UbDhg3T1q1bFRcXp9zcXHXq1Ennz583YkaNGqX/+7//07Jly/TNN9/o+PHjCgsLM+bz8vLUvXt35eTkaMuWLfr444+1cOFCjRs3zohJSUlR9+7dFRISoqSkJI0cOVKDBw/W119/Xaz3CwBAcenSpYs++eQTbdiwQf/617/0zTffqGvXrkZP0PT0dHl6elp9xtHRUR4eHkpPTzdiatSoYRVTcFwQU5SoqCi5u7sbm4+Pjy1vDSgxfv/9d+Xn51uN5efnW/3RBQAAALAVu7ZuWLt2rdXxwoUL5enpqe3bt6t9+/bKzMzUhx9+qMWLF+uRRx6RJH300Udq3Lixtm7dqoCAAK1bt04///yz1q9frxo1auiBBx7Q22+/rbFjx2r8+PFycnLSvHnz5Ovrq2nTpkmSGjdurG+//VYzZsxQ586di/2+AQC40/r27WvsN23aVM2aNZOfn5/i4+PVoUOHO3rtyMhIjR492jjOysqi2IsypWnTptq6dauOHTumHj166PXXX1eTJk2UnJysd955R8ePHzfiAAAAAFu5q17GlpmZKUny8PCQJG3fvl25ubnq2LGjEdOoUSPVqVNHiYmJkq58rbRp06ZWK446d+6srKws7dmzx4i5+hwFMQXnAACgtLvnnntUrVo1HTp0SJLk5eWlEydOWMVcvnxZp0+fNvr6enl5FWqXVHB8rd6/0pXewG5ublYbUJZcvZhh9erVCgwMlJubmwIDA7V69eoi4wAAAIDbddcUevPz8zVy5Ei1a9dOTZo0kXTla6FOTk6qXLmyVWyNGjVu6Wul14rJysqyeiPy1egvCAAoTX777TedOnVK3t7ekqS2bdvqzJkz2r59uxGzceNG5efnq02bNkbM5s2blZuba8TExcWpYcOGqlKlSvHeAFCCuLu7y8/P77oxfn5+cnd3L6aMAAAAUBbcNYXeYcOGKTk5WUuXLrV3KpLoLwgAuLudO3dOSUlJSkpKknSlH31SUpKOHDmic+fOKSIiQlu3blVqaqo2bNignj17qn79+kbLosaNG6tLly567rnn9MMPP+i7777T8OHD1bdvX9WsWVOS1L9/fzk5OWnQoEHas2ePPv/8c82cOdOqLQOAoh06dOiaxV4/Pz9jdT0AAABgK3dFoXf48OFauXKlNm3apNq1axvjXl5eysnJ0ZkzZ6ziMzIybulrpdeKcXNzk6ura5E5RUZGKjMz09iOHj16W/cIAIAtbdu2TS1atFCLFi0kSaNHj1aLFi00btw4mc1m7dq1S4899pjuvfdeDRo0SP7+/kpISJCzs7NxjkWLFqlRo0bq0KGDunXrpoceekjz58835t3d3bVu3TqlpKTI399fY8aM0bhx4xQeHl7s9wuURIcOHdKZM2fUrl07+fj4qF27djpz5gxFXgAAANwRdn0Zm8Vi0YgRI7R8+XLFx8fL19fXat7f31/lypXThg0b1KtXL0nS/v37deTIEbVt21bSla+Vvvvuuzpx4oTx9vC4uDi5ubnpvvvuM2Ku7odWEFNwjqI4Oztb/WMYAIC7SXBwsCwWyzXnv/766xuew8PDQ4sXL75uTLNmzZSQkHDL+QG4wt3dXd9++6290wAAAEAZYNdC77Bhw7R48WKtWLFClSpVMnrquru7y9XVVe7u7ho0aJBGjx4tDw8Pubm5acSIEWrbtq0CAgIkSZ06ddJ9992np556SpMnT1Z6erpef/11DRs2zCjUPv/885o1a5ZeeeUVPfvss9q4caO++OILrVq1ym73DgAAAAAAAAC2YtfWDXPnzlVmZqaCg4Pl7e1tbJ9//rkRM2PGDD366KPq1auX2rdvLy8vL8XExBjzZrNZK1eulNlsVtu2bfXkk0/qH//4h9566y0jxtfXV6tWrVJcXJyaN2+uadOm6b///a/RpxAAAAAAAAAASjK7t264ERcXF82ePVuzZ8++ZkzdunULtWb4s+DgYO3cufOWcwQAAAAAAACAu51dC70A/poLFy5Iknbs2FFs18zOzlZqaqrq1at3zZcY2trevXuL5ToAAAAAAAAlHYVeoATat2+fJOm5556zcybFo1KlSvZOAQAAAAAA4K5GoRcogUJDQyVJjRo1Uvny5Yvlmnv37tWTTz6pzz77TI0bNy6Wa0pXirwNGjQotusBAAAAAACURBR6gRKoWrVqGjx4sF2u3bhxY7Vs2dIu1wYAAAAAAEDRHOydAAAAAAAAAADg9lDoBQAAAAAAAIASjkIvAAAAAAAAAJRwFHoBAAAAAAAAoISj0AsAAAAAAAAAJRyFXgAAAAAAAAAo4RztnQAAAABQWuXl5SkhIUFpaWny9vZWUFCQzGazvdMCAABAKcSKXgAAAOAOiImJkZ+fn0JCQtS/f3+FhITIz89PMTEx9k4NAAAApRCFXgAAAMDGYmJi1KtXL504ccJq/MSJE+rVqxfFXgAAANgchV4AAADAhvLy8vT8889fN2bo0KHKy8srpowAAABQFlDoBQAAAGwoPj5eJ0+elCR16NBBiYmJOnv2rBITE9WhQwdJV1b2xsfH2zFLAAAAlDYUegEAAAAb2rhxoyQpICBAK1asUEBAgCpWrGh1fHUcAAAAYAsUegEAAAAbOnr0qCRpwIABcnCw/nXbwcFB/fr1s4oDAAAAbIFCLwAAAGBDPj4+kqRFixYpPz/fai4/P19LliyxigMAAABswdHeCQAAAAClySOPPKKJEydq69ateuyxx9S1a1e5uroqOztba9as0datW404AAAAwFYo9AIAAAA2FBwcrOrVq+vkyZNavXq1Vq1aZcyZTCZJkqenp4KDg+2UIQAAAEojWjcAAAAANmQ2m/X0009L+l9ht0BBz96BAwfKbDYXd2oAAAAoxSj0AgAAADaUl5enZcuWqVWrVqpdu7bVXO3atdWqVStFR0crLy/PThkCAACgNKJ1AwAAAGBDCQkJSk1N1ZIlS9SyZUvNmTNHhw8flp+fn1544QVt375dgYGBSkhIoH0DAAAAbIZCLwAAAGBDaWlpkqTDhw/riSee0JEjR4y5GTNmaOLEiVZxAAAAgC1Q6AUAAABsyNvbW5L05JNPFpo7cuSIMV4QBwAAANgCPXoBAAAAGwoMDCz0ErY/M5lMCgwMLKaMAAAAUBZQ6AUAAABsKD4+XhaL5boxFotF8fHxxZMQAAAAygQKvQAAAIANzZs3z9h3dna2mnNxcSkyDgAAALhdFHoBAAAAG1q5cqUkqVy5cjp16pSGDRumTp06adiwYfr9999Vrlw5qzgAAADAFngZGwAAAGBDeXl5kiSz2azKlSvr8uXLkqR169bpgw8+kKOjo3Jzc404AAAAwBZY0QsAAADYUMWKFSVJFy9elIODg1599VUdPHhQr776qhwcHHTx4kWrOAAAAMAWWNELAAAA2NCcOXP05JNPSpJycnI0adIkTZo0qcg4AADKggsXLmjfvn02PeeOHTtuKq5Ro0YqX768Ta8N3K0o9AIAAAA2lJ6ebtM4AABKun379snf39+m57zZ823fvl0tW7a06bWBuxWFXgAAAMCGUlNTbRoHAEBJ16hRI23fvv2GcbdSDL6Z8xVcGygrKPQCAAAANuTn5ydJGjp0qJYvX261ctfb21s9e/bUvHnzjDgAAEq78uXL39SqWovFIpPJdFNxAAqj0AsAAADY0AsvvKCIiAjFxMTo119/VWJiotLS0uTt7a22bduqbt26cnR01AsvvGDvVAEAuOvcqNhLkRe4Ngd7JwAAAACUJk5OTho1apQyMjJUt25dHThwQA8//LAOHDigunXrKiMjQ6NGjZKTk5O9UwUA4K50rWIuRV7g+ljRCwAAANjY5MmTJUkzZszQkCFDjHFHR0dFREQY8wAAoGgWi0U7duyQv78/L1QDbhIregEAAIA7ICAgQF5eXlZjXl5eCggIsFNGAAAAKM0o9AIAAAA2FhMTo169eunYsWNW48eOHVOvXr0UExNjp8wAAABQWlHoBQAAAGwoLy9PzzzzjCQVeplMwfEzzzyjvLy8Ys8NAAAApReFXgAAAMCGNmzYoKysLEkq9MK1guOsrCxt2LCh2HMDAABA6UWhFwAAALChTz75xNjv2LGjEhMTdfbsWSUmJqpjx45FxgEAAAC3y9HeCQAAAAClSWpqqiSpcePGWrFihRwcrqytCAgI0IoVK3T//fdr3759RhwAAABgC6zoBQAAAGzI1dVVknTx4sUi5wvGC+IA2NbmzZvVo0cP1axZUyaTSbGxsVbzTz/9tEwmk9XWpUsXq5jTp09rwIABcnNzU+XKlTVo0CCdO3fOKmbXrl0KCgqSi4uLfHx8NHny5EK5LFu2TI0aNZKLi4uaNm2q1atX2/x+AQAoQKEXAAAAsKFWrVpJklJSUvTYY49ZtW547LHHjJW8BXEAbOv8+fNq3ry5Zs+efc2YLl26KC0tzdiWLFliNT9gwADt2bNHcXFxWrlypTZv3qzw8HBjPisrS506dVLdunW1fft2TZkyRePHj9f8+fONmC1btqhfv34aNGiQdu7cqdDQUIWGhio5Odn2Nw0AgGjdAAAAANhUx44dNWnSJEnSmjVrtGrVKmOuoI1DQRwA2+vatau6du163RhnZ2d5eXkVObd3716tXbtWP/74o/EHmffff1/dunXT1KlTVbNmTS1atEg5OTlasGCBnJycdP/99yspKUnTp083CsIzZ85Uly5dFBERIUl6++23FRcXp1mzZmnevHk2vGMAAK5gRS8AAABgQ8HBwapevbokyWKxWM0VHHt6eio4OLi4UwPw/8XHx8vT01MNGzbU0KFDderUKWMuMTFRlStXtlp137FjRzk4OOj77783Ytq3by8nJycjpnPnztq/f7/++OMPI+bPf9Dp3LmzEhMTr5nXpUuXlJWVZbUBAHCzKPQCAAAANmQ2m43Ves7OzlZzBcdz586V2Wwu9twAXGnb8Mknn2jDhg3617/+pW+++UZdu3ZVXl6eJCk9PV2enp5Wn3F0dJSHh4fS09ONmBo1aljFFBzfKKZgvihRUVFyd3c3Nh8fn9u7WQBAmUKhFwAAALCxsLAwRUREKDc312o8NzdXERERCgsLs1NmAPr27avHHntMTZs2VWhoqFauXKkff/xR8fHx9k5NkZGRyszMNLajR4/aOyUAQAlCj14AAADAxmJiYjR16lR1795dXbt2laurq7Kzs7VmzRpNnTpVAQEBFHuBu8Q999yjatWq6dChQ+rQoYO8vLx04sQJq5jLly/r9OnTRl9fLy8vZWRkWMUUHN8o5lq9gaUrq/7//E0AAABuFit6AQAAABvKy8vTmDFj9Oijj2rFihV64YUX9Mwzz+iFF17QihUr9Oijj+rll182viYOwL5+++03nTp1St7e3pKktm3b6syZM9q+fbsRs3HjRuXn56tNmzZGzObNm61W7cfFxalhw4aqUqWKEbNhwwara8XFxalt27Z3+pYAAGUUhV4AAADAhhISEpSamqrXXntNDg7Wv247ODgoMjJSKSkpSkhIsFOGQOl27tw5JSUlKSkpSZKUkpKipKQkHTlyROfOnVNERIS2bt2q1NRUbdiwQT179lT9+vXVuXNnSVLjxo3VpUsXPffcc/rhhx/03Xffafjw4erbt69q1qwpSerfv7+cnJw0aNAg7dmzR59//rlmzpyp0aNHG3m89NJLWrt2raZNm6Z9+/Zp/Pjx2rZtm4YPH17sPxMAQNlAoRcAAACwobS0NElSkyZNipwvGC+IA2Bb27ZtU4sWLdSiRQtJ0ujRo9WiRQuNGzdOZrNZu3bt0mOPPaZ7771XgwYNkr+/vxISEqxaJixatEiNGjVShw4d1K1bNz300EOaP3++Me/u7q5169YpJSVF/v7+GjNmjMaNG6fw8HAjJjAwUIsXL9b8+fPVvHlzRUdHKzY29pr/2wAAwO2iRy8AAABgQwVf/05OTlbr1q2VkJCgtLQ0eXt7KygoSMnJyVZxAGwrODhYFovlmvNff/31Dc/h4eGhxYsXXzemWbNmN1yZ//jjj+vxxx+/4fUAALAFCr0AAACADQUFBalevXoaMWKEfv/9d6Wmphpz9erVU7Vq1eTr66ugoCD7JQkAAIBSh9YNAAAAgA2ZzWY9/vjj2rZtm7KzszVmzBjNnj1bY8aMUXZ2trZt26bevXvLbDbbO1UAAACUIqzoBQAAAGwoLy9Py5Ytk5+fn1JTUzVt2jRjzmw2y8/PT9HR0YqKiqLYCwAAAJuh0AsAAADYUEJCgtGuoXv37qpfv76ys7Pl6uqqQ4cOadWqVUZccHCw/RIFAABAqUKhFwAAALChY8eOSZJatGih5ORko7ArSXXr1lWLFi20c+dOIw4AAACwBXr0AgAAADZ08uRJSdLOnTvVrFkzJSYm6uzZs0pMTFSzZs20c+dOqzgAAADAFljRCwAAANhQ1apVJUmenp6KiYmRo+OVX7kDAgIUExOjWrVq6cSJE0YcAAAAYAus6AUAAABs6NSpU5KurNgNCwuzWtEbFhZmrOQtiAMAAABsgRW9AAAAgA1Vr15dkvTAAw/op59+UmBgoDFXt25dPfDAA9q5c6cRBwAAANgChV4AAADAhmrVqiVJRi/eq/3666/69ddfreIAAAAAW6B1AwAAAGBDQUFBcnV1vW6Mq6urgoKCiikjAAAAlAWs6AUAAABsKCcnR9nZ2ZKkrl27qnv37nJ1dVV2drZWrVqlNWvWKDs7Wzk5OTcsCAMAAAA3i0IvAAAAYEMRERGSpL///e/auXOn1qxZY8z5+voqNDRUsbGxioiI0KxZs+yVJgAAAEoZCr0AAACADR08eFCSNGXKFPn4+GjOnDk6fPiw/Pz89MILLyg1NVWxsbFGHAAAAGALFHoBAAAAG2rQoIHWrVuniIgI7dy5U6mpqcbczJkz9cADDxhxAAAAgK3wMjYAAADAhqZMmSJJWr58ue677z4lJibq7NmzSkxM1H333afY2FirOAAAAMAWWNELAAAA2JCTk5Px8rX169erSZMm8vDw0PLly7V+/XpJkqurq5ycnOycKQAAAEoTVvQCAAAANpSQkKDs7GwFBQUpJydHkydPVsOGDTV58mTl5OQoKChI2dnZSkhIsHeqAAAAKEVY0QsAAADYUFpamiRp9erVkqSnnnrKeBnbp59+KovFIjc3NyMOAAAAsAUKvQAAAIANeXt7S5JmzZqlDz74wHgZ2+7du9W0aVOFh4dbxQEAAAC2QOsGAAAAwIaCgoJUvXp1RUZGqkmTJlYvY2vSpIlee+01eXp6KigoyN6pAgAAoBSh0AsAAADYmMlkMvYtFouxAQAAAHcKhV4AAADAhhISEnTixAlFRUUpOTlZgYGBcnNzU2BgoPbs2aOJEyfqxIkTvIwNAAAANkWhFwAAALChgpesDR8+XIcOHdKmTZu0ePFibdq0SQcPHtTw4cOt4gAAAABb4GVsAAAAgA0VvGQtOTlZAQEBCg4OtppPTk62igMAAABsgRW9AAAAgA0FBQWpXr16mjhxonJzcxUfH68lS5YoPj5eubm5ioqKkq+vLy9jAwAAgE2xohcAAACwIbPZrGnTpql3795yd3dXdna2Mefq6qqLFy8qOjpaZrPZjlkCAACgtGFFLwAAAHAHWCyWQmMmk6nIcQAAAOB2UegFAKAE2rx5s3r06KGaNWvKZDIpNjbWmMvNzdXYsWPVtGlTVahQQTVr1tQ//vEPHT9+3Ooc9erVk8lkstomTZpkFbNr1y4FBQXJxcVFPj4+mjx5cnHcHlCi5eXlacyYMerRo4dOnjypYcOGqVOnTho2bJhOnDihHj166OWXX1ZeXp69UwUAAEApQqEXAIAS6Pz582revLlmz55daO7ChQvasWOH3njjDe3YsUMxMTHav3+/HnvssUKxb731ltLS0oxtxIgRxlxWVpY6deqkunXravv27ZoyZYrGjx+v+fPn39F7A0q6hIQEpaamys3NTZUrV9bs2bO1bt06zZ49W5UrV1alSpWUkpKihIQEe6cKAACAUoQevQAAlEBdu3ZV165di5xzd3dXXFyc1disWbP04IMP6siRI6pTp44xXqlSJXl5eRV5nkWLFiknJ0cLFiyQk5OT7r//fiUlJWn69OkKDw+33c0ApUxaWpqkK/8N1ahRQ++8844effRRrVy5Uq+//roWL15sFQcAAADYAit6AQAoAzIzM2UymVS5cmWr8UmTJqlq1apq0aKFpkyZosuXLxtziYmJat++vZycnIyxzp07a//+/frjjz+KK3WgxKlataokycPDQ7/++qvq16+vTZs2qX79+vr111/l4eFhFQcAAADYAit6AQAo5S5evKixY8eqX79+cnNzM8ZffPFFtWzZUh4eHtqyZYsiIyOVlpam6dOnS5LS09Pl6+trda4aNWoYc1WqVCnyepcuXdKlS5eM46ysLFvfEnBX2717t6QrK+YbNmyoX3/91ZirW7euKlasqNOnT2v37t3q1KmTvdIEAABAKUOhFwCAUiw3N1d9+vSRxWLR3LlzreZGjx5t7Ddr1kxOTk4aMmSIoqKi5Ozs/JevGRUVpQkTJvzlzwMlXWpqqiRZFXgLXD1WEAcAAADYAq0bAAAopQqKvL/++qvi4uKsVvMWpU2bNrp8+bJRfPLy8lJGRoZVTMHxtfr6SlJkZKQyMzON7ejRo7d3I0AJc/VKeJPJZDXn4OBQZBwAAABwu1jRCwBAKVRQ5D148KA2bdp0U71Ak5KS5ODgIE9PT0lS27Zt9c9//lO5ubkqV66cJCkuLk4NGza8ZtsGSXJ2dr6tFcFASde4cWNj/8yZM1qwYIEOHz4sPz8/Pfvss3J3dy8UBwAAANwuCr1AGXPhwgXt27fvlj+3d+9eq//7VzRq1Ejly5f/y58H8D/nzp3ToUOHjOOUlBQlJSXJw8ND3t7e6t27t3bs2KGVK1cqLy9P6enpkq68HMrJyUmJiYn6/vvvFRISokqVKikxMVGjRo3Sk08+aRRx+/fvrwkTJmjQoEEaO3askpOTNXPmTM2YMcMu9wyUFEuWLDH2q1Spovz8fON4zJgxVnFdu3Yt1twAAABQelHoBcqYffv2yd/f/y9//sknn/zLn92+fbtatmz5lz8P4H+2bdumkJAQ47ig3+7AgQM1fvx4ffXVV5KkBx54wOpzmzZtUnBwsJydnbV06VKNHz9ely5dkq+vr0aNGmXVt9fd3V3r1q3TsGHD5O/vr2rVqmncuHEKDw+/8zcIlGBnz5419i0Wi9Xc1cdXxwEAAAC3i0IvUMY0atRI27dvv+XPZWdnKzU1VfXq1ZOrq+tfvjYA2wgODi5UQLra9eYkqWXLltq6desNr9OsWTMlJCTccn5AWRYYGKjY2FhVqlRJx44dU2RkpA4ePKgGDRooKipKtWrV0tmzZxUYGGjvVAEAAFCKUOgFypjy5cvf8qraP79IRrpxEQkAgLKqefPmkq6s2K1Ro4ays7MlSevWrdOCBQuM44I4AAAAwBYcbhwCoCwrqsh7vXEAAMq6U6dOGfsFRd2ijq+OAwAAAG4XhV4A13SjYi7FXgAACvP09LRpHAAAAHAzaN0AoEh/LuJe3arh6jmTyUQbBwAArpKXlydJ8vDw0NGjRzV//nwdPnxYfn5+Cg8Pl4+Pj06fPm3EAQAAALbAil4AN3S9N4YDAABrBS8wPH36tPr27as2bdpo4sSJatOmjfr27avTp09bxQEAAAC2QKEXAAAAuAPGjx+v3bt3KzAwUG5ubgoMDFRycrLefPNNe6cGAACAUohCLwAAAGBDwcHBkqT169frwIED2rRpkxYvXqxNmzZp//79Wr9+vVUcAAAAYAsUegHc0J/79fISNgAAri04OFienp769ttv9fe//1179uxRdna29uzZo7///e/67rvv5OnpSaEXAAAANsXL2AAUyWKxFHrp2rXiAADA/5jNZs2dO1e9evXS6tWrtWrVKmOu4Hk6d+5cmc1me6UIAACAUogVvQCu6UZFXIq8AABcHy80BQAAQHGh0Avgmm7UooEWDgAAFJaXl6ehQ4dKklxcXKzmCo6HDh2qvLy8Ys8NAAAApReFXgBF+nMR12KxGNv14gAAKOvi4+N14sQJSVLHjh2VmJios2fPKjExUR07dpQknThxQvHx8XbMEgAAAKUNhV4AN8TXTgEAuHkbN26UJLVt21YrVqxQQECAKlasqICAAOP46jgAAADAFij0AgAAADZ05MgRSVL//v3l4GD967aDg4P69etnFQcAAADYAoVeAAAAwIbq1KkjSVq8eLHy8/Ot5vLz87VkyRKrOAAAAMAWKPQCuCGTyVRoAwAARXvkkUckSYmJierZs6dVj96ePXtq69atVnEAAACALTjaOwEAdyeLxXJTBV369QIAYC04OFienp46ceKE1q9fr5UrVxpzrq6ukiRPT08FBwfbKUMAAACURqzoBQAAAGzIbDZr7ty51/wWjMlk0ty5c2U2m+2QHQAAAEorCr0AinSz7Rlo4wAAQGFhYWGKjo5WjRo1rMa9vLwUHR2tsLAwO2UGAACA0orWDQBuqKj2DBR4AQC4vrCwMPXs2VMJCQlKS0uTt7e3goKCWMkLAACAO4JCLwAAAHCHmM1mevECAACgWNC6AQAAAAAAAABKOFb0Arghk8lk1b6Btg0AANycvLw8WjcAAACgWFDoBVAki8ViVdC9VnG3qP69AABAiomJ0ejRo/Xrr78aY3Xr1tX06dN5GRsAAABsjtYNAK7pRkVcirwAABQtJiZGvXr1UkZGhtV4RkaGevXqpZiYGDtlBgAAgNKKQi+Aa7pRiwZaOAAAUFheXp6ef/55SYWflQXHQ4cOVV5eXrHnBgAAgNKLQi+AIv35H6YWi8XYrhcHAEBZFx8fr5MnT1435sSJE4qPjy+ehAAAAFAm0KMXwA39ubj75/69AADgfzZu3GjsP/LII+rWrZtcXV2VnZ2t1atXa9WqVUZchw4d7JUmAAAAShkKvQAAAIANFbx8zcfHR7t37zYKu5JUp04d+fj46OjRo1YvaQMAAABuF4VeAAAA4A44evSoXF1drcZOnjyp7OxsO2UEAACA0owevQBuyGQyFdoAAEDR6tSpY+xXqlRJ8+fP1/HjxzV//nxVqlSpyDgAAADgdrGiF0CRbrYP75/79wIAUNZ5eHgY+5mZmQoPDzeOXVxciowDAAAAbhcregEAAAAb+uOPP4x9BwfrX7ev/iPq1XEAAADA7aLQC6BIN9uegTYOAABY+3Nx92pXPzevFwcAAADcKn67BHBDFoul0AYAAIoWHBwsSWrUqJE8PT2t5jw9PdWoUSOrOAAAAMAW6NELAAAA2FBwcLA8PT21b98+de/eXREREXJ1dVV2drbWrFmjVatWydPTk0IvAAAAbIpCLwAAAGBDZrNZc+fOVe/evbVx40atWrXKmCtfvrxMJpPmzp0rs9lsxywBAABQ2tC6AcAN/bkPL315AQC4vrCwMEVHR6tGjRpW4zVq1FB0dLTCwsLslBlQ+m3evFk9evRQzZo1ZTKZFBsba8zl5uZq7Nixatq0qSpUqKCaNWvqH//4h44fP251jnr16slkMlltkyZNsorZtWuXgoKC5OLiIh8fH02ePLlQLsuWLVOjRo3k4uKipk2bavXq1XfkngEAkCj0AriGP/fhvfqX3OvFAQCAK8LCwnTo0CFt2rRJixcv1qZNm3Tw4EGKvMAddv78eTVv3lyzZ88uNHfhwgXt2LFDb7zxhnbs2KGYmBjt379fjz32WKHYt956S2lpacY2YsQIYy4rK0udOnVS3bp1tX37dk2ZMkXjx4/X/PnzjZgtW7aoX79+GjRokHbu3KnQ0FCFhoYqOTn5ztw4AKDMo3UDgGuyWCzXXb1LkRcAAAB3m65du6pr165Fzrm7uysuLs5qbNasWXrwwQd15MgR1alTxxivVKmSvLy8ijzPokWLlJOTowULFsjJyUn333+/kpKSNH36dIWHh0uSZs6cqS5duigiIkKS9PbbbysuLk6zZs3SvHnzbHGrAABYYUUvgGu6UYsGWjgAAHBtMTExql+/vkJCQtS/f3+FhISofv36iomJsXdqAK6SmZkpk8mkypUrW41PmjRJVatWVYsWLTRlyhRdvnzZmEtMTFT79u3l5ORkjHXu3Fn79+/XH3/8YcR07NjR6pydO3dWYmLinbsZAECZxopeAEW6XouGq+dMJhMrewEA+JOYmBj17t1b3bt3V0REhFxdXZWdna01a9aod+/e9OkF7hIXL17U2LFj1a9fP7m5uRnjL774olq2bCkPDw9t2bJFkZGRSktL0/Tp0yVJ6enp8vX1tTpXQU/u9PR0ValSRenp6UX26U5PT79mPpcuXdKlS5eM46ysrNu+RwBA2UGhF8AN/bmQe6OWDgAAlGV5eXkaM2aM/P39tXv3bq1cudKYq1u3rvz9/fXyyy+rZ8+eMpvNdswUKNtyc3PVp08fWSwWzZ0712pu9OjRxn6zZs3k5OSkIUOGKCoqSs7Ozncsp6ioKE2YMOGOnR8AULrRugEAAACwoYSEBKWmpmrbtm1q1qyZEhMTdfbsWSUmJqpZs2batm2bUlJSlJCQYO9UgTKroMj766+/Ki4uzmo1b1HatGmjy5cvKzU1VZLk5eWljIwMq5iC44K+vteKuVbfX0mKjIxUZmamsR09evRWbw0AUIZR6AUAAABs6NixY5KuvBAqNjZWAQEBqlixogICAhQbG2u8JKogDkDxKijyHjx4UOvXr1fVqlVv+JmkpCQ5ODjI09NTktS2bVtt3rxZubm5RkxcXJwaNmyoKlWqGDEbNmywOk9cXJzatm17zes4OzvLzc3NagMA4GbRugHADdGmAQCAm3fy5ElJUlhYmCwWi+Lj45WWliZvb28FBQUpNDRUa9asMeIA2Na5c+d06NAh4zglJUVJSUny8PCQt7e3evfurR07dmjlypXKy8szeuZ6eHjIyclJiYmJ+v777xUSEqJKlSopMTFRo0aN0pNPPmkUcfv3768JEyZo0KBBGjt2rJKTkzVz5kzNmDHDuO5LL72khx9+WNOmTVP37t21dOlSbdu2TfPnzy/eHwgAoMyw64rezZs3q0ePHqpZs6ZMJpNiY2Ot5jMyMvT000+rZs2aKl++vLp06aKDBw9axaSnp+upp56Sl5eXKlSooJYtW+rLL7+0ijl9+rQGDBggNzc3Va5cWYMGDdK5c+fu9O0BJdrNvmCNF7EBAGCtevXqkqQ5c+bI19dXISEh6t+/v0JCQuTr66t58+ZZxQGwrW3btqlFixZq0aKFpCv9dlu0aKFx48bp2LFj+uqrr/Tbb7/pgQcekLe3t7Ft2bJF0pVVtUuXLtXDDz+s+++/X++++65GjRplVaB1d3fXunXrlJKSIn9/f40ZM0bjxo1TeHi4ERMYGKjFixdr/vz5at68uaKjoxUbG6smTZoU7w8EAFBm2HVF7/nz59W8eXM9++yzhd46bLFYFBoaqnLlymnFihVyc3PT9OnT1bFjR/3888+qUKGCJOkf//iHzpw5o6+++krVqlXT4sWL1adPH+PhLkkDBgxQWlqa4uLilJubq2eeeUbh4eFavHhxsd8zAAAASrdatWpJknbu3Flo7ujRo0bPzYI4ALYVHBx83cUIN1qo0LJlS23duvWG12nWrNkNe20//vjjevzxx294LgAAbMGuhd6uXbsaPcr+7ODBg9q6dauSk5N1//33S5Lmzp0rLy8vLVmyRIMHD5YkbdmyRXPnztWDDz4oSXr99dc1Y8YMbd++XS1atNDevXu1du1a/fjjj2rVqpUk6f3331e3bt00depU1axZsxjuFCh5brZdg8lkYlUvAABXCQwMvOHz0WQyKTAwsBizAgAAQGl3176M7dKlS5IkFxcXY8zBwUHOzs769ttvjbHAwEB9/vnnOn36tPLz87V06VJdvHhRwcHBkqTExERVrlzZKPJKUseOHeXg4KDvv//+utfPysqy2oCyymKxFNoAAEDR4uPjjWdl9erVNWbMGM2ePVtjxowx2jUU9O4FAAAAbOWufRlbo0aNVKdOHUVGRuqDDz5QhQoVNGPGDP32229KS0sz4r744gs98cQTqlq1qhwdHVW+fHktX75c9evXl3Slh2/Bm1ELODo6ysPDw2i6X5SoqChNmDDhztwcAAAASq1PPvlEkuTj4yMHBwdNmzbNmKtXr55cXFx09OhRffLJJ+rUqZO90gQAAEApc9eu6C1XrpxiYmJ04MABeXh4qHz58tq0aZO6du0qB4f/pf3GG2/ozJkzWr9+vbZt26bRo0erT58+2r17921dPzIyUpmZmcZW0EsNAAAAuJ7U1FRJ0ksvvaQDBw5oxowZGj58uGbMmKH9+/dr+PDhVnEAAACALdy1K3olyd/fX0lJScrMzFROTo6qV6+uNm3aGG0YDh8+rFmzZln18W3evLkSEhI0e/ZszZs3T15eXjpx4oTVeS9fvqzTp0/Ly8vrmtd2dnaWs7Pznbs5oAT5c5/Bm+3fCwBAWVSvXj199913mjlzpt5//339+uuvxtx7772nvLw8Iw4AAACwlbt2Re/V3N3dVb16dR08eFDbtm1Tz549JUkXLlyQJKsVvpJkNpuVn58vSWrbtq3OnDmj7du3G/MbN25Ufn6+2rRpU0x3AJQ8f+7DazKZjO16cQAAlHX/+Mc/JElHjx7VhQsXNH/+fB0/flzz58/XhQsX9Ntvv1nFAQAAALZg1xW9586d06FDh4zjlJQUJSUlycPDQ3Xq1NGyZctUvXp11alTR7t379ZLL72k0NBQo5dZo0aNVL9+fQ0ZMkRTp05V1apVFRsbq7i4OK1cuVKS1LhxY3Xp0kXPPfec5s2bp9zcXA0fPlx9+/ZVzZo17XLfQElhsViuu3qXIi8AAIUFBwcb34Y5deqUwsPDjbmCBQomk8l4eTAAAABgC3Zd0btt2za1aNFCLVq0kCSNHj1aLVq00Lhx4yRJaWlpeuqpp9SoUSO9+OKLeuqpp7RkyRLj8+XKldPq1atVvXp19ejRQ82aNdMnn3yijz/+WN26dTPiFi1apEaNGqlDhw7q1q2bHnroIc2fP794bxYogW7UooEWDgAAFLZlyxbjj6EF3zIrUHBssVi0ZcuWYs8NAAAApZddV/QGBwdfd0Xgiy++qBdffPG652jQoIG+/PLL68Z4eHho8eLFfylHoKy6XouGq+f+3L8XAICyLi0tzaZxAAAAwM24q1/GBuDu8OdC7o1aOgAAUJZ5enoa+927d1e3bt3k6uqq7OxsrV69WqtWrSoUBwAAANwuCr0AAACADeXl5Um68q2y2NhYOTr+71fu8PBweXp66o8//jDiAAAAAFuwa49eAAAAoLRJSEiQJJ0+fVphYWFKTEzU2bNnlZiYqLCwMP3xxx9WcQAAAIAtUOgFcEMmk6nQBgAArm/8+PHavXu3AgMD5ebmpsDAQCUnJ+vNN9+0d2oAAAAohSj0AijSzb5gjRexAQBgLTg4WJK0fv16HThwQJs2bdLixYu1adMm7d+/X+vXr7eKAwAAAGyBQi8AAABgQ8HBwfL09NS3336rv//979qzZ4+ys7O1Z88e/f3vf9d3330nT09PCr0AAACwKV7GBqBIN9uewWQysaoXAICrmM1mzZ07V7169dLq1au1atUqY67g+Tp37lyZzWZ7pQgAAIBSiBW9AG7IYrEU2gAAwI25uLhc9xgAAACwFQq9AAAAgA3l5eVpzJgxatWqlapWrWo1V7VqVbVq1Uovv/yy8vLy7JQhAAAASiNaNwAAAAA2lJCQoNTUVKWmphZqhXTs2DH99ttvRhx9egEAAGArrOgFcEN//kfqzfbvBQCgLDp27Jix7+npqf/85z9KS0vTf/7zH3l6ehYZBwAAANwuVvQCKJLFYrEq6F6ruEu/XgAArKWlpUmS3Nzc9Ntvv8nR8cqv3IMHD9bTTz8tDw8PnT171ogDAAAAbIEVvQCu6UZFXIq8AAAUlpSUJEny8fGRg4P1r9sODg6qU6eOVRwAAABgCxR6AVzTjVo00MIBAIDCzp8/L0nas2ePQkNDlZiYqLNnzyoxMVGhoaHas2ePVRyAK3bt2qXo6GhFR0dr165d9k4HAIASh0IvgCJ5eHgY+61bt5bFYjG21q1bFxkHAACkhx56SJJUt25d7d69W4GBgXJzc1NgYKCSk5NVt25dqzigrPvhhx/UtGlTtWjRQn369FGfPn3UokULNWvWTD/++KO90wMAoMSg0AugSH/88Yex/8MPP1jNXX18dRwAAJBGjBghBwcH/frrr7rvvvs0a9Ysffjhh5o1a5YaN26sX3/9VQ4ODhoxYoS9UwXs7ueff1aHDh3k6uqqzz77TDt27NCOHTv06aefytnZWR06dNDPP/9s7zQBACgReBkbAAAAYENOTk4aM2aMpkyZorVr12r16tXGnNlsliSNGTNGTk5O9koRuGuMHz9ef/vb3/Tll19atQV74IEH1K9fP4WFhWn8+PH64osv7JglAAAlA4VeAAAAwMYmT54sSZoxY4by8/ONcZPJpIiICGMeKOs2bdqkNWvWFPnuB5PJpNdee03dunWzQ2YAAJQ8FHoBFKlKlSpGW4brvXStSpUqxZUSAAAlyuTJk/XOO+9ozpw5Onz4sPz8/PTCCy+wkhe4ytmzZ1WjRo1rznt5eens2bPFmBEAACUXhV4ARTp9+vR1C7xXxwEAgKI5OTlp5MiR9k4DuGvVrVtXP/zwg3x8fIqc//77740XGAIAgOvjZWwAAADAHZKXl6f4+HgtWbJE8fHxysvLs3dKwF2lb9++Gj16tJKTkwvN7d69Wy+//LKeeOIJO2QGAEDJw4peAEWqX7/+TccdOnToDmcDAEDJExMTo1GjRunIkSPGWJ06dTRjxgyFhYXZMTPg7hEZGan169frgQce0N/+9jc1btxYFotFe/fu1fr16/Xggw/qtddes3eaAACUCKzoBVCkw4cPG/sWi6XQVlQcAAC4IiYmRr169dLRo0etxo8ePapevXopJibGTpkBdxcXFxdt2rRJ7777rtLS0jRv3jx98MEHSk9P1zvvvKNNmzbJxcXF3mkCAFAisKIXAIBi9OOPPyo/P19t2rSxGv/+++9lNpvVqlUrO2UGwFby8vL0zDPPSJKqVaum+++/XxaLRSaTSXv27NHJkyf1zDPPqGfPnjKbzXbOFrA/JycnjR07VmPHjrV3KgAAlGis6AUAoBgNGzas0Ao/STp27JiGDRtmh4wA2NqGDRuUlZWlcuXK6eTJk4qPj9c333yj+Ph4nTx5UuXKlVNWVpY2bNhg71SBu8Lnn3+uAQMG6PHHH9e8efPsnQ4AACUWhV4ARfLz8zP2u3TpYjV39fHVcQBu7Oeff1bLli0Ljbdo0UI///yzHTICYGuffvqpJCk3N1eOjo5q0KCB7r33XjVo0ECOjo7Kzc21igPKsrlz56pfv37atm2bDh48qBdeeEERERH2TgsAgBKJQi+AIl39grWvv/5aJpPJ2L7++usi4wDcmLOzszIyMgqNp6WlydGRjkpAaZCZmWnsX758WQcPHtSBAwd08OBBXb58ucg4oKyaNWuW3nzzTe3fv19JSUn65JNPNGfOHHunBQBAiUShF8A1Xf3Stb8yD6CwTp06KTIy0qrAc+bMGb322mv629/+ZsfMANjK77//buybTCb97W9/06RJk/S3v/1NJpOpyDigrPrll180cOBA47h///66fPmy0tLS7JgVAAAlE0uHAFzT1f8YvdY8xV7g1kydOlXt27dX3bp11aJFC0lSUlKSatSowde4gVLC2dnZ2Hd0dFRcXJzi4uIkSeXKlTNaN1wdB5RVly5dUoUKFYxjBwcHOTk5KTs7245ZAQBQMlHoBVCktm3bGvtPPvmkVQHqqaee0meffWbEJSYmFnt+QElVq1Yt7dq1S4sWLdJPP/0kV1dXPfPMM+rXr5/KlStn7/QA2EBqaqqxX1DULer46jigLHvjjTdUvnx54zgnJ0fvvvuu3N3djbHp06fbIzUAAEoUWjcAKNLWrVuN/T+vMrz6+Oo4ADenQoUKCg8P1+zZszV16lT94x//uOUi7+bNm9WjRw/VrFlTJpNJsbGxVvMWi0Xjxo2Tt7e3XF1d1bFjRx08eNAq5vTp0xowYIDc3NxUuXJlDRo0SOfOnbOK2bVrl4KCguTi4iIfHx9Nnjz5L90zUJZcXbCyRRxQmrVv31779+/Xzp07jS0wMFC//PKLcZyUlGTvNAEAKBFY0QsAwF0gLS1Nubm5qlOnzk3Fnz9/Xs2bN9ezzz6rsLCwQvOTJ0/Wv//9b3388cfy9fXVG2+8oc6dO+vnn3+Wi4uLJGnAgAFKS0tTXFyccnNz9cwzzyg8PFyLFy+WJGVlZalTp07q2LGj5s2bp927d+vZZ59V5cqVFR4ebrubB0qZSpUq2TQOKM3i4+PtnQIAAKUGhV4AAO4CjzzyiA4cOKC8vLybiu/atau6du1a5JzFYtF7772n119/XT179pQkffLJJ6pRo4ZiY2PVt29f7d27V2vXrtWPP/6oVq1aSZLef/99devWTVOnTlXNmjW1aNEi5eTkaMGCBXJyctL999+vpKQkTZ8+nUIvcB1ZWVk2jQMAAABuBq0bABQpICDA2DeZTIW2ouIA/HWffPKJNm7caJNzpaSkKD09XR07djTG3N3d1aZNG6OndmJioipXrmwUeSWpY8eOcnBw0Pfff2/EtG/fXk5OTkZM586dtX//fv3xxx/XvP6lS5eUlZVltQFlyd69e419k8mkBg0aqE2bNmrQoIHVM/TqOKAsO3jwoL788kulpKRIklatWqX27durdevWevfdd3n5LwAAN4kVvQCKlJiYaPWP0evFAbh9rVu3ttm50tPTJUk1atSwGq9Ro4Yxl56eLk9PT6t5R0dHeXh4WMX4+voWOkfBXJUqVYq8flRUlCZMmHD7NwKUAhaLpVB/bAD/s3z5cvXp00cODg4ymUyaP3++hgwZouDgYLm5uWn8+PFydHTU2LFj7Z0qAAB3PVb0AgBQjP680rU0rnyNjIxUZmamsR09etTeKQF206lTJ7Vv31733Xef2rdvr06dOtk7JeCu8u677+qVV17RxYsXNXfuXD3//POKiorSmjVrtHLlSs2ePVsLFy60d5oAAJQIrOgFUCRvb++bjktLS7vD2QClR+XKlYtcLW+xWGQymW66R+/1eHl5SZIyMjKs/lvOyMjQAw88YMScOHHC6nOXL1/W6dOnjc97eXkpIyPDKqbguCCmKM7OznJ2dr7t+wBKqg4dOmjDhg2SpHXr1l03Dijr9u/fr88//1wmk0kDBw7Uc889Z9V6qFOnTho5cqT9EgQAoASh0AugSAVf3ZZUZF+0gkLV1XEAbk50dLQ8PDzu2Pl9fX3l5eWlDRs2GIXdrKwsff/99xo6dKgkqW3btjpz5oy2b98uf39/SdLGjRuVn5+vNm3aGDH//Oc/lZubq3LlykmS4uLi1LBhw2u2bQAgxcbGqlKlSjcVB5R158+fN/57cXBwkKurq8qXL2/Mu7q66tKlS/ZKDwCAEoVCLwAAxaxdu3aF+uPeqnPnzunQoUPGcUpKipKSkuTh4aE6depo5MiReuedd9SgQQP5+vrqjTfeUM2aNRUaGipJaty4sbp06aLnnntO8+bNU25uroYPH66+ffuqZs2akqT+/ftrwoQJGjRokMaOHavk5GTNnDlTM2bMuK3cgdKuYsWKat26tX788cdrxrRu3VoVK1YsxqyAu9OfX/T752MAAHDzKPQCAFDMfv75Z506dUoVKlSQl5eXnJycbvkc27ZtU0hIiHE8evRoSdLAgQO1cOFCvfLKKzp//rzCw8N15swZPfTQQ1q7dq1cXFyMzyxatEjDhw9Xhw4d5ODgoF69eunf//63Me/u7q5169Zp2LBh8vf3V7Vq1TRu3DiFh4ffxt0DZcMPP/ygBx98sMhib+vWrfXDDz/YISvg7mOxWHTvvfcaxd1z586pRYsWcnBwMOYBAMDNodALoEheXl5GW4agoCAlJCQYc0FBQVZxAG5Nhw4djJ68Dg4OatSokZ599lmNGjXqps8RHBx83X/8mkwmvfXWW3rrrbeuGePh4aHFixdf9zrNmjWz+u8fwM374YcfdO7cOT311FM6fPiw/Pz89Omnn7KSF7jKRx99ZO8UAAAoNSj0AihSWlqasbLi22+/veZX6HgRG3BrUlJSZLFYlJubq6ysLB0/flw//PCD3njjDV2+fFkRERH2ThGADVWsWFHLly+3dxrAXWvgwIH2TgEAgFLDwd4JALh73eircnyVDrh1devWVb169dSgQQP5+/urR48eevvttzV37lzNnz/f3ukBAFCsfvjhB+Xl5V1z/tKlS/riiy+KMSMAAEouCr0ArulGL8LgRRmA7fTt21eff/65vdMAAKBYtW3bVqdOnTKO3dzc9MsvvxjHZ86cUb9+/eyRGgAAJQ6FXgBFqlOnjrEfEhIii8VibFe/AOrqOAB/Xbly5dSyZUt7pwEAQLH68zfEivrGGN8iAwDg5lDoBVCko0ePGvsbN260mrv6+Oo4AAAAwNb4FhkAADeHQi8AAAAAAAAAlHCO9k4AAAAAAFB2/fzzz0pPT5d0pU3Dvn37dO7cOUnS77//bs/UAAAoUSj0AiiSj4+P0Zbhel+X8/HxKa6UgFIrLy9PZrPZ3mkAuANycnI0Z84cHT58WH5+fnrhhRfk5ORk77SAu0qHDh2s+vA++uijkq78DmqxWGjdAADATaLQC6BIR44cualfqo8cOVIM2QCl0969e/XEE0/o559/1r333qvPP/9cTZs2tXdaAGzklVde0dSpU60KWKNHj9bLL7+syZMn2zEz4O6RkpJi7xQAACg1KPQCAGAnERER8vb21qRJk/Tpp5/qpZdeKvTyQwAl0yuvvKIpU6YUGrdYLMY4xV5Aqlu3rr1TAACg1OBlbACKdLNfkeOrdMBft2PHDkVFRalbt26aMWOGduzYYe+UANhATk6OUcx1cnLSq6++qkOHDunVV1812jZMmTJFOTk59kwTAAAApQyFXgA3ZLFYCm0Abt/Zs2dVuXJlSVKVKlV09uxZ+yYEwCbee+89SZKjo6POnj2rqKgo+fn5KSoqSmfPnjV6chfEAQAAALZA6wYAAIrRV199Zezn5+drw4YNSk5OVm5urh2zAmBLn376qSRp6NChhV685uTkpCFDhmjOnDn69NNP9corr9gjRQAAAJRCFHoBAChGoaGhVsdDhgwx9mmFApQOBX+48fLyKnK+YJw/8AAAAMCWaN0A4IZq1ap13WMANy8/P/+aW15enr3TA2ADISEhkqR3331Xly9ftpq7fPmyJk2aZBUHoLC0tDRt3LhRx44ds3cqAACUGBR6ARTp6j68x48fl8lkMrbjx48XGQfgxj755BNdunTJ3mkAuIOmT58uSbpw4YK8vb01f/58HT9+XPPnz5e3t7cuXLhgFQfA2sqVK+Xr66uOHTvKz89PMTEx9k4JAIASgUIvgGu6URGXIi9w65555hllZmbaOw0Ad5Crq6t69uwpSfr99981ZMgQ1apVS0OGDNHvv/8uSerZs6dcXV3tmSZw13rnnXc0YsQInTt3ThMnTtT48ePtnRIAACUChV4A13SjfqH0EwVuHX8gAcqG2NhYo9j7Zz179lRsbGzxJgSUIIcOHdKzzz6r8uXLa9CgQTp48KC9UwIAoETgZWwAilS7dm1j/+GHH1Z8fLxxHBwcrG+++caI++2334o7PaBE++KLL+Tm5lbk3D/+8Y9izgbAnRIbG6tz587pqaee0uHDh/X/2Lv3qKrq/P/jr8NBEFQwTS5eQbTURE3HFBtKy/ESGAw6zeS90rzWeC8as7JGJhKpGTW/zVRapk0ZYaKZWmpUVF5TTAtRshKwMjiiCHI4vz/8sYeTB6/IBnk+1tqrsz/vN2e/N2vRxjef8/mEhITo9ddfV/369c0uDajWioqK5OnpKUmqW7euiouLTa4IAICagUYvAJfKb3xRvslbdl42m5cNMoBLFx8fL6vVes64xWKh0QtcQ5KSkjR9+nRlZWVJkvbu3avQ0FAlJCQoJibG3OKAambatGnG6+LiYv3973+Xr68vG5UCAHAJaPQCAFDFtm/fLj8/P7PLAHAVJSUlaciQIYqMjNTKlSvVsWNHpaena968eRoyZIhWrVpFsxcoZ9euXcbrXr166dChQ8b5bbfdZkZJAADUODR6AQAAgEpkt9s1ffp0RUZGKjk5WW5uZ7fF6Nmzp5KTkxUdHa0ZM2YoKirK5ex+oDbavHmz2SUAAFDjVfpmbHl5ebrjjjt0xx13aMiQIZX99gCqSLNmzYzXvXv3doqVPy+fB+DCWrVqRWMHuMalpqYqKytLjz32mNHkLePm5qbY2FgdPnxYqampJlUIVD/333+/Tpw4YXYZAADUaJc9o7dr164ux0tKSrRv3z7t3LlTderUuezCAJjrhx9+MNbh3bp1q/HaVR6Ai3f48GGzSwBwlWVnZ0uSOnbs6DJeNl6WB0BatmyZ/vGPf6hBgwZmlwIAQI112Y3e3bt3a/r06efsGnzixAnt27dPnTt3vuLiAJjL4XBU2OAtiwO4NA8//LDatGmjhx9+2Gl84cKFOnjwoJ5//nlzCgNQaQIDAyVJ6enp6tq1qxYvXqzMzEyFhIRo4sSJSk9Pd8oDcOHfOwEAwIVZHJfZqXFzc1NOTs45m8nk5OSoWbNm19zuqDabTb6+vsrPz5ePj4/Z5QBV4mJ+2abZi9qkMp4FzZo103vvvadu3bo5je/cuVN33333NTlLnmcoahu73a42bdrIarXq8OHDKi0tNWJubm4KDg5WaWmpMjIyWMoFtcaFngVubm7685//LC8vL5df/8orr1ztEqslnqGo7Xbu3Klu3bppx44dFX6yHLjWXcqz4LLX6LVYLC6bQPwVFrg2NGnSxHjds2dPORwO4+jZs6fLPAAX9ssvv8jX1/eccR8fH/38888mVASgslmtVnXu3FmZmZlOTV5JKi0tVWZmpjp16kSTF/iN8r9v/vYAAAAXdtmNXofDoRtuuEH+/v5q27at+vXrp2eeeUbff/99ZdYHwCTlG05paWlOsfLnNKaAS9OmTRutX7/+nPH3339frVu3NqEiAJWtuLhYa9asOW/OmjVrVFxcXEUVAdWfxWLRP//5T7366qsuj0vx8ccfa9CgQWratKksFouSk5Od4g6HQ3PmzFFgYKC8vLzUt29fZWRkOOUcP35cw4YNk4+Pjxo2bKgHHnhABQUFTjl79uxReHi46tatqxYtWig+Pv6cWt5++221a9dOdevWVWhoqNatW3dJ9wIAwKW47DV6yx62RUVF+uWXX3To0CG9/vrrevLJJyurNgAArjnTpk3T5MmT9dNPP+mOO+6QJH344YdKSEhgfV7gGrFw4cJzZvL+VmlpqRYuXKhp06ZVUVVA9VaZs3ZPnjypzp076/7771dMTMw58fj4eP3zn//UsmXLFBwcrMcff1z9+/fX119/rbp160qShg0bpuzsbG3cuFFnzpzRfffdpwcffFArVqyQdPZjtP369VPfvn21ZMkS7d27V/fff78aNmyoBx98UJL02Wef6d5771VcXJwiIyO1YsUKRUdHa+fOnRVu1ggAwBVxVLJ//vOfDovF4rjvvvscU6ZMqey3N01+fr5DkiM/P9/sUoAqIck4LicOXIsq61mwePFiR7NmzRwWi8VhsVgcwcHBjmXLllVSldUPz1DUNoMGDTKekXXq1HE8+uijjoMHDzoeffRRR506dYzYoEGDzC4VqDIXehaMHj3aYbPZKv26khzvvvuucV5aWuoICAhwPPfcc8ZYXl6ew9PT07Fy5UqHw+FwfP311w5Jjm3bthk577//vsNisTh+/PFHh8Nx9ll+3XXXOYqKioycRx55xHHjjTca5/fcc48jIiLCqZ4ePXo4xo0bd9H18wxFbbdjxw6HJMeOHTvMLgUwzaU8Cy576YaKjB07Vq+++qpuv/12hYWFVfbbA6gi119/vfG6bE3u8oerPAAXZ8KECfrhhx+Um5srm82mQ4cOaeTIkWaXBaCSlN9UsaCgQHFxcQoJCVFcXJzTR7+vxc0Xgcv1/PPP68yZM+eMHz9+XDabrdKuc/jwYeXk5Khv377GmK+vr3r06GEsT5aWlqaGDRvqd7/7nZHTt29fubm56YsvvjBybrvtNnl4eBg5/fv31zfffKNff/3VyCl/nbKc3y6LVl5RUZFsNpvTAQDAxaqURq+j3AL5devW1ahRozRq1Cjdc889lfH2AEzw008/VWoeAGc//fSTvvnmG+3evZu1roFrTFmTx9PTU25uzr9uu7m5GY2hsjwA0l/+8he9+eab54y/9dZb+stf/lJp18nJyZEk+fv7O437+/sbsZycHPn5+TnF3d3d1ahRI6ccV+9R/hoV5ZTFXYmLi5Ovr69xtGjR4lJvEQBQi11Ro/e1115TaGiovLy85OXlpU6dOun111+vrNoAALjmnDx5Uvfff78CAwN122236bbbblNgYKAeeOABnTp1yuzyAFSCOnXqSDo7M69Zs2Z66aWXdPToUb300ktq1qyZsQlbWR4A6YsvvlCfPn3OGe/du7cxi7Y2iI2NVX5+vnGw2TkA4FJcdqN3wYIFmjBhgu666y699dZbeuuttzRgwACNHz9eiYmJlVkjABOEh4dXah6As6ZNm6atW7dqzZo1ysvLU15enlavXq2tW7dq+vTpZpcHoBKUbbQoSceOHdO4cePUrFkzjRs3TseOHXOZB9R2RUVFKikpOWf8zJkzKiwsrLTrBAQESJJyc3OdxnNzc41YQECA08+qJJWUlOj48eNOOa7eo/w1Ksopi7vi6ekpHx8fpwMAgIt12Y3ef/3rX3rxxRf17LPP6u6779bdd9+t+Ph4LV68WP/85z8rs0YAJvjkk0+M12XLs5Q/XOUBuLB33nlHL7/8sgYOHGj8A+6uu+7Sv//9b61atcrs8gBUgvKTHlwt3eAqD6jtbrnlFr300kvnjC9ZskTdunWrtOsEBwcrICBAH374oTFms9n0xRdfGHvMhIWFKS8vTzt27DByPvroI5WWlqpHjx5Gzscff+y0rvDGjRt144036rrrrjNyyl+nLIe9bAAAV4v75X5hdna2evXqdc54r169lJ2dfUVFAQBwrTp16tQ56/VJkp+fH0s3ANcILy8vRUVFafXq1SotLXWKlZ1HRUXJy8vLjPKAaumZZ55R37599dVXX+nOO++UJH344Yfatm2bNmzYcEnvVVBQoIMHDxrnhw8f1u7du9WoUSO1bNlSU6ZM0TPPPKO2bdsqODhYjz/+uJo2baro6GhJUvv27TVgwACNHTtWS5Ys0ZkzZzR58mT95S9/UdOmTSVJQ4cO1VNPPaUHHnhAjzzyiNLT0/XCCy84/QHnr3/9q26//XYlJCQoIiJCb775prZv3+6yoQ0AQGW47Bm9bdq00VtvvXXO+H//+1+1bdv2iooCAOBaFRYWpieeeEKnT582xgoLC/XUU08xwwe4hiQnJysqKsplLCoqSsnJyVVbEFDN3XrrrUpLS1Pz5s311ltvac2aNWrTpo327NlzyUuFbd++XTfffLNuvvlmSWeXTbr55ps1Z84cSdKsWbP00EMP6cEHH1T37t1VUFCg9evXq27dusZ7vPHGG2rXrp3uvPNO3XXXXfr973/v1KD19fXVhg0bdPjwYXXr1k3Tp0/XnDlz9OCDDxo5vXr10ooVK/TSSy+pc+fOWrVqlZKTk9WxY8cr+VYBAFAhi6P8Z7AvwTvvvKM///nP6tu3r2699VZJ0qeffqoPP/xQb731lv74xz9WaqFms9ls8vX1VX5+PuskoVYIDw83lmUYPXq0Xn31VSN23333aenSpZKk3//+90pNTTWjRKDKVcazID09Xf3791dRUZE6d+4sSfrqq69Ut25dffDBB7rpppsqs+RqgWcoarPCwkLNnDlTGRkZatu2rZ577jlm8qJW4llwefi+obbbuXOnunXrph07dqhr165mlwOY4lKeBZfd6JWkHTt2KDExUfv375d09iMu06dPN/5yei3hAYvayGKxXDDnCv4XAtQ4lfUsOHXqlN544w0dOHBA0tnn57Bhw67Z5g/PUADAxTwL7Ha7kpOTjX9f3nTTTbr77rtltVqrstRqhWcoajsavcClPQsueY3eBx98UAsWLFD9+vXVrVs3LV++/LILBVC9ORyO8zZ7afICl8fb21tjx441uwwAVcButys1NVXZ2dkKDAxUeHh4rW5aARU5ePCgIiIi9MMPP+jGG2+UJMXFxalFixZau3atQkJCTK4QAIDq75IbvS+//LKeeeYZ1a9f/2rUA6AaudCMXovFQrMXuETvvffeeeN33313FVUC4GpLSkrS9OnTlZWVZYwFBQUpISFBMTEx5hUGVEMPP/ywWrdurbS0NDVq1EiS9Msvv2j48OF6+OGHtXbtWpMrBACg+rvkRi9NHaB26Nu3r/F63LhxWrJkiXE+fvx4/d///Z+Rt2nTpiqvD6ipynb0ls79Y4nFYpHdbjehKgCVLSkpSUOGDFFkZKRWrlypjh07Kj09XfPmzdOQIUO0atUqmr1AOVu3btXnn39uNHklqXHjxvrHP/5h7AkDAADOz83sAgBUTx9++KHxunyT97fn5fMAXFhpaalxeHt76+DBg8Y5TV7g2mC32zV9+nRFRkYqOTlZPXv2VP369dWzZ08lJycrMjJSM2bM4GceKMfT01MnTpw4Z7ygoEAeHh4mVAQAQM1zyY1ei8VyURs0AQAAALVRamqqsrKy9Nhjj8nNzfnXbTc3N8XGxurw4cNKTU01qUKg+omMjNSDDz6oL774Qg6HQw6HQ59//rnGjx/PskYAAFyky1q6YfTo0fL09DxvXlJS0mUXBQAAANRU2dnZkqSOHTu6jJeNl+UBkP75z39q1KhRCgsLU506dSRJJSUluvvuu/XCCy+YXB0AADXDJTd6R40adTXqAFDN3HnnncayDH5+fvrpp5+MWJMmTZzyAFw8m81mvLZYLCooKHAa8/HxMaMsAJUoMDBQkpSenq6ePXueE09PT3fKAyA1bNhQq1evVkZGhg4cOCBJat++vdq0aWNyZQAA1BwWB7urXRSbzSZfX1/l5+fzj3DUGhezTAv/C0FtUhnPAjc3N+Nny+FwnPP6Wlyzk2coahu73a42bdooNDRU77zzjj799FNlZ2crMDBQt956qwYPHqz09HRlZGTIarWaXS5QJXgWXB6+b6jtdu7cqW7dumnHjh3q2rWr2eUApriUZ8Elz+gFAACXb/PmzWaXAOAqs1qtSkhI0JAhQ+Tr66vCwkIj5uXlpdOnT2vVqlU0eYFy7r///vPGX3nllSqqBACAmotGLwCXJkyYYLxu1KiRjh8/7vJ8woQJevHFF6u8PqCmuv32280uAUAVcTgcOn36tNPY6dOn+TQM4MLSpUvVvHlz/e53v+NnBACAy8TSDReJj8ygtim/bIOr/01cKA5ci67ms+DMmTO68cYbJUmenp7av39/pb6/mXiGorax2+1q2rSpjh07poiICN11113y8vJSYWGh1q1bp7Vr18rPz09Hjx5lVi9qjQs9C1544QX9+9//lru7u8aOHasRI0bwzBDPUIClGwCWbgBQifgHKFC5rrvuugrXv87Pz9fx48cvan1sANXXli1bdOzYMf3+97/Xe++9Jzc3NyM2fvx43Xbbbfr000+1ZcsWNjUF/r+//vWv+utf/6pPP/1UL730kp544gkNGjRIjz76qPGHUAAAcH40egGc17W4MRRgpueff97leHFxscaPHy9fX9+qLQhApduyZYsk6amnnnJq8kpnN2R88skn9Yc//IFGL+DCrbfeqltvvVUrV67U+PHj1aFDB82cOdPssgAAqBFo9AJwafz48VqyZIkkad68eXrssceM2Lx585zyAFy8UaNGuRwvKiri5wkAUKtlZ2fr5Zdf1ssvv6xmzZrpX//6l+655x6zywIAoMZwu3AKgNqo/AZrf/vb32SxWIzjb3/7m8s8AAAg9e7dW5L0xBNPqLS01ClWWlqqp556yikPgBQdHa0uXbro559/1tq1a/XJJ59o5MiRqlu3rtmlAQBQYzCjF0CFHA7HedcKZRM24NLNnTvX5XhJSUkVVwLgaundu7eaNGmiTz75RFFRUXrsscfUsWNHpaena968efrkk0/k5+dHoxco57333pO3t7eWLVum11577Zz48ePHTagKAICahUYvgApdaEMoi8VCsxe4RO+++67LcX6WgGuH1WrVkiVLNHjwYH344YdKSUkxYt7e3pLOfiKGDU+B/3n11VfNLgEAgBqPRi8AlwYNGmS8njJlihITE43zqVOnGhtKDRo0SGvWrKnq8oAaa9euXS7HT58+rXr16lVxNQCulpiYGL3zzjuaNm2avvvuO2Pcz89PCQkJiomJMbE6oPqpaA17AABw8SwOphBdFJvNJl9fX+Xn58vHx8fscoCrrvxsXlf/m7hQHLgWXc1nQVFRkby9vWW32yv1fasDnqGozex2u1JTU5Wdna3AwECFh4czkxe10oWeBTab7bxfX1ufHzxDUdvt3LlT3bp1044dO9S1a1ezywFMcSnPAmb0AgBQhSr6h+zp06eruBIAVcFqtbIWL3ARGjZs6HLZsLI9I67FP4QCAFDZaPQCAFCFLvQPWQAAaqPWrVvr2LFjevTRR3XrrbeaXQ4AADUSjV4ALkVGRhqbx3Tq1El79+41YqGhoU55AC7e5s2bzS4BAIBqZ//+/frXv/6lv//979q1a5fi4+MVHBxsdlkAANQoNHoBuLRmzRpjdmH5Ju9vz9mIDbg0t99+u9klAABQ7dSpU0fTpk3T6NGjNXfuXHXq1EkPPvigHn/8cTVs2NDs8gAAqBHczC4AAIDaJi8vTwkJCRozZozGjBmjxMRE5efnm10WAACma9SokZ5//nnt2rVLWVlZatOmjZ5//nmzywIAoEag0QvApaeeesp43bZtW6dY+fPyeQAubPv27QoJCVFiYqKOHz+u48ePa8GCBQoJCdHOnTvNLg8AAFPcfPPN6tq1q3Hcc889OnTokIqKijR9+nSzywMAoEZg6QYALj355JPG62+//faceNmyDk8++aSeeOKJqioLqPGmTp2qu+++W//+97/l7n72MVxSUqIxY8ZoypQp+vjjj02uEEBlstvtSk1NVXZ2tgIDAxUeHi6r1Wp2WUC1Ex0dbXYJAADUeDR6AZyXr6+vy/H69euroKCgiqsBar7t27c7NXklyd3dXbNmzdLvfvc7EysDUNmSkpI0ffp0ZWVlGWNBQUFKSEhQTEyMeYUB1RATBwAAuHI0egGcV0XrhtLkBS6Pj4+Pjhw5onbt2jmNf//992rQoIFJVQGobElJSRoyZIjuuusuRUVFqbCwUF5eXjp48KCGDBmiVatW0ewFXNixY4f2798vSbrpppt08803m1wRAAA1B41eAC49+eSTxvINr7zyiu6//34j9sorrzjlAbh4f/7zn/XAAw9o/vz56tWrlyTp008/1cyZM3XvvfeaXB2AymC32zV9+nS1bt1aH3zwgdauXWvE3N3d1bp1a82YMUNRUVEs4wD8f8eOHdNf/vIXbdmyRQ0bNpR0dvPSPn366M0331STJk3MLRAAgBqAzdgAuFT+43MPPPCALBaLcTzwwAMu8wBc2Pz58xUTE6ORI0cqKChIQUFBGj16tIYMGaJnn33W7PIAVILU1FRlZWUpMzNTjRs31r///W9lZ2fr3//+txo3bqzMzEwdPnxYqampZpcKVBsPPfSQTpw4oX379hmblaanp8tms+nhhx82uzwAAGoEZvQCqJDD4TA2XasoDuDSeHh46IUXXlBcXJwyMzMlSSEhIfL29ja5MgCV5fvvv5ck+fn56YcffjDW5B4zZoxGjx6tZs2a6dixY0YeAGn9+vXatGmT2rdvb4x16NBBixYtUr9+/UysDACAmoMZvQAqdL4m78XEAVTM29tboaGhCg0NpckLXGO++OILSdL999/vtPGidHbphtGjRzvlAZBKS0tVp06dc8br1Kmj0tJSEyoCAKDmYUYvAJf+/ve/G6+XLVumkSNHGuevvfaaRo0aZeT97W9/q/L6gJqm/DrX51N+DWwANVPZJ1527Nih0tJSubn9b25FaWmpdu3a5ZQHQLrjjjv017/+VStXrlTTpk0lST/++KOmTp2qO++80+TqAACoGZjRC8Cl2bNnG6/LN3l/e14+D0DFli5dqs2bNysvL0+//vprhQeAmq9t27aSpI0bNyo6OlppaWk6ceKE0tLSFB0drY0bNzrlAZAWLlwom82moKAghYSEKCQkRMHBwbLZbPrXv/5ldnkAANQIzOgFcF7XXXedy3EfHx/ZbLYqrgaouSZMmKCVK1fq8OHDuu+++zR8+HA1atTI7LIAXAUTJ07UzJkzVa9ePX311Vfq1auXEWvVqpV8fX118uRJTZw40cQqgeqlRYsW2rlzpzZt2qQDBw5Iktq3b6++ffuaXBkAADUHM3oBnFdFMwxp8gKXZtGiRcrOztasWbO0Zs0atWjRQvfcc48++OADPr4NXGM8PDw0depU5efnq6ioSNOmTdPChQs1bdo0nT59Wvn5+Zo6dao8PDzMLhWoNl577TUVFxfrD3/4gx566CE99NBDNHkBALhENHoBuPTMM88Yr4cNGyaLxWIcw4YNc5kH4Pw8PT117733auPGjfr666910003aeLEiQoKClJBQYHZ5QGoRPHx8Zo5c6Z++eUXLViwQJMnT9aCBQv0yy+/aObMmYqPjze7RKBaue+++5Sfn292GQAA1Gg0egG4VH6DtRUrVjjFyp+zERtwedzc3GSxWORwOGS3280uB8BVEB8fL5vNpkmTJqlfv36aNGmSbDYbTV7ABT7dAgDAlWONXgAAqkhRUZGSkpL0yiuv6JNPPlFkZKQWLlyoAQMGyM2Nv70C15qkpCRNnz5dWVlZkqQNGzZo7dq1SkhIUExMjLnFAdXQW2+9JR8fH5ex324ODAAAzkWjF4BL//d//2e8/uMf/6h3333X5fn//d//ady4cVVeH1DTTJw4UW+++aZatGih+++/XytXrtT1119vdlkArpKkpCQNGTJEERERmjlzpry8vFRYWKj3339fQ4YM0apVq2j2Ar8RHx8vq9V6zrjFYqHRCwDARbA4+IzMRbHZbPL19VV+fn6Ff2UGriUWi8V47ep/ExeKA9eiK3kWuLm5qWXLlrr55pudfn5+Kykp6UrLrHZ4hqK2sdvtatOmja6//nr99NNP+u6774xYq1at1KRJE/3yyy/KyMhw2dQCrkUXeha4ubkpJydHfn5+JlRXffEMRW23c+dOdevWTTt27FDXrl3NLgcwxaU8C/icKIDzat26tcvxFi1aVHElQM02cuRI9enTRw0bNpSvr2+FB4CaLzU1VVlZWdq+fbs6deqktLQ0nThxQmlpaerUqZO2b9+uw4cPKzU11exSAQAAcA1h6QYA53Xo0CGX499//30VVwLUbEuXLjW7BABV5Mcff5QkDRw4UMnJycYa3D179lRycrIiIyP1/vvvG3kAzs52Z4Y7AABXhhm9AFxasmSJ8XrdunVOsfLn5fMAAID0008/SZJiYmLO2WjRzc1N0dHRTnkApMOHD6tx48ZmlwEAQI1GoxeAS+U3WIuIiJDFYjGOiIgIl3kAAEBq0qSJpLNrbpeWljrFSktLlZyc7JQH1GYfffSROnToIJvNdk4sPz9fN910E8ucAABwkVi6AUCFHA7HeTeNYhM2AADO1axZM0nS+vXrFRUVpQEDBsjLy0uFhYVav3691q9f75QH1GbPP/+8xo4d63JzGV9fX40bN04LFixQeHi4CdUBAFCz0OgFUKHzNXnL4jR7AQBwFh4erqCgIFmtVq1fv14pKSlGzN3dXa1bt1ZpaSmNK0DSV199pWeffbbCeL9+/TR//vwqrAgAgJqLpRsAuFQ220iSdu3aJYfDYRy7du1ymQegegkKCnJadqXsmDRpkiSpd+/e58TGjx/v9B5HjhxRRESEvL295efnp5kzZ6qkpMSM2wFqDKvVqj/96U/KzMyU3W53itntdmVmZmrIkCFsPAVIys3NVZ06dSqMu7u7s541AAAXiUYvAJcGDhxovO7SpYtTrPx5+TwA1cu2bduUnZ1tHBs3bpQk/elPfzJyxo4d65QTHx9vxOx2uyIiIlRcXKzPPvtMy5Yt09KlSzVnzpwqvxegJrHb7Vq2bJmkc5c5KjtftmzZOU1goDZq1qyZ0tPTK4zv2bNHgYGBVVgRAAA1F41eAOdVUSP3jjvuqOJKAFyqJk2aKCAgwDhSUlIUEhKi22+/3cjx9vZ2yim/RuKGDRv09ddfa/ny5erSpYsGDhyop59+WosWLVJxcbEZtwTUCFu2bNGxY8ckSR4eHho6dKgWLFigoUOHysPDQ5J07NgxbdmyxcQqgerhrrvu0uOPP67Tp0+fEyssLNQTTzyhyMhIEyoDAKDmodEL4Lzef/99l+MfffRRFVcC4EoUFxdr+fLluv/++53W337jjTd0/fXXq2PHjoqNjdWpU6eMWFpamkJDQ+Xv72+M9e/fXzabTfv27avS+oGaZMOGDZLOfuQ8Ly9PY8eOVUBAgMaOHau8vDy5u7s75QG12ezZs3X8+HHdcMMNio+P1+rVq7V69Wo9++yzuvHGG3X8+HH97W9/M7tMAABqBDZjA+DS+++/b8zmffrpp50+qj137lynPADVX3JysvLy8jR69GhjbOjQoWrVqpWaNm2qPXv26JFHHtE333yjpKQkSVJOTo5Tk1eScZ6Tk1PhtYqKilRUVGSc22y2SrwToPrbtGmTJKlnz57q0KGDsrKyjFhQUJB69OihTz/91MgDajN/f3999tlnmjBhgmJjY43lTSwWi/r3769Fixad8ywCAACu0egF4NKAAQOM179dj7P8efk8ANXXyy+/rIEDB6pp06bG2IMPPmi8Dg0NVWBgoO68805lZmYqJCTksq8VFxenp5566orqBWqyslnzn3zyiSIjI7Vy5Up17NhR6enp+vvf/66UlBSnPKC2a9WqldatW6dff/1VBw8elMPhUNu2bXXdddeZXRoAADUKSzcAAHCN++6777Rp0yaNGTPmvHk9evSQJB08eFCSFBAQoNzcXKecsvOAgIAK3yc2Nlb5+fnG8f33319J+UCN061bN6dzh8NhHOfLA2q76667Tt27d9ctt9xCkxcAgMtAoxeAS//973+N1/PmzXOKlT8vnwegenr11Vfl5+eniIiI8+bt3r1bkozdzcPCwrR3715jUylJ2rhxo3x8fNShQ4cK38fT01M+Pj5OB1CbxMTEGK83bdqkXr16ycfHR7169XJarqF8HgAAAHClaPQCcOkvf/mL8bpsvbSyIzY21mUegOqntLRUr776qkaNGmVsACVJmZmZevrpp7Vjxw5lZWXpvffe08iRI3XbbbepU6dOkqR+/fqpQ4cOGjFihL766it98MEHmj17tiZNmiRPT0+zbgmo9o4fP268Pn36tFOs/Hn5PAAAAOBK0egFcF5lH+X+rZtvvrmKKwFwOTZt2qQjR47o/vvvdxr38PDQpk2b1K9fP7Vr107Tp0/X4MGDtWbNGiPHarUqJSVFVqtVYWFhGj58uEaOHOm0ISOAc5XNiq+sPAAAAOBisBkbgPP64osvXI7v2rWriisBcDn69et3zrqgktSiRQtt3br1gl9ftkEOgIvXq1cvubu7q3HjxsrIyFBsbKwyMjLUtm1bxcXFqW3btvrll1/Uq1cvs0sFAADANYQZvQBcevPNN43Xn332mVOs/Hn5PAAAcPY5WVJSotzcXA0bNkzDhg3TqlWrjNe5ubkqKSk55/kKAAAAXAlTG70ff/yxBg0apKZNm8pisSg5Odkpnpubq9GjR6tp06by9vbWgAEDlJGRcc77pKWl6Y477lC9evXk4+Oj2267TYWFhUb8+PHjGjZsmHx8fNSwYUM98MADKigouNq3B9Rof/7zn43Xt956qywWi3HceuutLvMAAICUnZ0tSVq+fLn27t3rtBlbenq6li9f7pQHAAAAVAZTG70nT55U586dtWjRonNiDodD0dHROnTokFavXq1du3apVatW6tu3r06ePGnkpaWlacCAAerXr5++/PJLbdu2TZMnT5ab2/9ubdiwYdq3b582btyolJQUffzxx3rwwQer5B6BmszVx70vJQ4AQG1UtvZuSEiIDh48qM2bN2vFihXavHmzMjIy1Lp1a6c8AAAAoDJYHNWkU2OxWPTuu+8qOjpakvTtt9/qxhtvVHp6um666SZJZ3cODwgI0Lx58zRmzBhJUs+ePfWHP/xBTz/9tMv33b9/vzp06KBt27bpd7/7nSRp/fr1uuuuu/TDDz+oadOmF1WfzWaTr6+v8vPz5ePjc4V3C9QMFovlgjnV5H8hQJXgWXB5+L6htrHb7WrTpo1CQ0OVnJzsNAGhtLRU0dHRSk9PV0ZGhqxWq4mVAlWHZ8Hl4fuG2m7nzp3q1q2bduzYoa5du5pdDmCKS3kWVNs1eouKiiRJdevWNcbc3Nzk6empTz75RJJ07NgxffHFF/Lz81OvXr3k7++v22+/3YhLZ2f8NmzY0GjySlLfvn3l5uZW4SZTAKSpU6carxMSEuRwOIwjISHBZR4AAJCsVqsSEhKUkpKi6OhopaWl6cSJE0pLS1N0dLRSUlI0f/58mrwAAACoVNW20duuXTu1bNlSsbGx+vXXX1VcXKxnn31WP/zwg7Ge2aFDhyRJTz75pMaOHav169era9euuvPOO421fHNycuTn5+f03u7u7mrUqJFycnIqvH5RUZFsNpvTAdQmzz//vPF62rRpTrHy5+XzAADAWTExMVq1apXLNXpXrVqlmJgYs0sEAADANabaNnrr1KmjpKQkffvtt2rUqJG8vb21efNmDRw40Pj4W2lpqSRp3Lhxuu+++3TzzTcrMTFRN954o1555ZUrun5cXJx8fX2No0WLFld8T0BN5Onp6XLc3d29iisBAKBmiYmJcblGL01eAAAAXA3VttErSd26ddPu3buVl5en7OxsrV+/Xr/88ss5G1h06NDB6evat2+vI0eOSJICAgJ07Ngxp3hJSYmOHz+ugICACq8dGxur/Px84/j+++8r89aAGqNsGZXfKikpqeJKAAAAAAAAUJFq3egt4+vrqyZNmigjI0Pbt29XVFSUJCkoKEhNmzbVN99845T/7bffqlWrVpKksLAw5eXlaceOHUb8o48+UmlpqXr06FHhNT09PeXj4+N0ALXJlClTjNdjxoyRxWIxjrLNEH+bBwAA/icpKUkhISHq06ePhg4dqj59+igkJERJSUlmlwYAAIBrkKmN3oKCAu3evVu7d++WJB0+fFi7d+82ZuO+/fbb2rJliw4dOqTVq1frD3/4g6Kjo9WvXz9JksVi0cyZM/XPf/5Tq1at0sGDB/X444/rwIEDeuCBBySdnd07YMAAjR07Vl9++aU+/fRTTZ48WX/5y1/UtGlTU+4bqAkSExON1y+//LJTrPx5+TwAAHBWUlKSBg8ebPxeW+bIkSMaPHgwzV4AAABUOlMX2dy+fbv69OljnJdt8DRq1CgtXbpU2dnZmjZtmnJzcxUYGKiRI0fq8ccfd3qPKVOm6PTp05o6daqOHz+uzp07a+PGjQoJCTFy3njjDU2ePFl33nmn3NzcNHjwYP3zn/+smpsEAABArWK323XfffdJkpo0aaKRI0eqdevWOnTokF577TUdO3ZM9913n6KiomS1Wk2uFgAAANcKi8PhcJhdRE1gs9nk6+ur/Px8lnFArbBx40Zj9nxMTIzTzKPy5xs2bNAf/vAHU2oEqhrPgsvD9w21zYYNG9S/f3/Vr19fjRo1cprV27JlSx0/flwFBQX64IMPjGctcK3jWXB5+L6httu5c6e6deumHTt2qGvXrmaXA5jiUp4FNWKNXgBVr/w/PN955x05HA7jeOedd1zmAQAA6fXXX5d0dpmyzp07Ky0tTSdOnFBaWpo6d+6sgoICpzwAAACgMtDoBXBegwYNcjlOgxcAANdOnDghSerevbuSk5PVs2dP1a9fXz179lRycrK6d+/ulAcAAABUBlPX6AVQ/a1Zs8bl+IYNG6q4EgAAaoayDX9//fVX2e12ffzxx8rOzlZgYKBuvfVWHT9+3CkPAAAAqAw0egG4tGHDBmPW7p49e9SpUycjtmfPHqc8AADwP2FhYXrxxRd18OBBNWjQQEVFRUbM09PTOA8LCzOrRAAAAFyDaPQCcKn8BmudO3e+qDwAACC1aNHCeF2+yfvb8/J5AAAAwJVijV4AFXI4HFcUBwCgNurVq5fc3M7/a7abm5t69epVRRUBKC8oKEgWi+WcY9KkSZKk3r17nxMbP36803scOXJEERER8vb2lp+fn2bOnKmSkhKnnC1btqhr167y9PRUmzZttHTp0qq6RQBALUWjF0CFLBbLFcUBAKiNUlNTVVpaKunsUg3llZ2XlpYqNTW1ymsDIG3btk3Z2dnGsXHjRknSn/70JyNn7NixTjnx8fFGzG63KyIiQsXFxfrss8+0bNkyLV26VHPmzDFyDh8+rIiICPXp00e7d+/WlClTNGbMGH3wwQdVd6MAgFqHRi8Al77++mvj9ffffy+Hw2Ec33//vcs8AABwdhZfmd/O7LVarS7zAFSdJk2aKCAgwDhSUlIUEhKi22+/3cjx9vZ2yvHx8TFiGzZs0Ndff63ly5erS5cuGjhwoJ5++mktWrRIxcXFkqQlS5YoODhYCQkJat++vSZPnqwhQ4YoMTGxyu8XAFB70OgF4FJoaKgkqU6dOmrevLlTrHnz5qpTp45THgAAOKtsNm9YWJiOHz+uxMRETZ48WYmJifrll1/Us2dPpzwA5ikuLtby5ct1//33O31a7Y033tD111+vjh07KjY2VqdOnTJiaWlpCg0Nlb+/vzHWv39/2Ww27du3z8jp27ev07X69++vtLS0q3xHAIDajM3YALhU9o/PRx991GV86tSpio+P5x+pAAD8RqNGjSRJR48eVbt27fTdd98Zseeff/6cPADmSU5OVl5enkaPHm2MDR06VK1atVLTpk21Z88ePfLII/rmm2+UlJQkScrJyXFq8koyznNycs6bY7PZVFhYKC8vL5f1FBUVOW3aaLPZrvgeAQC1BzN6AbhU9lHTf/zjHy7jZR87u9BmMwAA1DYBAQGSpO+++06FhYV66aWXdPToUb300ksqLCw0Gr9leQDM8/LLL2vgwIFq2rSpMfbggw+qf//+Cg0N1bBhw/Taa6/p3XffVWZm5lWvJy4uTr6+vsbRokWLq35NAMC1gw4NAJf27t0rSTpz5oy2b9+ugIAA1a1bVwEBAdq+fbvOnDnjlAcAAM4q38A9ceKEHnzwQTVt2lQPPvigCgoKXOYBqHrfffedNm3apDFjxpw3r0ePHpKkgwcPSjr7s5ubm+uUU3Ze9nNdUY6Pj0+Fs3klKTY2Vvn5+cZRfm8MAAAuhEYvAJc6dOhgvO7evbtyc3NVVFSk3Nxcde/e3WUeAAD4n3bt2rn86Ha7du1MqghAea+++qr8/PwUERFx3rzdu3dLkgIDAyWdXX977969OnbsmJGzceNG+fj4GL8bh4WF6cMPP3R6n40bNyosLOy81/L09JSPj4/TAQDAxWKNXgAV8vb2dtp4wlUcAAA4K2v+fPPNN4qIiNCMGTPk5eWlwsJCrV+/XmvXrnXKA1D1SktL9eqrr2rUqFFyd//fP4szMzO1YsUK3XXXXWrcuLH27NmjqVOn6rbbblOnTp0kSf369VOHDh00YsQIxcfHKycnR7Nnz9akSZPk6ekpSRo/frwWLlyoWbNm6f7779dHH32kt956y/j5BwDgamBGLwCXcnJyjCbvp59+aqzF6+bmpk8//VSSdOrUKWPDCQAAcFbZrL958+YpPT1dkydP1gMPPKDJkydr3759+vvf/+6UB6Dqbdq0SUeOHNH999/vNO7h4aFNmzapX79+ateunaZPn67BgwdrzZo1Ro7ValVKSoqsVqvCwsI0fPhwjRw5UnPnzjVygoODtXbtWm3cuFGdO3dWQkKC/vOf/6h///5Vdo8AgNqHGb0AXOrSpYuks7+k9urVS3a73SneqlUrfffdd+rSpQvNXgAAygkPD1dQUJA+++wz7d+/X0uWLFFmZqZCQkI0fvx43XPPPQoODlZ4eLjZpQK1Vr9+/eRwOM4Zb9GihbZu3XrBr2/VqpXWrVt33pzevXtr165dl10jAACXikYvAJfy8vIkSfHx8S7j8+bN07Bhw4w8AABwltVqVUJCggYPHqyGDRuqqKjIiD366KMqKirSO++8I6vVamKVAAAAuNawdAMAlxo2bChJmjVrlsv4Y4895pQHAADOVb7J6+ocAAAAqCw0egG4VLa78OHDh8+ZtZuXl6fvvvvOKQ8AAJxlt9t13333SZL8/Px0zz336L777tM999wjPz8/SdJ99913zrJIAAAAwJVg6QYALgUEBMjb21unTp3Sdddd5zLH29tbAQEBVVwZAADV24cffiibzab69evLy8tLb731lhFr1aqV6tevL5vNpg8//FD9+vUzsVIAAABcS5jRC6BCJ0+evKI4AAC10euvvy5JKigoUGhoqBYtWqRXXnlFixYtUmhoqAoKCpzyAAAAgMrAjF4AFbJYLOecl9+d+LfnAABAOnHihCSpTZs22rt3r1JSUoxYq1at1KZNGx08eNDIAwAAACoDM3oBuLR3717j9XfffSeHw6HS0lI5HA5jfd7f5gEAACkwMFCSdPDgQYWGhiotLU0nTpxQWlqaQkNDdfDgQac8AAAAoDLQ6AXgUufOnSVJVqtVLVu2dIq1bNlSVqvVKQ8AAJzVs2dP43XZH0nLjtLSUpd5AAAAwJVi6QYALpUtyTBjxgyX8cmTJ+uFF15g6QYAAH7j119/NV6vX79e69atM87L/lD62zwAAADgSjGjF4BLZevzzp8/32V84cKFTnkAAOCsJk2aSJKCg4NdrncfHBzslAcAAABUBmb0AnDpq6++UqdOnWS325WWlqaIiAidOHFCDRo00Nq1a2W32408AADwP82aNZMkZWVl6a677lJISIhOnz6tunXrKjMz05jhW5YHAEBNkZGRUaWbie7fv9/pv1WlQYMGatu2bZVeE6gMFgefu74oNptNvr6+ys/Pl4+Pj9nlAFXiYmbr8r8Q1CY8Cy4P3zfUNna7XW3atNH111+vn3/+WVlZWUYsODhYjRs31i+//KKMjAynpRyAaxnPgsvD9w3VSUZGhm644Qazy6gy3377Lc1eVAuX8ixgRi+ACnl4eKi4uPi8cQAA4MxqtSohIUFDhgzRwIED1bVrV+Xl5alhw4Y6ffq03n//fa1atYomLwCgRimbybt8+XK1b9++Sq5ZWFiorKwsBQUFycvLq0quuX//fg0fPrxKZy4DlYVGLwCXfvzxR6PJu2XLFvXp00cOh0MWi0WbN29W7969VVxcrB9//JGPngIA8BsxMTG6++67tXr16nNiUVFRiomJMaEqAACuXPv27dW1a9cqu96tt95aZdcCajoavQBcCg0NlSQFBgbq9ttvV2lpqVM8ICBAOTk5Cg0N1fHjx80oEQCAamvWrFlavXq1/P39NWLECLVu3VqHDh3S66+/rtWrV2vWrFmKj483u0wAAABcQ9zMLgBA9VT2MZVnn33WZfyZZ55xygMAAGcVFxcrMTFR/v7+OnTokJo1a6avv/5azZo106FDh+Tv76/ExMTzLo8EAAAAXCoavQBcatCggSTpkUcecRmfPXu2Ux4AADhr8eLFKikpUZcuXeTr66upU6dq4cKFmjp1qnx9fdWpUyeVlJRo8eLFZpcKAACAawhLNwBwae/evWrevLmys7N1/PhxNWrUyIgdP35cOTk5Rh4AAPifzMxMSdIHH3ygJk2a6KabbjLWud+3b582btzolAcAAABUBhq9AFxq1qyZPDw8VFxcrMaNG8tiscjNzU2lpaVyOBySJA8PDzZiAwDgN1q2bClJslqt+umnn7RlyxanuNVqld1uN/IAAACAysDSDQAqVFRUZLx2OByy2+1Gk/e3cQAA4Mxut1/SOAAAAHAlaPQCqFC9evWuKA4AQG10sUsysHQDAAAAKhONXgAu5eTk6NSpU5KkX3/9VQ6Hwzh+/fVXSdKpU6eMtXoBAMBZO3furNQ8AAAA4GKwRi8Al7p06SJJCg4OVsOGDZ1iDRs2VKtWrfTdd9+pS5cuNHsBACjnq6++Ml5nZGQoJSVFmZmZCgkJUWRkpNq2bXtOHgAAAHClmNELwKW8vDxJUnx8vMv4vHnznPIAAMBZxcXFxuvf//738vb2VmxsrLy9vfX73//eZR4AAABwpZjRC8Clhg0bKjc3V7NmzdKQIUPOiT/22GNGHgAAcO2nn37SuHHjjHOr1WpiNQAAALiWMaMXgEu7d++WJB0+fFgHDhxQQECA6tatq4CAAB04cEDfffedUx4AADjLYrE4nbdp00Zt27ZVmzZt5HA4KswDAAAArgQzegG4FBAQIG9vb506dUrt27c3xnNzc41zb29vBQQEmFUiAADV0v79+9WuXTtJUmlpqQ4ePFhhHgAAAFBZmNELAAAAVKIbb7yxUvMAAACAi0GjF4BLOTk5OnXqlKSzM478/f3l6ekpf39/YwbSqVOnlJOTY2aZAABUO8XFxXJzO/+v2W5ubmzGBgAAgEpFoxeAS126dJEkBQcHq127dsrJydHp06eVk5Ojdu3aqVWrVk55AADgrIULF6q0tPS8OaWlpVq4cGEVVQQAAIDagEYvAJfy8vIkSfHx8S7j8+bNc8oDAABnffzxx8ZrDw8PDR06VAsWLNDQoUPl4eHhMg8AAAC4UjR6AbjUsGFDSdKsWbNcxh977DGnPAAAcJbNZpMkWSwWBQQEaMWKFZo2bZpWrFihgIAAWSwWpzwAAACgMtDoBeDS7t27JUmHDx8+Z9ZuXl6evvvuO6c8AABwVtlz0+FwqFOnTkpLS9OJEyeUlpamTp06yeFwOOUBAAAAlYFGLwCXAgIC5O3tLUm67rrr5OXlpebNm8vLy0vXXXedJMnb21sBAQFmlgkAQLVTNmNXkr744gvt2bNHNptNe/bs0RdffOEyDwAAALhS7mYXAKD6OnnypNzc3ORwOHT69Gn9+OOPRsxisejkyZMmVgcAQPXUrFkz7dy5U5L0888/a9y4cUasfHO3WbNmVV4bAAAArl3M6AVQoVtuucX4eKmnp6fq1KkjT09PSWc/jnrLLbeYWR4AANXS4MGDjdflN1/77Xn5PAAAAOBK0egF4FJBQYG2bdsmi8WiwsJCnT59WsXFxTp9+rQKCwtlsVi0bds2FRQUmF0qAADVSqtWrYzXRUVFTrHy5+XzAAAAgCtFoxeASyNGjJAkDR8+XHXr1nWK1a1bV0OHDnXKAwAAZ4WHh8vPz++8OX5+fgoPD6+iigAAAFAbsEYvAJcyMzMlSTNmzHAZnzZtmt544w0jDwAA/E/Z0kcDBw7UyZMn9fPPP+v6669XvXr19P7775tcHQAAAK5FzOgF4FJISIgkaf78+S7jCxYscMoDAABnpaam6qefftKwYcP0wQcf6OOPP9bXX3+tjz/+WB988IGGDh2qY8eOKTU11exSAQAAcA2h0QvApddff12StHz5cp0+fdopdvr0aa1YscIpDwAAnJWdnS1JeuONN1RaWuoUKy0tNZ6hZXkAAABAZaDRC8Cl+vXrq3v37nI4HPLy8lLdunVVp04d1a1bV15eXnI4HOrevbvq169vdqkAAFQr5dfntVgs+sMf/qB//OMf+sMf/iCLxeIyDwAAALhSrNELoEJffvml3Nzc5HA4jF3CS0pKJJ39h+uXX35pZnkAAFRLBQUFxusWLVpo48aN2rhxoySpZcuWOnLkyDl5AAAAwJViRi+ACtWrV8/YTMbLy0vNmzeXl5eXpLObzNSrV8/M8gAAqJbmzp1rvP7++++dYuXPy+cBAAAAV4pGLwCXcnJydOrUKUnSr7/+qlOnTun777/XqVOn9Ouvv0qSTp06pZycHDPLBACg2il7TlZWHgAAAHAxWLoBgEtdunSRJAUHB6thw4ZOsYYNG6pVq1b67rvv1KVLF5q9AACUExAQoMOHD0uS7rrrLt11113y8vJSYWGh1q1bp7Vr1xp5AAAAQGVhRi8Al/Ly8iRJ8fHxLuPz5s1zygMAAGeFhYUZr+12u26++WYNGTJEN998s+x2u8s8AAAA4EoxoxeASw0bNlRubq5mzZqlIUOGnBN/7LHHjDwAAPA/x44dM16vX79e69evv2AeAAAAcKWY0QvApd27d0uSDh8+rEOHDik0NFSNGzdWaGioDh06pO+++84pDwAAnNWyZUtJqnDT0rLxsjwAAACgMtDoBeBSQECAvL29JUkhISFKT0/X8ePHlZ6erpCQEEmSt7c36wsCAPAbd9xxhyTp5MmTGjBggDp16qRmzZqpU6dOGjBggE6ePOmUBwAAAFQGlm4AUKEGDRro1KlT540DAABnvXv3lp+fn44dO+a0bMOPP/6oPXv2SJL8/PzUu3dvkyoEAADAtYgZvQBcOn78uHJzcyVJGRkZ8vf3l6enp/z9/ZWRkSFJys3N1fHjx80sEwCAasdqtWrUqFHnzRk1apSsVmsVVQQAAIDagEYvAJduv/12SVLPnj3Vpk0b5eTk6PTp08rJyVGbNm10yy23OOUBAICz7Ha7EhMTz5uTmJgou91eRRUBAACgNqDRC8Clo0ePSpL+/ve/u4zPnTvXKQ8AAJy1bt06lZSUnDenpKRE69atq6KKAAAAUBvQ6AXgUtOmTSVJf/vb31zG58yZ45QHAADOmjp1aqXmAQAAABeDRi8Al7Zu3SpJ+vzzz1VQUOAUKygo0JdffumUBwAAzvrhhx+czr28vNS4cWN5eXmdNw8AAAC4EjR6AbjUqFEj+fv7S5IaNGig9u3b65FHHlH79u3VoEEDSZK/v78aNWpkZpkAAFQ7v117t7CwUL/88osKCwvPmwcAAABcCXezCwBQfeXk5Khhw4bKz8/XgQMHdODAASPm6+urnJwcE6sDAKB6Ki0trdQ8AAAA4GIwoxdAhZKSkmSz2dS/f3+1bt1a1113nVq3bq3+/fvLZrMpKSnJ7BIBAKh23Nwu7lfsi80DAAAALga/XQJwyW63a/r06YqMjNS6deuUmZmp48ePKzMzU+vWrVNkZKRmzJjBx06BauzJJ5+UxWJxOtq1a2fET58+rUmTJqlx48aqX7++Bg8erNzcXKf3OHLkiCIiIuTt7S0/Pz/NnDlTJSUlVX0rQI1ysT8j/CwBAACgMtHoBeBSamqqsrKy9Nhjj50z48jNzU2xsbE6fPiwUlNTTaoQwMW46aablJ2dbRyffPKJEZs6darWrFmjt99+W1u3btXRo0cVExNjxO12uyIiIlRcXKzPPvtMy5Yt09KlSzVnzhwzbgUAAAAAcB6s0QvApezsbElSx44dXcbLxsvyAFRP7u7uCggIOGc8Pz9fL7/8slasWKE77rhDkvTqq6+qffv2+vzzz9WzZ09t2LBBX3/9tTZt2iR/f3916dJFTz/9tB555BE9+eST8vDwqOrbAQAAAABUgBm9AFwKDAyUJKWnp7uMl42X5QGonjIyMtS0aVO1bt1aw4YN05EjRyRJO3bs0JkzZ9S3b18jt127dmrZsqXS0tIkSWlpaQoNDZW/v7+RU7ZG9759+yq8ZlFRkWw2m9MBAAAAALi6aPQCcCk8PFxBQUGaN2+ezpw5oy1btmjlypXasmWLzpw5o7i4OAUHBys8PNzsUgFUoEePHlq6dKnWr1+vF198UYcPH1Z4eLhOnDihnJwceXh4qGHDhk5f4+/vr5ycHElSTk6OU5O3LF4Wq0hcXJx8fX2No0WLFpV7YwAAAACAc7B0AwCXrFarEhISNHjwYPn6+qqwsNCIeXl5qbCwUO+8846sVquJVQI4n4EDBxqvO3XqpB49eqhVq1Z666235OXlddWuGxsbq2nTphnnNpuNZi8AAAAAXGXM6AVwXhaLxeWYq3EA1VvDhg11ww036ODBgwoICFBxcbHy8vKccnJzc401fQMCApSbm3tOvCxWEU9PT/n4+DgdQG3yyiuvVGoeAAAAcDFo9AJwyW63a/r06YqMjFR+fr42b96sFStWaPPmzcrLy1NkZKRmzJghu91udqkALlJBQYEyMzMVGBiobt26qU6dOvrwww+N+DfffKMjR44oLCxMkhQWFqa9e/fq2LFjRs7GjRvl4+OjDh06VHn9QE1xvj+EXE4eAAAAcDFYugGAS6mpqcrKytLKlStVp04d9e7d2ykeGxurXr16KTU19ZwYgOphxowZGjRokFq1aqWjR4/qiSeekNVq1b333itfX1898MADmjZtmho1aiQfHx899NBDCgsLU8+ePSVJ/fr1U4cOHTRixAjFx8crJydHs2fP1qRJk+Tp6Wny3QHV14IFCy46r/wSKwAAAMCVYEYvAJeys7MlSR07dnQZLxsvywNQ/fzwww+69957deONN+qee+5R48aN9fnnn6tJkyaSpMTEREVGRmrw4MG67bbbFBAQoKSkJOPrrVarUlJSZLVaFRYWpuHDh2vkyJGaO3euWbcE1AhlS6K8/fbbGj16tFNs9OjRWrlypVMeAAAAUBmY0QvApcDAQElSenq6MbuvvPT0dKc8ANXPm2++ed543bp1tWjRIi1atKjCnFatWmndunWVXRpwTfvd736n7du3609/+tM5saVLl2rp0qVGHgAAAFBZmNELwKXw8HAFBQVp3rx5Ki0tdYqVlpYqLi5OwcHBCg8PN6lCAACqJ1dLN9x0000XlQcAAABcLmb0AnDJarUqISFBQ4YMUVRUlAYMGCAvLy8VFhZq/fr1Wrt2rVatWiWr1Wp2qQAAVCurVq06Z2zfvn0u80aMGFEVJQEAAKAWoNELoEIxMTGaMWOGEhMTlZKSYoy7u7trxowZiomJMbE6AACqp5EjR150Ho1eAAAAVBYavQAqlJSUpPnz5ysiIkIDBw40ZvS+//77mj9/vnr27EmzFwCACnTq1Emff/65Zs6cqYyMDLVt21bPPfecunbtqgMHDphdHgAAAK4xNHoBuGS32zV9+nRFRkYqOTlZbm7/W9J7/Pjxio6O1owZMxQVFcXyDQAAuLBnzx5ZrVa1adNGFotFISEhslqtNHkBAABwVdDoBeBSamqqsrKytHLlSqcmryS5ubkpNjZWvXr1Umpqqnr37m1OkQAAVEOvvfaasXyDp6enU2zq1KlOeQAAAEBlcbtwCoDaKDs7W5LUsWNHl/Gy8bI8AABw1sWuu8v6vAAAAKhMNHoBuBQYGChJSk9PdxkvGy/LAwAAZxUXF8tisZw3x2KxqLi4uIoqAlDek08+KYvF4nS0a9fOiJ8+fVqTJk1S48aNVb9+fQ0ePFi5ublO73HkyBFFRETI29tbfn5+mjlzpkpKSpxytmzZoq5du8rT01Nt2rTR0qVLq+L2AAC1GI1eAC6Fh4crKChI8+bNU2lpqVOstLRUcXFxCg4OVnh4uEkVAgBQPb3wwgtyOBznzXE4HHrhhReqqCIAv3XTTTcpOzvbOD755BMjNnXqVK1Zs0Zvv/22tm7dqqNHjzptQGy32xUREaHi4mJ99tlnWrZsmZYuXao5c+YYOYcPH1ZERIT69Omj3bt3a8qUKRozZow++OCDKr1PAEDtQqMXgEtWq1UJCQlKSUlRdHS00tLSdOLECaWlpSk6OlopKSmaP38+G7EBAPAbycnJlZoHoPK5u7srICDAOK6//npJUn5+vl5++WUtWLBAd9xxh7p166ZXX31Vn332mT7//HNJ0oYNG/T1119r+fLl6tKliwYOHKinn35aixYtMmbqL1myRMHBwUpISFD79u01efJkDRkyRImJiabdMwDg2kejF0CFYmJitGrVKu3du1e9evWSj4+PevXqpfT0dK1atcppZgMAADjLZrNVah6AypeRkaGmTZuqdevWGjZsmI4cOSJJ2rFjh86cOaO+ffsaue3atVPLli2VlpYmSUpLS1NoaKj8/f2NnP79+8tms2nfvn1GTvn3KMspe4+KFBUVyWazOR0AAFwsd7MLAFC9xcTEKCoqSqmpqcrOzlZgYKDCw8OZyQsAQAWysrIqNQ9A5erRo4eWLl2qG2+8UdnZ2XrqqacUHh6u9PR05eTkyMPDQw0bNnT6Gn9/f+Xk5EiScnJynJq8ZfGy2PlybDabCgsL5eXl5bK2uLg4PfXUU5VxmwCAWohGL4ALslqt6t27t9llAABQIxQUFFRqHoDKNXDgQON1p06d1KNHD7Vq1UpvvfVWhQ3YqhIbG6tp06YZ5zabTS1atDCxIgBATcLSDQAAAACAWqthw4a64YYbdPDgQQUEBKi4uFh5eXlOObm5uQoICJAkBQQEKDc395x4Wex8OT4+PudtJnt6esrHx8fpAADgYtHoBQAAAADUWgUFBcrMzFRgYKC6deumOnXq6MMPPzTi33zzjY4cOaKwsDBJUlhYmPbu3atjx44ZORs3bpSPj486dOhg5JR/j7KcsvcAAOBqoNELAAAAAKg1ZsyYoa1btyorK0ufffaZ/vjHP8pqteree++Vr6+vHnjgAU2bNk2bN2/Wjh07dN999yksLEw9e/aUJPXr108dOnTQiBEj9NVXX+mDDz7Q7NmzNWnSJHl6ekqSxo8fr0OHDmnWrFk6cOCAFi9erLfeektTp04189YBANc41ugFcEEFBQUaMWKEMjMzFRISotdff13169c3uywAAKoli8Uih8NxUXkAqt4PP/yge++9V7/88ouaNGmi3//+9/r888/VpEkTSVJiYqLc3Nw0ePBgFRUVqX///lq8eLHx9VarVSkpKZowYYLCwsJUr149jRo1SnPnzjVygoODtXbtWk2dOlUvvPCCmjdvrv/85z/q379/ld8vAKD2oNEL4LxuueUWbdu2zTjfu3evGjRooO7du+vLL780sTIAAKonPz+/c9bmrCgPQNV78803zxuvW7euFi1apEWLFlWY06pVK61bt+6879O7d2/t2rXrsmoEAOBysHQDgAqVNXktFovx0bQRI0bIYrFo27ZtuuWWW8wuEQCAaudimryXkgcAAABcDGb0AnCpoKDAaPKeOnVKdevWlSS99tpreumll+Tt7a1t27apoKCAZRwAAAAAAABMxoxeAC6NGDFCkjR8+HCjyVumbt26Gjp0qFMeAAAAAAAAzEOjF4BLmZmZks7uSuzKtGnTnPIAAAAAAABgHhq9AFwKCQmRJM2fP99lfMGCBU55AADgrN9+EuZK8wAAAICLQaMXgEuvv/66JGn58uU6efKktmzZopUrV2rLli06efKkVqxY4ZQHAADO8vPzq9Q8AAAA4GKwGRsAl+rXr6/u3btr27ZtFW621r17dzZiAwDgN44cOVKpeQAAAMDFYEYvgAo9+uijVxQHAAAAAABA1aDRC8Alu92u6dOna9CgQcrPz1d0dLRCQ0MVHR2t/Px8DRo0SDNmzJDdbje7VAAAAAAAgFqPpRsAuJSamqqsrCytXLlSPj4+evfdd53isbGx6tWrl1JTU9W7d29zigQAoBq6/fbbtXXr1ovKAwAAACoLM3oBuJSdnS1J6tixo8t42XhZHgAAOOuTTz6p1DwAAADgYtDoBeBSYGCgJCk9Pd1lvGy8LA8AAJx1scsasfwRAAAAKhONXgAuhYeHKygoSPPmzVNpaalTrLS0VHFxcQoODlZ4eLhJFQIAAAAAAKAMa/QCcMlqtSohIUFDhgzRoEGD5OXlpV9//VXXXXedCgsL9f7772vVqlWyWq1mlwoAAAAAAFDr0egFUKGYmBj97ne/07p1686Jde/eXTExMSZUBQAAAAAAgN9i6QYAFYqOjta2bdvk4eGhoUOHasGCBRo6dKg8PDy0bds2RUdHm10iAAAAAAAAxIxeABUoLCzU6tWr5eHhoRMnTsjDw8OIvfrqq2rQoIFWr16twsJCeXl5mVgpAAAAAAAAmNELwKWZM2dKkqZNm+bU5JUkDw8PTZkyxSkPAAAAAAAA5qHRC8CljIwMSdKYMWNcxh944AGnPAAAAAAAAJiHRi8Al9q2bStJ+s9//uMy/vLLLzvlAQAAAAAAwDw0egG49Nxzz0mSFixYoIKCAj3//PN66KGH9Pzzzxvn5fMAAAAAAABgHjZjA+CSl5eXoqKitHr1ajVo0MApNnXqVElSVFQUG7EBAAAAAABUA8zoBVChG2644YriAAAAAAAAqBo0egG4VFxcrMTERPn7+8tms2nSpEnq16+fJk2aJJvNJn9/fyUmJqq4uNjsUgEAAAAAAGo9Gr0AXFq8eLFKSkr0zDPPqEGDBlq4cKE++OADLVy4UA0aNNDcuXNVUlKixYsXm10qAAAAAABArUejF4BLmZmZkqTIyEiX8bLxsjwAAAAAAACYh0YvAJdCQkIkSSkpKS7jZeNleQAAAAAAADAPjV4ALk2cOFHu7u6aPXu2SkpKnGIlJSWaM2eO3N3dNXHiRJMqBAAAAAAAQBl3swsAUD15eHho6tSpeu6559S8eXMNGzZMrVu31qFDh/TGG28oNzdXM2fOlIeHh9mlAgAAAAAA1Ho0egFUKD4+Xt9++61Wr16tBQsWOMWioqIUHx9vUmUAAAAAAAAoj0YvgAolJSXpvffeU0REhNq0aaPCwkJ5eXnp4MGDeu+995SUlKSYmBizywQAAAAAAKj1aPQCcMlut2v69OmKjIxUcnKy3Nz+t6R3aWmpoqOjNWPGDEVFRclqtZpYKQAAAAAAANiMDYBLqampysrK0mOPPebU5JUkNzc3xcbG6vDhw0pNTTWpQgAAAAAAAJSh0QvApezsbElSx44dXcbLxsvyAAAAAAAAYB4avQBcCgwMlCSlp6e7jJeNl+UBAAAAAADAPDR6AbgUHh6uoKAgzZs3T2fOnNGWLVu0cuVKbdmyRWfOnFFcXJyCg4MVHh5udqkAAAAAAAC1nqmN3o8//liDBg1S06ZNZbFYlJyc7BTPzc3V6NGj1bRpU3l7e2vAgAHKyMhw+V4Oh0MDBw50+T5HjhxRRESEvL295efnp5kzZ6qkpOQq3RVwbbBarUpISNCaNWvk6+urPn36aOjQoerTp498fX21Zs0azZ8/n43YAAAAAAAAqgFTG70nT55U586dtWjRonNiDodD0dHROnTokFavXq1du3apVatW6tu3r06ePHlO/vPPPy+LxXLOuN1uV0REhIqLi/XZZ59p2bJlWrp0qebMmXNV7gm41rj6ubJYLC7HAQAAAAAAYA5TG70DBw7UM888oz/+8Y/nxDIyMvT555/rxRdfVPfu3XXjjTfqxRdfVGFhoVauXOmUu3v3biUkJOiVV1455302bNigr7/+WsuXL1eXLl00cOBAPf3001q0aJGKi4uv2r0BNZ3dbtf06dMVGRmp/Px8bd68WStWrNDmzZuVl5enyMhIzZgxQ3a73exSAQAAAAAAar1qu0ZvUVGRJKlu3brGmJubmzw9PfXJJ58YY6dOndLQoUO1aNEiBQQEnPM+aWlpCg0Nlb+/vzHWv39/2Ww27du377zXt9lsTgdQm6SmpiorK0uPPfaY6tSpo969e+vee+9V7969VadOHcXGxurw4cNKTU01u1QAAAAAAIBar9o2etu1a6eWLVsqNjZWv/76q4qLi/Xss8/qhx9+UHZ2tpE3depU9erVS1FRUS7fJycnx6nJK8k4z8nJqfD6cXFx8vX1NY4WLVpUwl0BNUfZz1nHjh1dxsvGy/88AgAAAAAAwBzVttFbp04dJSUl6dtvv1WjRo3k7e2tzZs3a+DAgXJzO1v2e++9p48++kjPP/98pV8/NjZW+fn5xvH9999X+jWA6iwwMFCSlJ6e7jJeNl6WBwAAAAAAAPNU20avJHXr1k27d+9WXl6esrOztX79ev3yyy9q3bq1JOmjjz5SZmamGjZsKHd3d7m7u0uSBg8erN69e0uSAgIClJub6/S+Zeeulnoo4+npKR8fH6cDqE3Cw8MVFBSkefPmqbS01ClWWlqquLg4BQcHKzw83KQKAQAAAAAAUKZaN3rL+Pr6qkmTJsrIyND27duNZRoeffRR7dmzR7t37zYOSUpMTNSrr74qSQoLC9PevXt17Ngx4/02btwoHx8fdejQocrvBagprFarEhISlJKSoujoaKWlpenEiRNKS0tTdHS0UlJSNH/+fFmtVrNLBQAAAAAAqPXczbx4QUGBDh48aJwfPnxYu3fvVqNGjdSyZUu9/fbbatKkiVq2bKm9e/fqr3/9q6Kjo9WvXz9JZ2fkupqV27JlSwUHB0uS+vXrpw4dOmjEiBGKj49XTk6OZs+erUmTJsnT07NqbhSooWJiYrRq1SpNnz5dvXr1MsaDg4O1atUqxcTEmFgdAAAAAAAAypja6N2+fbv69OljnE+bNk2SNGrUKC1dulTZ2dmaNm2acnNzFRgYqJEjR+rxxx+/pGtYrValpKRowoQJCgsLU7169TRq1CjNnTu3Uu8FuFbFxMQoKipKqampys7OVmBgoMLDw5nJCwAAAAAAUI2Y2ujt3bu3HA5HhfGHH35YDz/88CW9p6v3a9WqldatW3fJ9QE4y2q1GuteAwAAAAAAoPqpEWv0AgAAAAAAAAAqRqMXAAAAAAAAAGo4Gr0AAAAAAAAAUMPR6AVwQYWFhZo8ebL69++vyZMnq7Cw0OySAAAAAAAAUA6NXgDnFR0dLW9vby1atEgbNmzQokWL5O3trejoaLNLAwAAAAAAwP9HoxdAhaKjo7V69Wp5eHjo0Ucf1cGDB/Xoo4/Kw8NDq1evptkLAAAAAABQTbibXQCA6qmwsNBo8p44cUIeHh6SpLi4OD311FNq0KCBVq9ercLCQnl5eZlcLQAAAAAAQO3GjF4ALs2cOVOSNG3aNKPJW8bDw0NTpkxxygMAAAAAAIB5mNELwKWMjAxJ0pgxY1zGH3jgAcXHxxt5AAAAAIBrl6XktG4OcJNX3rfS0Wt33qBX3re6OcBNlpLTZpcCXDIavQBcatu2rTZs2KD//Oc/iouLOyf+8ssvG3kAAAAAgGtb3YIj2jmuvvTxOOljs6u5etpL2jmuvvYXHJHUy+xygEticTgcDrOLqAlsNpt8fX2Vn58vHx8fs8sBrrrCwkJ5e3ufs0avJBUXF6tBgwYqLi7WqVOnWKMXtQbPgsvD9w21jcViuehcfhVHbcGz4PLwfUN1suvLz/RAVLjeeOMNtW/Xzuxyrpr9Bw5o2LBhenl1qm6+hUYvzHcpzwJm9AJwycvLS1FRUVq9erW8vb3l7++v0tJSubm5KTc3V3a7XVFRUTR5AQAAAKAWcLjX1a6cUhU2vEFq2sXscq6awpxS7coplcO9rtmlAJeMRi+ACiUnJ6tevXo6deqUjh496hTz9vZWcnKyOYUBAAAAAADAybW7ejaAK9amTRudOnVKktSiRQvdcsstatGihSTp1KlTatOmjZnlAQAAAAAA4P9jRi8Al/Lz85WZmSlJOnnypLy9vY3YqVOnVK9ePWVmZio/P1++vr5mlQkAAAAAAAAxoxdABSIiIiRJAwYMcGrySmeXbejXr59THgAAAAAAAMxDoxeAS0eOHJEkPfHEEy7js2fPdsoDAAAAAACAeWj0AnCpZcuWkqSnnnrKZfyZZ55xygMAAAAAAIB5WKMXgEtr165Vw4YNtX79ep04cUI7duxQdna2AgMD1a1bN23YsMHIAwAAAAAAgLlo9AJwydfXVyEhIcrMzJSPj4/LnJCQEDZiAwAAAAAAqAZo9AKoUHx8vAYPHnzeOAAAtcWpU6d04MCBSn3PnTt3XlReu3btztkcFQAAACiPRi8Al+x2u6ZPn65BgwZp2bJlGjRokI4cOaKWLVtqzZo1GjVqlGbMmKGoqChZrVazywUA4Ko7cOCAunXrVqnvebHvt2PHDnXt2rVSrw0AAIBrC41eAC6lpqYqKytLK1eu1HXXXadPPvnEKR4bG6tevXopNTVVvXv3NqdIAOcVFxenpKQkHThwQF5eXurVq5eeffZZ3XjjjUZO7969tXXrVqevGzdunJYsWWKcHzlyRBMmTNDmzZtVv359jRo1SnFxcXJ359cI1C7t2rXTjh07Lph3Kc3gi3m/smsDAAAA58O/0AC4lJ2dLUnq2LGjy3jZeFkegOpn69atmjRpkrp3766SkhI99thj6tevn77++mvVq1fPyBs7dqzmzp1rnJf/eLjdbldERIQCAgL02WefKTs7WyNHjlSdOnU0b968Kr0fwGze3t4XNat28eLFmjhx4kXlMUsXAAAAlcXN7AIAVE+BgYGSpPT0dJfxsvGyPADVz/r16zV69GjddNNN6ty5s5YuXaojR46cM4PQ29tbAQEBxlF+A8YNGzbo66+/1vLly9WlSxcNHDhQTz/9tBYtWqTi4uKqviWgRpgwYUKl5gEAAAAXg0YvAJfCw8MVFBSkefPmqbS01ClWWlqquLg4BQcHKzw83KQKAVyq/Px8SVKjRo2cxt944w1df/316tixo2JjY3Xq1CkjlpaWptDQUPn7+xtj/fv3l81m0759+1xep6ioSDabzekAahuHw3FFcQAAAOBSsXQDAJesVqsSEhI0ZMgQ3X333WrTpo0KCwvl5eWlgwcPat26dVq1ahUbsQE1RGlpqaZMmaJbb73VaUmWoUOHqlWrVmratKn27NmjRx55RN98842SkpIkSTk5OU5NXknGeU5OjstrxcXF6amnnrpKdwLUHA6HQy+++KLTMg6LFy9mJi8AAACuChq9ACoUExOju+++W6tXrz4nFhUVpZiYGBOqAnA5Jk2apPT09HM2VnzwwQeN16GhoQoMDNSdd96pzMxMhYSEXNa1YmNjNW3aNOPcZrOpRYsWl1c4UMNNmDBBPXr0ULdu3bRjxw7W5AUAAMBVw9INACo0a9YsrV69Wn5+fpoxY4YWL16sGTNmyM/PT6tXr9asWbPMLhHARZg8ebJSUlK0efNmNW/e/Ly5PXr0kCQdPHhQkhQQEKDc3FynnLLzgIAAl+/h6ekpHx8fpwMAAAAAcHXR6AXgUnFxsRITE+Xv768ff/xRzz33nCZMmKDnnntOP/74o/z9/ZWYmMhmTEA15nA4NHnyZL377rv66KOPFBwcfMGv2b17t6T/bbQYFhamvXv36tixY0bOxo0b5ePjow4dOlyVugEAuJri4uLUvXt3NWjQQH5+foqOjtY333zjlNO7d29ZLBanY/z48U45R44cUUREhLy9veXn56eZM2eqpKTEKWfLli3q2rWrPD091aZNGy1duvRq3x4AoBaj0QvApcWLF6ukpETPPPOM3N2dV3lxd3fX3LlzVVJSosWLF5tUIYALmTRpkpYvX64VK1aoQYMGysnJUU5OjgoLCyVJmZmZevrpp7Vjxw5lZWXpvffe08iRI3XbbbepU6dOkqR+/fqpQ4cOGjFihL766it98MEHmj17tiZNmiRPT08zbw8AgMuydetWTZo0SZ9//rk2btyoM2fOqF+/fjp58qRT3tixY5WdnW0c8fHxRsxutysiIkLFxcX67LPPtGzZMi1dulRz5swxcg4fPqyIiAj16dNHu3fv1pQpUzRmzBh98MEHVXavAIDahTV6AbiUmZkpSYqMjHQZLxsvywNQ/bz44ouSzs5KKu/VV1/V6NGj5eHhoU2bNun555/XyZMn1aJFCw0ePFizZ882cq1Wq1JSUjRhwgSFhYWpXr16GjVqlObOnVuVtwIAQKVZv3690/nSpUvl5+enHTt26LbbbjPGvb29K1ymaMOGDfr666+1adMm+fv7q0uXLnr66af1yCOP6Mknn5SHh4eWLFmi4OBgJSQkSJLat2+vTz75RImJierfv//Vu0EAQK1FoxeAS2WbMKWkpGjMmDHnxFNSUpzyAFQ/DofjvPEWLVpo69atF3yfVq1aad26dZVVFgAA1Up+fr4kqVGjRk7jb7zxhpYvX66AgAANGjRIjz/+uLy9vSVJaWlpCg0Nlb+/v5Hfv39/TZgwQfv27dPNN9+stLQ09e3b1+k9+/fvrylTplzdGwIA1Fos3QDApYkTJ8rd3V2zZ88+Z62xkpISzZkzR+7u7po4caJJFQIAAABXprS0VFOmTNGtt96qjh07GuNDhw7V8uXLtXnzZsXGxur111/X8OHDjXhOTo5Tk1eScZ6Tk3PeHJvNZiyj9FtFRUWy2WxOBwAAF4tGLwCXPDw8NHXqVOXm5qp58+Z66aWXdPToUb300ktq3ry5cnNzNXXqVHl4eJhdKgAAAHBZJk2apPT0dL355ptO4w8++KD69++v0NBQDRs2TK+99prefffdq75sWVxcnHx9fY2jRYsWV/V6AIBrC0s3AKhQ2YYTiYmJGjdunDHu7u6umTNnOm1IAQAAANQkkydPVkpKij7++GM1b978vLk9evSQJB08eFAhISEKCAjQl19+6ZSTm5srSca6vgEBAcZY+RwfHx95eXm5vE5sbKymTZtmnNtsNpq9AICLRqMXwHnFx8frmWee0eLFi5WZmamQkBBNnDiRmbwAAACokRwOhx566CG9++672rJli4KDgy/4Nbt375YkBQYGSpLCwsL097//XceOHZOfn58kaePGjfLx8VGHDh2MnN+ucb9x40aFhYVVeB1PT095enpezm0BAECjF8CFeXh4sGkEAAAArgmTJk3SihUrtHr1ajVo0MBYU9fX11deXl7KzMzUihUrdNddd6lx48bas2ePpk6dqttuu02dOnWSJPXr108dOnTQiBEjFB8fr5ycHM2ePVuTJk0yGrXjx4/XwoULNWvWLN1///366KOP9NZbb2nt2rWm3TsA4NrGGr0AAAAAgFrjxRdfVH5+vnr37q3AwEDj+O9//yvp7CSHTZs2qV+/fmrXrp2mT5+uwYMHa82aNcZ7WK1WpaSkyGq1KiwsTMOHD9fIkSM1d+5cIyc4OFhr167Vxo0b1blzZyUkJOg///mP+vfvX+X3DACoHZjRCwAAAACoNRwOx3njLVq00NatWy/4Pq1atTpnaYbf6t27t3bt2nVJ9QEAcLmY0QsAAAAAAAAANRwzegFckN1uV2pqqrKzsxUYGKjw8HBZrVazywIAAAAAAMD/x4xeAOeVlJSkNm3aqE+fPho6dKj69OmjNm3aKCkpyezSAAAAAAAA8P/R6AVQoaSkJA0ZMkShoaFKS0vTiRMnlJaWptDQUA0ZMoRmLwAAAAAAQDVBoxeAS3a7XdOnT1dkZKSSk5PVs2dP1a9fXz179lRycrIiIyM1Y8YM2e12s0sFAAAAAACo9Wj0AnApNTVVWVlZeuyxx+Tm5vy/Cjc3N8XGxurw4cNKTU01qUIAAAAAAACUodELwKXs7GxJUseOHV3Gy8bL8gAAAAAAAGAeGr0AXAoMDJQkpaenu4yXjZflAQAAAAAAwDw0egG4FB4erqCgIM2bN0+lpaVOsdLSUsXFxSk4OFjh4eEmVQgAAAAAAIAy7mYXAKB6slqtSkhI0JAhQxQVFaUBAwbIy8tLhYWFWr9+vdauXatVq1bJarWaXSoAAAAAAECtR6MXQIViYmI0Y8YMJSYmKiUlxRh3d3fXjBkzFBMTY2J1AAAAAAAAKEOjF0CFkpKSNH/+fEVERGjgwIHGjN73339f8+fPV8+ePWn2AgAAAAAAVAM0egG4ZLfbNX36dEVGRio5OVlubv9b0nv8+PGKjo7WjBkzFBUVxfINAAAAAAAAJmMzNgAupaamKisrS4899phTk1eS3NzcFBsbq8OHDys1NdWkCgEAAAAAAFCGRi8Al7KzsyVJHTt2dBkvGy/LAwAAAAAAgHlo9AJwKTAwUJKUnp7uMl42XpYHAAAAAAAA89DoBeBSeHi4goKCNG/ePJ05c0ZbtmzRypUrtWXLFp05c0ZxcXEKDg5WeHi42aUCAAAAAADUemzGBsAlq9WqhIQEDR48WL6+viosLDRiXl5eKiws1DvvvMNGbAAAAAAAANUAM3oBnJfFYnE55mocAAAAAAAA5qDRC8Alu92u6dOnKzIyUvn5+dq8ebNWrFihzZs3Ky8vT5GRkZoxY4bsdrvZpQIAAAAAANR6LN0AwKXU1FRlZWVp5cqVqlOnjnr37u0Uj42NVa9evZSamnpODAAAAAAAAFWLGb0AXMrOzpYkdezY0WW8bLwsDwAAAAAAAOah0QvApcDAQElSenq6y3jZeFkeAAAAAAAAzEOjF4BL4eHhCgoK0rx581RaWuoUKy0tVVxcnIKDgxUeHm5ShQAAAAAAACjDGr0AXLJarUpISNCQIUN09913KyQkRKdPn1bdunWVmZmpdevWadWqVbJarWaXCgDAJcnIyNCJEyeq7Hr79+93+m9VadCggdq2bVul1wQAAIB5aPQCqFBMTIzuvvturV69+pxYVFSUYmJiTKgKAIDLl5GRoRtuuMGUaw8fPrzKr/ntt9/S7AUAAKglaPQCqNCsWbO0evVq+fv7a8SIEWrdurUOHTqk119/XatXr9asWbMUHx9vdpkAAFy0spm8y5cvV/v27avkmoWFhcrKylJQUJC8vLyq5Jr79+/X8OHDq3TmMgAAAMxFoxeAS8XFxUpMTJS/v79++OEHubv/738XcXFxat68uRITE/XMM8/Iw8PDxEoBALh07du3V9euXavserfeemuVXQsAAAC1E5uxAXBp8eLFKikp0TPPPOPU5JUkd3d3zZ07VyUlJVq8eLFJFQIAAAAAAKAMjV4ALmVmZkqSIiMjXcbLxsvyAAAAAAAAYB4avQBcCgkJkSSlpKS4jJeNl+UBAAAAAADAPDR6Abg0ceJEubu7a/bs2crLy9Mf//hHderUSX/84x+Vl5enOXPmyN3dXRMnTjS7VAAAAAAAgFqPzdgAuOTh4aGpU6fqueee03XXXWeM7927V8nJyZKkmTNnshEbAAAAAABANUCjF0CFtmzZckVxAAAAAMC14dSpU5KknTt3Vtk1CwsLlZWVpaCgIHl5eVXJNffv318l1wGuBhq9AFwqKCjQtm3bZLFYlJeXp1deeUWZmZkKCQnR/fffr4YNG2rbtm0qKChQ/fr1zS4XAAAAAHAVHThwQJI0duxYkyupGg0aNDC7BOCS0egF4NKIESMkScOHD5ePj4+mTJniFB86dKjeeOMNjRgxQu+++64JFQIAAAAAqkp0dLQkqV27dvL29q6Sa+7fv1/Dhw/X8uXL1b59+yq5pnS2ydu2bdsqux5QWWj0AnApMzNTkjRjxgyX8WnTpumNN94w8gAAAAAA167rr79eY8aMMeXa7du3V9euXU25NlCTuJldAIDqKSQkRJI0f/58l/EFCxY45QEAAAAAAMA8NHoBuPT6669LkpYvX67Tp087xU6fPq0VK1Y45QEAAAAAAMA8LN0AwKX69eure/fu2rZtm7y9vXXnnXeqT58+2rx5sz788EM5HA51796djdgAADWKpeS0bg5wk1fet9LRa3fOg1fet7o5wE2WktMXTgYAAMA1gUYvgAp9+eWXatOmjTIzM7Vp0yZt2rTJiIWEhOjLL780sToAAC5d3YIj2jmuvvTxOOljs6u5etpL2jmuvvYXHJHUy+xyAAAAUAVo9AKoUFJSkg4dOqSBAwfq5MmT+vnnn3X99derXr16Wr9+vZKSkhQTE2N2mQAAXLTT9Vuq6/8V6I033lD7du3MLueq2X/ggIYNG6aX72ppdikAAACoIjR6Abhkt9s1ffp0RUZGKjk5WW5u//t4a2lpqaKjozVjxgxFRUXJarWaWCkAABfP4V5Xu3JKVdjwBqlpF7PLuWoKc0q1K6dUDve6ZpcCAACAKnLtLkwG4IqkpqYqKytLjz32mFOTV5Lc3NwUGxurw4cPKzU11aQKAQAAAAAAUIZGLwCXsrOzJUkdO3Z0GS8bL8sDAAAAAACAeWj0AnApMDBQkpSenu4yXjZelgcAAAAAAADz0OgF4FJ4eLiCgoI0b948nTlzRlu2bNHKlSu1ZcsWnTlzRnFxcQoODlZ4eLjZpQIAAAAAANR6bMYGwCWr1aqEhAQNHjxYvr6+KiwsNGJeXl4qLCzUO++8w0ZsAAAAAAAA1QAzegGcl8VicTnmahwAAAAAAADmoNELwCW73a7p06crMjJS+fn52rx5s1asWKHNmzcrLy9PkZGRmjFjhux2u9mlAgAAAAAA1Hos3QDApdTUVGVlZWnlypWqU6eOevfu7RSPjY1Vr169lJqaek4MAAAAAAAAVYsZvQBcys7OliR17NjRZbxsvCwPAAAAAAAA5qHRC8ClwMBASVJ6errLeNl4WR4AAAAAAADMw9INAFwKDw9XUFCQ5s2bp+TkZLm5/e/vQqWlpYqLi1NwcLDCw8NNrBIAgEtz6tQpSdLOnTur7JqFhYXKyspSUFCQvLy8quSa+/fvr5LrAAAAoPqg0QvAJavVqoSEBA0ZMkTR0dGKjY1Vx44dlZ6erri4OKWkpGjVqlWyWq1mlwoAwEU7cOCAJGns2LEmV1I1GjRoYHYJAAAAqCI0egFUKCYmRqtWrdL06dPVq1cvYzw4OFirVq1STEyMidUBAHDpoqOjJUnt2rWTt7d3lVxz//79Gj58uJYvX6727dtXyTWls03etm3bVtn1AAAAYC4avQDOKyYmRlFRUUpNTVV2drYCAwMVHh7OTF4AQI10/fXXa8yYMaZcu3379uratasp1wYAAMC1j0YvgAuyWq3q3bu32WUAAAAAAACgAm4XTgEAAAAAAAAAVGc0egEAAAAAAACghqPRCwAAAAAAAAA1HI1eAAAAAAAAAKjhaPQCAAAAAAAAQA1HoxcAAAAAAAAAajgavQAAAAAAAABQw9HoBQAAAAAAAIAajkYvAAAAAAAAANRwNHoBAAAAAAAAoIaj0QsAAAAAAAAANRyNXgAAAAAAAACo4Wj0AgAAAAAAAEANR6MXAAAAAAAAAGo4Gr0AAAAAAAAAUMPR6AUAAAAAAACAGo5GLwAAAAAAAADUcDR6AQAAAAAAAKCGcze7AADVX3FxsRYvXqzMzEyFhIRo4sSJ8vDwMLssAAAAAAAA/H/M6AVwXrNmzVK9evU0depULVy4UFOnTlW9evU0a9Yss0sDAAAAqr1FixYpKChIdevWVY8ePfTll1+aXRIA4BpFoxdAhWbNmqXnnntOjRs31r///W9lZ2fr3//+txo3bqznnnuOZi8AAABwHv/97381bdo0PfHEE9q5c6c6d+6s/v3769ixY2aXBgC4BtHoBeBScXGxEhMT5e/vrx9++EFjxoxRQECAxowZox9++EH+/v5KTExUcXGx2aUCqALMRgIA4NItWLBAY8eO1X333acOHTpoyZIl8vb21iuvvGJ2aQCAaxBr9AJwafHixSopKdEzzzwjd3fn/1W4u7tr7ty5GjdunBYvXqwpU6aYUySAKlE2G2nJkiXq0aOHnn/+efXv31/ffPON/Pz8zC4PqDKnTp3SgQMHLvnr9u/f7/Tfy9GuXTt5e3tf9tcDqHrFxcXasWOHYmNjjTE3Nzf17dtXaWlpLr+mqKhIRUVFxrnNZrvqdQJVgWcoUDVo9AJwKTMzU5IUGRnpMl42XpYH4NpVfjaSJC1ZskRr167VK6+8okcffdTk6oCqc+DAAXXr1u2yv3748OGX/bU7duxQ165dL/vrAVS9n3/+WXa7Xf7+/k7j/v7+FTa84uLi9NRTT1VFeUCV4hkKVA0avQBcCgkJkSSlpKRozJgx58RTUlKc8gBcmy5nNhJwrWrXrp127NhxyV9XWFiorKwsBQUFycvL67KvDeDaFxsbq2nTphnnNptNLVq0MLEioHLwDAWqBo1eAC5NnDhRM2fO1OzZszV69Gin5RtKSko0Z84cubu7a+LEiSZWCeBqu5zZSHzsFNcqb2/vy54RdOutt1ZyNQCqu+uvv15Wq1W5ublO47m5uQoICHD5NZ6envL09KyK8oAqxTMUqBpsxgbAJQ8PD02dOlW5ublq3ry5XnrpJR09elQvvfSSmjdvrtzcXE2dOlUeHh5mlwqgmomLi5Ovr69xMBMJAFAbeXh4qFu3bvrwww+NsdLSUn344YcKCwszsTIAwLWKGb0AKhQfHy9JSkxM1Lhx44xxd3d3zZw504gDuHZdzmwkPnYKAMBZ06ZN06hRo/S73/1Ot9xyi55//nmdPHnSWPceAIDKRKMXwHnFx8frmWee0eLFi5WZmamQkBBNnDiRmbxALVF+NlJ0dLSk/81Gmjx5ssuv4WOnAACc9ec//1k//fST5syZo5ycHHXp0kXr168/Z0kkAAAqA41eABfk4eGhKVOmmF0GAJMwGwkAgMs3efLkCv84CgBAZaLRCwAAzovZSAAAAABQ/dHoBQAAF8RsJAAAAACo3tzMLgAAAAAAAAAAcGVo9AIAAAAAAABADUejFwAAAAAAAABqOBq9AAAAAAAAAFDD0egFAAAAAAAAgBqORi8AAAAAAAAA1HA0egEAAAAAAACghqPRCwAAAAAAAAA1HI1eAAAAAAAAAKjhTG30fvzxxxo0aJCaNm0qi8Wi5ORkp3hubq5Gjx6tpk2bytvbWwMGDFBGRoYRP378uB566CHdeOON8vLyUsuWLfXwww8rPz/f6X2OHDmiiIgIeXt7y8/PTzNnzlRJSUlV3CIAAAAAAAAAXHWmNnpPnjypzp07a9GiRefEHA6HoqOjdejQIa1evVq7du1Sq1at1LdvX508eVKSdPToUR09elTz589Xenq6li5dqvXr1+uBBx4w3sdutysiIkLFxcX67LPPtGzZMi1dulRz5sypsvsEAAAAAAAAgKvJ4nA4HGYXIUkWi0XvvvuuoqOjJUnffvutbrzxRqWnp+umm26SJJWWliogIEDz5s3TmDFjXL7P22+/reHDh+vkyZNyd3fX+++/r8jISB09elT+/v6SpCVLluiRRx7RTz/9JA8Pj4uqz2azydfXV/n5+fLx8bnyGwYA1Dg8Cy4P3zcAAM+Cy8P3DQBwKc+CartGb1FRkSSpbt26xpibm5s8PT31ySefVPh1ZTft7u4uSUpLS1NoaKjR5JWk/v37y2azad++fVepegAAAAAAAACoOtW20duuXTu1bNlSsbGx+vXXX1VcXKxnn31WP/zwg7Kzs11+zc8//6ynn35aDz74oDGWk5Pj1OSVZJzn5ORUeP2ioiLZbDanAwAAAAAAAACqo2rb6K1Tp46SkpL07bffqlGjRvL29tbmzZs1cOBAubmdW7bNZlNERIQ6dOigJ5988oqvHxcXJ19fX+No0aLFFb8nAAAAAAAAAFwN1bbRK0ndunXT7t27lZeXp+zsbK1fv16//PKLWrdu7ZR34sQJDRgwQA0aNNC7776rOnXqGLGAgADl5uY65ZedBwQEVHjt2NhY5efnG8f3339fiXcGAAAAAAAAAJWnWjd6y/j6+qpJkybKyMjQ9u3bFRUVZcRsNpv69esnDw8Pvffee05r+kpSWFiY9u7dq2PHjhljGzdulI+Pjzp06FDhNT09PeXj4+N0AAAAAAAAAEB15G7mxQsKCnTw4EHj/PDhw9q9e7caNWqkli1b6u2331aTJk3UsmVL7d27V3/9618VHR2tfv36Sfpfk/fUqVNavny501q6TZo0kdVqVb9+/dShQweNGDFC8fHxysnJ0ezZszVp0iR5enqact8AAAAAAAAAUJlMbfRu375dffr0Mc6nTZsmSRo1apSWLl2q7OxsTZs2Tbm5uQoMDNTIkSP1+OOPG/k7d+7UF198IUlq06aN03sfPnxYQUFBslqtSklJ0YQJExQWFqZ69epp1KhRmjt3bhXcIQAAAAAAAABcfRaHw+Ewu4iawGazydfXV/n5+SzjAAC1FM+Cy8P3DQDAs+Dy8H0DAFzKs6BGrNELAAAAAAAAAKgYjV4AAAAAAAAAqOFo9AIAAAAAAABADUejFwAAAAAAAABqOBq9AAAAAAAAAFDDuZtdQE3hcDgknd3pDgBQO5U9A8qeCbg4PEMBADxDLw/PUADApTxDafRepBMnTkiSWrRoYXIlAACznThxQr6+vmaXUWPwDAUAlOEZeml4hgIAylzMM9Ti4E+qF6W0tFRHjx5VgwYNZLFYzC4HqHI2m00tWrTQ999/Lx8fH7PLAUzhcDh04sQJNW3aVG5urH50sXiGorbjGQrwDL1cPENR2/EMBS7tGUqjF8BFsdls8vX1VX5+Pg9YAAAuAc9QAAAuD89Q4NLwp1QAAAAAAAAAqOFo9AIAAAAAAABADUejF8BF8fT01BNPPCFPT0+zSwEAoEbhGQoAwOXhGQpcGtboBQAAAAAAAIAajhm9AAAAAAAAAFDD0egFAAAAAAAAgBqORi8AAAAAAAAA1HA0egEAAAAAAACghqPRC+CCPv74Yw0aNEhNmzaVxWJRcnKy2SUBAFAj8AwFAODy8AwFLh2NXgAXdPLkSXXu3FmLFi0yuxQAAGoUnqEAAFwenqHApXM3uwAA1d/AgQM18P+1c8c2DAJREAXPkiugAHohpIprjVIogQKQaIL8nDlxBIGPlWYyiH620hNinnufAQBxbCgA3GND4Tpf9AIAAAAAhBN6AQAAAADCCb0AAAAAAOGEXgAAAACAcEIvAAAAAEC4d+8DgOc7z7Ps+/59Po6jbNtWhmEo4zh2vAwAns2GAsA9NhSue7XWWu8jgGdb17VM0/TzvtZalmX5/0EAEMKGAsA9NhSuE3oBAAAAAML5Ry8AAAAAQDihFwAAAAAgnNALAAAAABBO6AUAAAAACCf0AgAAAACEE3oBAAAAAMIJvQAAAAAA4YReAAAAAIBwQi8AAAAAQDihFwAAAAAgnNALAAAAABBO6AUAAAAACPcBkkOfkI2HoKsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1700x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(17, 10))\n",
    "\n",
    "axs[0].boxplot(df_clean['RegistrationYear'])\n",
    "axs[0].set_title('RegistrationYear')\n",
    "axs[0].set_ylabel('Год')\n",
    "        \n",
    "axs[1].boxplot(df_clean['Power'])\n",
    "axs[1].set_title('Power')\n",
    "axs[1].set_ylabel('Мощность л.с')\n",
    "\n",
    "axs[2].boxplot(df_clean['Price'])\n",
    "axs[2].set_title('Price')\n",
    "axs[2].set_ylabel('Стоимость ЕВРО')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем на другой тип данных DateCrawled, DateCreated и LastSeen\n",
    "df_clean['DateCrawled'] = pd.to_datetime(df_clean['DateCrawled'])\n",
    "df_clean['DateCreated'] = pd.to_datetime(df_clean['DateCreated'])\n",
    "df_clean['LastSeen'] = pd.to_datetime(df_clean['LastSeen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Потеряно 16.489026974707155%'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Потеряно {100 * (1 - df_clean.shape[0] / df.shape[0])}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пропущенные значения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Устранили аномальные значения, теперь смотрим кол-во пропущенных значений. \n",
    "\n",
    "Будем устранять аномальные значения заполнением `\"unknown\"` или медиальным значением, т.к. радикальным методом не получится, т.к. будет большая потеря данных, что и приведет к `invalid` данным, т.к. данные должны сохранять 70% от исходного после переработки, смотрим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateCrawled              0\n",
       "Price                    0\n",
       "VehicleType          10926\n",
       "RegistrationYear         0\n",
       "Gearbox               5336\n",
       "Power                    0\n",
       "Model                11014\n",
       "Kilometer                0\n",
       "RegistrationMonth        0\n",
       "FuelType             15455\n",
       "Brand                    0\n",
       "Repaired             42742\n",
       "DateCreated              0\n",
       "NumberOfPictures         0\n",
       "PostalCode               0\n",
       "LastSeen                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295937"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Радикальный метод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скорпируем\n",
    "df_clean_rad = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устраняем\n",
    "df_clean_rad = df_clean_rad[~df_clean_rad['VehicleType'].isna()]\n",
    "df_clean_rad = df_clean_rad[~df_clean_rad['Gearbox'].isna()]\n",
    "df_clean_rad = df_clean_rad[~df_clean_rad['Model'].isna()]\n",
    "df_clean_rad = df_clean_rad[~df_clean_rad['FuelType'].isna()]\n",
    "df_clean_rad = df_clean_rad[~df_clean_rad['Repaired'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Потеряно 21.300817403704166%'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Потеряно {100 * (1 - df_clean_rad.shape[0] / df_clean.shape[0])}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потеря составляет 21% от датафрейма df_clean, но не стоит забывать, что датафрейм также претерпевал потерю около 17% от исходного датафрейма, значит, потеря составляет свыше 30%. А нам хотя бы сохранить не менее 70% от исходных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Второй способ - заполнение `\"unknown\"` или медианным значением "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполним значением \"unknown\"\n",
    "df_clean['VehicleType'] = df_clean['VehicleType'].fillna('unknown')\n",
    "df_clean['Gearbox'] = df_clean['Gearbox'].fillna('unknown')\n",
    "df_clean['Model'] = df_clean['Model'].fillna('unknown')\n",
    "df_clean['FuelType'] = df_clean['FuelType'].fillna('unknown')\n",
    "df_clean['Repaired'] = df_clean['Repaired'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateCrawled          0\n",
       "Price                0\n",
       "VehicleType          0\n",
       "RegistrationYear     0\n",
       "Gearbox              0\n",
       "Power                0\n",
       "Model                0\n",
       "Kilometer            0\n",
       "RegistrationMonth    0\n",
       "FuelType             0\n",
       "Brand                0\n",
       "Repaired             0\n",
       "DateCreated          0\n",
       "NumberOfPictures     0\n",
       "PostalCode           0\n",
       "LastSeen             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим\n",
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Repaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-24 10:58:45</td>\n",
       "      <td>18300</td>\n",
       "      <td>coupe</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>190</td>\n",
       "      <td>unknown</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>yes</td>\n",
       "      <td>2016-03-24</td>\n",
       "      <td>0</td>\n",
       "      <td>66954</td>\n",
       "      <td>2016-04-07 01:46:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-14 12:52:21</td>\n",
       "      <td>9800</td>\n",
       "      <td>suv</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>grand</td>\n",
       "      <td>125000</td>\n",
       "      <td>8</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>jeep</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2016-03-14</td>\n",
       "      <td>0</td>\n",
       "      <td>90480</td>\n",
       "      <td>2016-04-05 12:47:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-03-17 16:54:04</td>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-17</td>\n",
       "      <td>0</td>\n",
       "      <td>91074</td>\n",
       "      <td>2016-03-17 17:40:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-31 17:25:20</td>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>60437</td>\n",
       "      <td>2016-04-06 10:17:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-04-04 17:36:23</td>\n",
       "      <td>650</td>\n",
       "      <td>sedan</td>\n",
       "      <td>1995</td>\n",
       "      <td>manual</td>\n",
       "      <td>102</td>\n",
       "      <td>3er</td>\n",
       "      <td>150000</td>\n",
       "      <td>10</td>\n",
       "      <td>petrol</td>\n",
       "      <td>bmw</td>\n",
       "      <td>yes</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>33775</td>\n",
       "      <td>2016-04-06 19:17:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "1 2016-03-24 10:58:45  18300       coupe              2011  manual    190   \n",
       "2 2016-03-14 12:52:21   9800         suv              2004    auto    163   \n",
       "3 2016-03-17 16:54:04   1500       small              2001  manual     75   \n",
       "4 2016-03-31 17:25:20   3600       small              2008  manual     69   \n",
       "5 2016-04-04 17:36:23    650       sedan              1995  manual    102   \n",
       "\n",
       "     Model  Kilometer  RegistrationMonth  FuelType       Brand Repaired  \\\n",
       "1  unknown     125000                  5  gasoline        audi      yes   \n",
       "2    grand     125000                  8  gasoline        jeep  unknown   \n",
       "3     golf     150000                  6    petrol  volkswagen       no   \n",
       "4    fabia      90000                  7  gasoline       skoda       no   \n",
       "5      3er     150000                 10    petrol         bmw      yes   \n",
       "\n",
       "  DateCreated  NumberOfPictures  PostalCode            LastSeen  \n",
       "1  2016-03-24                 0       66954 2016-04-07 01:46:50  \n",
       "2  2016-03-14                 0       90480 2016-04-05 12:47:46  \n",
       "3  2016-03-17                 0       91074 2016-03-17 17:40:17  \n",
       "4  2016-03-31                 0       60437 2016-04-06 10:17:21  \n",
       "5  2016-04-04                 0       33775 2016-04-06 19:17:07  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295937"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Уникальные значения "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С столбцом `RegistrationMonth` что то неладное, смотрим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['RegistrationMonth'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как оказывается, что существует одна лишняя цифра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     17814\n",
       "2     18856\n",
       "8     19722\n",
       "1     20187\n",
       "9     20953\n",
       "11    21050\n",
       "12    21206\n",
       "10    22962\n",
       "7     23837\n",
       "5     25619\n",
       "4     25753\n",
       "6     27556\n",
       "3     30422\n",
       "Name: RegistrationMonth, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['RegistrationMonth'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим кол-во, чтобы понять, что с ними делать - удалить или усреднять"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17814"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[df_clean['RegistrationMonth'] == 0]['RegistrationMonth'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21206"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[df_clean['RegistrationMonth'] == 12]['RegistrationMonth'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кол-во приближенное одинаково, поэтому не можем устранять их, усредняем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2917873319.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean.loc[df_clean['RegistrationMonth'] == 12]['RegistrationMonth'] = 6\n"
     ]
    }
   ],
   "source": [
    "df_clean.loc[df_clean['RegistrationMonth'] == 12]['RegistrationMonth'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['RegistrationMonth'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь с данными в порядке, можно уже приступать к обучению моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дублирующие значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Кол-во дублириющие значения\n",
    "df_clean.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Избавимся от них\n",
    "df_clean.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Кол-во дублириющие значения\n",
    "df_clean.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Потеряно 16.490155741613965%'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Потеряно {100 * (1 - df_clean.shape[0] / df.shape[0])}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь приступаем к обучению модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед обучением нужно сделать следующие: прямое кодирование, порядкое кодирование и масштабируемость модели. Поэтому обучение моделей будет разделен на 3 этапа: OH, OHE, SCALER. А также обучение будет проводиться кроссвалидацией\n",
    "\n",
    "Поскольку у нас присутствуют некоторые признаки, которые являются строковыми или ojbect типами, а для машинного обучения регрессионного типа требует числа. Поэтому примением кодировку, которая будет преобразовать в числа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 295933 entries, 1 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   DateCrawled        295933 non-null  datetime64[ns]\n",
      " 1   Price              295933 non-null  int64         \n",
      " 2   VehicleType        295933 non-null  object        \n",
      " 3   RegistrationYear   295933 non-null  int64         \n",
      " 4   Gearbox            295933 non-null  object        \n",
      " 5   Power              295933 non-null  int64         \n",
      " 6   Model              295933 non-null  object        \n",
      " 7   Kilometer          295933 non-null  int64         \n",
      " 8   RegistrationMonth  295933 non-null  int64         \n",
      " 9   FuelType           295933 non-null  object        \n",
      " 10  Brand              295933 non-null  object        \n",
      " 11  Repaired           295933 non-null  object        \n",
      " 12  DateCreated        295933 non-null  datetime64[ns]\n",
      " 13  NumberOfPictures   295933 non-null  int64         \n",
      " 14  PostalCode         295933 non-null  int64         \n",
      " 15  LastSeen           295933 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](3), int64(7), object(6)\n",
      "memory usage: 38.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и видим, что существуют несколько признаков, имеющих типа object. Теперь создадим список, который автоматически заполняет определенный тип"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь будем сохранить результаты машинного обучения\n",
    "results = pd.DataFrame()\n",
    "\n",
    "# А это будет счетчтиком для нумерация моеделй\n",
    "count_model = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Категориальные признаки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список категориальных признаков: ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'Brand', 'Repaired']\n"
     ]
    }
   ],
   "source": [
    "col_type_obj = df_clean.select_dtypes(include='object').columns.to_list()\n",
    "print('Список категориальных признаков:', col_type_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Численные признаки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список численных признаков: ['RegistrationYear', 'Power', 'Kilometer', 'RegistrationMonth']\n"
     ]
    }
   ],
   "source": [
    "col_type_num = df_clean.select_dtypes(exclude='object').columns.to_list()\n",
    "for i in ['DateCrawled', 'Price', 'DateCreated', 'NumberOfPictures', 'PostalCode', 'LastSeen']:\n",
    "    col_type_num.remove(i)\n",
    "print('Список численных признаков:', col_type_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прямое кодирование - One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Памятка себе:**_\n",
    "\n",
    "**Модели основанные на деревьях (все модели в проекте кроме Линейной) могут работать с порядковым кодированием категорий (OrdinalEncoding).**\n",
    "\n",
    "**OHE сильно раздувает размерность данных, что сказывается на вычислительной нагрузке (времени).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 295933 entries, 1 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   DateCrawled        295933 non-null  datetime64[ns]\n",
      " 1   Price              295933 non-null  int64         \n",
      " 2   VehicleType        295933 non-null  object        \n",
      " 3   RegistrationYear   295933 non-null  int64         \n",
      " 4   Gearbox            295933 non-null  object        \n",
      " 5   Power              295933 non-null  int64         \n",
      " 6   Model              295933 non-null  object        \n",
      " 7   Kilometer          295933 non-null  int64         \n",
      " 8   RegistrationMonth  295933 non-null  int64         \n",
      " 9   FuelType           295933 non-null  object        \n",
      " 10  Brand              295933 non-null  object        \n",
      " 11  Repaired           295933 non-null  object        \n",
      " 12  DateCreated        295933 non-null  datetime64[ns]\n",
      " 13  NumberOfPictures   295933 non-null  int64         \n",
      " 14  PostalCode         295933 non-null  int64         \n",
      " 15  LastSeen           295933 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](3), int64(7), object(6)\n",
      "memory usage: 38.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убираем лишние признаки перед прямым кодированием\n",
    "df_ohe = df_clean[['Price', 'VehicleType', 'RegistrationYear', 'Gearbox', 'Power', \n",
    "                   'Model', 'Kilometer', 'RegistrationMonth', 'FuelType', 'Brand', 'Repaired']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23102"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Смотирм\n",
    "df_ohe.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2381614365.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ohe.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Избавимся от них\n",
    "df_ohe.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Деление на обучающей и валидационной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем признак и цель \n",
    "features = df_ohe.drop('Price', axis=1)\n",
    "target = df_ohe['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим обучающую и валидационную выборку\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=(1 - 0.6), random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'> Здорово , что у нас есть выборка для тестов!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодируем\n",
    "encoder_ohe = OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучаем энкодер на заданных категориальных признаках тренировочной выборки\n",
    "encoder_ohe.fit(features_train[col_type_obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n"
     ]
    }
   ],
   "source": [
    "# Добавляем закодированные признаки в X_train_ohe\n",
    "# Encoder_ohe.get_feature_names_out() позволяет получить названия колонок\n",
    "features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:202: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n"
     ]
    }
   ],
   "source": [
    "# Энкодером, который обучен на ТРЕНИРОВОЧНОЙ ВЫБОРКЕ, кодируем тестовую\n",
    "features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем незакодированные категориальные признаки (изначальные колонки)\n",
    "features_train = features_train.drop(col_type_obj, axis=1)\n",
    "\n",
    "features_valid = features_valid.drop(col_type_obj, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Power</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>VehicleType_convertible</th>\n",
       "      <th>VehicleType_coupe</th>\n",
       "      <th>VehicleType_other</th>\n",
       "      <th>VehicleType_sedan</th>\n",
       "      <th>VehicleType_small</th>\n",
       "      <th>VehicleType_suv</th>\n",
       "      <th>...</th>\n",
       "      <th>Brand_smart</th>\n",
       "      <th>Brand_sonstige_autos</th>\n",
       "      <th>Brand_subaru</th>\n",
       "      <th>Brand_suzuki</th>\n",
       "      <th>Brand_toyota</th>\n",
       "      <th>Brand_trabant</th>\n",
       "      <th>Brand_volkswagen</th>\n",
       "      <th>Brand_volvo</th>\n",
       "      <th>Repaired_unknown</th>\n",
       "      <th>Repaired_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184019</th>\n",
       "      <td>2007</td>\n",
       "      <td>131</td>\n",
       "      <td>125000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224508</th>\n",
       "      <td>1997</td>\n",
       "      <td>75</td>\n",
       "      <td>100000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328264</th>\n",
       "      <td>1997</td>\n",
       "      <td>130</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136227</th>\n",
       "      <td>2009</td>\n",
       "      <td>143</td>\n",
       "      <td>60000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309930</th>\n",
       "      <td>2006</td>\n",
       "      <td>170</td>\n",
       "      <td>150000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RegistrationYear  Power  Kilometer  RegistrationMonth  \\\n",
       "184019              2007    131     125000                  6   \n",
       "224508              1997     75     100000                  9   \n",
       "328264              1997    130     150000                  3   \n",
       "136227              2009    143      60000                  3   \n",
       "309930              2006    170     150000                 12   \n",
       "\n",
       "        VehicleType_convertible  VehicleType_coupe  VehicleType_other  \\\n",
       "184019                      0.0                0.0                0.0   \n",
       "224508                      0.0                0.0                0.0   \n",
       "328264                      0.0                0.0                0.0   \n",
       "136227                      1.0                0.0                0.0   \n",
       "309930                      0.0                0.0                0.0   \n",
       "\n",
       "        VehicleType_sedan  VehicleType_small  VehicleType_suv  ...  \\\n",
       "184019                0.0                0.0              0.0  ...   \n",
       "224508                1.0                0.0              0.0  ...   \n",
       "328264                1.0                0.0              0.0  ...   \n",
       "136227                0.0                0.0              0.0  ...   \n",
       "309930                0.0                0.0              0.0  ...   \n",
       "\n",
       "        Brand_smart  Brand_sonstige_autos  Brand_subaru  Brand_suzuki  \\\n",
       "184019          0.0                   0.0           0.0           0.0   \n",
       "224508          0.0                   0.0           0.0           0.0   \n",
       "328264          0.0                   0.0           0.0           0.0   \n",
       "136227          0.0                   0.0           0.0           0.0   \n",
       "309930          0.0                   0.0           0.0           0.0   \n",
       "\n",
       "        Brand_toyota  Brand_trabant  Brand_volkswagen  Brand_volvo  \\\n",
       "184019           0.0            0.0               1.0          0.0   \n",
       "224508           0.0            0.0               0.0          0.0   \n",
       "328264           0.0            0.0               0.0          0.0   \n",
       "136227           0.0            0.0               0.0          0.0   \n",
       "309930           0.0            0.0               1.0          0.0   \n",
       "\n",
       "        Repaired_unknown  Repaired_yes  \n",
       "184019               0.0           0.0  \n",
       "224508               0.0           0.0  \n",
       "328264               0.0           0.0  \n",
       "136227               0.0           0.0  \n",
       "309930               0.0           0.0  \n",
       "\n",
       "[5 rows x 310 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Power</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>VehicleType_convertible</th>\n",
       "      <th>VehicleType_coupe</th>\n",
       "      <th>VehicleType_other</th>\n",
       "      <th>VehicleType_sedan</th>\n",
       "      <th>VehicleType_small</th>\n",
       "      <th>VehicleType_suv</th>\n",
       "      <th>...</th>\n",
       "      <th>Brand_smart</th>\n",
       "      <th>Brand_sonstige_autos</th>\n",
       "      <th>Brand_subaru</th>\n",
       "      <th>Brand_suzuki</th>\n",
       "      <th>Brand_toyota</th>\n",
       "      <th>Brand_trabant</th>\n",
       "      <th>Brand_volkswagen</th>\n",
       "      <th>Brand_volvo</th>\n",
       "      <th>Repaired_unknown</th>\n",
       "      <th>Repaired_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110198</th>\n",
       "      <td>2001</td>\n",
       "      <td>44</td>\n",
       "      <td>150000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96619</th>\n",
       "      <td>2007</td>\n",
       "      <td>105</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345457</th>\n",
       "      <td>2000</td>\n",
       "      <td>179</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142762</th>\n",
       "      <td>1997</td>\n",
       "      <td>231</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221541</th>\n",
       "      <td>2008</td>\n",
       "      <td>71</td>\n",
       "      <td>50000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RegistrationYear  Power  Kilometer  RegistrationMonth  \\\n",
       "110198              2001     44     150000                  5   \n",
       "96619               2007    105     150000                  3   \n",
       "345457              2000    179     150000                  0   \n",
       "142762              1997    231     150000                  3   \n",
       "221541              2008     71      50000                  9   \n",
       "\n",
       "        VehicleType_convertible  VehicleType_coupe  VehicleType_other  \\\n",
       "110198                      1.0                0.0                0.0   \n",
       "96619                       0.0                0.0                0.0   \n",
       "345457                      0.0                0.0                0.0   \n",
       "142762                      1.0                0.0                0.0   \n",
       "221541                      0.0                0.0                0.0   \n",
       "\n",
       "        VehicleType_sedan  VehicleType_small  VehicleType_suv  ...  \\\n",
       "110198                0.0                0.0              0.0  ...   \n",
       "96619                 0.0                0.0              0.0  ...   \n",
       "345457                1.0                0.0              0.0  ...   \n",
       "142762                0.0                0.0              0.0  ...   \n",
       "221541                0.0                1.0              0.0  ...   \n",
       "\n",
       "        Brand_smart  Brand_sonstige_autos  Brand_subaru  Brand_suzuki  \\\n",
       "110198          1.0                   0.0           0.0           0.0   \n",
       "96619           0.0                   0.0           0.0           0.0   \n",
       "345457          0.0                   0.0           0.0           0.0   \n",
       "142762          0.0                   0.0           0.0           0.0   \n",
       "221541          1.0                   0.0           0.0           0.0   \n",
       "\n",
       "        Brand_toyota  Brand_trabant  Brand_volkswagen  Brand_volvo  \\\n",
       "110198           0.0            0.0               0.0          0.0   \n",
       "96619            0.0            0.0               1.0          0.0   \n",
       "345457           0.0            0.0               0.0          0.0   \n",
       "142762           0.0            0.0               0.0          0.0   \n",
       "221541           0.0            0.0               0.0          0.0   \n",
       "\n",
       "        Repaired_unknown  Repaired_yes  \n",
       "110198               0.0           0.0  \n",
       "96619                0.0           0.0  \n",
       "345457               0.0           0.0  \n",
       "142762               0.0           0.0  \n",
       "221541               0.0           0.0  \n",
       "\n",
       "[5 rows x 310 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(features_train.head())\n",
    "display(features_valid.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем нужные параметры\n",
    "parameters = {}\n",
    "\n",
    "# Инициализируем модель\n",
    "model = GridSearchCV(LinearRegression(), param_grid = parameters, cv = 5, scoring = 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE TRAIN: 2678.2658313392585\n",
      "TIME TRAIN [s]: 3.71\n",
      "CPU times: total: 21.5 s\n",
      "Wall time: 19.9 s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"98d77f92-20f9-4bbb-b009-3f3e8c11d048\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"98d77f92-20f9-4bbb-b009-3f3e8c11d048\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"LinearRegression OHE\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"LinearRegression OHE\"\n",
    "%%time\n",
    "\n",
    "# Обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "time = model.refit_time_\n",
    "params = model.best_params_\n",
    "\n",
    "# Узнаем RMSE обучающей выборки\n",
    "result_RMSE_t = -model.best_score_\n",
    "print('RMSE TRAIN:', result_RMSE_t)\n",
    "print('TIME TRAIN [s]:', round(time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка на тестовой выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE VALID: 2693.317059048769\n",
      "Предсказание: 4844.076333852994\n",
      "CPU times: total: 125 ms\n",
      "Wall time: 378 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = timeit.default_timer()\n",
    "# Получим предсказания на тестовой выборки\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "elapsed = round(timeit.default_timer() - start_time, 3)\n",
    "\n",
    "# Узнаем RMSE\n",
    "result_RMSE_v = mean_squared_error(target_valid, predictions, squared=False)\n",
    "print('RMSE VALID:', result_RMSE_v)\n",
    "print('Предсказание:', predictions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зафиксируем результаты\n",
    "results[count_model] = pd.Series({\n",
    "    'NAME': 'LinearRegression_OHE', \n",
    "    'RMSE TRAIN': result_RMSE_t, \n",
    "    'RMSE VALID': result_RMSE_v, \n",
    "    'PREDICTIONS': predictions.mean(), \n",
    "    'TIME TRAINING [s]': model.refit_time_, \n",
    "    'TIME PREDICTION [s]': elapsed, \n",
    "    'PARAMETRS': model.best_params_\n",
    "})\n",
    "\n",
    "results[count_model]\n",
    "count_model+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Порядковое кодирование - OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Кодирование признаков - деление на обучающей и валидационной выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь преобразуем в другой тип, применяя OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убираем лишние признаки перед прямым кодированием\n",
    "df_clean = df_clean[['Price', 'VehicleType', 'RegistrationYear', 'Gearbox', 'Power', \n",
    "                   'Model', 'Kilometer', 'RegistrationMonth', 'FuelType', 'Brand', 'Repaired']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_clean.drop(['Price'], axis=1)\n",
    "target = df_clean['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим обучающую и валидационную выборку\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=(1 - 0.6), random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Обучающие признаки обучим и трансформируем \n",
    "features_train[col_type_obj] = Encoder.fit_transform(features_train[col_type_obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Валидациоaнные признаки только трансформируем\n",
    "features_valid[col_type_obj] = Encoder.transform(features_valid[col_type_obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177559, 10)\n",
      "(118374, 10)\n"
     ]
    }
   ],
   "source": [
    "# Проверим\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: 0.6 %\n",
      "Размер валидационной выборки: 0.4 %\n"
     ]
    }
   ],
   "source": [
    "print('Размер обучающей выборки:', round(features_train.shape[0] / features.shape[0], 2), '%')\n",
    "print('Размер валидационной выборки:', round(features_valid.shape[0] / target.shape[0], 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Repaired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131749</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54</td>\n",
       "      <td>75.0</td>\n",
       "      <td>150000</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279442</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>116.0</td>\n",
       "      <td>125000</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166435</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107</td>\n",
       "      <td>136.0</td>\n",
       "      <td>150000</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        VehicleType  RegistrationYear  Gearbox  Power  Model  Kilometer  \\\n",
       "131749          5.0              1996      1.0     54   75.0     150000   \n",
       "279442          4.0              2000      1.0     75  116.0     125000   \n",
       "166435          8.0              2000      1.0    107  136.0     150000   \n",
       "\n",
       "        RegistrationMonth  FuelType  Brand  Repaired  \n",
       "131749                  5       7.0   27.0       0.0  \n",
       "279442                  9       6.0   38.0       0.0  \n",
       "166435                  9       6.0   27.0       0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Repaired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193124</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>102.0</td>\n",
       "      <td>90000</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135</td>\n",
       "      <td>198.0</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235550</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>101.0</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        VehicleType  RegistrationYear  Gearbox  Power  Model  Kilometer  \\\n",
       "193124          5.0              2002      1.0     60  102.0      90000   \n",
       "2170            8.0              2005      1.0    135  198.0     125000   \n",
       "235550          5.0              2009      1.0     60  101.0     150000   \n",
       "\n",
       "        RegistrationMonth  FuelType  Brand  Repaired  \n",
       "193124                  3       6.0   10.0       0.0  \n",
       "2170                    5       6.0   27.0       0.0  \n",
       "235550                  3       6.0   31.0       2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(features_train.head(3))\n",
    "\n",
    "display(features_valid.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создадим датасет, в котором содержатся исключительно цифры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка на тестовой выборки**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрица гиперпараметров\n",
    "parameters = {'max_depth': range(1, 101, 10), 'min_samples_leaf': [1, 0.5, 2]}\n",
    "\n",
    "# Инициализируем модель c параметрами\n",
    "model = GridSearchCV(DecisionTreeRegressor(random_state = 12345), param_grid = parameters, cv = 5, scoring = 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE TRAIN: 1946.6320820939814\n",
      "TIME TRAIN [s]: 0.37\n",
      "CPU times: total: 48.5 s\n",
      "Wall time: 49.3 s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"d0ad0166-c5f6-443c-b517-9f6ffc21b4ea\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"d0ad0166-c5f6-443c-b517-9f6ffc21b4ea\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"DecisionTreeRegressor OE\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"DecisionTreeRegressor OE\"\n",
    "%%time\n",
    "\n",
    "# Обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "time = model.refit_time_\n",
    "params = model.best_params_\n",
    "\n",
    "# Узнаем RMSE обучающей выборки\n",
    "result_RMSE_t = -model.best_score_\n",
    "print('RMSE TRAIN:', result_RMSE_t)\n",
    "print('TIME TRAIN [s]:', round(time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка на тестовой выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=11, min_samples_leaf=2, random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=11, min_samples_leaf=2, random_state=12345)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=11, min_samples_leaf=2, random_state=12345)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализируем модель c лучшими гиперпараметрами\n",
    "model = DecisionTreeRegressor(random_state = 12345).set_params(max_depth = params['max_depth'], min_samples_leaf = params['min_samples_leaf'])\n",
    "\n",
    "# Обучим модель на тренировочной выборке\n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE VALID: 1911.4296286479232\n",
      "Предсказание: 4855.465560115789\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 25 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = timeit.default_timer()\n",
    "# Получим предсказания на тестовой выборки\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "elapsed = round(timeit.default_timer() - start_time, 3)\n",
    "\n",
    "result_RMSE_v = mean_squared_error(target_valid, predictions, squared=False)\n",
    "print('RMSE VALID:', result_RMSE_v)\n",
    "\n",
    "print('Предсказание:', predictions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зафиксируем результаты\n",
    "results[count_model] = pd.Series({\n",
    "    'NAME': 'DecisionTreeRegressor_OE', \n",
    "    'RMSE TRAIN': result_RMSE_t, \n",
    "    'RMSE VALID': result_RMSE_v, \n",
    "    'PREDICTIONS': predictions.mean(), \n",
    "    'TIME TRAINING [s]': round(time, 2), \n",
    "    'TIME PREDICTION [s]': elapsed, \n",
    "    'PARAMETRS': params\n",
    "})\n",
    "\n",
    "results[count_model]\n",
    "count_model+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрица гиперпараметров для случайного леса\n",
    "parameters = {'bootstrap': [True], 'max_depth': [5, 15], 'max_features': ['auto', 'log2'], 'n_estimators': [25, 50]}\n",
    "\n",
    "# Инициализируем модель c параметрами\n",
    "model = GridSearchCV(RandomForestRegressor(random_state = 12345), parameters, cv = 5, scoring = 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE TRAIN: 1635.4065969530275\n",
      "TIME TRAIN [s]: 6.38\n",
      "CPU times: total: 3min 20s\n",
      "Wall time: 3min 25s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"92597532-b09b-4500-917d-b897f948a941\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"92597532-b09b-4500-917d-b897f948a941\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"RandomForestRegressor OE\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"RandomForestRegressor OE\"\n",
    "%%time\n",
    "\n",
    "# Обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "time = model.refit_time_\n",
    "params = model.best_params_\n",
    "\n",
    "# Узнаем RMSE обучающей выборки\n",
    "result_RMSE_t = -model.best_score_\n",
    "print('RMSE TRAIN:', result_RMSE_t)\n",
    "print('TIME TRAIN [s]:', round(time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка на тестовой выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=15, max_features=&#x27;log2&#x27;, n_estimators=50,\n",
       "                      random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=15, max_features=&#x27;log2&#x27;, n_estimators=50,\n",
       "                      random_state=12345)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=15, max_features='log2', n_estimators=50,\n",
       "                      random_state=12345)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализируем модель c лучшими гиперпараметрами\n",
    "model = RandomForestRegressor(random_state = 12345).set_params(\n",
    "    max_depth = params['max_depth'], \n",
    "    max_features = params['max_features'], \n",
    "    n_estimators = params['n_estimators']\n",
    ")\n",
    "\n",
    "# Обучим модель на тренировочной выборке\n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE VALID: 1606.6479762704178\n",
      "Предсказание: 4854.598314764133\n",
      "CPU times: total: 812 ms\n",
      "Wall time: 906 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = timeit.default_timer()\n",
    "# Получим предсказания на тестовой выборки\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "elapsed = round(timeit.default_timer() - start_time, 3)\n",
    "\n",
    "result_RMSE_v = mean_squared_error(target_valid, predictions, squared=False)\n",
    "print('RMSE VALID:', result_RMSE_v)\n",
    "print('Предсказание:', predictions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[count_model] = pd.Series({\n",
    "    'NAME': 'RandomForestRegressor_OE', \n",
    "    'RMSE TRAIN': result_RMSE_t, \n",
    "    'RMSE VALID': result_RMSE_v, \n",
    "    'PREDICTIONS': predictions.mean(), \n",
    "    'TIME TRAINING [s]': time, \n",
    "    'TIME PREDICTION [s]': elapsed, \n",
    "    'PARAMETRS': params\n",
    "})\n",
    "\n",
    "results[count_model]\n",
    "count_model+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрица гиперпараметров для LightGBMRegressor\n",
    "parameters = {'num_leaves': [5, 10],\n",
    "              'learning_rate': [0.1, 0.3],\n",
    "              'max_depth': [3, 5],\n",
    "              'n_estimators': [10, 25]}\n",
    "\n",
    "# Инициализируем модель c параметрами\n",
    "model = GridSearchCV(LGBMRegressor(), parameters, cv = 5, scoring = 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE TRAIN: 1887.95083563258\n",
      "TIME TRAIN [s]: 0.13\n",
      "CPU times: total: 2min 15s\n",
      "Wall time: 9.91 s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"9b313814-89d3-4afe-8b4d-ae19506b13ed\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"9b313814-89d3-4afe-8b4d-ae19506b13ed\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"LightGBMRegressor OE\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"LightGBMRegressor OE\"\n",
    "%%time\n",
    "\n",
    "# Обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "time = model.refit_time_\n",
    "params = model.best_params_\n",
    "\n",
    "# Узнаем RMSE обучающей выборки\n",
    "result_RMSE_t = -model.best_score_\n",
    "print('RMSE TRAIN:', result_RMSE_t)\n",
    "print('TIME TRAIN [s]:', round(time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка на тестовой выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(learning_rate=0.3, max_depth=5, n_estimators=25, num_leaves=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(learning_rate=0.3, max_depth=5, n_estimators=25, num_leaves=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(learning_rate=0.3, max_depth=5, n_estimators=25, num_leaves=10)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализируем модель c лучшими гиперпараметрами\n",
    "model = LGBMRegressor().set_params(\n",
    "    max_depth = params['max_depth'], \n",
    "    num_leaves = params['num_leaves'], \n",
    "    learning_rate = params['learning_rate'],\n",
    "    n_estimators = params['n_estimators']\n",
    ")\n",
    "\n",
    "# Обучим модель на тренировочной выборке\n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE VALID: 1858.723461074672\n",
      "Предсказание: 4861.046970265422\n",
      "CPU times: total: 422 ms\n",
      "Wall time: 36 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = timeit.default_timer()\n",
    "# Получим предсказания на тестовой выборки\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "elapsed = round(timeit.default_timer() - start_time, 3)\n",
    "\n",
    "result_RMSE_v = mean_squared_error(target_valid, predictions, squared=False)\n",
    "print('RMSE VALID:', result_RMSE_v)\n",
    "print('Предсказание:', predictions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зафиксируем результаты\n",
    "results[count_model] = pd.Series({\n",
    "    'NAME': 'LightGBMRegressor_OE_C', \n",
    "    'RMSE TRAIN': result_RMSE_t, \n",
    "    'RMSE VALID': result_RMSE_v, \n",
    "    'PREDICTIONS': predictions.mean(), \n",
    "    'TIME TRAINING [s]': time, \n",
    "    'TIME PREDICTION [s]': elapsed, \n",
    "    'PARAMETRS': params\n",
    "})\n",
    "\n",
    "results[count_model]\n",
    "count_model+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрица гиперпараметров для LightGBMRegressor\n",
    "parameters = {'depth' : [6, 8, 10],\n",
    "              'learning_rate' : [0.01, 0.05, 0.1],\n",
    "              'iterations' : [10, 15, 20]}\n",
    "\n",
    "# Инициализируем модель c параметрами\n",
    "model = GridSearchCV(CatBoostRegressor(), parameters, cv = 5, scoring = 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4595.6975750\ttotal: 152ms\tremaining: 1.36s\n",
      "1:\tlearn: 4565.0904929\ttotal: 161ms\tremaining: 645ms\n",
      "2:\tlearn: 4534.9589066\ttotal: 170ms\tremaining: 397ms\n",
      "3:\tlearn: 4505.2428554\ttotal: 180ms\tremaining: 270ms\n",
      "4:\tlearn: 4475.7557038\ttotal: 190ms\tremaining: 190ms\n",
      "5:\tlearn: 4446.9740799\ttotal: 198ms\tremaining: 132ms\n",
      "6:\tlearn: 4418.6968903\ttotal: 208ms\tremaining: 89.1ms\n",
      "7:\tlearn: 4391.0918699\ttotal: 217ms\tremaining: 54.3ms\n",
      "8:\tlearn: 4363.5150246\ttotal: 227ms\tremaining: 25.2ms\n",
      "9:\tlearn: 4335.8113842\ttotal: 236ms\tremaining: 0us\n",
      "0:\tlearn: 4587.1013079\ttotal: 9.88ms\tremaining: 89ms\n",
      "1:\tlearn: 4556.5692240\ttotal: 18.3ms\tremaining: 73.2ms\n",
      "2:\tlearn: 4526.8269200\ttotal: 26.7ms\tremaining: 62.2ms\n",
      "3:\tlearn: 4496.9895735\ttotal: 35.4ms\tremaining: 53.1ms\n",
      "4:\tlearn: 4467.5828003\ttotal: 44.3ms\tremaining: 44.3ms\n",
      "5:\tlearn: 4439.0487143\ttotal: 52.9ms\tremaining: 35.3ms\n",
      "6:\tlearn: 4410.6546440\ttotal: 61.6ms\tremaining: 26.4ms\n",
      "7:\tlearn: 4383.0422919\ttotal: 69.9ms\tremaining: 17.5ms\n",
      "8:\tlearn: 4355.8783718\ttotal: 78ms\tremaining: 8.67ms\n",
      "9:\tlearn: 4328.5430622\ttotal: 86.2ms\tremaining: 0us\n",
      "0:\tlearn: 4597.5807386\ttotal: 9.48ms\tremaining: 85.3ms\n",
      "1:\tlearn: 4566.9262922\ttotal: 17.8ms\tremaining: 71.4ms\n",
      "2:\tlearn: 4537.0352976\ttotal: 26.4ms\tremaining: 61.7ms\n",
      "3:\tlearn: 4507.2665811\ttotal: 34.7ms\tremaining: 52.1ms\n",
      "4:\tlearn: 4477.7327902\ttotal: 44.2ms\tremaining: 44.2ms\n",
      "5:\tlearn: 4448.8562125\ttotal: 52.6ms\tremaining: 35.1ms\n",
      "6:\tlearn: 4420.3991300\ttotal: 60.7ms\tremaining: 26ms\n",
      "7:\tlearn: 4392.7253010\ttotal: 68.6ms\tremaining: 17.2ms\n",
      "8:\tlearn: 4365.4957931\ttotal: 76.5ms\tremaining: 8.5ms\n",
      "9:\tlearn: 4338.1353840\ttotal: 84.3ms\tremaining: 0us\n",
      "0:\tlearn: 4593.1182658\ttotal: 11.4ms\tremaining: 102ms\n",
      "1:\tlearn: 4562.6149473\ttotal: 21.1ms\tremaining: 84.5ms\n",
      "2:\tlearn: 4532.7734975\ttotal: 29.6ms\tremaining: 69.1ms\n",
      "3:\tlearn: 4503.2915414\ttotal: 37.6ms\tremaining: 56.5ms\n",
      "4:\tlearn: 4473.7778560\ttotal: 46.6ms\tremaining: 46.6ms\n",
      "5:\tlearn: 4445.0877532\ttotal: 54.6ms\tremaining: 36.4ms\n",
      "6:\tlearn: 4416.6302224\ttotal: 62.8ms\tremaining: 26.9ms\n",
      "7:\tlearn: 4389.1202462\ttotal: 71ms\tremaining: 17.7ms\n",
      "8:\tlearn: 4361.5188722\ttotal: 79ms\tremaining: 8.78ms\n",
      "9:\tlearn: 4333.7986068\ttotal: 87ms\tremaining: 0us\n",
      "0:\tlearn: 4588.8617128\ttotal: 21.6ms\tremaining: 194ms\n",
      "1:\tlearn: 4558.4683563\ttotal: 30.3ms\tremaining: 121ms\n",
      "2:\tlearn: 4528.4238416\ttotal: 38.8ms\tremaining: 90.5ms\n",
      "3:\tlearn: 4498.6892509\ttotal: 47.6ms\tremaining: 71.4ms\n",
      "4:\tlearn: 4469.0875780\ttotal: 56.8ms\tremaining: 56.8ms\n",
      "5:\tlearn: 4440.3212828\ttotal: 65.9ms\tremaining: 44ms\n",
      "6:\tlearn: 4411.7007871\ttotal: 74.9ms\tremaining: 32.1ms\n",
      "7:\tlearn: 4384.2028939\ttotal: 83.1ms\tremaining: 20.8ms\n",
      "8:\tlearn: 4356.7924636\ttotal: 91.5ms\tremaining: 10.2ms\n",
      "9:\tlearn: 4329.0978050\ttotal: 101ms\tremaining: 0us\n",
      "0:\tlearn: 4474.4785029\ttotal: 10.3ms\tremaining: 92.6ms\n",
      "1:\tlearn: 4334.1285305\ttotal: 19.1ms\tremaining: 76.4ms\n",
      "2:\tlearn: 4198.7671646\ttotal: 27.9ms\tremaining: 65.1ms\n",
      "3:\tlearn: 4071.1922407\ttotal: 37.3ms\tremaining: 55.9ms\n",
      "4:\tlearn: 3948.4488816\ttotal: 46.1ms\tremaining: 46.1ms\n",
      "5:\tlearn: 3838.4325137\ttotal: 55ms\tremaining: 36.7ms\n",
      "6:\tlearn: 3731.0469874\ttotal: 63.8ms\tremaining: 27.4ms\n",
      "7:\tlearn: 3632.8314215\ttotal: 73.4ms\tremaining: 18.4ms\n",
      "8:\tlearn: 3538.1509081\ttotal: 83.7ms\tremaining: 9.3ms\n",
      "9:\tlearn: 3448.0223800\ttotal: 93.4ms\tremaining: 0us\n",
      "0:\tlearn: 4467.0669821\ttotal: 17.1ms\tremaining: 154ms\n",
      "1:\tlearn: 4322.7889640\ttotal: 26.6ms\tremaining: 106ms\n",
      "2:\tlearn: 4188.9567737\ttotal: 35.7ms\tremaining: 83.2ms\n",
      "3:\tlearn: 4062.1638108\ttotal: 45.9ms\tremaining: 68.8ms\n",
      "4:\tlearn: 3943.4179026\ttotal: 56.1ms\tremaining: 56.1ms\n",
      "5:\tlearn: 3833.1957923\ttotal: 65.6ms\tremaining: 43.7ms\n",
      "6:\tlearn: 3729.8856270\ttotal: 74.1ms\tremaining: 31.7ms\n",
      "7:\tlearn: 3630.7186810\ttotal: 83.1ms\tremaining: 20.8ms\n",
      "8:\tlearn: 3535.1161394\ttotal: 91.7ms\tremaining: 10.2ms\n",
      "9:\tlearn: 3444.9377844\ttotal: 100ms\tremaining: 0us\n",
      "0:\tlearn: 4475.4942490\ttotal: 10.8ms\tremaining: 96.8ms\n",
      "1:\tlearn: 4330.8031644\ttotal: 19.5ms\tremaining: 77.9ms\n",
      "2:\tlearn: 4196.5939494\ttotal: 28.6ms\tremaining: 66.7ms\n",
      "3:\tlearn: 4069.4584167\ttotal: 37.3ms\tremaining: 56ms\n",
      "4:\tlearn: 3951.3493329\ttotal: 47ms\tremaining: 47ms\n",
      "5:\tlearn: 3840.3774206\ttotal: 55.3ms\tremaining: 36.9ms\n",
      "6:\tlearn: 3733.9178898\ttotal: 64.9ms\tremaining: 27.8ms\n",
      "7:\tlearn: 3632.4976176\ttotal: 73.8ms\tremaining: 18.4ms\n",
      "8:\tlearn: 3536.6866789\ttotal: 82.3ms\tremaining: 9.15ms\n",
      "9:\tlearn: 3446.6393508\ttotal: 90.7ms\tremaining: 0us\n",
      "0:\tlearn: 4471.0646009\ttotal: 10.6ms\tremaining: 95.1ms\n",
      "1:\tlearn: 4327.1143351\ttotal: 19.7ms\tremaining: 78.9ms\n",
      "2:\tlearn: 4191.8058289\ttotal: 28.5ms\tremaining: 66.5ms\n",
      "3:\tlearn: 4065.5133323\ttotal: 36.8ms\tremaining: 55.2ms\n",
      "4:\tlearn: 3946.3276592\ttotal: 46ms\tremaining: 46ms\n",
      "5:\tlearn: 3832.6264800\ttotal: 54.8ms\tremaining: 36.5ms\n",
      "6:\tlearn: 3727.7852727\ttotal: 63.9ms\tremaining: 27.4ms\n",
      "7:\tlearn: 3629.9953835\ttotal: 72.6ms\tremaining: 18.1ms\n",
      "8:\tlearn: 3536.0116851\ttotal: 81.8ms\tremaining: 9.09ms\n",
      "9:\tlearn: 3446.9643262\ttotal: 90.1ms\tremaining: 0us\n",
      "0:\tlearn: 4468.6604377\ttotal: 9.76ms\tremaining: 87.8ms\n",
      "1:\tlearn: 4329.5828880\ttotal: 19.7ms\tremaining: 78.6ms\n",
      "2:\tlearn: 4194.4965948\ttotal: 28.2ms\tremaining: 65.8ms\n",
      "3:\tlearn: 4063.9371341\ttotal: 37.1ms\tremaining: 55.7ms\n",
      "4:\tlearn: 3943.7546102\ttotal: 46.6ms\tremaining: 46.6ms\n",
      "5:\tlearn: 3832.5937795\ttotal: 55.4ms\tremaining: 36.9ms\n",
      "6:\tlearn: 3727.0899046\ttotal: 63.4ms\tremaining: 27.2ms\n",
      "7:\tlearn: 3626.6120810\ttotal: 71.6ms\tremaining: 17.9ms\n",
      "8:\tlearn: 3531.8119137\ttotal: 79.7ms\tremaining: 8.85ms\n",
      "9:\tlearn: 3445.1987071\ttotal: 87.4ms\tremaining: 0us\n",
      "0:\tlearn: 4325.5366851\ttotal: 10.1ms\tremaining: 90.6ms\n",
      "1:\tlearn: 4059.2138065\ttotal: 18.6ms\tremaining: 74.4ms\n",
      "2:\tlearn: 3825.5166143\ttotal: 27.1ms\tremaining: 63.1ms\n",
      "3:\tlearn: 3615.1427470\ttotal: 35.3ms\tremaining: 52.9ms\n",
      "4:\tlearn: 3431.2729242\ttotal: 44ms\tremaining: 44ms\n",
      "5:\tlearn: 3266.9530130\ttotal: 53.3ms\tremaining: 35.5ms\n",
      "6:\tlearn: 3127.3990449\ttotal: 62.1ms\tremaining: 26.6ms\n",
      "7:\tlearn: 3006.3902461\ttotal: 70.7ms\tremaining: 17.7ms\n",
      "8:\tlearn: 2895.2183097\ttotal: 79.3ms\tremaining: 8.81ms\n",
      "9:\tlearn: 2795.1205639\ttotal: 87.6ms\tremaining: 0us\n",
      "0:\tlearn: 4319.6187217\ttotal: 9.9ms\tremaining: 89.1ms\n",
      "1:\tlearn: 4054.2574781\ttotal: 18.6ms\tremaining: 74.2ms\n",
      "2:\tlearn: 3815.9692253\ttotal: 27.2ms\tremaining: 63.5ms\n",
      "3:\tlearn: 3612.2983150\ttotal: 35.1ms\tremaining: 52.6ms\n",
      "4:\tlearn: 3429.3936697\ttotal: 43.2ms\tremaining: 43.2ms\n",
      "5:\tlearn: 3264.1046699\ttotal: 51.4ms\tremaining: 34.2ms\n",
      "6:\tlearn: 3122.8519874\ttotal: 58.8ms\tremaining: 25.2ms\n",
      "7:\tlearn: 2994.8007883\ttotal: 67.3ms\tremaining: 16.8ms\n",
      "8:\tlearn: 2886.2506628\ttotal: 75.4ms\tremaining: 8.38ms\n",
      "9:\tlearn: 2787.5263679\ttotal: 83.4ms\tremaining: 0us\n",
      "0:\tlearn: 4325.4602513\ttotal: 10.4ms\tremaining: 93.7ms\n",
      "1:\tlearn: 4067.4020134\ttotal: 19.1ms\tremaining: 76.6ms\n",
      "2:\tlearn: 3829.6063136\ttotal: 27.7ms\tremaining: 64.7ms\n",
      "3:\tlearn: 3628.1639252\ttotal: 36.7ms\tremaining: 55ms\n",
      "4:\tlearn: 3441.0110240\ttotal: 45.5ms\tremaining: 45.5ms\n",
      "5:\tlearn: 3280.5839932\ttotal: 54.2ms\tremaining: 36.1ms\n",
      "6:\tlearn: 3137.4282523\ttotal: 62.7ms\tremaining: 26.9ms\n",
      "7:\tlearn: 3003.8519463\ttotal: 71.7ms\tremaining: 17.9ms\n",
      "8:\tlearn: 2890.8697071\ttotal: 80.2ms\tremaining: 8.91ms\n",
      "9:\tlearn: 2788.1803190\ttotal: 88.8ms\tremaining: 0us\n",
      "0:\tlearn: 4321.0631421\ttotal: 9.61ms\tremaining: 86.5ms\n",
      "1:\tlearn: 4054.0549656\ttotal: 18.6ms\tremaining: 74.3ms\n",
      "2:\tlearn: 3819.8358243\ttotal: 26.8ms\tremaining: 62.6ms\n",
      "3:\tlearn: 3611.1188894\ttotal: 35.1ms\tremaining: 52.7ms\n",
      "4:\tlearn: 3430.3339827\ttotal: 43.1ms\tremaining: 43.1ms\n",
      "5:\tlearn: 3268.4311749\ttotal: 51.9ms\tremaining: 34.6ms\n",
      "6:\tlearn: 3122.9348252\ttotal: 60ms\tremaining: 25.7ms\n",
      "7:\tlearn: 2999.8173752\ttotal: 69.6ms\tremaining: 17.4ms\n",
      "8:\tlearn: 2887.3826580\ttotal: 78.8ms\tremaining: 8.76ms\n",
      "9:\tlearn: 2792.1037566\ttotal: 87ms\tremaining: 0us\n",
      "0:\tlearn: 4321.0008481\ttotal: 9.99ms\tremaining: 89.9ms\n",
      "1:\tlearn: 4062.7198693\ttotal: 18.4ms\tremaining: 73.5ms\n",
      "2:\tlearn: 3828.2455904\ttotal: 26.9ms\tremaining: 62.7ms\n",
      "3:\tlearn: 3613.7895991\ttotal: 35.5ms\tremaining: 53.2ms\n",
      "4:\tlearn: 3426.3627954\ttotal: 44.5ms\tremaining: 44.5ms\n",
      "5:\tlearn: 3261.6642717\ttotal: 54ms\tremaining: 36ms\n",
      "6:\tlearn: 3121.7534535\ttotal: 62ms\tremaining: 26.6ms\n",
      "7:\tlearn: 3001.7868268\ttotal: 70.9ms\tremaining: 17.7ms\n",
      "8:\tlearn: 2892.9273622\ttotal: 79.2ms\tremaining: 8.8ms\n",
      "9:\tlearn: 2798.0922417\ttotal: 87.7ms\tremaining: 0us\n",
      "0:\tlearn: 4595.6975750\ttotal: 10.1ms\tremaining: 142ms\n",
      "1:\tlearn: 4565.0904929\ttotal: 18.6ms\tremaining: 121ms\n",
      "2:\tlearn: 4534.9589066\ttotal: 27.8ms\tremaining: 111ms\n",
      "3:\tlearn: 4505.2428554\ttotal: 36.2ms\tremaining: 99.6ms\n",
      "4:\tlearn: 4475.7557038\ttotal: 45.3ms\tremaining: 90.5ms\n",
      "5:\tlearn: 4446.9740799\ttotal: 53.7ms\tremaining: 80.5ms\n",
      "6:\tlearn: 4418.6968903\ttotal: 62.6ms\tremaining: 71.6ms\n",
      "7:\tlearn: 4391.0918699\ttotal: 71.1ms\tremaining: 62.2ms\n",
      "8:\tlearn: 4363.5150246\ttotal: 79.1ms\tremaining: 52.7ms\n",
      "9:\tlearn: 4335.8113842\ttotal: 87.6ms\tremaining: 43.8ms\n",
      "10:\tlearn: 4308.8667159\ttotal: 95.5ms\tremaining: 34.7ms\n",
      "11:\tlearn: 4282.2402519\ttotal: 104ms\tremaining: 25.9ms\n",
      "12:\tlearn: 4255.8810446\ttotal: 112ms\tremaining: 17.2ms\n",
      "13:\tlearn: 4230.3486773\ttotal: 120ms\tremaining: 8.55ms\n",
      "14:\tlearn: 4204.1490439\ttotal: 128ms\tremaining: 0us\n",
      "0:\tlearn: 4587.1013079\ttotal: 10.3ms\tremaining: 144ms\n",
      "1:\tlearn: 4556.5692240\ttotal: 18.9ms\tremaining: 123ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:\tlearn: 4526.8269200\ttotal: 28.1ms\tremaining: 112ms\n",
      "3:\tlearn: 4496.9895735\ttotal: 37.1ms\tremaining: 102ms\n",
      "4:\tlearn: 4467.5828003\ttotal: 46.5ms\tremaining: 93ms\n",
      "5:\tlearn: 4439.0487143\ttotal: 56.3ms\tremaining: 84.4ms\n",
      "6:\tlearn: 4410.6546440\ttotal: 64.6ms\tremaining: 73.8ms\n",
      "7:\tlearn: 4383.0422919\ttotal: 72.8ms\tremaining: 63.7ms\n",
      "8:\tlearn: 4355.8783718\ttotal: 80.9ms\tremaining: 54ms\n",
      "9:\tlearn: 4328.5430622\ttotal: 89.3ms\tremaining: 44.6ms\n",
      "10:\tlearn: 4301.7043955\ttotal: 97.1ms\tremaining: 35.3ms\n",
      "11:\tlearn: 4274.8930987\ttotal: 105ms\tremaining: 26.3ms\n",
      "12:\tlearn: 4248.5994869\ttotal: 113ms\tremaining: 17.5ms\n",
      "13:\tlearn: 4222.9759387\ttotal: 122ms\tremaining: 8.69ms\n",
      "14:\tlearn: 4196.9059752\ttotal: 130ms\tremaining: 0us\n",
      "0:\tlearn: 4597.5807386\ttotal: 10.1ms\tremaining: 141ms\n",
      "1:\tlearn: 4566.9262922\ttotal: 18.9ms\tremaining: 123ms\n",
      "2:\tlearn: 4537.0352976\ttotal: 27.5ms\tremaining: 110ms\n",
      "3:\tlearn: 4507.2665811\ttotal: 36.1ms\tremaining: 99.2ms\n",
      "4:\tlearn: 4477.7327902\ttotal: 45.3ms\tremaining: 90.7ms\n",
      "5:\tlearn: 4448.8562125\ttotal: 54.4ms\tremaining: 81.6ms\n",
      "6:\tlearn: 4420.3991300\ttotal: 63ms\tremaining: 72ms\n",
      "7:\tlearn: 4392.7253010\ttotal: 72.4ms\tremaining: 63.3ms\n",
      "8:\tlearn: 4365.4957931\ttotal: 80.7ms\tremaining: 53.8ms\n",
      "9:\tlearn: 4338.1353840\ttotal: 88.9ms\tremaining: 44.5ms\n",
      "10:\tlearn: 4311.2096301\ttotal: 97ms\tremaining: 35.3ms\n",
      "11:\tlearn: 4284.3529900\ttotal: 105ms\tremaining: 26.3ms\n",
      "12:\tlearn: 4258.0173569\ttotal: 113ms\tremaining: 17.4ms\n",
      "13:\tlearn: 4231.9400061\ttotal: 121ms\tremaining: 8.67ms\n",
      "14:\tlearn: 4205.9546644\ttotal: 130ms\tremaining: 0us\n",
      "0:\tlearn: 4593.1182658\ttotal: 11.1ms\tremaining: 156ms\n",
      "1:\tlearn: 4562.6149473\ttotal: 19.5ms\tremaining: 127ms\n",
      "2:\tlearn: 4532.7734975\ttotal: 28ms\tremaining: 112ms\n",
      "3:\tlearn: 4503.2915414\ttotal: 36.6ms\tremaining: 101ms\n",
      "4:\tlearn: 4473.7778560\ttotal: 45.9ms\tremaining: 91.8ms\n",
      "5:\tlearn: 4445.0877532\ttotal: 55.5ms\tremaining: 83.2ms\n",
      "6:\tlearn: 4416.6302224\ttotal: 64.1ms\tremaining: 73.3ms\n",
      "7:\tlearn: 4389.1202462\ttotal: 72.8ms\tremaining: 63.7ms\n",
      "8:\tlearn: 4361.5188722\ttotal: 81.7ms\tremaining: 54.4ms\n",
      "9:\tlearn: 4333.7986068\ttotal: 90ms\tremaining: 45ms\n",
      "10:\tlearn: 4306.9701233\ttotal: 98.5ms\tremaining: 35.8ms\n",
      "11:\tlearn: 4280.4160903\ttotal: 107ms\tremaining: 26.8ms\n",
      "12:\tlearn: 4253.8108257\ttotal: 116ms\tremaining: 17.8ms\n",
      "13:\tlearn: 4227.8867207\ttotal: 123ms\tremaining: 8.82ms\n",
      "14:\tlearn: 4201.6823936\ttotal: 132ms\tremaining: 0us\n",
      "0:\tlearn: 4588.8617128\ttotal: 9.99ms\tremaining: 140ms\n",
      "1:\tlearn: 4558.4683563\ttotal: 18.9ms\tremaining: 123ms\n",
      "2:\tlearn: 4528.4238416\ttotal: 27.4ms\tremaining: 110ms\n",
      "3:\tlearn: 4498.6892509\ttotal: 36.4ms\tremaining: 100ms\n",
      "4:\tlearn: 4469.0875780\ttotal: 45.3ms\tremaining: 90.7ms\n",
      "5:\tlearn: 4440.3212828\ttotal: 53.7ms\tremaining: 80.5ms\n",
      "6:\tlearn: 4411.7007871\ttotal: 62.7ms\tremaining: 71.6ms\n",
      "7:\tlearn: 4384.2028939\ttotal: 71.3ms\tremaining: 62.4ms\n",
      "8:\tlearn: 4356.7924636\ttotal: 79.7ms\tremaining: 53.1ms\n",
      "9:\tlearn: 4329.0978050\ttotal: 89.1ms\tremaining: 44.6ms\n",
      "10:\tlearn: 4302.5967178\ttotal: 97.8ms\tremaining: 35.6ms\n",
      "11:\tlearn: 4276.0497192\ttotal: 107ms\tremaining: 26.7ms\n",
      "12:\tlearn: 4249.7092948\ttotal: 115ms\tremaining: 17.7ms\n",
      "13:\tlearn: 4224.0620963\ttotal: 123ms\tremaining: 8.82ms\n",
      "14:\tlearn: 4198.0657305\ttotal: 132ms\tremaining: 0us\n",
      "0:\tlearn: 4474.4785029\ttotal: 10ms\tremaining: 140ms\n",
      "1:\tlearn: 4334.1285305\ttotal: 19ms\tremaining: 123ms\n",
      "2:\tlearn: 4198.7671646\ttotal: 27.7ms\tremaining: 111ms\n",
      "3:\tlearn: 4071.1922407\ttotal: 36.4ms\tremaining: 100ms\n",
      "4:\tlearn: 3948.4488816\ttotal: 44.8ms\tremaining: 89.5ms\n",
      "5:\tlearn: 3838.4325137\ttotal: 53.5ms\tremaining: 80.3ms\n",
      "6:\tlearn: 3731.0469874\ttotal: 61.8ms\tremaining: 70.7ms\n",
      "7:\tlearn: 3632.8314215\ttotal: 70.9ms\tremaining: 62ms\n",
      "8:\tlearn: 3538.1509081\ttotal: 79.8ms\tremaining: 53.2ms\n",
      "9:\tlearn: 3448.0223800\ttotal: 89ms\tremaining: 44.5ms\n",
      "10:\tlearn: 3367.5048608\ttotal: 97.9ms\tremaining: 35.6ms\n",
      "11:\tlearn: 3287.3619434\ttotal: 106ms\tremaining: 26.6ms\n",
      "12:\tlearn: 3215.3255898\ttotal: 115ms\tremaining: 17.7ms\n",
      "13:\tlearn: 3144.9975578\ttotal: 123ms\tremaining: 8.8ms\n",
      "14:\tlearn: 3080.1141959\ttotal: 132ms\tremaining: 0us\n",
      "0:\tlearn: 4467.0669821\ttotal: 10.5ms\tremaining: 146ms\n",
      "1:\tlearn: 4322.7889640\ttotal: 18.8ms\tremaining: 122ms\n",
      "2:\tlearn: 4188.9567737\ttotal: 27.1ms\tremaining: 108ms\n",
      "3:\tlearn: 4062.1638108\ttotal: 36.1ms\tremaining: 99.3ms\n",
      "4:\tlearn: 3943.4179026\ttotal: 44.7ms\tremaining: 89.5ms\n",
      "5:\tlearn: 3833.1957923\ttotal: 52.8ms\tremaining: 79.3ms\n",
      "6:\tlearn: 3729.8856270\ttotal: 60.8ms\tremaining: 69.4ms\n",
      "7:\tlearn: 3630.7186810\ttotal: 69ms\tremaining: 60.3ms\n",
      "8:\tlearn: 3535.1161394\ttotal: 77.5ms\tremaining: 51.6ms\n",
      "9:\tlearn: 3444.9377844\ttotal: 85.9ms\tremaining: 42.9ms\n",
      "10:\tlearn: 3362.4122204\ttotal: 94.5ms\tremaining: 34.3ms\n",
      "11:\tlearn: 3283.9561696\ttotal: 103ms\tremaining: 25.8ms\n",
      "12:\tlearn: 3211.2737563\ttotal: 112ms\tremaining: 17.2ms\n",
      "13:\tlearn: 3145.4890193\ttotal: 121ms\tremaining: 8.64ms\n",
      "14:\tlearn: 3082.1262387\ttotal: 129ms\tremaining: 0us\n",
      "0:\tlearn: 4475.4942490\ttotal: 11.4ms\tremaining: 160ms\n",
      "1:\tlearn: 4330.8031644\ttotal: 20.4ms\tremaining: 133ms\n",
      "2:\tlearn: 4196.5939494\ttotal: 28.6ms\tremaining: 114ms\n",
      "3:\tlearn: 4069.4584167\ttotal: 37ms\tremaining: 102ms\n",
      "4:\tlearn: 3951.3493329\ttotal: 45.6ms\tremaining: 91.2ms\n",
      "5:\tlearn: 3840.3774206\ttotal: 53.9ms\tremaining: 80.8ms\n",
      "6:\tlearn: 3733.9178898\ttotal: 62.6ms\tremaining: 71.5ms\n",
      "7:\tlearn: 3632.4976176\ttotal: 71.3ms\tremaining: 62.4ms\n",
      "8:\tlearn: 3536.6866789\ttotal: 79.2ms\tremaining: 52.8ms\n",
      "9:\tlearn: 3446.6393508\ttotal: 87.7ms\tremaining: 43.9ms\n",
      "10:\tlearn: 3364.9085046\ttotal: 96.4ms\tremaining: 35.1ms\n",
      "11:\tlearn: 3287.5752882\ttotal: 105ms\tremaining: 26.3ms\n",
      "12:\tlearn: 3214.4631060\ttotal: 114ms\tremaining: 17.5ms\n",
      "13:\tlearn: 3148.9049018\ttotal: 123ms\tremaining: 8.76ms\n",
      "14:\tlearn: 3083.4947485\ttotal: 133ms\tremaining: 0us\n",
      "0:\tlearn: 4471.0646009\ttotal: 11.2ms\tremaining: 157ms\n",
      "1:\tlearn: 4327.1143351\ttotal: 20.1ms\tremaining: 131ms\n",
      "2:\tlearn: 4191.8058289\ttotal: 28.7ms\tremaining: 115ms\n",
      "3:\tlearn: 4065.5133323\ttotal: 37.5ms\tremaining: 103ms\n",
      "4:\tlearn: 3946.3276592\ttotal: 46.5ms\tremaining: 93.1ms\n",
      "5:\tlearn: 3832.6264800\ttotal: 55.4ms\tremaining: 83.1ms\n",
      "6:\tlearn: 3727.7852727\ttotal: 64ms\tremaining: 73.1ms\n",
      "7:\tlearn: 3629.9953835\ttotal: 72.5ms\tremaining: 63.5ms\n",
      "8:\tlearn: 3536.0116851\ttotal: 81ms\tremaining: 54ms\n",
      "9:\tlearn: 3446.9643262\ttotal: 89.5ms\tremaining: 44.8ms\n",
      "10:\tlearn: 3367.4691475\ttotal: 97.3ms\tremaining: 35.4ms\n",
      "11:\tlearn: 3289.0599920\ttotal: 106ms\tremaining: 26.6ms\n",
      "12:\tlearn: 3214.9578967\ttotal: 115ms\tremaining: 17.8ms\n",
      "13:\tlearn: 3146.8433918\ttotal: 124ms\tremaining: 8.89ms\n",
      "14:\tlearn: 3081.5943953\ttotal: 133ms\tremaining: 0us\n",
      "0:\tlearn: 4468.6604377\ttotal: 9.97ms\tremaining: 140ms\n",
      "1:\tlearn: 4329.5828880\ttotal: 19.2ms\tremaining: 125ms\n",
      "2:\tlearn: 4194.4965948\ttotal: 27.6ms\tremaining: 110ms\n",
      "3:\tlearn: 4063.9371341\ttotal: 36.2ms\tremaining: 99.6ms\n",
      "4:\tlearn: 3943.7546102\ttotal: 45.1ms\tremaining: 90.3ms\n",
      "5:\tlearn: 3832.5937795\ttotal: 53.1ms\tremaining: 79.6ms\n",
      "6:\tlearn: 3727.0899046\ttotal: 61.4ms\tremaining: 70.2ms\n",
      "7:\tlearn: 3626.6120810\ttotal: 69.9ms\tremaining: 61.2ms\n",
      "8:\tlearn: 3531.8119137\ttotal: 78.2ms\tremaining: 52.1ms\n",
      "9:\tlearn: 3445.1987071\ttotal: 86.1ms\tremaining: 43ms\n",
      "10:\tlearn: 3365.9913863\ttotal: 94.3ms\tremaining: 34.3ms\n",
      "11:\tlearn: 3285.8739821\ttotal: 102ms\tremaining: 25.6ms\n",
      "12:\tlearn: 3212.1323718\ttotal: 111ms\tremaining: 17.1ms\n",
      "13:\tlearn: 3143.9372796\ttotal: 119ms\tremaining: 8.51ms\n",
      "14:\tlearn: 3081.0492717\ttotal: 129ms\tremaining: 0us\n",
      "0:\tlearn: 4325.5366851\ttotal: 9.96ms\tremaining: 140ms\n",
      "1:\tlearn: 4059.2138065\ttotal: 18.5ms\tremaining: 120ms\n",
      "2:\tlearn: 3825.5166143\ttotal: 27.3ms\tremaining: 109ms\n",
      "3:\tlearn: 3615.1427470\ttotal: 35.5ms\tremaining: 97.6ms\n",
      "4:\tlearn: 3431.2729242\ttotal: 44.1ms\tremaining: 88.3ms\n",
      "5:\tlearn: 3266.9530130\ttotal: 52.8ms\tremaining: 79.2ms\n",
      "6:\tlearn: 3127.3990449\ttotal: 61.1ms\tremaining: 69.8ms\n",
      "7:\tlearn: 3006.3902461\ttotal: 69.6ms\tremaining: 60.9ms\n",
      "8:\tlearn: 2895.2183097\ttotal: 78.1ms\tremaining: 52.1ms\n",
      "9:\tlearn: 2795.1205639\ttotal: 86.2ms\tremaining: 43.1ms\n",
      "10:\tlearn: 2711.9527244\ttotal: 94.1ms\tremaining: 34.2ms\n",
      "11:\tlearn: 2638.5030203\ttotal: 102ms\tremaining: 25.6ms\n",
      "12:\tlearn: 2567.1762587\ttotal: 111ms\tremaining: 17ms\n",
      "13:\tlearn: 2507.0345629\ttotal: 120ms\tremaining: 8.54ms\n",
      "14:\tlearn: 2456.3075359\ttotal: 128ms\tremaining: 0us\n",
      "0:\tlearn: 4319.6187217\ttotal: 10.2ms\tremaining: 143ms\n",
      "1:\tlearn: 4054.2574781\ttotal: 19ms\tremaining: 124ms\n",
      "2:\tlearn: 3815.9692253\ttotal: 27.6ms\tremaining: 110ms\n",
      "3:\tlearn: 3612.2983150\ttotal: 36.4ms\tremaining: 100ms\n",
      "4:\tlearn: 3429.3936697\ttotal: 44.4ms\tremaining: 88.8ms\n",
      "5:\tlearn: 3264.1046699\ttotal: 52.8ms\tremaining: 79.2ms\n",
      "6:\tlearn: 3122.8519874\ttotal: 60.7ms\tremaining: 69.4ms\n",
      "7:\tlearn: 2994.8007883\ttotal: 69.3ms\tremaining: 60.6ms\n",
      "8:\tlearn: 2886.2506628\ttotal: 77.6ms\tremaining: 51.8ms\n",
      "9:\tlearn: 2787.5263679\ttotal: 85.7ms\tremaining: 42.9ms\n",
      "10:\tlearn: 2707.3029441\ttotal: 93.6ms\tremaining: 34ms\n",
      "11:\tlearn: 2632.1442790\ttotal: 102ms\tremaining: 25.6ms\n",
      "12:\tlearn: 2563.4281336\ttotal: 111ms\tremaining: 17.1ms\n",
      "13:\tlearn: 2504.2252968\ttotal: 120ms\tremaining: 8.54ms\n",
      "14:\tlearn: 2451.5570391\ttotal: 128ms\tremaining: 0us\n",
      "0:\tlearn: 4325.4602513\ttotal: 10.5ms\tremaining: 147ms\n",
      "1:\tlearn: 4067.4020134\ttotal: 19.4ms\tremaining: 126ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:\tlearn: 3829.6063136\ttotal: 28.1ms\tremaining: 112ms\n",
      "3:\tlearn: 3628.1639252\ttotal: 37.1ms\tremaining: 102ms\n",
      "4:\tlearn: 3441.0110240\ttotal: 46.1ms\tremaining: 92.3ms\n",
      "5:\tlearn: 3280.5839932\ttotal: 54.6ms\tremaining: 81.9ms\n",
      "6:\tlearn: 3137.4282523\ttotal: 63.5ms\tremaining: 72.6ms\n",
      "7:\tlearn: 3003.8519463\ttotal: 72.1ms\tremaining: 63.1ms\n",
      "8:\tlearn: 2890.8697071\ttotal: 80.2ms\tremaining: 53.5ms\n",
      "9:\tlearn: 2788.1803190\ttotal: 88.3ms\tremaining: 44.1ms\n",
      "10:\tlearn: 2702.5982791\ttotal: 96.4ms\tremaining: 35.1ms\n",
      "11:\tlearn: 2629.3268461\ttotal: 104ms\tremaining: 26.1ms\n",
      "12:\tlearn: 2563.6207465\ttotal: 112ms\tremaining: 17.3ms\n",
      "13:\tlearn: 2502.3193216\ttotal: 121ms\tremaining: 8.62ms\n",
      "14:\tlearn: 2450.9680750\ttotal: 129ms\tremaining: 0us\n",
      "0:\tlearn: 4321.0631421\ttotal: 10.7ms\tremaining: 150ms\n",
      "1:\tlearn: 4054.0549656\ttotal: 19.3ms\tremaining: 125ms\n",
      "2:\tlearn: 3819.8358243\ttotal: 27.9ms\tremaining: 112ms\n",
      "3:\tlearn: 3611.1188894\ttotal: 36.8ms\tremaining: 101ms\n",
      "4:\tlearn: 3430.3339827\ttotal: 45.5ms\tremaining: 91ms\n",
      "5:\tlearn: 3268.4311749\ttotal: 54.7ms\tremaining: 82ms\n",
      "6:\tlearn: 3122.9348252\ttotal: 64.2ms\tremaining: 73.4ms\n",
      "7:\tlearn: 2999.8173752\ttotal: 73.3ms\tremaining: 64.2ms\n",
      "8:\tlearn: 2887.3826580\ttotal: 82.3ms\tremaining: 54.9ms\n",
      "9:\tlearn: 2792.1037566\ttotal: 90.2ms\tremaining: 45.1ms\n",
      "10:\tlearn: 2706.8846741\ttotal: 98.3ms\tremaining: 35.7ms\n",
      "11:\tlearn: 2633.4313892\ttotal: 107ms\tremaining: 26.7ms\n",
      "12:\tlearn: 2568.7132609\ttotal: 115ms\tremaining: 17.7ms\n",
      "13:\tlearn: 2507.5136684\ttotal: 124ms\tremaining: 8.82ms\n",
      "14:\tlearn: 2455.4907530\ttotal: 132ms\tremaining: 0us\n",
      "0:\tlearn: 4321.0008481\ttotal: 10.3ms\tremaining: 144ms\n",
      "1:\tlearn: 4062.7198693\ttotal: 19.3ms\tremaining: 125ms\n",
      "2:\tlearn: 3828.2455904\ttotal: 28.1ms\tremaining: 113ms\n",
      "3:\tlearn: 3613.7895991\ttotal: 36.5ms\tremaining: 100ms\n",
      "4:\tlearn: 3426.3627954\ttotal: 45.6ms\tremaining: 91.1ms\n",
      "5:\tlearn: 3261.6642717\ttotal: 54.3ms\tremaining: 81.4ms\n",
      "6:\tlearn: 3121.7534535\ttotal: 62.8ms\tremaining: 71.8ms\n",
      "7:\tlearn: 3001.7868268\ttotal: 72.2ms\tremaining: 63.1ms\n",
      "8:\tlearn: 2892.9273622\ttotal: 80.6ms\tremaining: 53.8ms\n",
      "9:\tlearn: 2798.0922417\ttotal: 88.4ms\tremaining: 44.2ms\n",
      "10:\tlearn: 2712.7662274\ttotal: 96.5ms\tremaining: 35.1ms\n",
      "11:\tlearn: 2635.1928593\ttotal: 105ms\tremaining: 26.2ms\n",
      "12:\tlearn: 2570.8069515\ttotal: 113ms\tremaining: 17.4ms\n",
      "13:\tlearn: 2509.4229765\ttotal: 121ms\tremaining: 8.64ms\n",
      "14:\tlearn: 2459.8519754\ttotal: 130ms\tremaining: 0us\n",
      "0:\tlearn: 4595.6975750\ttotal: 10.7ms\tremaining: 203ms\n",
      "1:\tlearn: 4565.0904929\ttotal: 18.8ms\tremaining: 169ms\n",
      "2:\tlearn: 4534.9589066\ttotal: 27ms\tremaining: 153ms\n",
      "3:\tlearn: 4505.2428554\ttotal: 35.7ms\tremaining: 143ms\n",
      "4:\tlearn: 4475.7557038\ttotal: 44.6ms\tremaining: 134ms\n",
      "5:\tlearn: 4446.9740799\ttotal: 53.1ms\tremaining: 124ms\n",
      "6:\tlearn: 4418.6968903\ttotal: 62.2ms\tremaining: 116ms\n",
      "7:\tlearn: 4391.0918699\ttotal: 71.7ms\tremaining: 107ms\n",
      "8:\tlearn: 4363.5150246\ttotal: 80.7ms\tremaining: 98.6ms\n",
      "9:\tlearn: 4335.8113842\ttotal: 89.5ms\tremaining: 89.5ms\n",
      "10:\tlearn: 4308.8667159\ttotal: 97.3ms\tremaining: 79.6ms\n",
      "11:\tlearn: 4282.2402519\ttotal: 106ms\tremaining: 70.4ms\n",
      "12:\tlearn: 4255.8810446\ttotal: 114ms\tremaining: 61.2ms\n",
      "13:\tlearn: 4230.3486773\ttotal: 122ms\tremaining: 52.2ms\n",
      "14:\tlearn: 4204.1490439\ttotal: 131ms\tremaining: 43.6ms\n",
      "15:\tlearn: 4178.7495304\ttotal: 139ms\tremaining: 34.7ms\n",
      "16:\tlearn: 4153.1606737\ttotal: 147ms\tremaining: 26ms\n",
      "17:\tlearn: 4127.8976740\ttotal: 155ms\tremaining: 17.2ms\n",
      "18:\tlearn: 4103.0012000\ttotal: 164ms\tremaining: 8.62ms\n",
      "19:\tlearn: 4078.8234863\ttotal: 172ms\tremaining: 0us\n",
      "0:\tlearn: 4587.1013079\ttotal: 10.9ms\tremaining: 206ms\n",
      "1:\tlearn: 4556.5692240\ttotal: 20.5ms\tremaining: 185ms\n",
      "2:\tlearn: 4526.8269200\ttotal: 29.6ms\tremaining: 168ms\n",
      "3:\tlearn: 4496.9895735\ttotal: 38.9ms\tremaining: 156ms\n",
      "4:\tlearn: 4467.5828003\ttotal: 47.3ms\tremaining: 142ms\n",
      "5:\tlearn: 4439.0487143\ttotal: 56.3ms\tremaining: 131ms\n",
      "6:\tlearn: 4410.6546440\ttotal: 64.3ms\tremaining: 119ms\n",
      "7:\tlearn: 4383.0422919\ttotal: 72.9ms\tremaining: 109ms\n",
      "8:\tlearn: 4355.8783718\ttotal: 81ms\tremaining: 99ms\n",
      "9:\tlearn: 4328.5430622\ttotal: 90ms\tremaining: 90ms\n",
      "10:\tlearn: 4301.7043955\ttotal: 98.4ms\tremaining: 80.5ms\n",
      "11:\tlearn: 4274.8930987\ttotal: 107ms\tremaining: 71.2ms\n",
      "12:\tlearn: 4248.5994869\ttotal: 116ms\tremaining: 62.2ms\n",
      "13:\tlearn: 4222.9759387\ttotal: 125ms\tremaining: 53.4ms\n",
      "14:\tlearn: 4196.9059752\ttotal: 134ms\tremaining: 44.5ms\n",
      "15:\tlearn: 4171.8329036\ttotal: 142ms\tremaining: 35.5ms\n",
      "16:\tlearn: 4146.7604845\ttotal: 150ms\tremaining: 26.5ms\n",
      "17:\tlearn: 4122.3922751\ttotal: 159ms\tremaining: 17.6ms\n",
      "18:\tlearn: 4097.5400630\ttotal: 167ms\tremaining: 8.78ms\n",
      "19:\tlearn: 4073.5253450\ttotal: 175ms\tremaining: 0us\n",
      "0:\tlearn: 4597.5807386\ttotal: 10.1ms\tremaining: 192ms\n",
      "1:\tlearn: 4566.9262922\ttotal: 18.7ms\tremaining: 169ms\n",
      "2:\tlearn: 4537.0352976\ttotal: 26.8ms\tremaining: 152ms\n",
      "3:\tlearn: 4507.2665811\ttotal: 35.4ms\tremaining: 142ms\n",
      "4:\tlearn: 4477.7327902\ttotal: 44.5ms\tremaining: 133ms\n",
      "5:\tlearn: 4448.8562125\ttotal: 53.1ms\tremaining: 124ms\n",
      "6:\tlearn: 4420.3991300\ttotal: 61.7ms\tremaining: 115ms\n",
      "7:\tlearn: 4392.7253010\ttotal: 69.8ms\tremaining: 105ms\n",
      "8:\tlearn: 4365.4957931\ttotal: 77.9ms\tremaining: 95.2ms\n",
      "9:\tlearn: 4338.1353840\ttotal: 85.9ms\tremaining: 85.9ms\n",
      "10:\tlearn: 4311.2096301\ttotal: 94.2ms\tremaining: 77ms\n",
      "11:\tlearn: 4284.3529900\ttotal: 102ms\tremaining: 68.2ms\n",
      "12:\tlearn: 4258.0173569\ttotal: 111ms\tremaining: 59.9ms\n",
      "13:\tlearn: 4231.9400061\ttotal: 120ms\tremaining: 51.2ms\n",
      "14:\tlearn: 4205.9546644\ttotal: 128ms\tremaining: 42.7ms\n",
      "15:\tlearn: 4180.4127076\ttotal: 136ms\tremaining: 34ms\n",
      "16:\tlearn: 4155.3032947\ttotal: 144ms\tremaining: 25.5ms\n",
      "17:\tlearn: 4130.9746488\ttotal: 153ms\tremaining: 17ms\n",
      "18:\tlearn: 4106.0974347\ttotal: 161ms\tremaining: 8.45ms\n",
      "19:\tlearn: 4081.0585980\ttotal: 169ms\tremaining: 0us\n",
      "0:\tlearn: 4593.1182658\ttotal: 10.4ms\tremaining: 197ms\n",
      "1:\tlearn: 4562.6149473\ttotal: 18.8ms\tremaining: 169ms\n",
      "2:\tlearn: 4532.7734975\ttotal: 27.2ms\tremaining: 154ms\n",
      "3:\tlearn: 4503.2915414\ttotal: 35.8ms\tremaining: 143ms\n",
      "4:\tlearn: 4473.7778560\ttotal: 44.5ms\tremaining: 134ms\n",
      "5:\tlearn: 4445.0877532\ttotal: 53.4ms\tremaining: 125ms\n",
      "6:\tlearn: 4416.6302224\ttotal: 62ms\tremaining: 115ms\n",
      "7:\tlearn: 4389.1202462\ttotal: 70ms\tremaining: 105ms\n",
      "8:\tlearn: 4361.5188722\ttotal: 78.3ms\tremaining: 95.7ms\n",
      "9:\tlearn: 4333.7986068\ttotal: 86.4ms\tremaining: 86.4ms\n",
      "10:\tlearn: 4306.9701233\ttotal: 94.8ms\tremaining: 77.6ms\n",
      "11:\tlearn: 4280.4160903\ttotal: 103ms\tremaining: 68.5ms\n",
      "12:\tlearn: 4253.8108257\ttotal: 111ms\tremaining: 59.8ms\n",
      "13:\tlearn: 4227.8867207\ttotal: 119ms\tremaining: 51ms\n",
      "14:\tlearn: 4201.6823936\ttotal: 127ms\tremaining: 42.4ms\n",
      "15:\tlearn: 4176.1236748\ttotal: 135ms\tremaining: 33.8ms\n",
      "16:\tlearn: 4151.0520609\ttotal: 144ms\tremaining: 25.3ms\n",
      "17:\tlearn: 4126.0488138\ttotal: 152ms\tremaining: 16.9ms\n",
      "18:\tlearn: 4101.3899855\ttotal: 160ms\tremaining: 8.44ms\n",
      "19:\tlearn: 4077.1884078\ttotal: 168ms\tremaining: 0us\n",
      "0:\tlearn: 4588.8617128\ttotal: 10.8ms\tremaining: 206ms\n",
      "1:\tlearn: 4558.4683563\ttotal: 19.9ms\tremaining: 179ms\n",
      "2:\tlearn: 4528.4238416\ttotal: 28.8ms\tremaining: 163ms\n",
      "3:\tlearn: 4498.6892509\ttotal: 37.8ms\tremaining: 151ms\n",
      "4:\tlearn: 4469.0875780\ttotal: 46.4ms\tremaining: 139ms\n",
      "5:\tlearn: 4440.3212828\ttotal: 54.8ms\tremaining: 128ms\n",
      "6:\tlearn: 4411.7007871\ttotal: 63.2ms\tremaining: 117ms\n",
      "7:\tlearn: 4384.2028939\ttotal: 71.3ms\tremaining: 107ms\n",
      "8:\tlearn: 4356.7924636\ttotal: 79.6ms\tremaining: 97.2ms\n",
      "9:\tlearn: 4329.0978050\ttotal: 87.7ms\tremaining: 87.7ms\n",
      "10:\tlearn: 4302.5967178\ttotal: 96ms\tremaining: 78.5ms\n",
      "11:\tlearn: 4276.0497192\ttotal: 105ms\tremaining: 69.7ms\n",
      "12:\tlearn: 4249.7092948\ttotal: 112ms\tremaining: 60.5ms\n",
      "13:\tlearn: 4224.0620963\ttotal: 121ms\tremaining: 51.7ms\n",
      "14:\tlearn: 4198.0657305\ttotal: 129ms\tremaining: 43ms\n",
      "15:\tlearn: 4172.8617526\ttotal: 137ms\tremaining: 34.2ms\n",
      "16:\tlearn: 4147.9942980\ttotal: 145ms\tremaining: 25.5ms\n",
      "17:\tlearn: 4122.9070090\ttotal: 153ms\tremaining: 17ms\n",
      "18:\tlearn: 4098.3027838\ttotal: 161ms\tremaining: 8.49ms\n",
      "19:\tlearn: 4073.8235921\ttotal: 170ms\tremaining: 0us\n",
      "0:\tlearn: 4474.4785029\ttotal: 9.66ms\tremaining: 184ms\n",
      "1:\tlearn: 4334.1285305\ttotal: 18.6ms\tremaining: 167ms\n",
      "2:\tlearn: 4198.7671646\ttotal: 27.1ms\tremaining: 154ms\n",
      "3:\tlearn: 4071.1922407\ttotal: 35.8ms\tremaining: 143ms\n",
      "4:\tlearn: 3948.4488816\ttotal: 44.7ms\tremaining: 134ms\n",
      "5:\tlearn: 3838.4325137\ttotal: 53.4ms\tremaining: 125ms\n",
      "6:\tlearn: 3731.0469874\ttotal: 62.8ms\tremaining: 117ms\n",
      "7:\tlearn: 3632.8314215\ttotal: 71.5ms\tremaining: 107ms\n",
      "8:\tlearn: 3538.1509081\ttotal: 79.8ms\tremaining: 97.5ms\n",
      "9:\tlearn: 3448.0223800\ttotal: 88.7ms\tremaining: 88.7ms\n",
      "10:\tlearn: 3367.5048608\ttotal: 97.4ms\tremaining: 79.7ms\n",
      "11:\tlearn: 3287.3619434\ttotal: 106ms\tremaining: 70.8ms\n",
      "12:\tlearn: 3215.3255898\ttotal: 114ms\tremaining: 61.5ms\n",
      "13:\tlearn: 3144.9975578\ttotal: 123ms\tremaining: 52.8ms\n",
      "14:\tlearn: 3080.1141959\ttotal: 132ms\tremaining: 43.9ms\n",
      "15:\tlearn: 3019.1870218\ttotal: 140ms\tremaining: 35.1ms\n",
      "16:\tlearn: 2960.7000755\ttotal: 149ms\tremaining: 26.3ms\n",
      "17:\tlearn: 2909.4380609\ttotal: 157ms\tremaining: 17.5ms\n",
      "18:\tlearn: 2859.9314853\ttotal: 166ms\tremaining: 8.75ms\n",
      "19:\tlearn: 2812.9072404\ttotal: 175ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4467.0669821\ttotal: 10.5ms\tremaining: 199ms\n",
      "1:\tlearn: 4322.7889640\ttotal: 19.9ms\tremaining: 179ms\n",
      "2:\tlearn: 4188.9567737\ttotal: 28.5ms\tremaining: 162ms\n",
      "3:\tlearn: 4062.1638108\ttotal: 37.1ms\tremaining: 149ms\n",
      "4:\tlearn: 3943.4179026\ttotal: 45.6ms\tremaining: 137ms\n",
      "5:\tlearn: 3833.1957923\ttotal: 54.4ms\tremaining: 127ms\n",
      "6:\tlearn: 3729.8856270\ttotal: 63ms\tremaining: 117ms\n",
      "7:\tlearn: 3630.7186810\ttotal: 71.5ms\tremaining: 107ms\n",
      "8:\tlearn: 3535.1161394\ttotal: 80.3ms\tremaining: 98.2ms\n",
      "9:\tlearn: 3444.9377844\ttotal: 88.7ms\tremaining: 88.7ms\n",
      "10:\tlearn: 3362.4122204\ttotal: 97.2ms\tremaining: 79.5ms\n",
      "11:\tlearn: 3283.9561696\ttotal: 105ms\tremaining: 70.2ms\n",
      "12:\tlearn: 3211.2737563\ttotal: 114ms\tremaining: 61.2ms\n",
      "13:\tlearn: 3145.4890193\ttotal: 122ms\tremaining: 52.2ms\n",
      "14:\tlearn: 3082.1262387\ttotal: 130ms\tremaining: 43.5ms\n",
      "15:\tlearn: 3022.2644153\ttotal: 138ms\tremaining: 34.6ms\n",
      "16:\tlearn: 2966.7410404\ttotal: 147ms\tremaining: 25.9ms\n",
      "17:\tlearn: 2912.3821688\ttotal: 155ms\tremaining: 17.2ms\n",
      "18:\tlearn: 2861.3010325\ttotal: 163ms\tremaining: 8.58ms\n",
      "19:\tlearn: 2812.8113556\ttotal: 171ms\tremaining: 0us\n",
      "0:\tlearn: 4475.4942490\ttotal: 10.6ms\tremaining: 201ms\n",
      "1:\tlearn: 4330.8031644\ttotal: 19.5ms\tremaining: 176ms\n",
      "2:\tlearn: 4196.5939494\ttotal: 28.8ms\tremaining: 163ms\n",
      "3:\tlearn: 4069.4584167\ttotal: 37.7ms\tremaining: 151ms\n",
      "4:\tlearn: 3951.3493329\ttotal: 46.7ms\tremaining: 140ms\n",
      "5:\tlearn: 3840.3774206\ttotal: 54.6ms\tremaining: 127ms\n",
      "6:\tlearn: 3733.9178898\ttotal: 63ms\tremaining: 117ms\n",
      "7:\tlearn: 3632.4976176\ttotal: 71.4ms\tremaining: 107ms\n",
      "8:\tlearn: 3536.6866789\ttotal: 79.9ms\tremaining: 97.6ms\n",
      "9:\tlearn: 3446.6393508\ttotal: 88ms\tremaining: 88ms\n",
      "10:\tlearn: 3364.9085046\ttotal: 96.4ms\tremaining: 78.9ms\n",
      "11:\tlearn: 3287.5752882\ttotal: 105ms\tremaining: 69.7ms\n",
      "12:\tlearn: 3214.4631060\ttotal: 113ms\tremaining: 60.6ms\n",
      "13:\tlearn: 3148.9049018\ttotal: 121ms\tremaining: 52ms\n",
      "14:\tlearn: 3083.4947485\ttotal: 130ms\tremaining: 43.2ms\n",
      "15:\tlearn: 3023.8024558\ttotal: 138ms\tremaining: 34.4ms\n",
      "16:\tlearn: 2968.0121149\ttotal: 146ms\tremaining: 25.8ms\n",
      "17:\tlearn: 2914.5750627\ttotal: 154ms\tremaining: 17.2ms\n",
      "18:\tlearn: 2863.4036188\ttotal: 163ms\tremaining: 8.55ms\n",
      "19:\tlearn: 2814.6816556\ttotal: 171ms\tremaining: 0us\n",
      "0:\tlearn: 4471.0646009\ttotal: 10.7ms\tremaining: 203ms\n",
      "1:\tlearn: 4327.1143351\ttotal: 19.8ms\tremaining: 178ms\n",
      "2:\tlearn: 4191.8058289\ttotal: 28.8ms\tremaining: 163ms\n",
      "3:\tlearn: 4065.5133323\ttotal: 37.7ms\tremaining: 151ms\n",
      "4:\tlearn: 3946.3276592\ttotal: 46.6ms\tremaining: 140ms\n",
      "5:\tlearn: 3832.6264800\ttotal: 55.4ms\tremaining: 129ms\n",
      "6:\tlearn: 3727.7852727\ttotal: 63.6ms\tremaining: 118ms\n",
      "7:\tlearn: 3629.9953835\ttotal: 72.7ms\tremaining: 109ms\n",
      "8:\tlearn: 3536.0116851\ttotal: 81.5ms\tremaining: 99.7ms\n",
      "9:\tlearn: 3446.9643262\ttotal: 90.3ms\tremaining: 90.3ms\n",
      "10:\tlearn: 3367.4691475\ttotal: 98.6ms\tremaining: 80.7ms\n",
      "11:\tlearn: 3289.0599920\ttotal: 107ms\tremaining: 71.4ms\n",
      "12:\tlearn: 3214.9578967\ttotal: 116ms\tremaining: 62.2ms\n",
      "13:\tlearn: 3146.8433918\ttotal: 124ms\tremaining: 53.3ms\n",
      "14:\tlearn: 3081.5943953\ttotal: 133ms\tremaining: 44.3ms\n",
      "15:\tlearn: 3022.2295012\ttotal: 141ms\tremaining: 35.3ms\n",
      "16:\tlearn: 2964.5868180\ttotal: 150ms\tremaining: 26.5ms\n",
      "17:\tlearn: 2911.8372961\ttotal: 158ms\tremaining: 17.6ms\n",
      "18:\tlearn: 2860.3061697\ttotal: 166ms\tremaining: 8.74ms\n",
      "19:\tlearn: 2814.0619208\ttotal: 174ms\tremaining: 0us\n",
      "0:\tlearn: 4468.6604377\ttotal: 11.3ms\tremaining: 216ms\n",
      "1:\tlearn: 4329.5828880\ttotal: 20.9ms\tremaining: 188ms\n",
      "2:\tlearn: 4194.4965948\ttotal: 30.4ms\tremaining: 172ms\n",
      "3:\tlearn: 4063.9371341\ttotal: 39.8ms\tremaining: 159ms\n",
      "4:\tlearn: 3943.7546102\ttotal: 50.3ms\tremaining: 151ms\n",
      "5:\tlearn: 3832.5937795\ttotal: 59.8ms\tremaining: 140ms\n",
      "6:\tlearn: 3727.0899046\ttotal: 70.1ms\tremaining: 130ms\n",
      "7:\tlearn: 3626.6120810\ttotal: 80.1ms\tremaining: 120ms\n",
      "8:\tlearn: 3531.8119137\ttotal: 90.4ms\tremaining: 111ms\n",
      "9:\tlearn: 3445.1987071\ttotal: 99.8ms\tremaining: 99.8ms\n",
      "10:\tlearn: 3365.9913863\ttotal: 109ms\tremaining: 89.3ms\n",
      "11:\tlearn: 3285.8739821\ttotal: 119ms\tremaining: 79.6ms\n",
      "12:\tlearn: 3212.1323718\ttotal: 130ms\tremaining: 69.9ms\n",
      "13:\tlearn: 3143.9372796\ttotal: 139ms\tremaining: 59.8ms\n",
      "14:\tlearn: 3081.0492717\ttotal: 149ms\tremaining: 49.5ms\n",
      "15:\tlearn: 3019.3434542\ttotal: 158ms\tremaining: 39.6ms\n",
      "16:\tlearn: 2962.2005979\ttotal: 168ms\tremaining: 29.6ms\n",
      "17:\tlearn: 2908.8785850\ttotal: 177ms\tremaining: 19.6ms\n",
      "18:\tlearn: 2859.4904820\ttotal: 186ms\tremaining: 9.79ms\n",
      "19:\tlearn: 2811.8728890\ttotal: 195ms\tremaining: 0us\n",
      "0:\tlearn: 4325.5366851\ttotal: 11.3ms\tremaining: 216ms\n",
      "1:\tlearn: 4059.2138065\ttotal: 20.9ms\tremaining: 188ms\n",
      "2:\tlearn: 3825.5166143\ttotal: 30.3ms\tremaining: 172ms\n",
      "3:\tlearn: 3615.1427470\ttotal: 39.8ms\tremaining: 159ms\n",
      "4:\tlearn: 3431.2729242\ttotal: 50.1ms\tremaining: 150ms\n",
      "5:\tlearn: 3266.9530130\ttotal: 59.3ms\tremaining: 138ms\n",
      "6:\tlearn: 3127.3990449\ttotal: 68.9ms\tremaining: 128ms\n",
      "7:\tlearn: 3006.3902461\ttotal: 82.8ms\tremaining: 124ms\n",
      "8:\tlearn: 2895.2183097\ttotal: 92.4ms\tremaining: 113ms\n",
      "9:\tlearn: 2795.1205639\ttotal: 101ms\tremaining: 101ms\n",
      "10:\tlearn: 2711.9527244\ttotal: 110ms\tremaining: 90.2ms\n",
      "11:\tlearn: 2638.5030203\ttotal: 120ms\tremaining: 79.7ms\n",
      "12:\tlearn: 2567.1762587\ttotal: 130ms\tremaining: 70.3ms\n",
      "13:\tlearn: 2507.0345629\ttotal: 140ms\tremaining: 60.2ms\n",
      "14:\tlearn: 2456.3075359\ttotal: 150ms\tremaining: 50.1ms\n",
      "15:\tlearn: 2411.3936128\ttotal: 160ms\tremaining: 40ms\n",
      "16:\tlearn: 2372.8291579\ttotal: 169ms\tremaining: 29.9ms\n",
      "17:\tlearn: 2334.5745540\ttotal: 179ms\tremaining: 19.9ms\n",
      "18:\tlearn: 2302.8331187\ttotal: 189ms\tremaining: 9.95ms\n",
      "19:\tlearn: 2274.1495318\ttotal: 198ms\tremaining: 0us\n",
      "0:\tlearn: 4319.6187217\ttotal: 10.6ms\tremaining: 201ms\n",
      "1:\tlearn: 4054.2574781\ttotal: 19.6ms\tremaining: 176ms\n",
      "2:\tlearn: 3815.9692253\ttotal: 28.2ms\tremaining: 160ms\n",
      "3:\tlearn: 3612.2983150\ttotal: 37.6ms\tremaining: 151ms\n",
      "4:\tlearn: 3429.3936697\ttotal: 46ms\tremaining: 138ms\n",
      "5:\tlearn: 3264.1046699\ttotal: 54.5ms\tremaining: 127ms\n",
      "6:\tlearn: 3122.8519874\ttotal: 62.3ms\tremaining: 116ms\n",
      "7:\tlearn: 2994.8007883\ttotal: 71.2ms\tremaining: 107ms\n",
      "8:\tlearn: 2886.2506628\ttotal: 79.8ms\tremaining: 97.5ms\n",
      "9:\tlearn: 2787.5263679\ttotal: 87.7ms\tremaining: 87.7ms\n",
      "10:\tlearn: 2707.3029441\ttotal: 95.6ms\tremaining: 78.2ms\n",
      "11:\tlearn: 2632.1442790\ttotal: 104ms\tremaining: 69.2ms\n",
      "12:\tlearn: 2563.4281336\ttotal: 113ms\tremaining: 60.7ms\n",
      "13:\tlearn: 2504.2252968\ttotal: 121ms\tremaining: 51.9ms\n",
      "14:\tlearn: 2451.5570391\ttotal: 130ms\tremaining: 43.3ms\n",
      "15:\tlearn: 2407.9065108\ttotal: 138ms\tremaining: 34.5ms\n",
      "16:\tlearn: 2366.3022783\ttotal: 146ms\tremaining: 25.7ms\n",
      "17:\tlearn: 2331.0857892\ttotal: 153ms\tremaining: 17ms\n",
      "18:\tlearn: 2297.3236272\ttotal: 161ms\tremaining: 8.49ms\n",
      "19:\tlearn: 2266.4895697\ttotal: 169ms\tremaining: 0us\n",
      "0:\tlearn: 4325.4602513\ttotal: 10.7ms\tremaining: 203ms\n",
      "1:\tlearn: 4067.4020134\ttotal: 20.2ms\tremaining: 182ms\n",
      "2:\tlearn: 3829.6063136\ttotal: 28.9ms\tremaining: 164ms\n",
      "3:\tlearn: 3628.1639252\ttotal: 38ms\tremaining: 152ms\n",
      "4:\tlearn: 3441.0110240\ttotal: 47ms\tremaining: 141ms\n",
      "5:\tlearn: 3280.5839932\ttotal: 55.4ms\tremaining: 129ms\n",
      "6:\tlearn: 3137.4282523\ttotal: 64ms\tremaining: 119ms\n",
      "7:\tlearn: 3003.8519463\ttotal: 72.9ms\tremaining: 109ms\n",
      "8:\tlearn: 2890.8697071\ttotal: 81.3ms\tremaining: 99.3ms\n",
      "9:\tlearn: 2788.1803190\ttotal: 89.7ms\tremaining: 89.7ms\n",
      "10:\tlearn: 2702.5982791\ttotal: 97.7ms\tremaining: 80ms\n",
      "11:\tlearn: 2629.3268461\ttotal: 106ms\tremaining: 70.5ms\n",
      "12:\tlearn: 2563.6207465\ttotal: 115ms\tremaining: 61.7ms\n",
      "13:\tlearn: 2502.3193216\ttotal: 123ms\tremaining: 52.7ms\n",
      "14:\tlearn: 2450.9680750\ttotal: 131ms\tremaining: 43.7ms\n",
      "15:\tlearn: 2405.1608152\ttotal: 139ms\tremaining: 34.8ms\n",
      "16:\tlearn: 2365.3656088\ttotal: 147ms\tremaining: 26ms\n",
      "17:\tlearn: 2325.0638023\ttotal: 155ms\tremaining: 17.3ms\n",
      "18:\tlearn: 2291.2965435\ttotal: 163ms\tremaining: 8.6ms\n",
      "19:\tlearn: 2262.2588543\ttotal: 172ms\tremaining: 0us\n",
      "0:\tlearn: 4321.0631421\ttotal: 10.1ms\tremaining: 193ms\n",
      "1:\tlearn: 4054.0549656\ttotal: 18.9ms\tremaining: 170ms\n",
      "2:\tlearn: 3819.8358243\ttotal: 27.6ms\tremaining: 156ms\n",
      "3:\tlearn: 3611.1188894\ttotal: 36.1ms\tremaining: 144ms\n",
      "4:\tlearn: 3430.3339827\ttotal: 45.1ms\tremaining: 135ms\n",
      "5:\tlearn: 3268.4311749\ttotal: 54ms\tremaining: 126ms\n",
      "6:\tlearn: 3122.9348252\ttotal: 62.4ms\tremaining: 116ms\n",
      "7:\tlearn: 2999.8173752\ttotal: 71.3ms\tremaining: 107ms\n",
      "8:\tlearn: 2887.3826580\ttotal: 80.4ms\tremaining: 98.3ms\n",
      "9:\tlearn: 2792.1037566\ttotal: 88.8ms\tremaining: 88.8ms\n",
      "10:\tlearn: 2706.8846741\ttotal: 97.4ms\tremaining: 79.7ms\n",
      "11:\tlearn: 2633.4313892\ttotal: 106ms\tremaining: 70.9ms\n",
      "12:\tlearn: 2568.7132609\ttotal: 115ms\tremaining: 61.8ms\n",
      "13:\tlearn: 2507.5136684\ttotal: 124ms\tremaining: 53ms\n",
      "14:\tlearn: 2455.4907530\ttotal: 132ms\tremaining: 44ms\n",
      "15:\tlearn: 2412.2733818\ttotal: 140ms\tremaining: 35.1ms\n",
      "16:\tlearn: 2367.6944161\ttotal: 149ms\tremaining: 26.3ms\n",
      "17:\tlearn: 2330.1393376\ttotal: 157ms\tremaining: 17.4ms\n",
      "18:\tlearn: 2296.1355621\ttotal: 165ms\tremaining: 8.68ms\n",
      "19:\tlearn: 2269.0133836\ttotal: 173ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4321.0008481\ttotal: 9.86ms\tremaining: 187ms\n",
      "1:\tlearn: 4062.7198693\ttotal: 18.2ms\tremaining: 164ms\n",
      "2:\tlearn: 3828.2455904\ttotal: 26.6ms\tremaining: 151ms\n",
      "3:\tlearn: 3613.7895991\ttotal: 35.2ms\tremaining: 141ms\n",
      "4:\tlearn: 3426.3627954\ttotal: 44.7ms\tremaining: 134ms\n",
      "5:\tlearn: 3261.6642717\ttotal: 53.4ms\tremaining: 125ms\n",
      "6:\tlearn: 3121.7534535\ttotal: 61.5ms\tremaining: 114ms\n",
      "7:\tlearn: 3001.7868268\ttotal: 70.6ms\tremaining: 106ms\n",
      "8:\tlearn: 2892.9273622\ttotal: 79.4ms\tremaining: 97ms\n",
      "9:\tlearn: 2798.0922417\ttotal: 88.2ms\tremaining: 88.2ms\n",
      "10:\tlearn: 2712.7662274\ttotal: 96.6ms\tremaining: 79ms\n",
      "11:\tlearn: 2635.1928593\ttotal: 106ms\tremaining: 70.3ms\n",
      "12:\tlearn: 2570.8069515\ttotal: 114ms\tremaining: 61.6ms\n",
      "13:\tlearn: 2509.4229765\ttotal: 123ms\tremaining: 52.8ms\n",
      "14:\tlearn: 2459.8519754\ttotal: 134ms\tremaining: 44.6ms\n",
      "15:\tlearn: 2413.3457570\ttotal: 142ms\tremaining: 35.6ms\n",
      "16:\tlearn: 2373.3160557\ttotal: 151ms\tremaining: 26.7ms\n",
      "17:\tlearn: 2334.6835630\ttotal: 160ms\tremaining: 17.7ms\n",
      "18:\tlearn: 2301.0910679\ttotal: 168ms\tremaining: 8.86ms\n",
      "19:\tlearn: 2272.8640812\ttotal: 178ms\tremaining: 0us\n",
      "0:\tlearn: 4593.8610044\ttotal: 14.7ms\tremaining: 132ms\n",
      "1:\tlearn: 4561.7441058\ttotal: 26.2ms\tremaining: 105ms\n",
      "2:\tlearn: 4530.5462092\ttotal: 37.6ms\tremaining: 87.8ms\n",
      "3:\tlearn: 4499.6361735\ttotal: 49.2ms\tremaining: 73.9ms\n",
      "4:\tlearn: 4468.9376964\ttotal: 60.9ms\tremaining: 60.9ms\n",
      "5:\tlearn: 4438.7777971\ttotal: 72.4ms\tremaining: 48.3ms\n",
      "6:\tlearn: 4408.5214599\ttotal: 83.2ms\tremaining: 35.6ms\n",
      "7:\tlearn: 4378.8981462\ttotal: 94ms\tremaining: 23.5ms\n",
      "8:\tlearn: 4349.6226302\ttotal: 105ms\tremaining: 11.7ms\n",
      "9:\tlearn: 4320.6211424\ttotal: 116ms\tremaining: 0us\n",
      "0:\tlearn: 4585.4083131\ttotal: 12.9ms\tremaining: 117ms\n",
      "1:\tlearn: 4553.4777515\ttotal: 24.7ms\tremaining: 98.8ms\n",
      "2:\tlearn: 4522.2822708\ttotal: 36.6ms\tremaining: 85.3ms\n",
      "3:\tlearn: 4491.7564239\ttotal: 48.4ms\tremaining: 72.6ms\n",
      "4:\tlearn: 4461.2118057\ttotal: 60.2ms\tremaining: 60.2ms\n",
      "5:\tlearn: 4431.0890711\ttotal: 72.1ms\tremaining: 48ms\n",
      "6:\tlearn: 4401.4812279\ttotal: 83.7ms\tremaining: 35.9ms\n",
      "7:\tlearn: 4371.6158466\ttotal: 94.8ms\tremaining: 23.7ms\n",
      "8:\tlearn: 4342.2222758\ttotal: 105ms\tremaining: 11.7ms\n",
      "9:\tlearn: 4313.0557171\ttotal: 117ms\tremaining: 0us\n",
      "0:\tlearn: 4596.4587552\ttotal: 13.8ms\tremaining: 124ms\n",
      "1:\tlearn: 4564.9074120\ttotal: 25.1ms\tremaining: 100ms\n",
      "2:\tlearn: 4533.6385734\ttotal: 37.1ms\tremaining: 86.5ms\n",
      "3:\tlearn: 4503.0324306\ttotal: 49.2ms\tremaining: 73.8ms\n",
      "4:\tlearn: 4472.3758126\ttotal: 60.7ms\tremaining: 60.7ms\n",
      "5:\tlearn: 4441.8817399\ttotal: 72.1ms\tremaining: 48.1ms\n",
      "6:\tlearn: 4411.4464957\ttotal: 83.6ms\tremaining: 35.8ms\n",
      "7:\tlearn: 4381.7034171\ttotal: 95.6ms\tremaining: 23.9ms\n",
      "8:\tlearn: 4352.1617851\ttotal: 106ms\tremaining: 11.8ms\n",
      "9:\tlearn: 4323.0205642\ttotal: 117ms\tremaining: 0us\n",
      "0:\tlearn: 4591.6674091\ttotal: 13.6ms\tremaining: 123ms\n",
      "1:\tlearn: 4559.9189252\ttotal: 25.7ms\tremaining: 103ms\n",
      "2:\tlearn: 4528.7125385\ttotal: 37.5ms\tremaining: 87.5ms\n",
      "3:\tlearn: 4497.9700520\ttotal: 48.9ms\tremaining: 73.3ms\n",
      "4:\tlearn: 4467.0857791\ttotal: 59.9ms\tremaining: 59.9ms\n",
      "5:\tlearn: 4436.6779568\ttotal: 71.4ms\tremaining: 47.6ms\n",
      "6:\tlearn: 4406.4025472\ttotal: 82.4ms\tremaining: 35.3ms\n",
      "7:\tlearn: 4377.3064763\ttotal: 93.4ms\tremaining: 23.4ms\n",
      "8:\tlearn: 4347.6796244\ttotal: 105ms\tremaining: 11.7ms\n",
      "9:\tlearn: 4318.3548709\ttotal: 117ms\tremaining: 0us\n",
      "0:\tlearn: 4587.1859055\ttotal: 13.7ms\tremaining: 123ms\n",
      "1:\tlearn: 4555.0977181\ttotal: 25ms\tremaining: 100ms\n",
      "2:\tlearn: 4523.7787327\ttotal: 36.3ms\tremaining: 84.7ms\n",
      "3:\tlearn: 4493.3151929\ttotal: 47.6ms\tremaining: 71.4ms\n",
      "4:\tlearn: 4462.8043907\ttotal: 59.1ms\tremaining: 59.1ms\n",
      "5:\tlearn: 4432.6818089\ttotal: 70.8ms\tremaining: 47.2ms\n",
      "6:\tlearn: 4402.4161410\ttotal: 81.9ms\tremaining: 35.1ms\n",
      "7:\tlearn: 4373.2226379\ttotal: 93.1ms\tremaining: 23.3ms\n",
      "8:\tlearn: 4343.7621226\ttotal: 104ms\tremaining: 11.6ms\n",
      "9:\tlearn: 4314.4962980\ttotal: 115ms\tremaining: 0us\n",
      "0:\tlearn: 4465.2277522\ttotal: 13.1ms\tremaining: 117ms\n",
      "1:\tlearn: 4313.1868486\ttotal: 24.1ms\tremaining: 96.6ms\n",
      "2:\tlearn: 4172.5627909\ttotal: 35.8ms\tremaining: 83.5ms\n",
      "3:\tlearn: 4039.2656137\ttotal: 47.3ms\tremaining: 70.9ms\n",
      "4:\tlearn: 3915.4451501\ttotal: 58.5ms\tremaining: 58.5ms\n",
      "5:\tlearn: 3795.4097525\ttotal: 69.4ms\tremaining: 46.3ms\n",
      "6:\tlearn: 3684.8558295\ttotal: 80.1ms\tremaining: 34.3ms\n",
      "7:\tlearn: 3578.3187770\ttotal: 91.4ms\tremaining: 22.9ms\n",
      "8:\tlearn: 3482.1216529\ttotal: 102ms\tremaining: 11.4ms\n",
      "9:\tlearn: 3391.1501941\ttotal: 113ms\tremaining: 0us\n",
      "0:\tlearn: 4458.5389811\ttotal: 12.6ms\tremaining: 113ms\n",
      "1:\tlearn: 4308.3433990\ttotal: 23.7ms\tremaining: 94.8ms\n",
      "2:\tlearn: 4167.1311034\ttotal: 35.4ms\tremaining: 82.5ms\n",
      "3:\tlearn: 4034.9897216\ttotal: 46.7ms\tremaining: 70ms\n",
      "4:\tlearn: 3911.0185966\ttotal: 59.2ms\tremaining: 59.2ms\n",
      "5:\tlearn: 3790.0676358\ttotal: 72.5ms\tremaining: 48.3ms\n",
      "6:\tlearn: 3679.0512923\ttotal: 84.4ms\tremaining: 36.2ms\n",
      "7:\tlearn: 3575.0378202\ttotal: 96.6ms\tremaining: 24.2ms\n",
      "8:\tlearn: 3477.1599665\ttotal: 109ms\tremaining: 12.1ms\n",
      "9:\tlearn: 3384.5305136\ttotal: 121ms\tremaining: 0us\n",
      "0:\tlearn: 4469.8406154\ttotal: 13ms\tremaining: 117ms\n",
      "1:\tlearn: 4317.9521736\ttotal: 24.3ms\tremaining: 97.1ms\n",
      "2:\tlearn: 4176.9761361\ttotal: 36.6ms\tremaining: 85.4ms\n",
      "3:\tlearn: 4046.6497575\ttotal: 49.2ms\tremaining: 73.8ms\n",
      "4:\tlearn: 3921.0199373\ttotal: 61.9ms\tremaining: 61.9ms\n",
      "5:\tlearn: 3802.8014624\ttotal: 74.1ms\tremaining: 49.4ms\n",
      "6:\tlearn: 3693.3458389\ttotal: 85.3ms\tremaining: 36.6ms\n",
      "7:\tlearn: 3586.6748824\ttotal: 96.7ms\tremaining: 24.2ms\n",
      "8:\tlearn: 3487.3592769\ttotal: 108ms\tremaining: 12ms\n",
      "9:\tlearn: 3395.4254417\ttotal: 118ms\tremaining: 0us\n",
      "0:\tlearn: 4463.7512820\ttotal: 12.9ms\tremaining: 116ms\n",
      "1:\tlearn: 4313.4866450\ttotal: 24.4ms\tremaining: 97.8ms\n",
      "2:\tlearn: 4174.4493222\ttotal: 35.4ms\tremaining: 82.7ms\n",
      "3:\tlearn: 4042.6187403\ttotal: 46.3ms\tremaining: 69.5ms\n",
      "4:\tlearn: 3914.4632903\ttotal: 57.3ms\tremaining: 57.3ms\n",
      "5:\tlearn: 3796.9202783\ttotal: 69.4ms\tremaining: 46.2ms\n",
      "6:\tlearn: 3681.8078820\ttotal: 80.6ms\tremaining: 34.5ms\n",
      "7:\tlearn: 3575.6807650\ttotal: 92.5ms\tremaining: 23.1ms\n",
      "8:\tlearn: 3477.6157988\ttotal: 103ms\tremaining: 11.5ms\n",
      "9:\tlearn: 3384.2457371\ttotal: 114ms\tremaining: 0us\n",
      "0:\tlearn: 4460.2195290\ttotal: 13.4ms\tremaining: 120ms\n",
      "1:\tlearn: 4308.2169019\ttotal: 25ms\tremaining: 100ms\n",
      "2:\tlearn: 4166.7774074\ttotal: 36.6ms\tremaining: 85.5ms\n",
      "3:\tlearn: 4035.7406617\ttotal: 48ms\tremaining: 72ms\n",
      "4:\tlearn: 3911.8118060\ttotal: 59.1ms\tremaining: 59.1ms\n",
      "5:\tlearn: 3794.6977923\ttotal: 70.5ms\tremaining: 47ms\n",
      "6:\tlearn: 3682.4491161\ttotal: 81.2ms\tremaining: 34.8ms\n",
      "7:\tlearn: 3581.8937207\ttotal: 92.8ms\tremaining: 23.2ms\n",
      "8:\tlearn: 3483.7917570\ttotal: 104ms\tremaining: 11.6ms\n",
      "9:\tlearn: 3390.8631971\ttotal: 116ms\tremaining: 0us\n",
      "0:\tlearn: 4306.8652252\ttotal: 13.1ms\tremaining: 118ms\n",
      "1:\tlearn: 4026.4585616\ttotal: 24.6ms\tremaining: 98.3ms\n",
      "2:\tlearn: 3779.5803336\ttotal: 36.1ms\tremaining: 84.2ms\n",
      "3:\tlearn: 3559.4627803\ttotal: 47.7ms\tremaining: 71.6ms\n",
      "4:\tlearn: 3369.1078138\ttotal: 58.6ms\tremaining: 58.6ms\n",
      "5:\tlearn: 3194.4027442\ttotal: 69.3ms\tremaining: 46.2ms\n",
      "6:\tlearn: 3041.5103002\ttotal: 80.3ms\tremaining: 34.4ms\n",
      "7:\tlearn: 2912.2664786\ttotal: 91.8ms\tremaining: 23ms\n",
      "8:\tlearn: 2799.7007241\ttotal: 103ms\tremaining: 11.4ms\n",
      "9:\tlearn: 2700.5710982\ttotal: 114ms\tremaining: 0us\n",
      "0:\tlearn: 4302.4050775\ttotal: 12.6ms\tremaining: 113ms\n",
      "1:\tlearn: 4024.2806521\ttotal: 23.6ms\tremaining: 94.2ms\n",
      "2:\tlearn: 3785.1823957\ttotal: 34.7ms\tremaining: 80.9ms\n",
      "3:\tlearn: 3563.5476213\ttotal: 45.6ms\tremaining: 68.3ms\n",
      "4:\tlearn: 3371.3381967\ttotal: 56.2ms\tremaining: 56.2ms\n",
      "5:\tlearn: 3197.3322727\ttotal: 67.1ms\tremaining: 44.7ms\n",
      "6:\tlearn: 3043.8997976\ttotal: 77.8ms\tremaining: 33.4ms\n",
      "7:\tlearn: 2908.0960156\ttotal: 88.6ms\tremaining: 22.1ms\n",
      "8:\tlearn: 2795.8682478\ttotal: 99ms\tremaining: 11ms\n",
      "9:\tlearn: 2694.7669480\ttotal: 110ms\tremaining: 0us\n",
      "0:\tlearn: 4314.0432876\ttotal: 12.4ms\tremaining: 112ms\n",
      "1:\tlearn: 4034.8034889\ttotal: 23.4ms\tremaining: 93.7ms\n",
      "2:\tlearn: 3788.2500357\ttotal: 34.7ms\tremaining: 81.1ms\n",
      "3:\tlearn: 3573.6166217\ttotal: 46.5ms\tremaining: 69.8ms\n",
      "4:\tlearn: 3379.7742359\ttotal: 58ms\tremaining: 58ms\n",
      "5:\tlearn: 3210.0820458\ttotal: 70.7ms\tremaining: 47.1ms\n",
      "6:\tlearn: 3052.5537358\ttotal: 81.8ms\tremaining: 35.1ms\n",
      "7:\tlearn: 2913.4909344\ttotal: 93.6ms\tremaining: 23.4ms\n",
      "8:\tlearn: 2801.1511537\ttotal: 104ms\tremaining: 11.6ms\n",
      "9:\tlearn: 2697.3147261\ttotal: 115ms\tremaining: 0us\n",
      "0:\tlearn: 4306.2878525\ttotal: 13ms\tremaining: 117ms\n",
      "1:\tlearn: 4023.5245851\ttotal: 24.5ms\tremaining: 98ms\n",
      "2:\tlearn: 3775.6204016\ttotal: 36ms\tremaining: 83.9ms\n",
      "3:\tlearn: 3558.9405587\ttotal: 47.3ms\tremaining: 71ms\n",
      "4:\tlearn: 3366.1734276\ttotal: 58.5ms\tremaining: 58.5ms\n",
      "5:\tlearn: 3199.5268154\ttotal: 69.7ms\tremaining: 46.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6:\tlearn: 3047.9842126\ttotal: 81.3ms\tremaining: 34.9ms\n",
      "7:\tlearn: 2911.7654209\ttotal: 92.6ms\tremaining: 23.2ms\n",
      "8:\tlearn: 2798.5866422\ttotal: 104ms\tremaining: 11.6ms\n",
      "9:\tlearn: 2696.1825645\ttotal: 116ms\tremaining: 0us\n",
      "0:\tlearn: 4303.9643419\ttotal: 19.9ms\tremaining: 179ms\n",
      "1:\tlearn: 4021.1011339\ttotal: 30.8ms\tremaining: 123ms\n",
      "2:\tlearn: 3772.9747484\ttotal: 42.4ms\tremaining: 98.9ms\n",
      "3:\tlearn: 3557.6904953\ttotal: 53.6ms\tremaining: 80.4ms\n",
      "4:\tlearn: 3370.5521681\ttotal: 66.2ms\tremaining: 66.2ms\n",
      "5:\tlearn: 3200.7023413\ttotal: 77.6ms\tremaining: 51.7ms\n",
      "6:\tlearn: 3050.1964189\ttotal: 88.4ms\tremaining: 37.9ms\n",
      "7:\tlearn: 2916.0218413\ttotal: 99ms\tremaining: 24.7ms\n",
      "8:\tlearn: 2801.3552053\ttotal: 111ms\tremaining: 12.3ms\n",
      "9:\tlearn: 2696.5273050\ttotal: 123ms\tremaining: 0us\n",
      "0:\tlearn: 4593.8610044\ttotal: 13.5ms\tremaining: 189ms\n",
      "1:\tlearn: 4561.7441058\ttotal: 25.1ms\tremaining: 163ms\n",
      "2:\tlearn: 4530.5462092\ttotal: 36.5ms\tremaining: 146ms\n",
      "3:\tlearn: 4499.6361735\ttotal: 48ms\tremaining: 132ms\n",
      "4:\tlearn: 4468.9376964\ttotal: 59.7ms\tremaining: 119ms\n",
      "5:\tlearn: 4438.7777971\ttotal: 71.4ms\tremaining: 107ms\n",
      "6:\tlearn: 4408.5214599\ttotal: 82.8ms\tremaining: 94.6ms\n",
      "7:\tlearn: 4378.8981462\ttotal: 94.4ms\tremaining: 82.6ms\n",
      "8:\tlearn: 4349.6226302\ttotal: 106ms\tremaining: 70.5ms\n",
      "9:\tlearn: 4320.6211424\ttotal: 116ms\tremaining: 58.1ms\n",
      "10:\tlearn: 4291.8987099\ttotal: 128ms\tremaining: 46.4ms\n",
      "11:\tlearn: 4263.3516704\ttotal: 139ms\tremaining: 34.8ms\n",
      "12:\tlearn: 4235.4061250\ttotal: 151ms\tremaining: 23.3ms\n",
      "13:\tlearn: 4207.8394780\ttotal: 164ms\tremaining: 11.7ms\n",
      "14:\tlearn: 4180.6140954\ttotal: 175ms\tremaining: 0us\n",
      "0:\tlearn: 4585.4083131\ttotal: 14ms\tremaining: 196ms\n",
      "1:\tlearn: 4553.4777515\ttotal: 26.2ms\tremaining: 170ms\n",
      "2:\tlearn: 4522.2822708\ttotal: 37.7ms\tremaining: 151ms\n",
      "3:\tlearn: 4491.7564239\ttotal: 49ms\tremaining: 135ms\n",
      "4:\tlearn: 4461.2118057\ttotal: 60.4ms\tremaining: 121ms\n",
      "5:\tlearn: 4431.0890711\ttotal: 72ms\tremaining: 108ms\n",
      "6:\tlearn: 4401.4812279\ttotal: 83.1ms\tremaining: 95ms\n",
      "7:\tlearn: 4371.6158466\ttotal: 93.9ms\tremaining: 82.1ms\n",
      "8:\tlearn: 4342.2222758\ttotal: 105ms\tremaining: 70ms\n",
      "9:\tlearn: 4313.0557171\ttotal: 117ms\tremaining: 58.3ms\n",
      "10:\tlearn: 4284.2248805\ttotal: 129ms\tremaining: 46.8ms\n",
      "11:\tlearn: 4256.0596696\ttotal: 140ms\tremaining: 35.1ms\n",
      "12:\tlearn: 4228.2773589\ttotal: 152ms\tremaining: 23.3ms\n",
      "13:\tlearn: 4200.9384267\ttotal: 162ms\tremaining: 11.6ms\n",
      "14:\tlearn: 4173.4637814\ttotal: 173ms\tremaining: 0us\n",
      "0:\tlearn: 4596.4587552\ttotal: 12.1ms\tremaining: 170ms\n",
      "1:\tlearn: 4564.9074120\ttotal: 23.4ms\tremaining: 152ms\n",
      "2:\tlearn: 4533.6385734\ttotal: 34.5ms\tremaining: 138ms\n",
      "3:\tlearn: 4503.0324306\ttotal: 45.7ms\tremaining: 126ms\n",
      "4:\tlearn: 4472.3758126\ttotal: 57.3ms\tremaining: 115ms\n",
      "5:\tlearn: 4441.8817399\ttotal: 69.7ms\tremaining: 105ms\n",
      "6:\tlearn: 4411.4464957\ttotal: 81.3ms\tremaining: 92.9ms\n",
      "7:\tlearn: 4381.7034171\ttotal: 93.6ms\tremaining: 81.9ms\n",
      "8:\tlearn: 4352.1617851\ttotal: 106ms\tremaining: 70.5ms\n",
      "9:\tlearn: 4323.0205642\ttotal: 119ms\tremaining: 59.4ms\n",
      "10:\tlearn: 4294.5613561\ttotal: 131ms\tremaining: 47.5ms\n",
      "11:\tlearn: 4265.8742258\ttotal: 143ms\tremaining: 35.8ms\n",
      "12:\tlearn: 4237.9036962\ttotal: 155ms\tremaining: 23.8ms\n",
      "13:\tlearn: 4210.4189660\ttotal: 166ms\tremaining: 11.9ms\n",
      "14:\tlearn: 4183.0421148\ttotal: 177ms\tremaining: 0us\n",
      "0:\tlearn: 4591.6674091\ttotal: 16.6ms\tremaining: 233ms\n",
      "1:\tlearn: 4559.9189252\ttotal: 29.2ms\tremaining: 190ms\n",
      "2:\tlearn: 4528.7125385\ttotal: 41.5ms\tremaining: 166ms\n",
      "3:\tlearn: 4497.9700520\ttotal: 55.1ms\tremaining: 151ms\n",
      "4:\tlearn: 4467.0857791\ttotal: 67.4ms\tremaining: 135ms\n",
      "5:\tlearn: 4436.6779568\ttotal: 79.8ms\tremaining: 120ms\n",
      "6:\tlearn: 4406.4025472\ttotal: 91.7ms\tremaining: 105ms\n",
      "7:\tlearn: 4377.3064763\ttotal: 104ms\tremaining: 90.6ms\n",
      "8:\tlearn: 4347.6796244\ttotal: 115ms\tremaining: 76.5ms\n",
      "9:\tlearn: 4318.3548709\ttotal: 126ms\tremaining: 62.9ms\n",
      "10:\tlearn: 4290.0816266\ttotal: 138ms\tremaining: 50ms\n",
      "11:\tlearn: 4261.8185028\ttotal: 149ms\tremaining: 37.3ms\n",
      "12:\tlearn: 4233.8512203\ttotal: 160ms\tremaining: 24.7ms\n",
      "13:\tlearn: 4206.0684716\ttotal: 172ms\tremaining: 12.3ms\n",
      "14:\tlearn: 4178.8516498\ttotal: 184ms\tremaining: 0us\n",
      "0:\tlearn: 4587.1859055\ttotal: 14.6ms\tremaining: 204ms\n",
      "1:\tlearn: 4555.0977181\ttotal: 26.4ms\tremaining: 172ms\n",
      "2:\tlearn: 4523.7787327\ttotal: 40.1ms\tremaining: 160ms\n",
      "3:\tlearn: 4493.3151929\ttotal: 51ms\tremaining: 140ms\n",
      "4:\tlearn: 4462.8043907\ttotal: 62.6ms\tremaining: 125ms\n",
      "5:\tlearn: 4432.6818089\ttotal: 74.3ms\tremaining: 111ms\n",
      "6:\tlearn: 4402.4161410\ttotal: 85.7ms\tremaining: 98ms\n",
      "7:\tlearn: 4373.2226379\ttotal: 97ms\tremaining: 84.9ms\n",
      "8:\tlearn: 4343.7621226\ttotal: 108ms\tremaining: 72.1ms\n",
      "9:\tlearn: 4314.4962980\ttotal: 120ms\tremaining: 59.8ms\n",
      "10:\tlearn: 4285.7010022\ttotal: 131ms\tremaining: 47.7ms\n",
      "11:\tlearn: 4257.4430537\ttotal: 143ms\tremaining: 35.7ms\n",
      "12:\tlearn: 4229.8023145\ttotal: 155ms\tremaining: 23.9ms\n",
      "13:\tlearn: 4202.1024222\ttotal: 167ms\tremaining: 11.9ms\n",
      "14:\tlearn: 4174.8722931\ttotal: 178ms\tremaining: 0us\n",
      "0:\tlearn: 4465.2277522\ttotal: 14.5ms\tremaining: 203ms\n",
      "1:\tlearn: 4313.1868486\ttotal: 26ms\tremaining: 169ms\n",
      "2:\tlearn: 4172.5627909\ttotal: 38ms\tremaining: 152ms\n",
      "3:\tlearn: 4039.2656137\ttotal: 49ms\tremaining: 135ms\n",
      "4:\tlearn: 3915.4451501\ttotal: 60.9ms\tremaining: 122ms\n",
      "5:\tlearn: 3795.4097525\ttotal: 72.6ms\tremaining: 109ms\n",
      "6:\tlearn: 3684.8558295\ttotal: 84.2ms\tremaining: 96.2ms\n",
      "7:\tlearn: 3578.3187770\ttotal: 95.4ms\tremaining: 83.4ms\n",
      "8:\tlearn: 3482.1216529\ttotal: 107ms\tremaining: 71.1ms\n",
      "9:\tlearn: 3391.1501941\ttotal: 118ms\tremaining: 58.9ms\n",
      "10:\tlearn: 3302.5638393\ttotal: 130ms\tremaining: 47.1ms\n",
      "11:\tlearn: 3220.1026283\ttotal: 141ms\tremaining: 35.2ms\n",
      "12:\tlearn: 3142.0103676\ttotal: 153ms\tremaining: 23.6ms\n",
      "13:\tlearn: 3069.4997352\ttotal: 165ms\tremaining: 11.8ms\n",
      "14:\tlearn: 3001.6086590\ttotal: 176ms\tremaining: 0us\n",
      "0:\tlearn: 4458.5389811\ttotal: 13.9ms\tremaining: 195ms\n",
      "1:\tlearn: 4308.3433990\ttotal: 26ms\tremaining: 169ms\n",
      "2:\tlearn: 4167.1311034\ttotal: 37.6ms\tremaining: 151ms\n",
      "3:\tlearn: 4034.9897216\ttotal: 49.3ms\tremaining: 136ms\n",
      "4:\tlearn: 3911.0185966\ttotal: 61.3ms\tremaining: 123ms\n",
      "5:\tlearn: 3790.0676358\ttotal: 73.3ms\tremaining: 110ms\n",
      "6:\tlearn: 3679.0512923\ttotal: 84.4ms\tremaining: 96.4ms\n",
      "7:\tlearn: 3575.0378202\ttotal: 95.8ms\tremaining: 83.8ms\n",
      "8:\tlearn: 3477.1599665\ttotal: 108ms\tremaining: 71.8ms\n",
      "9:\tlearn: 3384.5305136\ttotal: 119ms\tremaining: 59.4ms\n",
      "10:\tlearn: 3296.4934261\ttotal: 130ms\tremaining: 47.4ms\n",
      "11:\tlearn: 3215.5814453\ttotal: 142ms\tremaining: 35.5ms\n",
      "12:\tlearn: 3137.7221546\ttotal: 153ms\tremaining: 23.6ms\n",
      "13:\tlearn: 3066.0194780\ttotal: 165ms\tremaining: 11.8ms\n",
      "14:\tlearn: 2996.6337062\ttotal: 177ms\tremaining: 0us\n",
      "0:\tlearn: 4469.8406154\ttotal: 13.2ms\tremaining: 185ms\n",
      "1:\tlearn: 4317.9521736\ttotal: 25ms\tremaining: 162ms\n",
      "2:\tlearn: 4176.9761361\ttotal: 36.5ms\tremaining: 146ms\n",
      "3:\tlearn: 4046.6497575\ttotal: 48.1ms\tremaining: 132ms\n",
      "4:\tlearn: 3921.0199373\ttotal: 60.3ms\tremaining: 121ms\n",
      "5:\tlearn: 3802.8014624\ttotal: 71.6ms\tremaining: 107ms\n",
      "6:\tlearn: 3693.3458389\ttotal: 83.1ms\tremaining: 95ms\n",
      "7:\tlearn: 3586.6748824\ttotal: 94.3ms\tremaining: 82.5ms\n",
      "8:\tlearn: 3487.3592769\ttotal: 106ms\tremaining: 70.7ms\n",
      "9:\tlearn: 3395.4254417\ttotal: 118ms\tremaining: 58.8ms\n",
      "10:\tlearn: 3308.7028183\ttotal: 130ms\tremaining: 47.1ms\n",
      "11:\tlearn: 3224.5932709\ttotal: 141ms\tremaining: 35.3ms\n",
      "12:\tlearn: 3146.1873812\ttotal: 152ms\tremaining: 23.4ms\n",
      "13:\tlearn: 3074.0737187\ttotal: 163ms\tremaining: 11.7ms\n",
      "14:\tlearn: 3006.1868474\ttotal: 175ms\tremaining: 0us\n",
      "0:\tlearn: 4463.7512820\ttotal: 13.5ms\tremaining: 189ms\n",
      "1:\tlearn: 4313.4866450\ttotal: 25.7ms\tremaining: 167ms\n",
      "2:\tlearn: 4174.4493222\ttotal: 37.9ms\tremaining: 151ms\n",
      "3:\tlearn: 4042.6187403\ttotal: 49.2ms\tremaining: 135ms\n",
      "4:\tlearn: 3914.4632903\ttotal: 61.2ms\tremaining: 122ms\n",
      "5:\tlearn: 3796.9202783\ttotal: 73.3ms\tremaining: 110ms\n",
      "6:\tlearn: 3681.8078820\ttotal: 84.9ms\tremaining: 97ms\n",
      "7:\tlearn: 3575.6807650\ttotal: 95.8ms\tremaining: 83.9ms\n",
      "8:\tlearn: 3477.6157988\ttotal: 107ms\tremaining: 71.4ms\n",
      "9:\tlearn: 3384.2457371\ttotal: 119ms\tremaining: 59.3ms\n",
      "10:\tlearn: 3299.1131592\ttotal: 130ms\tremaining: 47.3ms\n",
      "11:\tlearn: 3217.8858997\ttotal: 142ms\tremaining: 35.5ms\n",
      "12:\tlearn: 3142.2954388\ttotal: 153ms\tremaining: 23.6ms\n",
      "13:\tlearn: 3070.8999019\ttotal: 165ms\tremaining: 11.8ms\n",
      "14:\tlearn: 3002.0239101\ttotal: 177ms\tremaining: 0us\n",
      "0:\tlearn: 4460.2195290\ttotal: 20.5ms\tremaining: 287ms\n",
      "1:\tlearn: 4308.2169019\ttotal: 32.4ms\tremaining: 210ms\n",
      "2:\tlearn: 4166.7774074\ttotal: 45.4ms\tremaining: 181ms\n",
      "3:\tlearn: 4035.7406617\ttotal: 57.2ms\tremaining: 157ms\n",
      "4:\tlearn: 3911.8118060\ttotal: 68.6ms\tremaining: 137ms\n",
      "5:\tlearn: 3794.6977923\ttotal: 80.4ms\tremaining: 121ms\n",
      "6:\tlearn: 3682.4491161\ttotal: 92.3ms\tremaining: 106ms\n",
      "7:\tlearn: 3581.8937207\ttotal: 105ms\tremaining: 92.1ms\n",
      "8:\tlearn: 3483.7917570\ttotal: 118ms\tremaining: 78.4ms\n",
      "9:\tlearn: 3390.8631971\ttotal: 130ms\tremaining: 64.9ms\n",
      "10:\tlearn: 3303.7685644\ttotal: 142ms\tremaining: 51.6ms\n",
      "11:\tlearn: 3219.6505103\ttotal: 155ms\tremaining: 38.9ms\n",
      "12:\tlearn: 3141.9473111\ttotal: 168ms\tremaining: 25.8ms\n",
      "13:\tlearn: 3070.3288832\ttotal: 180ms\tremaining: 12.9ms\n",
      "14:\tlearn: 3002.5056604\ttotal: 193ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4306.8652252\ttotal: 13.3ms\tremaining: 186ms\n",
      "1:\tlearn: 4026.4585616\ttotal: 25.8ms\tremaining: 168ms\n",
      "2:\tlearn: 3779.5803336\ttotal: 37.4ms\tremaining: 150ms\n",
      "3:\tlearn: 3559.4627803\ttotal: 49.5ms\tremaining: 136ms\n",
      "4:\tlearn: 3369.1078138\ttotal: 61.5ms\tremaining: 123ms\n",
      "5:\tlearn: 3194.4027442\ttotal: 72.9ms\tremaining: 109ms\n",
      "6:\tlearn: 3041.5103002\ttotal: 84.7ms\tremaining: 96.8ms\n",
      "7:\tlearn: 2912.2664786\ttotal: 96ms\tremaining: 84ms\n",
      "8:\tlearn: 2799.7007241\ttotal: 107ms\tremaining: 71.6ms\n",
      "9:\tlearn: 2700.5710982\ttotal: 119ms\tremaining: 59.4ms\n",
      "10:\tlearn: 2609.0011429\ttotal: 130ms\tremaining: 47.3ms\n",
      "11:\tlearn: 2530.3198922\ttotal: 142ms\tremaining: 35.4ms\n",
      "12:\tlearn: 2464.4847626\ttotal: 152ms\tremaining: 23.4ms\n",
      "13:\tlearn: 2405.8345228\ttotal: 163ms\tremaining: 11.6ms\n",
      "14:\tlearn: 2349.6882437\ttotal: 174ms\tremaining: 0us\n",
      "0:\tlearn: 4302.4050775\ttotal: 14.2ms\tremaining: 199ms\n",
      "1:\tlearn: 4024.2806521\ttotal: 26.3ms\tremaining: 171ms\n",
      "2:\tlearn: 3785.1823957\ttotal: 37.5ms\tremaining: 150ms\n",
      "3:\tlearn: 3563.5476213\ttotal: 49.2ms\tremaining: 135ms\n",
      "4:\tlearn: 3371.3381967\ttotal: 60.5ms\tremaining: 121ms\n",
      "5:\tlearn: 3197.3322727\ttotal: 71.8ms\tremaining: 108ms\n",
      "6:\tlearn: 3043.8997976\ttotal: 82.5ms\tremaining: 94.3ms\n",
      "7:\tlearn: 2908.0960156\ttotal: 93.9ms\tremaining: 82.1ms\n",
      "8:\tlearn: 2795.8682478\ttotal: 105ms\tremaining: 69.9ms\n",
      "9:\tlearn: 2694.7669480\ttotal: 116ms\tremaining: 57.9ms\n",
      "10:\tlearn: 2607.1958714\ttotal: 127ms\tremaining: 46.2ms\n",
      "11:\tlearn: 2529.6145655\ttotal: 138ms\tremaining: 34.5ms\n",
      "12:\tlearn: 2460.5336712\ttotal: 149ms\tremaining: 22.9ms\n",
      "13:\tlearn: 2400.0546625\ttotal: 159ms\tremaining: 11.4ms\n",
      "14:\tlearn: 2344.5404879\ttotal: 171ms\tremaining: 0us\n",
      "0:\tlearn: 4314.0432876\ttotal: 14.6ms\tremaining: 205ms\n",
      "1:\tlearn: 4034.8034889\ttotal: 26.6ms\tremaining: 173ms\n",
      "2:\tlearn: 3788.2500357\ttotal: 38.1ms\tremaining: 152ms\n",
      "3:\tlearn: 3573.6166217\ttotal: 49.7ms\tremaining: 137ms\n",
      "4:\tlearn: 3379.7742359\ttotal: 60.8ms\tremaining: 122ms\n",
      "5:\tlearn: 3210.0820458\ttotal: 72ms\tremaining: 108ms\n",
      "6:\tlearn: 3052.5537358\ttotal: 83.8ms\tremaining: 95.7ms\n",
      "7:\tlearn: 2913.4909344\ttotal: 94.7ms\tremaining: 82.9ms\n",
      "8:\tlearn: 2801.1511537\ttotal: 105ms\tremaining: 70.3ms\n",
      "9:\tlearn: 2697.3147261\ttotal: 116ms\tremaining: 58ms\n",
      "10:\tlearn: 2608.6477390\ttotal: 127ms\tremaining: 46.2ms\n",
      "11:\tlearn: 2529.8129355\ttotal: 138ms\tremaining: 34.4ms\n",
      "12:\tlearn: 2463.0596463\ttotal: 149ms\tremaining: 22.9ms\n",
      "13:\tlearn: 2399.3140841\ttotal: 160ms\tremaining: 11.4ms\n",
      "14:\tlearn: 2342.0641593\ttotal: 172ms\tremaining: 0us\n",
      "0:\tlearn: 4306.2878525\ttotal: 14.4ms\tremaining: 201ms\n",
      "1:\tlearn: 4023.5245851\ttotal: 26.1ms\tremaining: 170ms\n",
      "2:\tlearn: 3775.6204016\ttotal: 37.7ms\tremaining: 151ms\n",
      "3:\tlearn: 3558.9405587\ttotal: 49.9ms\tremaining: 137ms\n",
      "4:\tlearn: 3366.1734276\ttotal: 61.4ms\tremaining: 123ms\n",
      "5:\tlearn: 3199.5268154\ttotal: 73.4ms\tremaining: 110ms\n",
      "6:\tlearn: 3047.9842126\ttotal: 85.2ms\tremaining: 97.3ms\n",
      "7:\tlearn: 2911.7654209\ttotal: 95.7ms\tremaining: 83.7ms\n",
      "8:\tlearn: 2798.5866422\ttotal: 107ms\tremaining: 71.3ms\n",
      "9:\tlearn: 2696.1825645\ttotal: 118ms\tremaining: 58.8ms\n",
      "10:\tlearn: 2612.2216114\ttotal: 129ms\tremaining: 47ms\n",
      "11:\tlearn: 2533.9862851\ttotal: 140ms\tremaining: 35ms\n",
      "12:\tlearn: 2462.6247338\ttotal: 152ms\tremaining: 23.3ms\n",
      "13:\tlearn: 2403.1074080\ttotal: 163ms\tremaining: 11.6ms\n",
      "14:\tlearn: 2348.5387024\ttotal: 174ms\tremaining: 0us\n",
      "0:\tlearn: 4303.9643419\ttotal: 13.3ms\tremaining: 186ms\n",
      "1:\tlearn: 4021.1011339\ttotal: 24.5ms\tremaining: 159ms\n",
      "2:\tlearn: 3772.9747484\ttotal: 36.6ms\tremaining: 146ms\n",
      "3:\tlearn: 3557.6904953\ttotal: 47.7ms\tremaining: 131ms\n",
      "4:\tlearn: 3370.5521681\ttotal: 58.8ms\tremaining: 118ms\n",
      "5:\tlearn: 3200.7023413\ttotal: 70.4ms\tremaining: 106ms\n",
      "6:\tlearn: 3050.1964189\ttotal: 81.1ms\tremaining: 92.6ms\n",
      "7:\tlearn: 2916.0218413\ttotal: 92.1ms\tremaining: 80.6ms\n",
      "8:\tlearn: 2801.3552053\ttotal: 103ms\tremaining: 68.8ms\n",
      "9:\tlearn: 2696.5273050\ttotal: 114ms\tremaining: 57ms\n",
      "10:\tlearn: 2608.2282055\ttotal: 125ms\tremaining: 45.5ms\n",
      "11:\tlearn: 2531.7075181\ttotal: 136ms\tremaining: 34ms\n",
      "12:\tlearn: 2463.4903500\ttotal: 147ms\tremaining: 22.6ms\n",
      "13:\tlearn: 2403.9044763\ttotal: 159ms\tremaining: 11.3ms\n",
      "14:\tlearn: 2350.3242850\ttotal: 170ms\tremaining: 0us\n",
      "0:\tlearn: 4593.8610044\ttotal: 14.2ms\tremaining: 271ms\n",
      "1:\tlearn: 4561.7441058\ttotal: 25.6ms\tremaining: 231ms\n",
      "2:\tlearn: 4530.5462092\ttotal: 37ms\tremaining: 210ms\n",
      "3:\tlearn: 4499.6361735\ttotal: 48.5ms\tremaining: 194ms\n",
      "4:\tlearn: 4468.9376964\ttotal: 59.8ms\tremaining: 179ms\n",
      "5:\tlearn: 4438.7777971\ttotal: 71.4ms\tremaining: 167ms\n",
      "6:\tlearn: 4408.5214599\ttotal: 82.7ms\tremaining: 154ms\n",
      "7:\tlearn: 4378.8981462\ttotal: 94.2ms\tremaining: 141ms\n",
      "8:\tlearn: 4349.6226302\ttotal: 106ms\tremaining: 129ms\n",
      "9:\tlearn: 4320.6211424\ttotal: 117ms\tremaining: 117ms\n",
      "10:\tlearn: 4291.8987099\ttotal: 129ms\tremaining: 105ms\n",
      "11:\tlearn: 4263.3516704\ttotal: 140ms\tremaining: 93.1ms\n",
      "12:\tlearn: 4235.4061250\ttotal: 151ms\tremaining: 81.1ms\n",
      "13:\tlearn: 4207.8394780\ttotal: 161ms\tremaining: 69.1ms\n",
      "14:\tlearn: 4180.6140954\ttotal: 172ms\tremaining: 57.5ms\n",
      "15:\tlearn: 4153.5998863\ttotal: 183ms\tremaining: 45.8ms\n",
      "16:\tlearn: 4126.6079762\ttotal: 194ms\tremaining: 34.3ms\n",
      "17:\tlearn: 4099.7938553\ttotal: 205ms\tremaining: 22.8ms\n",
      "18:\tlearn: 4073.4299997\ttotal: 217ms\tremaining: 11.4ms\n",
      "19:\tlearn: 4047.8072394\ttotal: 229ms\tremaining: 0us\n",
      "0:\tlearn: 4585.4083131\ttotal: 13.2ms\tremaining: 251ms\n",
      "1:\tlearn: 4553.4777515\ttotal: 24.5ms\tremaining: 220ms\n",
      "2:\tlearn: 4522.2822708\ttotal: 36ms\tremaining: 204ms\n",
      "3:\tlearn: 4491.7564239\ttotal: 47.7ms\tremaining: 191ms\n",
      "4:\tlearn: 4461.2118057\ttotal: 58.8ms\tremaining: 176ms\n",
      "5:\tlearn: 4431.0890711\ttotal: 70.6ms\tremaining: 165ms\n",
      "6:\tlearn: 4401.4812279\ttotal: 82.3ms\tremaining: 153ms\n",
      "7:\tlearn: 4371.6158466\ttotal: 93.9ms\tremaining: 141ms\n",
      "8:\tlearn: 4342.2222758\ttotal: 105ms\tremaining: 128ms\n",
      "9:\tlearn: 4313.0557171\ttotal: 116ms\tremaining: 116ms\n",
      "10:\tlearn: 4284.2248805\ttotal: 128ms\tremaining: 105ms\n",
      "11:\tlearn: 4256.0596696\ttotal: 140ms\tremaining: 93.1ms\n",
      "12:\tlearn: 4228.2773589\ttotal: 151ms\tremaining: 81.5ms\n",
      "13:\tlearn: 4200.9384267\ttotal: 162ms\tremaining: 69.5ms\n",
      "14:\tlearn: 4173.4637814\ttotal: 174ms\tremaining: 57.8ms\n",
      "15:\tlearn: 4146.9497043\ttotal: 184ms\tremaining: 46.1ms\n",
      "16:\tlearn: 4119.9303790\ttotal: 195ms\tremaining: 34.4ms\n",
      "17:\tlearn: 4093.5908396\ttotal: 206ms\tremaining: 22.9ms\n",
      "18:\tlearn: 4067.3216116\ttotal: 217ms\tremaining: 11.4ms\n",
      "19:\tlearn: 4041.3523581\ttotal: 228ms\tremaining: 0us\n",
      "0:\tlearn: 4596.4587552\ttotal: 13.3ms\tremaining: 254ms\n",
      "1:\tlearn: 4564.9074120\ttotal: 24.8ms\tremaining: 223ms\n",
      "2:\tlearn: 4533.6385734\ttotal: 36.3ms\tremaining: 206ms\n",
      "3:\tlearn: 4503.0324306\ttotal: 47.5ms\tremaining: 190ms\n",
      "4:\tlearn: 4472.3758126\ttotal: 60ms\tremaining: 180ms\n",
      "5:\tlearn: 4441.8817399\ttotal: 71.6ms\tremaining: 167ms\n",
      "6:\tlearn: 4411.4464957\ttotal: 83.7ms\tremaining: 155ms\n",
      "7:\tlearn: 4381.7034171\ttotal: 95.2ms\tremaining: 143ms\n",
      "8:\tlearn: 4352.1617851\ttotal: 106ms\tremaining: 130ms\n",
      "9:\tlearn: 4323.0205642\ttotal: 117ms\tremaining: 117ms\n",
      "10:\tlearn: 4294.5613561\ttotal: 128ms\tremaining: 104ms\n",
      "11:\tlearn: 4265.8742258\ttotal: 139ms\tremaining: 92.5ms\n",
      "12:\tlearn: 4237.9036962\ttotal: 150ms\tremaining: 80.6ms\n",
      "13:\tlearn: 4210.4189660\ttotal: 161ms\tremaining: 68.9ms\n",
      "14:\tlearn: 4183.0421148\ttotal: 172ms\tremaining: 57.3ms\n",
      "15:\tlearn: 4156.4739977\ttotal: 183ms\tremaining: 45.8ms\n",
      "16:\tlearn: 4129.3568746\ttotal: 194ms\tremaining: 34.3ms\n",
      "17:\tlearn: 4103.1180931\ttotal: 206ms\tremaining: 22.9ms\n",
      "18:\tlearn: 4077.0113206\ttotal: 217ms\tremaining: 11.4ms\n",
      "19:\tlearn: 4050.9297822\ttotal: 228ms\tremaining: 0us\n",
      "0:\tlearn: 4591.6674091\ttotal: 13.4ms\tremaining: 255ms\n",
      "1:\tlearn: 4559.9189252\ttotal: 25.2ms\tremaining: 226ms\n",
      "2:\tlearn: 4528.7125385\ttotal: 37ms\tremaining: 209ms\n",
      "3:\tlearn: 4497.9700520\ttotal: 48.5ms\tremaining: 194ms\n",
      "4:\tlearn: 4467.0857791\ttotal: 59.2ms\tremaining: 178ms\n",
      "5:\tlearn: 4436.6779568\ttotal: 70.7ms\tremaining: 165ms\n",
      "6:\tlearn: 4406.4025472\ttotal: 81.7ms\tremaining: 152ms\n",
      "7:\tlearn: 4377.3064763\ttotal: 92.7ms\tremaining: 139ms\n",
      "8:\tlearn: 4347.6796244\ttotal: 104ms\tremaining: 127ms\n",
      "9:\tlearn: 4318.3548709\ttotal: 115ms\tremaining: 115ms\n",
      "10:\tlearn: 4290.0816266\ttotal: 126ms\tremaining: 103ms\n",
      "11:\tlearn: 4261.8185028\ttotal: 136ms\tremaining: 90.9ms\n",
      "12:\tlearn: 4233.8512203\ttotal: 148ms\tremaining: 79.5ms\n",
      "13:\tlearn: 4206.0684716\ttotal: 159ms\tremaining: 68.3ms\n",
      "14:\tlearn: 4178.8516498\ttotal: 170ms\tremaining: 56.7ms\n",
      "15:\tlearn: 4152.3485192\ttotal: 181ms\tremaining: 45.3ms\n",
      "16:\tlearn: 4126.0374886\ttotal: 192ms\tremaining: 34ms\n",
      "17:\tlearn: 4099.7275244\ttotal: 205ms\tremaining: 22.7ms\n",
      "18:\tlearn: 4073.6995661\ttotal: 216ms\tremaining: 11.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:\tlearn: 4047.7018502\ttotal: 228ms\tremaining: 0us\n",
      "0:\tlearn: 4587.1859055\ttotal: 13.3ms\tremaining: 252ms\n",
      "1:\tlearn: 4555.0977181\ttotal: 24.2ms\tremaining: 217ms\n",
      "2:\tlearn: 4523.7787327\ttotal: 35.5ms\tremaining: 201ms\n",
      "3:\tlearn: 4493.3151929\ttotal: 46.8ms\tremaining: 187ms\n",
      "4:\tlearn: 4462.8043907\ttotal: 59.5ms\tremaining: 179ms\n",
      "5:\tlearn: 4432.6818089\ttotal: 71.1ms\tremaining: 166ms\n",
      "6:\tlearn: 4402.4161410\ttotal: 82.3ms\tremaining: 153ms\n",
      "7:\tlearn: 4373.2226379\ttotal: 93.6ms\tremaining: 140ms\n",
      "8:\tlearn: 4343.7621226\ttotal: 105ms\tremaining: 128ms\n",
      "9:\tlearn: 4314.4962980\ttotal: 116ms\tremaining: 116ms\n",
      "10:\tlearn: 4285.7010022\ttotal: 127ms\tremaining: 104ms\n",
      "11:\tlearn: 4257.4430537\ttotal: 138ms\tremaining: 91.9ms\n",
      "12:\tlearn: 4229.8023145\ttotal: 150ms\tremaining: 80.7ms\n",
      "13:\tlearn: 4202.1024222\ttotal: 162ms\tremaining: 69.4ms\n",
      "14:\tlearn: 4174.8722931\ttotal: 173ms\tremaining: 57.8ms\n",
      "15:\tlearn: 4148.3671708\ttotal: 184ms\tremaining: 46ms\n",
      "16:\tlearn: 4122.0002380\ttotal: 196ms\tremaining: 34.5ms\n",
      "17:\tlearn: 4095.3778123\ttotal: 207ms\tremaining: 23ms\n",
      "18:\tlearn: 4069.4667490\ttotal: 217ms\tremaining: 11.4ms\n",
      "19:\tlearn: 4043.9535193\ttotal: 229ms\tremaining: 0us\n",
      "0:\tlearn: 4465.2277522\ttotal: 13.2ms\tremaining: 251ms\n",
      "1:\tlearn: 4313.1868486\ttotal: 23.9ms\tremaining: 215ms\n",
      "2:\tlearn: 4172.5627909\ttotal: 35.1ms\tremaining: 199ms\n",
      "3:\tlearn: 4039.2656137\ttotal: 47ms\tremaining: 188ms\n",
      "4:\tlearn: 3915.4451501\ttotal: 58.3ms\tremaining: 175ms\n",
      "5:\tlearn: 3795.4097525\ttotal: 69.5ms\tremaining: 162ms\n",
      "6:\tlearn: 3684.8558295\ttotal: 81.8ms\tremaining: 152ms\n",
      "7:\tlearn: 3578.3187770\ttotal: 94.3ms\tremaining: 141ms\n",
      "8:\tlearn: 3482.1216529\ttotal: 107ms\tremaining: 131ms\n",
      "9:\tlearn: 3391.1501941\ttotal: 119ms\tremaining: 119ms\n",
      "10:\tlearn: 3302.5638393\ttotal: 130ms\tremaining: 106ms\n",
      "11:\tlearn: 3220.1026283\ttotal: 141ms\tremaining: 94ms\n",
      "12:\tlearn: 3142.0103676\ttotal: 152ms\tremaining: 81.9ms\n",
      "13:\tlearn: 3069.4997352\ttotal: 163ms\tremaining: 69.8ms\n",
      "14:\tlearn: 3001.6086590\ttotal: 174ms\tremaining: 58ms\n",
      "15:\tlearn: 2938.0827304\ttotal: 186ms\tremaining: 46.5ms\n",
      "16:\tlearn: 2876.5942937\ttotal: 197ms\tremaining: 34.7ms\n",
      "17:\tlearn: 2819.7325046\ttotal: 207ms\tremaining: 23ms\n",
      "18:\tlearn: 2765.9647162\ttotal: 219ms\tremaining: 11.5ms\n",
      "19:\tlearn: 2716.1137613\ttotal: 230ms\tremaining: 0us\n",
      "0:\tlearn: 4458.5389811\ttotal: 13.4ms\tremaining: 254ms\n",
      "1:\tlearn: 4308.3433990\ttotal: 25.1ms\tremaining: 226ms\n",
      "2:\tlearn: 4167.1311034\ttotal: 36.8ms\tremaining: 209ms\n",
      "3:\tlearn: 4034.9897216\ttotal: 48ms\tremaining: 192ms\n",
      "4:\tlearn: 3911.0185966\ttotal: 59ms\tremaining: 177ms\n",
      "5:\tlearn: 3790.0676358\ttotal: 70.4ms\tremaining: 164ms\n",
      "6:\tlearn: 3679.0512923\ttotal: 81.3ms\tremaining: 151ms\n",
      "7:\tlearn: 3575.0378202\ttotal: 92.8ms\tremaining: 139ms\n",
      "8:\tlearn: 3477.1599665\ttotal: 104ms\tremaining: 127ms\n",
      "9:\tlearn: 3384.5305136\ttotal: 115ms\tremaining: 115ms\n",
      "10:\tlearn: 3296.4934261\ttotal: 126ms\tremaining: 103ms\n",
      "11:\tlearn: 3215.5814453\ttotal: 137ms\tremaining: 91.1ms\n",
      "12:\tlearn: 3137.7221546\ttotal: 147ms\tremaining: 79.4ms\n",
      "13:\tlearn: 3066.0194780\ttotal: 159ms\tremaining: 68.2ms\n",
      "14:\tlearn: 2996.6337062\ttotal: 170ms\tremaining: 56.7ms\n",
      "15:\tlearn: 2931.8971629\ttotal: 181ms\tremaining: 45.3ms\n",
      "16:\tlearn: 2871.4671026\ttotal: 192ms\tremaining: 33.9ms\n",
      "17:\tlearn: 2814.2374775\ttotal: 203ms\tremaining: 22.5ms\n",
      "18:\tlearn: 2761.7723264\ttotal: 213ms\tremaining: 11.2ms\n",
      "19:\tlearn: 2711.2168934\ttotal: 224ms\tremaining: 0us\n",
      "0:\tlearn: 4469.8406154\ttotal: 13ms\tremaining: 247ms\n",
      "1:\tlearn: 4317.9521736\ttotal: 24.1ms\tremaining: 217ms\n",
      "2:\tlearn: 4176.9761361\ttotal: 35.5ms\tremaining: 201ms\n",
      "3:\tlearn: 4046.6497575\ttotal: 46.7ms\tremaining: 187ms\n",
      "4:\tlearn: 3921.0199373\ttotal: 58.8ms\tremaining: 176ms\n",
      "5:\tlearn: 3802.8014624\ttotal: 69.9ms\tremaining: 163ms\n",
      "6:\tlearn: 3693.3458389\ttotal: 81.5ms\tremaining: 151ms\n",
      "7:\tlearn: 3586.6748824\ttotal: 92.5ms\tremaining: 139ms\n",
      "8:\tlearn: 3487.3592769\ttotal: 104ms\tremaining: 127ms\n",
      "9:\tlearn: 3395.4254417\ttotal: 115ms\tremaining: 115ms\n",
      "10:\tlearn: 3308.7028183\ttotal: 126ms\tremaining: 103ms\n",
      "11:\tlearn: 3224.5932709\ttotal: 137ms\tremaining: 91.3ms\n",
      "12:\tlearn: 3146.1873812\ttotal: 147ms\tremaining: 79.4ms\n",
      "13:\tlearn: 3074.0737187\ttotal: 159ms\tremaining: 68.1ms\n",
      "14:\tlearn: 3006.1868474\ttotal: 171ms\tremaining: 56.9ms\n",
      "15:\tlearn: 2941.3045442\ttotal: 182ms\tremaining: 45.4ms\n",
      "16:\tlearn: 2881.3097501\ttotal: 194ms\tremaining: 34.2ms\n",
      "17:\tlearn: 2825.1446919\ttotal: 205ms\tremaining: 22.8ms\n",
      "18:\tlearn: 2770.8836994\ttotal: 216ms\tremaining: 11.4ms\n",
      "19:\tlearn: 2719.6804869\ttotal: 227ms\tremaining: 0us\n",
      "0:\tlearn: 4463.7512820\ttotal: 14.1ms\tremaining: 269ms\n",
      "1:\tlearn: 4313.4866450\ttotal: 25.8ms\tremaining: 232ms\n",
      "2:\tlearn: 4174.4493222\ttotal: 37ms\tremaining: 210ms\n",
      "3:\tlearn: 4042.6187403\ttotal: 48.4ms\tremaining: 193ms\n",
      "4:\tlearn: 3914.4632903\ttotal: 59.9ms\tremaining: 180ms\n",
      "5:\tlearn: 3796.9202783\ttotal: 71.8ms\tremaining: 168ms\n",
      "6:\tlearn: 3681.8078820\ttotal: 83.3ms\tremaining: 155ms\n",
      "7:\tlearn: 3575.6807650\ttotal: 94.7ms\tremaining: 142ms\n",
      "8:\tlearn: 3477.6157988\ttotal: 106ms\tremaining: 130ms\n",
      "9:\tlearn: 3384.2457371\ttotal: 117ms\tremaining: 117ms\n",
      "10:\tlearn: 3299.1131592\ttotal: 128ms\tremaining: 105ms\n",
      "11:\tlearn: 3217.8858997\ttotal: 141ms\tremaining: 94.2ms\n",
      "12:\tlearn: 3142.2954388\ttotal: 152ms\tremaining: 82.1ms\n",
      "13:\tlearn: 3070.8999019\ttotal: 165ms\tremaining: 70.9ms\n",
      "14:\tlearn: 3002.0239101\ttotal: 177ms\tremaining: 59.1ms\n",
      "15:\tlearn: 2937.7494873\ttotal: 189ms\tremaining: 47.4ms\n",
      "16:\tlearn: 2876.6211087\ttotal: 202ms\tremaining: 35.6ms\n",
      "17:\tlearn: 2820.9154843\ttotal: 215ms\tremaining: 23.9ms\n",
      "18:\tlearn: 2767.9469656\ttotal: 228ms\tremaining: 12ms\n",
      "19:\tlearn: 2718.3554450\ttotal: 240ms\tremaining: 0us\n",
      "0:\tlearn: 4460.2195290\ttotal: 12.3ms\tremaining: 233ms\n",
      "1:\tlearn: 4308.2169019\ttotal: 22.7ms\tremaining: 204ms\n",
      "2:\tlearn: 4166.7774074\ttotal: 35.2ms\tremaining: 200ms\n",
      "3:\tlearn: 4035.7406617\ttotal: 47ms\tremaining: 188ms\n",
      "4:\tlearn: 3911.8118060\ttotal: 59ms\tremaining: 177ms\n",
      "5:\tlearn: 3794.6977923\ttotal: 70ms\tremaining: 163ms\n",
      "6:\tlearn: 3682.4491161\ttotal: 81.1ms\tremaining: 151ms\n",
      "7:\tlearn: 3581.8937207\ttotal: 92.5ms\tremaining: 139ms\n",
      "8:\tlearn: 3483.7917570\ttotal: 103ms\tremaining: 126ms\n",
      "9:\tlearn: 3390.8631971\ttotal: 114ms\tremaining: 114ms\n",
      "10:\tlearn: 3303.7685644\ttotal: 125ms\tremaining: 103ms\n",
      "11:\tlearn: 3219.6505103\ttotal: 136ms\tremaining: 90.9ms\n",
      "12:\tlearn: 3141.9473111\ttotal: 147ms\tremaining: 79.2ms\n",
      "13:\tlearn: 3070.3288832\ttotal: 158ms\tremaining: 67.7ms\n",
      "14:\tlearn: 3002.5056604\ttotal: 169ms\tremaining: 56.3ms\n",
      "15:\tlearn: 2939.3030621\ttotal: 180ms\tremaining: 45ms\n",
      "16:\tlearn: 2878.5969725\ttotal: 191ms\tremaining: 33.7ms\n",
      "17:\tlearn: 2820.0594134\ttotal: 202ms\tremaining: 22.4ms\n",
      "18:\tlearn: 2767.6385917\ttotal: 212ms\tremaining: 11.2ms\n",
      "19:\tlearn: 2716.8417866\ttotal: 223ms\tremaining: 0us\n",
      "0:\tlearn: 4306.8652252\ttotal: 13.2ms\tremaining: 250ms\n",
      "1:\tlearn: 4026.4585616\ttotal: 25.3ms\tremaining: 228ms\n",
      "2:\tlearn: 3779.5803336\ttotal: 36.5ms\tremaining: 207ms\n",
      "3:\tlearn: 3559.4627803\ttotal: 48.3ms\tremaining: 193ms\n",
      "4:\tlearn: 3369.1078138\ttotal: 59.1ms\tremaining: 177ms\n",
      "5:\tlearn: 3194.4027442\ttotal: 70.2ms\tremaining: 164ms\n",
      "6:\tlearn: 3041.5103002\ttotal: 81.2ms\tremaining: 151ms\n",
      "7:\tlearn: 2912.2664786\ttotal: 91.9ms\tremaining: 138ms\n",
      "8:\tlearn: 2799.7007241\ttotal: 103ms\tremaining: 126ms\n",
      "9:\tlearn: 2700.5710982\ttotal: 114ms\tremaining: 114ms\n",
      "10:\tlearn: 2609.0011429\ttotal: 124ms\tremaining: 102ms\n",
      "11:\tlearn: 2530.3198922\ttotal: 135ms\tremaining: 90ms\n",
      "12:\tlearn: 2464.4847626\ttotal: 145ms\tremaining: 78.3ms\n",
      "13:\tlearn: 2405.8345228\ttotal: 156ms\tremaining: 66.9ms\n",
      "14:\tlearn: 2349.6882437\ttotal: 167ms\tremaining: 55.7ms\n",
      "15:\tlearn: 2301.6630737\ttotal: 179ms\tremaining: 44.6ms\n",
      "16:\tlearn: 2263.2869155\ttotal: 190ms\tremaining: 33.5ms\n",
      "17:\tlearn: 2224.6202719\ttotal: 200ms\tremaining: 22.3ms\n",
      "18:\tlearn: 2193.4556854\ttotal: 211ms\tremaining: 11.1ms\n",
      "19:\tlearn: 2162.2698696\ttotal: 223ms\tremaining: 0us\n",
      "0:\tlearn: 4302.4050775\ttotal: 13.1ms\tremaining: 249ms\n",
      "1:\tlearn: 4024.2806521\ttotal: 24.8ms\tremaining: 223ms\n",
      "2:\tlearn: 3785.1823957\ttotal: 36.3ms\tremaining: 206ms\n",
      "3:\tlearn: 3563.5476213\ttotal: 47.9ms\tremaining: 192ms\n",
      "4:\tlearn: 3371.3381967\ttotal: 58.8ms\tremaining: 176ms\n",
      "5:\tlearn: 3197.3322727\ttotal: 70.1ms\tremaining: 163ms\n",
      "6:\tlearn: 3043.8997976\ttotal: 81.1ms\tremaining: 151ms\n",
      "7:\tlearn: 2908.0960156\ttotal: 91.8ms\tremaining: 138ms\n",
      "8:\tlearn: 2795.8682478\ttotal: 102ms\tremaining: 125ms\n",
      "9:\tlearn: 2694.7669480\ttotal: 113ms\tremaining: 113ms\n",
      "10:\tlearn: 2607.1958714\ttotal: 124ms\tremaining: 101ms\n",
      "11:\tlearn: 2529.6145655\ttotal: 134ms\tremaining: 89.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:\tlearn: 2460.5336712\ttotal: 146ms\tremaining: 78.5ms\n",
      "13:\tlearn: 2400.0546625\ttotal: 157ms\tremaining: 67.3ms\n",
      "14:\tlearn: 2344.5404879\ttotal: 169ms\tremaining: 56.4ms\n",
      "15:\tlearn: 2297.7846058\ttotal: 180ms\tremaining: 45.1ms\n",
      "16:\tlearn: 2257.7152643\ttotal: 191ms\tremaining: 33.6ms\n",
      "17:\tlearn: 2222.5343474\ttotal: 201ms\tremaining: 22.3ms\n",
      "18:\tlearn: 2188.4905137\ttotal: 211ms\tremaining: 11.1ms\n",
      "19:\tlearn: 2159.0219060\ttotal: 222ms\tremaining: 0us\n",
      "0:\tlearn: 4314.0432876\ttotal: 13.1ms\tremaining: 250ms\n",
      "1:\tlearn: 4034.8034889\ttotal: 24.5ms\tremaining: 221ms\n",
      "2:\tlearn: 3788.2500357\ttotal: 35.8ms\tremaining: 203ms\n",
      "3:\tlearn: 3573.6166217\ttotal: 47.1ms\tremaining: 188ms\n",
      "4:\tlearn: 3379.7742359\ttotal: 58.1ms\tremaining: 174ms\n",
      "5:\tlearn: 3210.0820458\ttotal: 69.8ms\tremaining: 163ms\n",
      "6:\tlearn: 3052.5537358\ttotal: 82.1ms\tremaining: 152ms\n",
      "7:\tlearn: 2913.4909344\ttotal: 93ms\tremaining: 140ms\n",
      "8:\tlearn: 2801.1511537\ttotal: 104ms\tremaining: 127ms\n",
      "9:\tlearn: 2697.3147261\ttotal: 115ms\tremaining: 115ms\n",
      "10:\tlearn: 2608.6477390\ttotal: 126ms\tremaining: 103ms\n",
      "11:\tlearn: 2529.8129355\ttotal: 137ms\tremaining: 91.4ms\n",
      "12:\tlearn: 2463.0596463\ttotal: 148ms\tremaining: 79.9ms\n",
      "13:\tlearn: 2399.3140841\ttotal: 160ms\tremaining: 68.4ms\n",
      "14:\tlearn: 2342.0641593\ttotal: 171ms\tremaining: 57.1ms\n",
      "15:\tlearn: 2294.9601126\ttotal: 182ms\tremaining: 45.5ms\n",
      "16:\tlearn: 2253.9445848\ttotal: 193ms\tremaining: 34ms\n",
      "17:\tlearn: 2218.6248378\ttotal: 203ms\tremaining: 22.6ms\n",
      "18:\tlearn: 2184.7279922\ttotal: 215ms\tremaining: 11.3ms\n",
      "19:\tlearn: 2150.8553909\ttotal: 225ms\tremaining: 0us\n",
      "0:\tlearn: 4306.2878525\ttotal: 13.6ms\tremaining: 258ms\n",
      "1:\tlearn: 4023.5245851\ttotal: 24.9ms\tremaining: 224ms\n",
      "2:\tlearn: 3775.6204016\ttotal: 37.1ms\tremaining: 210ms\n",
      "3:\tlearn: 3558.9405587\ttotal: 48.8ms\tremaining: 195ms\n",
      "4:\tlearn: 3366.1734276\ttotal: 60.1ms\tremaining: 180ms\n",
      "5:\tlearn: 3199.5268154\ttotal: 71.3ms\tremaining: 166ms\n",
      "6:\tlearn: 3047.9842126\ttotal: 82.7ms\tremaining: 154ms\n",
      "7:\tlearn: 2911.7654209\ttotal: 93.3ms\tremaining: 140ms\n",
      "8:\tlearn: 2798.5866422\ttotal: 104ms\tremaining: 127ms\n",
      "9:\tlearn: 2696.1825645\ttotal: 114ms\tremaining: 114ms\n",
      "10:\tlearn: 2612.2216114\ttotal: 125ms\tremaining: 102ms\n",
      "11:\tlearn: 2533.9862851\ttotal: 135ms\tremaining: 90.3ms\n",
      "12:\tlearn: 2462.6247338\ttotal: 147ms\tremaining: 78.9ms\n",
      "13:\tlearn: 2403.1074080\ttotal: 158ms\tremaining: 67.6ms\n",
      "14:\tlearn: 2348.5387024\ttotal: 168ms\tremaining: 56.1ms\n",
      "15:\tlearn: 2301.9872373\ttotal: 179ms\tremaining: 44.6ms\n",
      "16:\tlearn: 2261.8471873\ttotal: 190ms\tremaining: 33.4ms\n",
      "17:\tlearn: 2224.7710412\ttotal: 200ms\tremaining: 22.2ms\n",
      "18:\tlearn: 2193.1650312\ttotal: 210ms\tremaining: 11.1ms\n",
      "19:\tlearn: 2160.0702966\ttotal: 222ms\tremaining: 0us\n",
      "0:\tlearn: 4303.9643419\ttotal: 13.3ms\tremaining: 253ms\n",
      "1:\tlearn: 4021.1011339\ttotal: 24.4ms\tremaining: 220ms\n",
      "2:\tlearn: 3772.9747484\ttotal: 35.7ms\tremaining: 202ms\n",
      "3:\tlearn: 3557.6904953\ttotal: 46.6ms\tremaining: 186ms\n",
      "4:\tlearn: 3370.5521681\ttotal: 58.2ms\tremaining: 175ms\n",
      "5:\tlearn: 3200.7023413\ttotal: 69.9ms\tremaining: 163ms\n",
      "6:\tlearn: 3050.1964189\ttotal: 80.9ms\tremaining: 150ms\n",
      "7:\tlearn: 2916.0218413\ttotal: 91.6ms\tremaining: 137ms\n",
      "8:\tlearn: 2801.3552053\ttotal: 103ms\tremaining: 125ms\n",
      "9:\tlearn: 2696.5273050\ttotal: 113ms\tremaining: 113ms\n",
      "10:\tlearn: 2608.2282055\ttotal: 124ms\tremaining: 102ms\n",
      "11:\tlearn: 2531.7075181\ttotal: 135ms\tremaining: 90.1ms\n",
      "12:\tlearn: 2463.4903500\ttotal: 147ms\tremaining: 78.9ms\n",
      "13:\tlearn: 2403.9044763\ttotal: 158ms\tremaining: 67.7ms\n",
      "14:\tlearn: 2350.3242850\ttotal: 169ms\tremaining: 56.5ms\n",
      "15:\tlearn: 2304.4139137\ttotal: 181ms\tremaining: 45.3ms\n",
      "16:\tlearn: 2264.1446891\ttotal: 192ms\tremaining: 33.9ms\n",
      "17:\tlearn: 2227.5780959\ttotal: 203ms\tremaining: 22.5ms\n",
      "18:\tlearn: 2196.4317018\ttotal: 214ms\tremaining: 11.2ms\n",
      "19:\tlearn: 2164.4881975\ttotal: 224ms\tremaining: 0us\n",
      "0:\tlearn: 4592.7268043\ttotal: 24.4ms\tremaining: 219ms\n",
      "1:\tlearn: 4560.1222029\ttotal: 46.9ms\tremaining: 187ms\n",
      "2:\tlearn: 4527.6844531\ttotal: 68.4ms\tremaining: 160ms\n",
      "3:\tlearn: 4495.0028795\ttotal: 91.5ms\tremaining: 137ms\n",
      "4:\tlearn: 4463.3935021\ttotal: 114ms\tremaining: 114ms\n",
      "5:\tlearn: 4432.1185036\ttotal: 136ms\tremaining: 90.6ms\n",
      "6:\tlearn: 4401.0439582\ttotal: 158ms\tremaining: 67.8ms\n",
      "7:\tlearn: 4369.6354934\ttotal: 180ms\tremaining: 45ms\n",
      "8:\tlearn: 4339.2256634\ttotal: 202ms\tremaining: 22.4ms\n",
      "9:\tlearn: 4309.1714313\ttotal: 225ms\tremaining: 0us\n",
      "0:\tlearn: 4584.1330709\ttotal: 24.6ms\tremaining: 222ms\n",
      "1:\tlearn: 4550.7276915\ttotal: 47.3ms\tremaining: 189ms\n",
      "2:\tlearn: 4518.4090743\ttotal: 70.1ms\tremaining: 164ms\n",
      "3:\tlearn: 4486.1209528\ttotal: 91.9ms\tremaining: 138ms\n",
      "4:\tlearn: 4454.0564579\ttotal: 113ms\tremaining: 113ms\n",
      "5:\tlearn: 4423.3003671\ttotal: 136ms\tremaining: 90.8ms\n",
      "6:\tlearn: 4392.1817988\ttotal: 158ms\tremaining: 67.8ms\n",
      "7:\tlearn: 4361.2074341\ttotal: 179ms\tremaining: 44.8ms\n",
      "8:\tlearn: 4331.3195529\ttotal: 201ms\tremaining: 22.3ms\n",
      "9:\tlearn: 4301.0756397\ttotal: 223ms\tremaining: 0us\n",
      "0:\tlearn: 4595.2490752\ttotal: 22.7ms\tremaining: 205ms\n",
      "1:\tlearn: 4562.0597321\ttotal: 45ms\tremaining: 180ms\n",
      "2:\tlearn: 4529.7789061\ttotal: 67.4ms\tremaining: 157ms\n",
      "3:\tlearn: 4497.3221750\ttotal: 89.8ms\tremaining: 135ms\n",
      "4:\tlearn: 4465.8022025\ttotal: 112ms\tremaining: 112ms\n",
      "5:\tlearn: 4434.8716159\ttotal: 134ms\tremaining: 89.6ms\n",
      "6:\tlearn: 4403.7088199\ttotal: 161ms\tremaining: 68.8ms\n",
      "7:\tlearn: 4372.8768942\ttotal: 182ms\tremaining: 45.5ms\n",
      "8:\tlearn: 4342.3543846\ttotal: 203ms\tremaining: 22.5ms\n",
      "9:\tlearn: 4311.9637630\ttotal: 225ms\tremaining: 0us\n",
      "0:\tlearn: 4590.2753862\ttotal: 24.3ms\tremaining: 218ms\n",
      "1:\tlearn: 4557.1181143\ttotal: 47.9ms\tremaining: 191ms\n",
      "2:\tlearn: 4524.4393089\ttotal: 69.8ms\tremaining: 163ms\n",
      "3:\tlearn: 4492.2863916\ttotal: 94.1ms\tremaining: 141ms\n",
      "4:\tlearn: 4460.8535162\ttotal: 116ms\tremaining: 116ms\n",
      "5:\tlearn: 4429.9127995\ttotal: 138ms\tremaining: 92.2ms\n",
      "6:\tlearn: 4398.8033931\ttotal: 164ms\tremaining: 70.4ms\n",
      "7:\tlearn: 4367.9253595\ttotal: 185ms\tremaining: 46.3ms\n",
      "8:\tlearn: 4337.5469124\ttotal: 206ms\tremaining: 22.9ms\n",
      "9:\tlearn: 4307.5522152\ttotal: 228ms\tremaining: 0us\n",
      "0:\tlearn: 4586.0672089\ttotal: 23.3ms\tremaining: 209ms\n",
      "1:\tlearn: 4553.0076385\ttotal: 45.3ms\tremaining: 181ms\n",
      "2:\tlearn: 4520.3116065\ttotal: 67.2ms\tremaining: 157ms\n",
      "3:\tlearn: 4487.8495319\ttotal: 90.3ms\tremaining: 135ms\n",
      "4:\tlearn: 4456.2971818\ttotal: 112ms\tremaining: 112ms\n",
      "5:\tlearn: 4425.1608335\ttotal: 135ms\tremaining: 90ms\n",
      "6:\tlearn: 4394.1959286\ttotal: 157ms\tremaining: 67.2ms\n",
      "7:\tlearn: 4363.3545849\ttotal: 180ms\tremaining: 44.9ms\n",
      "8:\tlearn: 4333.1808949\ttotal: 201ms\tremaining: 22.4ms\n",
      "9:\tlearn: 4303.2142847\ttotal: 223ms\tremaining: 0us\n",
      "0:\tlearn: 4459.5035002\ttotal: 25.1ms\tremaining: 226ms\n",
      "1:\tlearn: 4301.5087091\ttotal: 47.5ms\tremaining: 190ms\n",
      "2:\tlearn: 4154.7664979\ttotal: 70.7ms\tremaining: 165ms\n",
      "3:\tlearn: 4015.7551445\ttotal: 92.6ms\tremaining: 139ms\n",
      "4:\tlearn: 3890.4185504\ttotal: 114ms\tremaining: 114ms\n",
      "5:\tlearn: 3766.2557553\ttotal: 136ms\tremaining: 90.6ms\n",
      "6:\tlearn: 3650.4781796\ttotal: 158ms\tremaining: 67.6ms\n",
      "7:\tlearn: 3541.4116181\ttotal: 180ms\tremaining: 45ms\n",
      "8:\tlearn: 3438.0850989\ttotal: 201ms\tremaining: 22.4ms\n",
      "9:\tlearn: 3342.1293930\ttotal: 224ms\tremaining: 0us\n",
      "0:\tlearn: 4452.1083263\ttotal: 26ms\tremaining: 234ms\n",
      "1:\tlearn: 4294.9352356\ttotal: 48.3ms\tremaining: 193ms\n",
      "2:\tlearn: 4148.6808212\ttotal: 69.9ms\tremaining: 163ms\n",
      "3:\tlearn: 4009.0698782\ttotal: 91.5ms\tremaining: 137ms\n",
      "4:\tlearn: 3879.3191715\ttotal: 113ms\tremaining: 113ms\n",
      "5:\tlearn: 3759.5793378\ttotal: 135ms\tremaining: 89.8ms\n",
      "6:\tlearn: 3643.3645215\ttotal: 157ms\tremaining: 67.5ms\n",
      "7:\tlearn: 3532.9844009\ttotal: 179ms\tremaining: 44.7ms\n",
      "8:\tlearn: 3430.0610191\ttotal: 200ms\tremaining: 22.2ms\n",
      "9:\tlearn: 3332.5029579\ttotal: 222ms\tremaining: 0us\n",
      "0:\tlearn: 4463.7379408\ttotal: 24.3ms\tremaining: 219ms\n",
      "1:\tlearn: 4304.3257162\ttotal: 48.2ms\tremaining: 193ms\n",
      "2:\tlearn: 4158.7783184\ttotal: 69.9ms\tremaining: 163ms\n",
      "3:\tlearn: 4019.8496770\ttotal: 91.5ms\tremaining: 137ms\n",
      "4:\tlearn: 3892.7561906\ttotal: 114ms\tremaining: 114ms\n",
      "5:\tlearn: 3770.2130846\ttotal: 135ms\tremaining: 89.9ms\n",
      "6:\tlearn: 3653.3516678\ttotal: 157ms\tremaining: 67.2ms\n",
      "7:\tlearn: 3541.4802663\ttotal: 179ms\tremaining: 44.7ms\n",
      "8:\tlearn: 3437.9763732\ttotal: 201ms\tremaining: 22.3ms\n",
      "9:\tlearn: 3339.8716223\ttotal: 222ms\tremaining: 0us\n",
      "0:\tlearn: 4456.7194987\ttotal: 23.1ms\tremaining: 208ms\n",
      "1:\tlearn: 4299.7188150\ttotal: 46.2ms\tremaining: 185ms\n",
      "2:\tlearn: 4150.0182903\ttotal: 68ms\tremaining: 159ms\n",
      "3:\tlearn: 4011.0109365\ttotal: 92.5ms\tremaining: 139ms\n",
      "4:\tlearn: 3883.4783901\ttotal: 115ms\tremaining: 115ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5:\tlearn: 3760.7980595\ttotal: 136ms\tremaining: 90.9ms\n",
      "6:\tlearn: 3644.2465625\ttotal: 159ms\tremaining: 68.2ms\n",
      "7:\tlearn: 3535.0977014\ttotal: 181ms\tremaining: 45.3ms\n",
      "8:\tlearn: 3432.0432964\ttotal: 204ms\tremaining: 22.7ms\n",
      "9:\tlearn: 3335.2602075\ttotal: 226ms\tremaining: 0us\n",
      "0:\tlearn: 4454.5786610\ttotal: 24.6ms\tremaining: 222ms\n",
      "1:\tlearn: 4300.3613487\ttotal: 47.6ms\tremaining: 190ms\n",
      "2:\tlearn: 4151.6931092\ttotal: 69.8ms\tremaining: 163ms\n",
      "3:\tlearn: 4012.4953641\ttotal: 91ms\tremaining: 137ms\n",
      "4:\tlearn: 3881.5304280\ttotal: 113ms\tremaining: 113ms\n",
      "5:\tlearn: 3759.3952993\ttotal: 135ms\tremaining: 90.3ms\n",
      "6:\tlearn: 3645.4668957\ttotal: 157ms\tremaining: 67.4ms\n",
      "7:\tlearn: 3535.9410464\ttotal: 179ms\tremaining: 44.8ms\n",
      "8:\tlearn: 3432.1930648\ttotal: 201ms\tremaining: 22.3ms\n",
      "9:\tlearn: 3336.8770746\ttotal: 224ms\tremaining: 0us\n",
      "0:\tlearn: 4295.2808498\ttotal: 22.8ms\tremaining: 205ms\n",
      "1:\tlearn: 4000.3753108\ttotal: 46.1ms\tremaining: 184ms\n",
      "2:\tlearn: 3743.7437281\ttotal: 69.6ms\tremaining: 162ms\n",
      "3:\tlearn: 3514.2763504\ttotal: 91.3ms\tremaining: 137ms\n",
      "4:\tlearn: 3314.7419767\ttotal: 114ms\tremaining: 114ms\n",
      "5:\tlearn: 3132.8948966\ttotal: 136ms\tremaining: 90.5ms\n",
      "6:\tlearn: 2974.2943699\ttotal: 158ms\tremaining: 67.5ms\n",
      "7:\tlearn: 2838.2807033\ttotal: 179ms\tremaining: 44.8ms\n",
      "8:\tlearn: 2720.6531697\ttotal: 201ms\tremaining: 22.4ms\n",
      "9:\tlearn: 2614.4779545\ttotal: 223ms\tremaining: 0us\n",
      "0:\tlearn: 4289.4056635\ttotal: 23.6ms\tremaining: 213ms\n",
      "1:\tlearn: 3996.0555054\ttotal: 44.9ms\tremaining: 180ms\n",
      "2:\tlearn: 3743.2928439\ttotal: 68.1ms\tremaining: 159ms\n",
      "3:\tlearn: 3514.5456124\ttotal: 90.4ms\tremaining: 136ms\n",
      "4:\tlearn: 3314.1931326\ttotal: 113ms\tremaining: 113ms\n",
      "5:\tlearn: 3136.9071549\ttotal: 136ms\tremaining: 90.6ms\n",
      "6:\tlearn: 2977.4319915\ttotal: 159ms\tremaining: 68.2ms\n",
      "7:\tlearn: 2840.4992104\ttotal: 181ms\tremaining: 45.2ms\n",
      "8:\tlearn: 2722.0834460\ttotal: 203ms\tremaining: 22.6ms\n",
      "9:\tlearn: 2618.5539567\ttotal: 225ms\tremaining: 0us\n",
      "0:\tlearn: 4301.7000186\ttotal: 23.1ms\tremaining: 208ms\n",
      "1:\tlearn: 4003.9459544\ttotal: 46.3ms\tremaining: 185ms\n",
      "2:\tlearn: 3746.9348551\ttotal: 68.5ms\tremaining: 160ms\n",
      "3:\tlearn: 3518.0135261\ttotal: 90.2ms\tremaining: 135ms\n",
      "4:\tlearn: 3321.0209633\ttotal: 111ms\tremaining: 111ms\n",
      "5:\tlearn: 3144.4490049\ttotal: 135ms\tremaining: 89.9ms\n",
      "6:\tlearn: 2985.7250221\ttotal: 157ms\tremaining: 67.1ms\n",
      "7:\tlearn: 2847.4045715\ttotal: 178ms\tremaining: 44.6ms\n",
      "8:\tlearn: 2727.0579010\ttotal: 200ms\tremaining: 22.2ms\n",
      "9:\tlearn: 2623.6051225\ttotal: 222ms\tremaining: 0us\n",
      "0:\tlearn: 4292.0406367\ttotal: 23.6ms\tremaining: 213ms\n",
      "1:\tlearn: 4000.1851944\ttotal: 48.3ms\tremaining: 193ms\n",
      "2:\tlearn: 3742.5319068\ttotal: 70.2ms\tremaining: 164ms\n",
      "3:\tlearn: 3517.8223174\ttotal: 92.9ms\tremaining: 139ms\n",
      "4:\tlearn: 3320.7270411\ttotal: 115ms\tremaining: 115ms\n",
      "5:\tlearn: 3141.5377855\ttotal: 136ms\tremaining: 90.7ms\n",
      "6:\tlearn: 2983.5992149\ttotal: 159ms\tremaining: 68.2ms\n",
      "7:\tlearn: 2847.4273575\ttotal: 180ms\tremaining: 45.1ms\n",
      "8:\tlearn: 2728.8159113\ttotal: 204ms\tremaining: 22.6ms\n",
      "9:\tlearn: 2622.1665876\ttotal: 225ms\tremaining: 0us\n",
      "0:\tlearn: 4292.5624923\ttotal: 23.6ms\tremaining: 212ms\n",
      "1:\tlearn: 3996.3628260\ttotal: 45.8ms\tremaining: 183ms\n",
      "2:\tlearn: 3741.7320674\ttotal: 67.7ms\tremaining: 158ms\n",
      "3:\tlearn: 3516.2309056\ttotal: 89.9ms\tremaining: 135ms\n",
      "4:\tlearn: 3313.3942387\ttotal: 114ms\tremaining: 114ms\n",
      "5:\tlearn: 3140.0579757\ttotal: 135ms\tremaining: 90.2ms\n",
      "6:\tlearn: 2982.0365382\ttotal: 158ms\tremaining: 67.9ms\n",
      "7:\tlearn: 2847.6253791\ttotal: 182ms\tremaining: 45.5ms\n",
      "8:\tlearn: 2724.5086660\ttotal: 204ms\tremaining: 22.7ms\n",
      "9:\tlearn: 2619.7439758\ttotal: 226ms\tremaining: 0us\n",
      "0:\tlearn: 4592.7268043\ttotal: 24.6ms\tremaining: 345ms\n",
      "1:\tlearn: 4560.1222029\ttotal: 48.4ms\tremaining: 315ms\n",
      "2:\tlearn: 4527.6844531\ttotal: 72.2ms\tremaining: 289ms\n",
      "3:\tlearn: 4495.0028795\ttotal: 97ms\tremaining: 267ms\n",
      "4:\tlearn: 4463.3935021\ttotal: 119ms\tremaining: 238ms\n",
      "5:\tlearn: 4432.1185036\ttotal: 140ms\tremaining: 210ms\n",
      "6:\tlearn: 4401.0439582\ttotal: 163ms\tremaining: 186ms\n",
      "7:\tlearn: 4369.6354934\ttotal: 186ms\tremaining: 163ms\n",
      "8:\tlearn: 4339.2256634\ttotal: 208ms\tremaining: 139ms\n",
      "9:\tlearn: 4309.1714313\ttotal: 231ms\tremaining: 115ms\n",
      "10:\tlearn: 4279.0712175\ttotal: 252ms\tremaining: 91.7ms\n",
      "11:\tlearn: 4250.0223553\ttotal: 275ms\tremaining: 68.7ms\n",
      "12:\tlearn: 4221.3827552\ttotal: 297ms\tremaining: 45.6ms\n",
      "13:\tlearn: 4193.3213753\ttotal: 320ms\tremaining: 22.8ms\n",
      "14:\tlearn: 4164.5408197\ttotal: 342ms\tremaining: 0us\n",
      "0:\tlearn: 4584.1330709\ttotal: 26.6ms\tremaining: 373ms\n",
      "1:\tlearn: 4550.7276915\ttotal: 50.2ms\tremaining: 326ms\n",
      "2:\tlearn: 4518.4090743\ttotal: 72.2ms\tremaining: 289ms\n",
      "3:\tlearn: 4486.1209528\ttotal: 95.4ms\tremaining: 262ms\n",
      "4:\tlearn: 4454.0564579\ttotal: 117ms\tremaining: 235ms\n",
      "5:\tlearn: 4423.3003671\ttotal: 140ms\tremaining: 210ms\n",
      "6:\tlearn: 4392.1817988\ttotal: 163ms\tremaining: 186ms\n",
      "7:\tlearn: 4361.2074341\ttotal: 184ms\tremaining: 161ms\n",
      "8:\tlearn: 4331.3195529\ttotal: 206ms\tremaining: 137ms\n",
      "9:\tlearn: 4301.0756397\ttotal: 228ms\tremaining: 114ms\n",
      "10:\tlearn: 4271.2945846\ttotal: 251ms\tremaining: 91.2ms\n",
      "11:\tlearn: 4242.0711441\ttotal: 274ms\tremaining: 68.4ms\n",
      "12:\tlearn: 4213.4857295\ttotal: 295ms\tremaining: 45.4ms\n",
      "13:\tlearn: 4184.9061783\ttotal: 317ms\tremaining: 22.7ms\n",
      "14:\tlearn: 4156.7392322\ttotal: 340ms\tremaining: 0us\n",
      "0:\tlearn: 4595.2490752\ttotal: 24.1ms\tremaining: 338ms\n",
      "1:\tlearn: 4562.0597321\ttotal: 44.9ms\tremaining: 292ms\n",
      "2:\tlearn: 4529.7789061\ttotal: 67ms\tremaining: 268ms\n",
      "3:\tlearn: 4497.3221750\ttotal: 89.8ms\tremaining: 247ms\n",
      "4:\tlearn: 4465.8022025\ttotal: 113ms\tremaining: 226ms\n",
      "5:\tlearn: 4434.8716159\ttotal: 135ms\tremaining: 203ms\n",
      "6:\tlearn: 4403.7088199\ttotal: 158ms\tremaining: 180ms\n",
      "7:\tlearn: 4372.8768942\ttotal: 180ms\tremaining: 157ms\n",
      "8:\tlearn: 4342.3543846\ttotal: 201ms\tremaining: 134ms\n",
      "9:\tlearn: 4311.9637630\ttotal: 225ms\tremaining: 112ms\n",
      "10:\tlearn: 4282.0875233\ttotal: 248ms\tremaining: 90.2ms\n",
      "11:\tlearn: 4252.5846244\ttotal: 270ms\tremaining: 67.5ms\n",
      "12:\tlearn: 4223.9621900\ttotal: 294ms\tremaining: 45.2ms\n",
      "13:\tlearn: 4195.2865430\ttotal: 316ms\tremaining: 22.5ms\n",
      "14:\tlearn: 4167.0034264\ttotal: 338ms\tremaining: 0us\n",
      "0:\tlearn: 4590.2753862\ttotal: 24.8ms\tremaining: 347ms\n",
      "1:\tlearn: 4557.1181143\ttotal: 48ms\tremaining: 312ms\n",
      "2:\tlearn: 4524.4393089\ttotal: 70.7ms\tremaining: 283ms\n",
      "3:\tlearn: 4492.2863916\ttotal: 93.9ms\tremaining: 258ms\n",
      "4:\tlearn: 4460.8535162\ttotal: 117ms\tremaining: 234ms\n",
      "5:\tlearn: 4429.9127995\ttotal: 140ms\tremaining: 209ms\n",
      "6:\tlearn: 4398.8033931\ttotal: 162ms\tremaining: 186ms\n",
      "7:\tlearn: 4367.9253595\ttotal: 186ms\tremaining: 163ms\n",
      "8:\tlearn: 4337.5469124\ttotal: 208ms\tremaining: 138ms\n",
      "9:\tlearn: 4307.5522152\ttotal: 229ms\tremaining: 115ms\n",
      "10:\tlearn: 4277.7270089\ttotal: 251ms\tremaining: 91.3ms\n",
      "11:\tlearn: 4248.0177063\ttotal: 273ms\tremaining: 68.3ms\n",
      "12:\tlearn: 4218.6957461\ttotal: 297ms\tremaining: 45.7ms\n",
      "13:\tlearn: 4190.0571731\ttotal: 321ms\tremaining: 22.9ms\n",
      "14:\tlearn: 4161.7913130\ttotal: 343ms\tremaining: 0us\n",
      "0:\tlearn: 4586.0672089\ttotal: 23.2ms\tremaining: 325ms\n",
      "1:\tlearn: 4553.0076385\ttotal: 45.1ms\tremaining: 293ms\n",
      "2:\tlearn: 4520.3116065\ttotal: 67.3ms\tremaining: 269ms\n",
      "3:\tlearn: 4487.8495319\ttotal: 90.6ms\tremaining: 249ms\n",
      "4:\tlearn: 4456.2971818\ttotal: 113ms\tremaining: 226ms\n",
      "5:\tlearn: 4425.1608335\ttotal: 134ms\tremaining: 201ms\n",
      "6:\tlearn: 4394.1959286\ttotal: 155ms\tremaining: 177ms\n",
      "7:\tlearn: 4363.3545849\ttotal: 177ms\tremaining: 155ms\n",
      "8:\tlearn: 4333.1808949\ttotal: 199ms\tremaining: 132ms\n",
      "9:\tlearn: 4303.2142847\ttotal: 220ms\tremaining: 110ms\n",
      "10:\tlearn: 4273.6290698\ttotal: 243ms\tremaining: 88.2ms\n",
      "11:\tlearn: 4244.0873203\ttotal: 265ms\tremaining: 66.3ms\n",
      "12:\tlearn: 4215.3638648\ttotal: 287ms\tremaining: 44.1ms\n",
      "13:\tlearn: 4186.8064070\ttotal: 309ms\tremaining: 22.1ms\n",
      "14:\tlearn: 4158.7999529\ttotal: 331ms\tremaining: 0us\n",
      "0:\tlearn: 4459.5035002\ttotal: 25.1ms\tremaining: 351ms\n",
      "1:\tlearn: 4301.5087091\ttotal: 46.8ms\tremaining: 304ms\n",
      "2:\tlearn: 4154.7664979\ttotal: 69ms\tremaining: 276ms\n",
      "3:\tlearn: 4015.7551445\ttotal: 91.6ms\tremaining: 252ms\n",
      "4:\tlearn: 3890.4185504\ttotal: 113ms\tremaining: 227ms\n",
      "5:\tlearn: 3766.2557553\ttotal: 135ms\tremaining: 203ms\n",
      "6:\tlearn: 3650.4781796\ttotal: 158ms\tremaining: 180ms\n",
      "7:\tlearn: 3541.4116181\ttotal: 180ms\tremaining: 158ms\n",
      "8:\tlearn: 3438.0850989\ttotal: 202ms\tremaining: 135ms\n",
      "9:\tlearn: 3342.1293930\ttotal: 223ms\tremaining: 111ms\n",
      "10:\tlearn: 3250.6796378\ttotal: 243ms\tremaining: 88.5ms\n",
      "11:\tlearn: 3164.6291715\ttotal: 266ms\tremaining: 66.5ms\n",
      "12:\tlearn: 3083.5321851\ttotal: 288ms\tremaining: 44.3ms\n",
      "13:\tlearn: 3008.0477958\ttotal: 310ms\tremaining: 22.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:\tlearn: 2936.6781445\ttotal: 332ms\tremaining: 0us\n",
      "0:\tlearn: 4452.1083263\ttotal: 24.3ms\tremaining: 340ms\n",
      "1:\tlearn: 4294.9352356\ttotal: 47ms\tremaining: 306ms\n",
      "2:\tlearn: 4148.6808212\ttotal: 69ms\tremaining: 276ms\n",
      "3:\tlearn: 4009.0698782\ttotal: 90.4ms\tremaining: 249ms\n",
      "4:\tlearn: 3879.3191715\ttotal: 112ms\tremaining: 224ms\n",
      "5:\tlearn: 3759.5793378\ttotal: 133ms\tremaining: 200ms\n",
      "6:\tlearn: 3643.3645215\ttotal: 156ms\tremaining: 178ms\n",
      "7:\tlearn: 3532.9844009\ttotal: 178ms\tremaining: 156ms\n",
      "8:\tlearn: 3430.0610191\ttotal: 202ms\tremaining: 134ms\n",
      "9:\tlearn: 3332.5029579\ttotal: 223ms\tremaining: 112ms\n",
      "10:\tlearn: 3240.5895501\ttotal: 245ms\tremaining: 89ms\n",
      "11:\tlearn: 3155.4974475\ttotal: 267ms\tremaining: 66.7ms\n",
      "12:\tlearn: 3075.1709229\ttotal: 289ms\tremaining: 44.5ms\n",
      "13:\tlearn: 2999.2949444\ttotal: 312ms\tremaining: 22.3ms\n",
      "14:\tlearn: 2928.3963049\ttotal: 335ms\tremaining: 0us\n",
      "0:\tlearn: 4463.7379408\ttotal: 25.6ms\tremaining: 358ms\n",
      "1:\tlearn: 4304.3257162\ttotal: 48.2ms\tremaining: 313ms\n",
      "2:\tlearn: 4158.7783184\ttotal: 70.4ms\tremaining: 282ms\n",
      "3:\tlearn: 4019.8496770\ttotal: 92.6ms\tremaining: 255ms\n",
      "4:\tlearn: 3892.7561906\ttotal: 117ms\tremaining: 233ms\n",
      "5:\tlearn: 3770.2130846\ttotal: 139ms\tremaining: 209ms\n",
      "6:\tlearn: 3653.3516678\ttotal: 162ms\tremaining: 185ms\n",
      "7:\tlearn: 3541.4802663\ttotal: 185ms\tremaining: 162ms\n",
      "8:\tlearn: 3437.9763732\ttotal: 206ms\tremaining: 137ms\n",
      "9:\tlearn: 3339.8716223\ttotal: 227ms\tremaining: 114ms\n",
      "10:\tlearn: 3249.0491870\ttotal: 251ms\tremaining: 91.3ms\n",
      "11:\tlearn: 3162.9401802\ttotal: 273ms\tremaining: 68.4ms\n",
      "12:\tlearn: 3082.4003058\ttotal: 296ms\tremaining: 45.5ms\n",
      "13:\tlearn: 3006.2561847\ttotal: 319ms\tremaining: 22.8ms\n",
      "14:\tlearn: 2933.9600651\ttotal: 341ms\tremaining: 0us\n",
      "0:\tlearn: 4456.7194987\ttotal: 24.5ms\tremaining: 343ms\n",
      "1:\tlearn: 4299.7188150\ttotal: 47.9ms\tremaining: 311ms\n",
      "2:\tlearn: 4150.0182903\ttotal: 69.7ms\tremaining: 279ms\n",
      "3:\tlearn: 4011.0109365\ttotal: 91.9ms\tremaining: 253ms\n",
      "4:\tlearn: 3883.4783901\ttotal: 115ms\tremaining: 229ms\n",
      "5:\tlearn: 3760.7980595\ttotal: 136ms\tremaining: 204ms\n",
      "6:\tlearn: 3644.2465625\ttotal: 158ms\tremaining: 180ms\n",
      "7:\tlearn: 3535.0977014\ttotal: 179ms\tremaining: 157ms\n",
      "8:\tlearn: 3432.0432964\ttotal: 201ms\tremaining: 134ms\n",
      "9:\tlearn: 3335.2602075\ttotal: 224ms\tremaining: 112ms\n",
      "10:\tlearn: 3244.9135992\ttotal: 245ms\tremaining: 89.2ms\n",
      "11:\tlearn: 3160.1094536\ttotal: 268ms\tremaining: 67ms\n",
      "12:\tlearn: 3079.4632019\ttotal: 291ms\tremaining: 44.7ms\n",
      "13:\tlearn: 3002.5204812\ttotal: 314ms\tremaining: 22.4ms\n",
      "14:\tlearn: 2933.0579825\ttotal: 336ms\tremaining: 0us\n",
      "0:\tlearn: 4454.5786610\ttotal: 24.6ms\tremaining: 345ms\n",
      "1:\tlearn: 4300.3613487\ttotal: 47.7ms\tremaining: 310ms\n",
      "2:\tlearn: 4151.6931092\ttotal: 69.3ms\tremaining: 277ms\n",
      "3:\tlearn: 4012.4953641\ttotal: 91.2ms\tremaining: 251ms\n",
      "4:\tlearn: 3881.5304280\ttotal: 114ms\tremaining: 228ms\n",
      "5:\tlearn: 3759.3952993\ttotal: 136ms\tremaining: 205ms\n",
      "6:\tlearn: 3645.4668957\ttotal: 161ms\tremaining: 184ms\n",
      "7:\tlearn: 3535.9410464\ttotal: 183ms\tremaining: 160ms\n",
      "8:\tlearn: 3432.1930648\ttotal: 205ms\tremaining: 136ms\n",
      "9:\tlearn: 3336.8770746\ttotal: 227ms\tremaining: 113ms\n",
      "10:\tlearn: 3245.3345284\ttotal: 249ms\tremaining: 90.5ms\n",
      "11:\tlearn: 3160.0157616\ttotal: 271ms\tremaining: 67.7ms\n",
      "12:\tlearn: 3079.8600990\ttotal: 293ms\tremaining: 45.1ms\n",
      "13:\tlearn: 3005.8347263\ttotal: 315ms\tremaining: 22.5ms\n",
      "14:\tlearn: 2935.2292176\ttotal: 337ms\tremaining: 0us\n",
      "0:\tlearn: 4295.2808498\ttotal: 23.8ms\tremaining: 333ms\n",
      "1:\tlearn: 4000.3753108\ttotal: 46.4ms\tremaining: 301ms\n",
      "2:\tlearn: 3743.7437281\ttotal: 69.6ms\tremaining: 278ms\n",
      "3:\tlearn: 3514.2763504\ttotal: 91.3ms\tremaining: 251ms\n",
      "4:\tlearn: 3314.7419767\ttotal: 114ms\tremaining: 228ms\n",
      "5:\tlearn: 3132.8948966\ttotal: 135ms\tremaining: 202ms\n",
      "6:\tlearn: 2974.2943699\ttotal: 157ms\tremaining: 179ms\n",
      "7:\tlearn: 2838.2807033\ttotal: 178ms\tremaining: 155ms\n",
      "8:\tlearn: 2720.6531697\ttotal: 199ms\tremaining: 132ms\n",
      "9:\tlearn: 2614.4779545\ttotal: 220ms\tremaining: 110ms\n",
      "10:\tlearn: 2522.0384266\ttotal: 242ms\tremaining: 88.1ms\n",
      "11:\tlearn: 2441.3031924\ttotal: 265ms\tremaining: 66.1ms\n",
      "12:\tlearn: 2370.5584601\ttotal: 287ms\tremaining: 44.2ms\n",
      "13:\tlearn: 2309.3782089\ttotal: 311ms\tremaining: 22.2ms\n",
      "14:\tlearn: 2252.6925766\ttotal: 333ms\tremaining: 0us\n",
      "0:\tlearn: 4289.4056635\ttotal: 21.7ms\tremaining: 304ms\n",
      "1:\tlearn: 3996.0555054\ttotal: 43.1ms\tremaining: 280ms\n",
      "2:\tlearn: 3743.2928439\ttotal: 64.9ms\tremaining: 260ms\n",
      "3:\tlearn: 3514.5456124\ttotal: 87.2ms\tremaining: 240ms\n",
      "4:\tlearn: 3314.1931326\ttotal: 108ms\tremaining: 217ms\n",
      "5:\tlearn: 3136.9071549\ttotal: 130ms\tremaining: 195ms\n",
      "6:\tlearn: 2977.4319915\ttotal: 152ms\tremaining: 173ms\n",
      "7:\tlearn: 2840.4992104\ttotal: 173ms\tremaining: 151ms\n",
      "8:\tlearn: 2722.0834460\ttotal: 195ms\tremaining: 130ms\n",
      "9:\tlearn: 2618.5539567\ttotal: 216ms\tremaining: 108ms\n",
      "10:\tlearn: 2526.1667318\ttotal: 239ms\tremaining: 86.8ms\n",
      "11:\tlearn: 2447.3054481\ttotal: 261ms\tremaining: 65.2ms\n",
      "12:\tlearn: 2377.0398231\ttotal: 282ms\tremaining: 43.3ms\n",
      "13:\tlearn: 2314.4248211\ttotal: 303ms\tremaining: 21.7ms\n",
      "14:\tlearn: 2258.8614438\ttotal: 325ms\tremaining: 0us\n",
      "0:\tlearn: 4301.7000186\ttotal: 23ms\tremaining: 323ms\n",
      "1:\tlearn: 4003.9459544\ttotal: 45.8ms\tremaining: 298ms\n",
      "2:\tlearn: 3746.9348551\ttotal: 67.8ms\tremaining: 271ms\n",
      "3:\tlearn: 3518.0135261\ttotal: 90.4ms\tremaining: 249ms\n",
      "4:\tlearn: 3321.0209633\ttotal: 112ms\tremaining: 223ms\n",
      "5:\tlearn: 3144.4490049\ttotal: 133ms\tremaining: 200ms\n",
      "6:\tlearn: 2985.7250221\ttotal: 155ms\tremaining: 178ms\n",
      "7:\tlearn: 2847.4045715\ttotal: 178ms\tremaining: 156ms\n",
      "8:\tlearn: 2727.0579010\ttotal: 200ms\tremaining: 134ms\n",
      "9:\tlearn: 2623.6051225\ttotal: 222ms\tremaining: 111ms\n",
      "10:\tlearn: 2529.8825163\ttotal: 244ms\tremaining: 88.7ms\n",
      "11:\tlearn: 2448.6277814\ttotal: 265ms\tremaining: 66.3ms\n",
      "12:\tlearn: 2377.9143852\ttotal: 287ms\tremaining: 44.1ms\n",
      "13:\tlearn: 2316.8346125\ttotal: 308ms\tremaining: 22ms\n",
      "14:\tlearn: 2261.3233129\ttotal: 330ms\tremaining: 0us\n",
      "0:\tlearn: 4292.0406367\ttotal: 23.2ms\tremaining: 325ms\n",
      "1:\tlearn: 4000.1851944\ttotal: 45.3ms\tremaining: 295ms\n",
      "2:\tlearn: 3742.5319068\ttotal: 67.1ms\tremaining: 268ms\n",
      "3:\tlearn: 3517.8223174\ttotal: 88.9ms\tremaining: 245ms\n",
      "4:\tlearn: 3320.7270411\ttotal: 111ms\tremaining: 222ms\n",
      "5:\tlearn: 3141.5377855\ttotal: 133ms\tremaining: 199ms\n",
      "6:\tlearn: 2983.5992149\ttotal: 154ms\tremaining: 176ms\n",
      "7:\tlearn: 2847.4273575\ttotal: 176ms\tremaining: 154ms\n",
      "8:\tlearn: 2728.8159113\ttotal: 197ms\tremaining: 132ms\n",
      "9:\tlearn: 2622.1665876\ttotal: 219ms\tremaining: 110ms\n",
      "10:\tlearn: 2529.3328276\ttotal: 241ms\tremaining: 87.6ms\n",
      "11:\tlearn: 2451.1005132\ttotal: 263ms\tremaining: 65.8ms\n",
      "12:\tlearn: 2380.3669957\ttotal: 284ms\tremaining: 43.7ms\n",
      "13:\tlearn: 2319.4176850\ttotal: 306ms\tremaining: 21.8ms\n",
      "14:\tlearn: 2264.1983936\ttotal: 328ms\tremaining: 0us\n",
      "0:\tlearn: 4292.5624923\ttotal: 24.3ms\tremaining: 340ms\n",
      "1:\tlearn: 3996.3628260\ttotal: 46.5ms\tremaining: 303ms\n",
      "2:\tlearn: 3741.7320674\ttotal: 69.5ms\tremaining: 278ms\n",
      "3:\tlearn: 3516.2309056\ttotal: 91.9ms\tremaining: 253ms\n",
      "4:\tlearn: 3313.3942387\ttotal: 114ms\tremaining: 228ms\n",
      "5:\tlearn: 3140.0579757\ttotal: 136ms\tremaining: 204ms\n",
      "6:\tlearn: 2982.0365382\ttotal: 158ms\tremaining: 181ms\n",
      "7:\tlearn: 2847.6253791\ttotal: 180ms\tremaining: 158ms\n",
      "8:\tlearn: 2724.5086660\ttotal: 202ms\tremaining: 135ms\n",
      "9:\tlearn: 2619.7439758\ttotal: 223ms\tremaining: 111ms\n",
      "10:\tlearn: 2526.6528211\ttotal: 245ms\tremaining: 89.1ms\n",
      "11:\tlearn: 2450.7230028\ttotal: 267ms\tremaining: 66.6ms\n",
      "12:\tlearn: 2383.8570540\ttotal: 288ms\tremaining: 44.3ms\n",
      "13:\tlearn: 2325.1072448\ttotal: 311ms\tremaining: 22.2ms\n",
      "14:\tlearn: 2267.4267451\ttotal: 332ms\tremaining: 0us\n",
      "0:\tlearn: 4592.7268043\ttotal: 26.4ms\tremaining: 502ms\n",
      "1:\tlearn: 4560.1222029\ttotal: 48.4ms\tremaining: 436ms\n",
      "2:\tlearn: 4527.6844531\ttotal: 69.5ms\tremaining: 394ms\n",
      "3:\tlearn: 4495.0028795\ttotal: 90.9ms\tremaining: 364ms\n",
      "4:\tlearn: 4463.3935021\ttotal: 112ms\tremaining: 337ms\n",
      "5:\tlearn: 4432.1185036\ttotal: 134ms\tremaining: 313ms\n",
      "6:\tlearn: 4401.0439582\ttotal: 156ms\tremaining: 289ms\n",
      "7:\tlearn: 4369.6354934\ttotal: 176ms\tremaining: 265ms\n",
      "8:\tlearn: 4339.2256634\ttotal: 197ms\tremaining: 241ms\n",
      "9:\tlearn: 4309.1714313\ttotal: 219ms\tremaining: 219ms\n",
      "10:\tlearn: 4279.0712175\ttotal: 240ms\tremaining: 196ms\n",
      "11:\tlearn: 4250.0223553\ttotal: 261ms\tremaining: 174ms\n",
      "12:\tlearn: 4221.3827552\ttotal: 281ms\tremaining: 151ms\n",
      "13:\tlearn: 4193.3213753\ttotal: 302ms\tremaining: 130ms\n",
      "14:\tlearn: 4164.5408197\ttotal: 324ms\tremaining: 108ms\n",
      "15:\tlearn: 4136.1564838\ttotal: 346ms\tremaining: 86.6ms\n",
      "16:\tlearn: 4108.3279684\ttotal: 368ms\tremaining: 64.9ms\n",
      "17:\tlearn: 4080.5162260\ttotal: 389ms\tremaining: 43.2ms\n",
      "18:\tlearn: 4053.8228855\ttotal: 409ms\tremaining: 21.5ms\n",
      "19:\tlearn: 4027.3995184\ttotal: 431ms\tremaining: 0us\n",
      "0:\tlearn: 4584.1330709\ttotal: 23.4ms\tremaining: 444ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\tlearn: 4550.7276915\ttotal: 46.5ms\tremaining: 419ms\n",
      "2:\tlearn: 4518.4090743\ttotal: 69ms\tremaining: 391ms\n",
      "3:\tlearn: 4486.1209528\ttotal: 90.8ms\tremaining: 363ms\n",
      "4:\tlearn: 4454.0564579\ttotal: 112ms\tremaining: 337ms\n",
      "5:\tlearn: 4423.3003671\ttotal: 134ms\tremaining: 313ms\n",
      "6:\tlearn: 4392.1817988\ttotal: 156ms\tremaining: 290ms\n",
      "7:\tlearn: 4361.2074341\ttotal: 178ms\tremaining: 267ms\n",
      "8:\tlearn: 4331.3195529\ttotal: 199ms\tremaining: 243ms\n",
      "9:\tlearn: 4301.0756397\ttotal: 221ms\tremaining: 221ms\n",
      "10:\tlearn: 4271.2945846\ttotal: 243ms\tremaining: 199ms\n",
      "11:\tlearn: 4242.0711441\ttotal: 265ms\tremaining: 176ms\n",
      "12:\tlearn: 4213.4857295\ttotal: 287ms\tremaining: 154ms\n",
      "13:\tlearn: 4184.9061783\ttotal: 308ms\tremaining: 132ms\n",
      "14:\tlearn: 4156.7392322\ttotal: 329ms\tremaining: 110ms\n",
      "15:\tlearn: 4128.8591128\ttotal: 351ms\tremaining: 87.7ms\n",
      "16:\tlearn: 4101.5647434\ttotal: 372ms\tremaining: 65.7ms\n",
      "17:\tlearn: 4074.1432716\ttotal: 394ms\tremaining: 43.8ms\n",
      "18:\tlearn: 4047.0340051\ttotal: 415ms\tremaining: 21.9ms\n",
      "19:\tlearn: 4020.4465380\ttotal: 436ms\tremaining: 0us\n",
      "0:\tlearn: 4595.2490752\ttotal: 22.5ms\tremaining: 428ms\n",
      "1:\tlearn: 4562.0597321\ttotal: 46.7ms\tremaining: 421ms\n",
      "2:\tlearn: 4529.7789061\ttotal: 68.3ms\tremaining: 387ms\n",
      "3:\tlearn: 4497.3221750\ttotal: 90.6ms\tremaining: 362ms\n",
      "4:\tlearn: 4465.8022025\ttotal: 113ms\tremaining: 338ms\n",
      "5:\tlearn: 4434.8716159\ttotal: 135ms\tremaining: 315ms\n",
      "6:\tlearn: 4403.7088199\ttotal: 156ms\tremaining: 290ms\n",
      "7:\tlearn: 4372.8768942\ttotal: 179ms\tremaining: 269ms\n",
      "8:\tlearn: 4342.3543846\ttotal: 201ms\tremaining: 246ms\n",
      "9:\tlearn: 4311.9637630\ttotal: 224ms\tremaining: 224ms\n",
      "10:\tlearn: 4282.0875233\ttotal: 247ms\tremaining: 202ms\n",
      "11:\tlearn: 4252.5846244\ttotal: 269ms\tremaining: 179ms\n",
      "12:\tlearn: 4223.9621900\ttotal: 291ms\tremaining: 156ms\n",
      "13:\tlearn: 4195.2865430\ttotal: 313ms\tremaining: 134ms\n",
      "14:\tlearn: 4167.0034264\ttotal: 336ms\tremaining: 112ms\n",
      "15:\tlearn: 4139.1530911\ttotal: 358ms\tremaining: 89.5ms\n",
      "16:\tlearn: 4111.8214700\ttotal: 379ms\tremaining: 66.9ms\n",
      "17:\tlearn: 4084.9329409\ttotal: 402ms\tremaining: 44.7ms\n",
      "18:\tlearn: 4057.6263801\ttotal: 424ms\tremaining: 22.3ms\n",
      "19:\tlearn: 4030.8849574\ttotal: 446ms\tremaining: 0us\n",
      "0:\tlearn: 4590.2753862\ttotal: 25.8ms\tremaining: 490ms\n",
      "1:\tlearn: 4557.1181143\ttotal: 52.4ms\tremaining: 472ms\n",
      "2:\tlearn: 4524.4393089\ttotal: 77.5ms\tremaining: 439ms\n",
      "3:\tlearn: 4492.2863916\ttotal: 101ms\tremaining: 404ms\n",
      "4:\tlearn: 4460.8535162\ttotal: 124ms\tremaining: 371ms\n",
      "5:\tlearn: 4429.9127995\ttotal: 147ms\tremaining: 343ms\n",
      "6:\tlearn: 4398.8033931\ttotal: 169ms\tremaining: 314ms\n",
      "7:\tlearn: 4367.9253595\ttotal: 190ms\tremaining: 286ms\n",
      "8:\tlearn: 4337.5469124\ttotal: 212ms\tremaining: 259ms\n",
      "9:\tlearn: 4307.5522152\ttotal: 235ms\tremaining: 235ms\n",
      "10:\tlearn: 4277.7270089\ttotal: 257ms\tremaining: 210ms\n",
      "11:\tlearn: 4248.0177063\ttotal: 279ms\tremaining: 186ms\n",
      "12:\tlearn: 4218.6957461\ttotal: 299ms\tremaining: 161ms\n",
      "13:\tlearn: 4190.0571731\ttotal: 321ms\tremaining: 138ms\n",
      "14:\tlearn: 4161.7913130\ttotal: 344ms\tremaining: 115ms\n",
      "15:\tlearn: 4133.6819829\ttotal: 366ms\tremaining: 91.6ms\n",
      "16:\tlearn: 4106.0653831\ttotal: 389ms\tremaining: 68.7ms\n",
      "17:\tlearn: 4078.7957108\ttotal: 411ms\tremaining: 45.7ms\n",
      "18:\tlearn: 4051.4724182\ttotal: 434ms\tremaining: 22.8ms\n",
      "19:\tlearn: 4024.5777205\ttotal: 455ms\tremaining: 0us\n",
      "0:\tlearn: 4586.0672089\ttotal: 24.4ms\tremaining: 464ms\n",
      "1:\tlearn: 4553.0076385\ttotal: 47.5ms\tremaining: 428ms\n",
      "2:\tlearn: 4520.3116065\ttotal: 69.8ms\tremaining: 395ms\n",
      "3:\tlearn: 4487.8495319\ttotal: 91.3ms\tremaining: 365ms\n",
      "4:\tlearn: 4456.2971818\ttotal: 114ms\tremaining: 341ms\n",
      "5:\tlearn: 4425.1608335\ttotal: 139ms\tremaining: 325ms\n",
      "6:\tlearn: 4394.1959286\ttotal: 163ms\tremaining: 302ms\n",
      "7:\tlearn: 4363.3545849\ttotal: 185ms\tremaining: 277ms\n",
      "8:\tlearn: 4333.1808949\ttotal: 208ms\tremaining: 254ms\n",
      "9:\tlearn: 4303.2142847\ttotal: 230ms\tremaining: 230ms\n",
      "10:\tlearn: 4273.6290698\ttotal: 252ms\tremaining: 206ms\n",
      "11:\tlearn: 4244.0873203\ttotal: 274ms\tremaining: 183ms\n",
      "12:\tlearn: 4215.3638648\ttotal: 297ms\tremaining: 160ms\n",
      "13:\tlearn: 4186.8064070\ttotal: 318ms\tremaining: 136ms\n",
      "14:\tlearn: 4158.7999529\ttotal: 340ms\tremaining: 113ms\n",
      "15:\tlearn: 4130.6361076\ttotal: 361ms\tremaining: 90.3ms\n",
      "16:\tlearn: 4102.7230918\ttotal: 384ms\tremaining: 67.8ms\n",
      "17:\tlearn: 4075.2593867\ttotal: 406ms\tremaining: 45.2ms\n",
      "18:\tlearn: 4048.6940857\ttotal: 429ms\tremaining: 22.6ms\n",
      "19:\tlearn: 4021.9392940\ttotal: 453ms\tremaining: 0us\n",
      "0:\tlearn: 4459.5035002\ttotal: 23.6ms\tremaining: 449ms\n",
      "1:\tlearn: 4301.5087091\ttotal: 46.2ms\tremaining: 415ms\n",
      "2:\tlearn: 4154.7664979\ttotal: 68.3ms\tremaining: 387ms\n",
      "3:\tlearn: 4015.7551445\ttotal: 90.7ms\tremaining: 363ms\n",
      "4:\tlearn: 3890.4185504\ttotal: 112ms\tremaining: 336ms\n",
      "5:\tlearn: 3766.2557553\ttotal: 136ms\tremaining: 317ms\n",
      "6:\tlearn: 3650.4781796\ttotal: 158ms\tremaining: 294ms\n",
      "7:\tlearn: 3541.4116181\ttotal: 180ms\tremaining: 270ms\n",
      "8:\tlearn: 3438.0850989\ttotal: 201ms\tremaining: 245ms\n",
      "9:\tlearn: 3342.1293930\ttotal: 223ms\tremaining: 223ms\n",
      "10:\tlearn: 3250.6796378\ttotal: 245ms\tremaining: 200ms\n",
      "11:\tlearn: 3164.6291715\ttotal: 267ms\tremaining: 178ms\n",
      "12:\tlearn: 3083.5321851\ttotal: 288ms\tremaining: 155ms\n",
      "13:\tlearn: 3008.0477958\ttotal: 310ms\tremaining: 133ms\n",
      "14:\tlearn: 2936.6781445\ttotal: 333ms\tremaining: 111ms\n",
      "15:\tlearn: 2869.4174350\ttotal: 356ms\tremaining: 88.9ms\n",
      "16:\tlearn: 2809.0812804\ttotal: 377ms\tremaining: 66.6ms\n",
      "17:\tlearn: 2749.9109236\ttotal: 404ms\tremaining: 44.9ms\n",
      "18:\tlearn: 2695.5489340\ttotal: 427ms\tremaining: 22.5ms\n",
      "19:\tlearn: 2642.8334978\ttotal: 449ms\tremaining: 0us\n",
      "0:\tlearn: 4452.1083263\ttotal: 23.5ms\tremaining: 447ms\n",
      "1:\tlearn: 4294.9352356\ttotal: 46.6ms\tremaining: 420ms\n",
      "2:\tlearn: 4148.6808212\ttotal: 69.5ms\tremaining: 394ms\n",
      "3:\tlearn: 4009.0698782\ttotal: 92.1ms\tremaining: 368ms\n",
      "4:\tlearn: 3879.3191715\ttotal: 114ms\tremaining: 343ms\n",
      "5:\tlearn: 3759.5793378\ttotal: 136ms\tremaining: 318ms\n",
      "6:\tlearn: 3643.3645215\ttotal: 159ms\tremaining: 295ms\n",
      "7:\tlearn: 3532.9844009\ttotal: 180ms\tremaining: 270ms\n",
      "8:\tlearn: 3430.0610191\ttotal: 202ms\tremaining: 247ms\n",
      "9:\tlearn: 3332.5029579\ttotal: 223ms\tremaining: 223ms\n",
      "10:\tlearn: 3240.5895501\ttotal: 244ms\tremaining: 200ms\n",
      "11:\tlearn: 3155.4974475\ttotal: 266ms\tremaining: 177ms\n",
      "12:\tlearn: 3075.1709229\ttotal: 288ms\tremaining: 155ms\n",
      "13:\tlearn: 2999.2949444\ttotal: 310ms\tremaining: 133ms\n",
      "14:\tlearn: 2928.3963049\ttotal: 333ms\tremaining: 111ms\n",
      "15:\tlearn: 2861.0781017\ttotal: 354ms\tremaining: 88.6ms\n",
      "16:\tlearn: 2798.9896056\ttotal: 377ms\tremaining: 66.5ms\n",
      "17:\tlearn: 2739.8712652\ttotal: 398ms\tremaining: 44.2ms\n",
      "18:\tlearn: 2684.7169587\ttotal: 421ms\tremaining: 22.1ms\n",
      "19:\tlearn: 2635.0367893\ttotal: 443ms\tremaining: 0us\n",
      "0:\tlearn: 4463.7379408\ttotal: 24ms\tremaining: 455ms\n",
      "1:\tlearn: 4304.3257162\ttotal: 47ms\tremaining: 423ms\n",
      "2:\tlearn: 4158.7783184\ttotal: 71.7ms\tremaining: 406ms\n",
      "3:\tlearn: 4019.8496770\ttotal: 94.5ms\tremaining: 378ms\n",
      "4:\tlearn: 3892.7561906\ttotal: 118ms\tremaining: 355ms\n",
      "5:\tlearn: 3770.2130846\ttotal: 141ms\tremaining: 329ms\n",
      "6:\tlearn: 3653.3516678\ttotal: 163ms\tremaining: 302ms\n",
      "7:\tlearn: 3541.4802663\ttotal: 185ms\tremaining: 277ms\n",
      "8:\tlearn: 3437.9763732\ttotal: 206ms\tremaining: 252ms\n",
      "9:\tlearn: 3339.8716223\ttotal: 228ms\tremaining: 228ms\n",
      "10:\tlearn: 3249.0491870\ttotal: 250ms\tremaining: 205ms\n",
      "11:\tlearn: 3162.9401802\ttotal: 273ms\tremaining: 182ms\n",
      "12:\tlearn: 3082.4003058\ttotal: 295ms\tremaining: 159ms\n",
      "13:\tlearn: 3006.2561847\ttotal: 317ms\tremaining: 136ms\n",
      "14:\tlearn: 2933.9600651\ttotal: 339ms\tremaining: 113ms\n",
      "15:\tlearn: 2866.3886868\ttotal: 361ms\tremaining: 90.4ms\n",
      "16:\tlearn: 2804.9930964\ttotal: 384ms\tremaining: 67.8ms\n",
      "17:\tlearn: 2746.0876619\ttotal: 406ms\tremaining: 45.1ms\n",
      "18:\tlearn: 2692.3312280\ttotal: 430ms\tremaining: 22.6ms\n",
      "19:\tlearn: 2640.2806153\ttotal: 452ms\tremaining: 0us\n",
      "0:\tlearn: 4456.7194987\ttotal: 25.1ms\tremaining: 477ms\n",
      "1:\tlearn: 4299.7188150\ttotal: 47.5ms\tremaining: 427ms\n",
      "2:\tlearn: 4150.0182903\ttotal: 69.6ms\tremaining: 394ms\n",
      "3:\tlearn: 4011.0109365\ttotal: 90.8ms\tremaining: 363ms\n",
      "4:\tlearn: 3883.4783901\ttotal: 114ms\tremaining: 341ms\n",
      "5:\tlearn: 3760.7980595\ttotal: 135ms\tremaining: 315ms\n",
      "6:\tlearn: 3644.2465625\ttotal: 157ms\tremaining: 291ms\n",
      "7:\tlearn: 3535.0977014\ttotal: 179ms\tremaining: 269ms\n",
      "8:\tlearn: 3432.0432964\ttotal: 201ms\tremaining: 246ms\n",
      "9:\tlearn: 3335.2602075\ttotal: 223ms\tremaining: 223ms\n",
      "10:\tlearn: 3244.9135992\ttotal: 244ms\tremaining: 200ms\n",
      "11:\tlearn: 3160.1094536\ttotal: 267ms\tremaining: 178ms\n",
      "12:\tlearn: 3079.4632019\ttotal: 289ms\tremaining: 155ms\n",
      "13:\tlearn: 3002.5204812\ttotal: 312ms\tremaining: 134ms\n",
      "14:\tlearn: 2933.0579825\ttotal: 334ms\tremaining: 111ms\n",
      "15:\tlearn: 2865.6867555\ttotal: 355ms\tremaining: 88.7ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:\tlearn: 2804.4154913\ttotal: 377ms\tremaining: 66.4ms\n",
      "17:\tlearn: 2746.3308931\ttotal: 401ms\tremaining: 44.6ms\n",
      "18:\tlearn: 2691.2755166\ttotal: 423ms\tremaining: 22.3ms\n",
      "19:\tlearn: 2640.1363039\ttotal: 445ms\tremaining: 0us\n",
      "0:\tlearn: 4454.5786610\ttotal: 24.8ms\tremaining: 472ms\n",
      "1:\tlearn: 4300.3613487\ttotal: 50.2ms\tremaining: 452ms\n",
      "2:\tlearn: 4151.6931092\ttotal: 74ms\tremaining: 419ms\n",
      "3:\tlearn: 4012.4953641\ttotal: 98.7ms\tremaining: 395ms\n",
      "4:\tlearn: 3881.5304280\ttotal: 123ms\tremaining: 368ms\n",
      "5:\tlearn: 3759.3952993\ttotal: 146ms\tremaining: 342ms\n",
      "6:\tlearn: 3645.4668957\ttotal: 169ms\tremaining: 314ms\n",
      "7:\tlearn: 3535.9410464\ttotal: 191ms\tremaining: 287ms\n",
      "8:\tlearn: 3432.1930648\ttotal: 213ms\tremaining: 260ms\n",
      "9:\tlearn: 3336.8770746\ttotal: 233ms\tremaining: 233ms\n",
      "10:\tlearn: 3245.3345284\ttotal: 255ms\tremaining: 209ms\n",
      "11:\tlearn: 3160.0157616\ttotal: 278ms\tremaining: 185ms\n",
      "12:\tlearn: 3079.8600990\ttotal: 299ms\tremaining: 161ms\n",
      "13:\tlearn: 3005.8347263\ttotal: 322ms\tremaining: 138ms\n",
      "14:\tlearn: 2935.2292176\ttotal: 344ms\tremaining: 115ms\n",
      "15:\tlearn: 2868.2032357\ttotal: 365ms\tremaining: 91.3ms\n",
      "16:\tlearn: 2806.4019335\ttotal: 387ms\tremaining: 68.3ms\n",
      "17:\tlearn: 2749.2712701\ttotal: 408ms\tremaining: 45.4ms\n",
      "18:\tlearn: 2694.0340604\ttotal: 430ms\tremaining: 22.6ms\n",
      "19:\tlearn: 2643.6888133\ttotal: 452ms\tremaining: 0us\n",
      "0:\tlearn: 4295.2808498\ttotal: 23.8ms\tremaining: 452ms\n",
      "1:\tlearn: 4000.3753108\ttotal: 47.9ms\tremaining: 431ms\n",
      "2:\tlearn: 3743.7437281\ttotal: 69.1ms\tremaining: 392ms\n",
      "3:\tlearn: 3514.2763504\ttotal: 90.2ms\tremaining: 361ms\n",
      "4:\tlearn: 3314.7419767\ttotal: 112ms\tremaining: 335ms\n",
      "5:\tlearn: 3132.8948966\ttotal: 133ms\tremaining: 311ms\n",
      "6:\tlearn: 2974.2943699\ttotal: 155ms\tremaining: 289ms\n",
      "7:\tlearn: 2838.2807033\ttotal: 176ms\tremaining: 264ms\n",
      "8:\tlearn: 2720.6531697\ttotal: 198ms\tremaining: 242ms\n",
      "9:\tlearn: 2614.4779545\ttotal: 220ms\tremaining: 220ms\n",
      "10:\tlearn: 2522.0384266\ttotal: 242ms\tremaining: 198ms\n",
      "11:\tlearn: 2441.3031924\ttotal: 264ms\tremaining: 176ms\n",
      "12:\tlearn: 2370.5584601\ttotal: 286ms\tremaining: 154ms\n",
      "13:\tlearn: 2309.3782089\ttotal: 309ms\tremaining: 132ms\n",
      "14:\tlearn: 2252.6925766\ttotal: 331ms\tremaining: 110ms\n",
      "15:\tlearn: 2205.9803251\ttotal: 353ms\tremaining: 88.2ms\n",
      "16:\tlearn: 2162.3766369\ttotal: 374ms\tremaining: 66ms\n",
      "17:\tlearn: 2125.2343953\ttotal: 396ms\tremaining: 44.1ms\n",
      "18:\tlearn: 2092.4768670\ttotal: 418ms\tremaining: 22ms\n",
      "19:\tlearn: 2064.0321486\ttotal: 439ms\tremaining: 0us\n",
      "0:\tlearn: 4289.4056635\ttotal: 24.9ms\tremaining: 473ms\n",
      "1:\tlearn: 3996.0555054\ttotal: 46.6ms\tremaining: 420ms\n",
      "2:\tlearn: 3743.2928439\ttotal: 68.3ms\tremaining: 387ms\n",
      "3:\tlearn: 3514.5456124\ttotal: 90.9ms\tremaining: 364ms\n",
      "4:\tlearn: 3314.1931326\ttotal: 113ms\tremaining: 339ms\n",
      "5:\tlearn: 3136.9071549\ttotal: 135ms\tremaining: 315ms\n",
      "6:\tlearn: 2977.4319915\ttotal: 159ms\tremaining: 295ms\n",
      "7:\tlearn: 2840.4992104\ttotal: 180ms\tremaining: 271ms\n",
      "8:\tlearn: 2722.0834460\ttotal: 202ms\tremaining: 247ms\n",
      "9:\tlearn: 2618.5539567\ttotal: 223ms\tremaining: 223ms\n",
      "10:\tlearn: 2526.1667318\ttotal: 246ms\tremaining: 201ms\n",
      "11:\tlearn: 2447.3054481\ttotal: 268ms\tremaining: 179ms\n",
      "12:\tlearn: 2377.0398231\ttotal: 290ms\tremaining: 156ms\n",
      "13:\tlearn: 2314.4248211\ttotal: 311ms\tremaining: 133ms\n",
      "14:\tlearn: 2258.8614438\ttotal: 334ms\tremaining: 111ms\n",
      "15:\tlearn: 2211.8187615\ttotal: 354ms\tremaining: 88.6ms\n",
      "16:\tlearn: 2172.8266027\ttotal: 376ms\tremaining: 66.3ms\n",
      "17:\tlearn: 2130.8303857\ttotal: 396ms\tremaining: 44.1ms\n",
      "18:\tlearn: 2099.5029693\ttotal: 418ms\tremaining: 22ms\n",
      "19:\tlearn: 2065.8002651\ttotal: 440ms\tremaining: 0us\n",
      "0:\tlearn: 4301.7000186\ttotal: 23.6ms\tremaining: 448ms\n",
      "1:\tlearn: 4003.9459544\ttotal: 47.1ms\tremaining: 424ms\n",
      "2:\tlearn: 3746.9348551\ttotal: 68.4ms\tremaining: 388ms\n",
      "3:\tlearn: 3518.0135261\ttotal: 91.6ms\tremaining: 366ms\n",
      "4:\tlearn: 3321.0209633\ttotal: 114ms\tremaining: 342ms\n",
      "5:\tlearn: 3144.4490049\ttotal: 137ms\tremaining: 319ms\n",
      "6:\tlearn: 2985.7250221\ttotal: 160ms\tremaining: 297ms\n",
      "7:\tlearn: 2847.4045715\ttotal: 181ms\tremaining: 272ms\n",
      "8:\tlearn: 2727.0579010\ttotal: 204ms\tremaining: 249ms\n",
      "9:\tlearn: 2623.6051225\ttotal: 226ms\tremaining: 226ms\n",
      "10:\tlearn: 2529.8825163\ttotal: 250ms\tremaining: 204ms\n",
      "11:\tlearn: 2448.6277814\ttotal: 273ms\tremaining: 182ms\n",
      "12:\tlearn: 2377.9143852\ttotal: 296ms\tremaining: 159ms\n",
      "13:\tlearn: 2316.8346125\ttotal: 318ms\tremaining: 136ms\n",
      "14:\tlearn: 2261.3233129\ttotal: 342ms\tremaining: 114ms\n",
      "15:\tlearn: 2211.3786103\ttotal: 365ms\tremaining: 91.2ms\n",
      "16:\tlearn: 2171.0490266\ttotal: 389ms\tremaining: 68.6ms\n",
      "17:\tlearn: 2130.0204533\ttotal: 410ms\tremaining: 45.5ms\n",
      "18:\tlearn: 2093.2583060\ttotal: 430ms\tremaining: 22.7ms\n",
      "19:\tlearn: 2062.9231509\ttotal: 452ms\tremaining: 0us\n",
      "0:\tlearn: 4292.0406367\ttotal: 24.7ms\tremaining: 468ms\n",
      "1:\tlearn: 4000.1851944\ttotal: 48.4ms\tremaining: 435ms\n",
      "2:\tlearn: 3742.5319068\ttotal: 70.8ms\tremaining: 401ms\n",
      "3:\tlearn: 3517.8223174\ttotal: 93.9ms\tremaining: 376ms\n",
      "4:\tlearn: 3320.7270411\ttotal: 115ms\tremaining: 346ms\n",
      "5:\tlearn: 3141.5377855\ttotal: 138ms\tremaining: 322ms\n",
      "6:\tlearn: 2983.5992149\ttotal: 161ms\tremaining: 300ms\n",
      "7:\tlearn: 2847.4273575\ttotal: 183ms\tremaining: 275ms\n",
      "8:\tlearn: 2728.8159113\ttotal: 205ms\tremaining: 251ms\n",
      "9:\tlearn: 2622.1665876\ttotal: 228ms\tremaining: 228ms\n",
      "10:\tlearn: 2529.3328276\ttotal: 250ms\tremaining: 205ms\n",
      "11:\tlearn: 2451.1005132\ttotal: 273ms\tremaining: 182ms\n",
      "12:\tlearn: 2380.3669957\ttotal: 295ms\tremaining: 159ms\n",
      "13:\tlearn: 2319.4176850\ttotal: 317ms\tremaining: 136ms\n",
      "14:\tlearn: 2264.1983936\ttotal: 339ms\tremaining: 113ms\n",
      "15:\tlearn: 2216.0384982\ttotal: 362ms\tremaining: 90.6ms\n",
      "16:\tlearn: 2176.3387445\ttotal: 385ms\tremaining: 67.9ms\n",
      "17:\tlearn: 2141.0646083\ttotal: 406ms\tremaining: 45.1ms\n",
      "18:\tlearn: 2106.9820883\ttotal: 427ms\tremaining: 22.5ms\n",
      "19:\tlearn: 2072.5157594\ttotal: 449ms\tremaining: 0us\n",
      "0:\tlearn: 4292.5624923\ttotal: 24.1ms\tremaining: 458ms\n",
      "1:\tlearn: 3996.3628260\ttotal: 46.7ms\tremaining: 420ms\n",
      "2:\tlearn: 3741.7320674\ttotal: 70ms\tremaining: 397ms\n",
      "3:\tlearn: 3516.2309056\ttotal: 93.1ms\tremaining: 372ms\n",
      "4:\tlearn: 3313.3942387\ttotal: 115ms\tremaining: 344ms\n",
      "5:\tlearn: 3140.0579757\ttotal: 137ms\tremaining: 320ms\n",
      "6:\tlearn: 2982.0365382\ttotal: 159ms\tremaining: 295ms\n",
      "7:\tlearn: 2847.6253791\ttotal: 181ms\tremaining: 271ms\n",
      "8:\tlearn: 2724.5086660\ttotal: 203ms\tremaining: 248ms\n",
      "9:\tlearn: 2619.7439758\ttotal: 226ms\tremaining: 226ms\n",
      "10:\tlearn: 2526.6528211\ttotal: 248ms\tremaining: 203ms\n",
      "11:\tlearn: 2450.7230028\ttotal: 272ms\tremaining: 181ms\n",
      "12:\tlearn: 2383.8570540\ttotal: 295ms\tremaining: 159ms\n",
      "13:\tlearn: 2325.1072448\ttotal: 320ms\tremaining: 137ms\n",
      "14:\tlearn: 2267.4267451\ttotal: 342ms\tremaining: 114ms\n",
      "15:\tlearn: 2217.4992671\ttotal: 366ms\tremaining: 91.4ms\n",
      "16:\tlearn: 2177.9208537\ttotal: 390ms\tremaining: 68.8ms\n",
      "17:\tlearn: 2136.7708756\ttotal: 413ms\tremaining: 45.9ms\n",
      "18:\tlearn: 2104.6838578\ttotal: 439ms\tremaining: 23.1ms\n",
      "19:\tlearn: 2074.7043792\ttotal: 463ms\tremaining: 0us\n",
      "0:\tlearn: 4292.6884486\ttotal: 28ms\tremaining: 531ms\n",
      "1:\tlearn: 3998.4492194\ttotal: 53.3ms\tremaining: 480ms\n",
      "2:\tlearn: 3743.1994915\ttotal: 78.3ms\tremaining: 444ms\n",
      "3:\tlearn: 3514.3690218\ttotal: 103ms\tremaining: 411ms\n",
      "4:\tlearn: 3310.7681710\ttotal: 128ms\tremaining: 384ms\n",
      "5:\tlearn: 3134.7327419\ttotal: 152ms\tremaining: 356ms\n",
      "6:\tlearn: 2976.6019672\ttotal: 177ms\tremaining: 329ms\n",
      "7:\tlearn: 2841.7769690\ttotal: 202ms\tremaining: 302ms\n",
      "8:\tlearn: 2723.1084031\ttotal: 226ms\tremaining: 277ms\n",
      "9:\tlearn: 2621.5374083\ttotal: 251ms\tremaining: 251ms\n",
      "10:\tlearn: 2527.2522847\ttotal: 276ms\tremaining: 226ms\n",
      "11:\tlearn: 2446.0472900\ttotal: 301ms\tremaining: 201ms\n",
      "12:\tlearn: 2379.0186817\ttotal: 326ms\tremaining: 175ms\n",
      "13:\tlearn: 2314.4885843\ttotal: 351ms\tremaining: 150ms\n",
      "14:\tlearn: 2259.8224623\ttotal: 376ms\tremaining: 125ms\n",
      "15:\tlearn: 2214.3353087\ttotal: 402ms\tremaining: 101ms\n",
      "16:\tlearn: 2171.7500251\ttotal: 428ms\tremaining: 75.5ms\n",
      "17:\tlearn: 2135.1566625\ttotal: 454ms\tremaining: 50.4ms\n",
      "18:\tlearn: 2100.0875746\ttotal: 479ms\tremaining: 25.2ms\n",
      "19:\tlearn: 2068.2668204\ttotal: 504ms\tremaining: 0us\n",
      "RMSE TRAIN: 2080.35864896805\n",
      "TIME TRAIN [s]: 0.57\n",
      "CPU times: total: 23.7 s\n",
      "Wall time: 38.8 s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"fba89291-5766-48a8-861a-3112387b806c\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"fba89291-5766-48a8-861a-3112387b806c\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"CatBoostRegressor OE\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"CatBoostRegressor OE\"\n",
    "%%time\n",
    "\n",
    "# Обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "time = model.refit_time_\n",
    "params = model.best_params_\n",
    "\n",
    "# Узнаем RMSE обучающей выборки\n",
    "result_RMSE_t = -model.best_score_\n",
    "print('RMSE TRAIN:', result_RMSE_t)\n",
    "print('TIME TRAIN [s]:', round(time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка на тестовой выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4292.6884486\ttotal: 28.6ms\tremaining: 544ms\n",
      "1:\tlearn: 3998.4492194\ttotal: 55.3ms\tremaining: 498ms\n",
      "2:\tlearn: 3743.1994915\ttotal: 82.7ms\tremaining: 469ms\n",
      "3:\tlearn: 3514.3690218\ttotal: 110ms\tremaining: 439ms\n",
      "4:\tlearn: 3310.7681710\ttotal: 140ms\tremaining: 420ms\n",
      "5:\tlearn: 3134.7327419\ttotal: 170ms\tremaining: 397ms\n",
      "6:\tlearn: 2976.6019672\ttotal: 200ms\tremaining: 371ms\n",
      "7:\tlearn: 2841.7769690\ttotal: 229ms\tremaining: 344ms\n",
      "8:\tlearn: 2723.1084031\ttotal: 258ms\tremaining: 315ms\n",
      "9:\tlearn: 2621.5374083\ttotal: 284ms\tremaining: 284ms\n",
      "10:\tlearn: 2527.2522847\ttotal: 313ms\tremaining: 256ms\n",
      "11:\tlearn: 2446.0472900\ttotal: 339ms\tremaining: 226ms\n",
      "12:\tlearn: 2379.0186817\ttotal: 365ms\tremaining: 197ms\n",
      "13:\tlearn: 2314.4885843\ttotal: 391ms\tremaining: 168ms\n",
      "14:\tlearn: 2259.8224623\ttotal: 417ms\tremaining: 139ms\n",
      "15:\tlearn: 2214.3353087\ttotal: 442ms\tremaining: 110ms\n",
      "16:\tlearn: 2171.7500251\ttotal: 468ms\tremaining: 82.5ms\n",
      "17:\tlearn: 2135.1566625\ttotal: 495ms\tremaining: 55ms\n",
      "18:\tlearn: 2100.0875746\ttotal: 520ms\tremaining: 27.4ms\n",
      "19:\tlearn: 2068.2668204\ttotal: 546ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1ec981f1c70>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализируем модель c лучшими гиперпараметрами\n",
    "model = CatBoostRegressor().set_params(\n",
    "    depth = params['depth'], \n",
    "    learning_rate = params['learning_rate'], \n",
    "    iterations = params['iterations']\n",
    ")\n",
    "\n",
    "# Обучим модель на тренировочной выборке\n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE VALID: 2058.2621331876317\n",
      "Предсказание: 4856.60198898797\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = timeit.default_timer()\n",
    "# Получим предсказания на тестовой выборки\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "elapsed = round(timeit.default_timer() - start_time, 3)\n",
    "\n",
    "result_RMSE_v = mean_squared_error(target_valid, predictions, squared=False)\n",
    "print('RMSE VALID:', result_RMSE_v)\n",
    "print('Предсказание:', predictions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зафиксируем результаты\n",
    "results[count_model] = pd.Series({\n",
    "    'NAME': 'CatBoostRegressor_OE', \n",
    "    'RMSE TRAIN': result_RMSE_t, \n",
    "    'RMSE VALID': result_RMSE_v, \n",
    "    'PREDICTIONS': predictions.mean(), \n",
    "    'TIME TRAINING [s]': time, \n",
    "    'TIME PREDICTION [s]': elapsed, \n",
    "    'PARAMETRS': params\n",
    "})\n",
    "\n",
    "results[count_model]\n",
    "count_model+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Масштабирование признаков - StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Масштабируем One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Деление на обучающей и валидационной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_ohe.drop(['Price'], axis=1)\n",
    "target = df_ohe['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим обучающую и валидационную выборку\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=(1 - 0.6), random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодируем\n",
    "encoder_ohe = OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'><b>Комментарий студента</b> Подправил </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучаем энкодер на заданных категориальных признаках тренировочной выборки\n",
    "encoder_ohe.fit(features_train[col_type_obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2474216900.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])\n"
     ]
    }
   ],
   "source": [
    "# Добавляем закодированные признаки в X_train_ohe\n",
    "# Encoder_ohe.get_feature_names_out() позволяет получить названия колонок\n",
    "features_train[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_train[col_type_obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:202: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n",
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\2424170447.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])\n"
     ]
    }
   ],
   "source": [
    "# Энкодером, который обучен на ТРЕНИРОВОЧНОЙ ВЫБОРКЕ, кодируем тестовую\n",
    "features_valid[encoder_ohe.get_feature_names_out()] = encoder_ohe.transform(features_valid[col_type_obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем незакодированные категориальные признаки (изначальные колонки)\n",
    "features_train = features_train.drop(col_type_obj, axis=1)\n",
    "\n",
    "features_valid = features_valid.drop(col_type_obj, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Power</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>VehicleType_convertible</th>\n",
       "      <th>VehicleType_coupe</th>\n",
       "      <th>VehicleType_other</th>\n",
       "      <th>VehicleType_sedan</th>\n",
       "      <th>VehicleType_small</th>\n",
       "      <th>VehicleType_suv</th>\n",
       "      <th>...</th>\n",
       "      <th>Brand_smart</th>\n",
       "      <th>Brand_sonstige_autos</th>\n",
       "      <th>Brand_subaru</th>\n",
       "      <th>Brand_suzuki</th>\n",
       "      <th>Brand_toyota</th>\n",
       "      <th>Brand_trabant</th>\n",
       "      <th>Brand_volkswagen</th>\n",
       "      <th>Brand_volvo</th>\n",
       "      <th>Repaired_unknown</th>\n",
       "      <th>Repaired_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184019</th>\n",
       "      <td>2007</td>\n",
       "      <td>131</td>\n",
       "      <td>125000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224508</th>\n",
       "      <td>1997</td>\n",
       "      <td>75</td>\n",
       "      <td>100000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328264</th>\n",
       "      <td>1997</td>\n",
       "      <td>130</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136227</th>\n",
       "      <td>2009</td>\n",
       "      <td>143</td>\n",
       "      <td>60000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309930</th>\n",
       "      <td>2006</td>\n",
       "      <td>170</td>\n",
       "      <td>150000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RegistrationYear  Power  Kilometer  RegistrationMonth  \\\n",
       "184019              2007    131     125000                  6   \n",
       "224508              1997     75     100000                  9   \n",
       "328264              1997    130     150000                  3   \n",
       "136227              2009    143      60000                  3   \n",
       "309930              2006    170     150000                 12   \n",
       "\n",
       "        VehicleType_convertible  VehicleType_coupe  VehicleType_other  \\\n",
       "184019                      0.0                0.0                0.0   \n",
       "224508                      0.0                0.0                0.0   \n",
       "328264                      0.0                0.0                0.0   \n",
       "136227                      1.0                0.0                0.0   \n",
       "309930                      0.0                0.0                0.0   \n",
       "\n",
       "        VehicleType_sedan  VehicleType_small  VehicleType_suv  ...  \\\n",
       "184019                0.0                0.0              0.0  ...   \n",
       "224508                1.0                0.0              0.0  ...   \n",
       "328264                1.0                0.0              0.0  ...   \n",
       "136227                0.0                0.0              0.0  ...   \n",
       "309930                0.0                0.0              0.0  ...   \n",
       "\n",
       "        Brand_smart  Brand_sonstige_autos  Brand_subaru  Brand_suzuki  \\\n",
       "184019          0.0                   0.0           0.0           0.0   \n",
       "224508          0.0                   0.0           0.0           0.0   \n",
       "328264          0.0                   0.0           0.0           0.0   \n",
       "136227          0.0                   0.0           0.0           0.0   \n",
       "309930          0.0                   0.0           0.0           0.0   \n",
       "\n",
       "        Brand_toyota  Brand_trabant  Brand_volkswagen  Brand_volvo  \\\n",
       "184019           0.0            0.0               1.0          0.0   \n",
       "224508           0.0            0.0               0.0          0.0   \n",
       "328264           0.0            0.0               0.0          0.0   \n",
       "136227           0.0            0.0               0.0          0.0   \n",
       "309930           0.0            0.0               1.0          0.0   \n",
       "\n",
       "        Repaired_unknown  Repaired_yes  \n",
       "184019               0.0           0.0  \n",
       "224508               0.0           0.0  \n",
       "328264               0.0           0.0  \n",
       "136227               0.0           0.0  \n",
       "309930               0.0           0.0  \n",
       "\n",
       "[5 rows x 310 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Power</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>VehicleType_convertible</th>\n",
       "      <th>VehicleType_coupe</th>\n",
       "      <th>VehicleType_other</th>\n",
       "      <th>VehicleType_sedan</th>\n",
       "      <th>VehicleType_small</th>\n",
       "      <th>VehicleType_suv</th>\n",
       "      <th>...</th>\n",
       "      <th>Brand_smart</th>\n",
       "      <th>Brand_sonstige_autos</th>\n",
       "      <th>Brand_subaru</th>\n",
       "      <th>Brand_suzuki</th>\n",
       "      <th>Brand_toyota</th>\n",
       "      <th>Brand_trabant</th>\n",
       "      <th>Brand_volkswagen</th>\n",
       "      <th>Brand_volvo</th>\n",
       "      <th>Repaired_unknown</th>\n",
       "      <th>Repaired_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110198</th>\n",
       "      <td>2001</td>\n",
       "      <td>44</td>\n",
       "      <td>150000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96619</th>\n",
       "      <td>2007</td>\n",
       "      <td>105</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345457</th>\n",
       "      <td>2000</td>\n",
       "      <td>179</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142762</th>\n",
       "      <td>1997</td>\n",
       "      <td>231</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221541</th>\n",
       "      <td>2008</td>\n",
       "      <td>71</td>\n",
       "      <td>50000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RegistrationYear  Power  Kilometer  RegistrationMonth  \\\n",
       "110198              2001     44     150000                  5   \n",
       "96619               2007    105     150000                  3   \n",
       "345457              2000    179     150000                  0   \n",
       "142762              1997    231     150000                  3   \n",
       "221541              2008     71      50000                  9   \n",
       "\n",
       "        VehicleType_convertible  VehicleType_coupe  VehicleType_other  \\\n",
       "110198                      1.0                0.0                0.0   \n",
       "96619                       0.0                0.0                0.0   \n",
       "345457                      0.0                0.0                0.0   \n",
       "142762                      1.0                0.0                0.0   \n",
       "221541                      0.0                0.0                0.0   \n",
       "\n",
       "        VehicleType_sedan  VehicleType_small  VehicleType_suv  ...  \\\n",
       "110198                0.0                0.0              0.0  ...   \n",
       "96619                 0.0                0.0              0.0  ...   \n",
       "345457                1.0                0.0              0.0  ...   \n",
       "142762                0.0                0.0              0.0  ...   \n",
       "221541                0.0                1.0              0.0  ...   \n",
       "\n",
       "        Brand_smart  Brand_sonstige_autos  Brand_subaru  Brand_suzuki  \\\n",
       "110198          1.0                   0.0           0.0           0.0   \n",
       "96619           0.0                   0.0           0.0           0.0   \n",
       "345457          0.0                   0.0           0.0           0.0   \n",
       "142762          0.0                   0.0           0.0           0.0   \n",
       "221541          1.0                   0.0           0.0           0.0   \n",
       "\n",
       "        Brand_toyota  Brand_trabant  Brand_volkswagen  Brand_volvo  \\\n",
       "110198           0.0            0.0               0.0          0.0   \n",
       "96619            0.0            0.0               1.0          0.0   \n",
       "345457           0.0            0.0               0.0          0.0   \n",
       "142762           0.0            0.0               0.0          0.0   \n",
       "221541           0.0            0.0               0.0          0.0   \n",
       "\n",
       "        Repaired_unknown  Repaired_yes  \n",
       "110198               0.0           0.0  \n",
       "96619                0.0           0.0  \n",
       "345457               0.0           0.0  \n",
       "142762               0.0           0.0  \n",
       "221541               0.0           0.0  \n",
       "\n",
       "[5 rows x 310 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(features_train.head())\n",
    "display(features_valid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабируем признаки: обучающую и валидационную выборку\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем обучающую, валидационную и тестовую выборки функцией transform(), т.е.\n",
    "# обучаем его на численных признаках тренировочной выборки, трансформируем её же\n",
    "features_train[col_type_num] = scaler.fit_transform(features_train[col_type_num])\n",
    "features_valid[col_type_num] = scaler.fit_transform(features_valid[col_type_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'>Отлично, что scaler был обучен только на тренировочной части данных!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163698, 310)\n",
      "(109133, 310)\n"
     ]
    }
   ],
   "source": [
    "# Проверим\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: 0.6 %\n",
      "Размер валидационной выборки: 0.4 %\n"
     ]
    }
   ],
   "source": [
    "print('Размер обучающей выборки:', round(features_train.shape[0] / features.shape[0], 2), '%')\n",
    "print('Размер валидационной выборки:', round(features_valid.shape[0] / target.shape[0], 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Power</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>VehicleType_convertible</th>\n",
       "      <th>VehicleType_coupe</th>\n",
       "      <th>VehicleType_other</th>\n",
       "      <th>VehicleType_sedan</th>\n",
       "      <th>VehicleType_small</th>\n",
       "      <th>VehicleType_suv</th>\n",
       "      <th>...</th>\n",
       "      <th>Brand_smart</th>\n",
       "      <th>Brand_sonstige_autos</th>\n",
       "      <th>Brand_subaru</th>\n",
       "      <th>Brand_suzuki</th>\n",
       "      <th>Brand_toyota</th>\n",
       "      <th>Brand_trabant</th>\n",
       "      <th>Brand_volkswagen</th>\n",
       "      <th>Brand_volvo</th>\n",
       "      <th>Repaired_unknown</th>\n",
       "      <th>Repaired_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184019</th>\n",
       "      <td>0.639959</td>\n",
       "      <td>0.160845</td>\n",
       "      <td>-0.090133</td>\n",
       "      <td>0.005881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224508</th>\n",
       "      <td>-0.882114</td>\n",
       "      <td>-0.762130</td>\n",
       "      <td>-0.770483</td>\n",
       "      <td>0.840874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328264</th>\n",
       "      <td>-0.882114</td>\n",
       "      <td>0.144363</td>\n",
       "      <td>0.590217</td>\n",
       "      <td>-0.829112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136227</th>\n",
       "      <td>0.944374</td>\n",
       "      <td>0.358625</td>\n",
       "      <td>-1.859043</td>\n",
       "      <td>-0.829112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309930</th>\n",
       "      <td>0.487752</td>\n",
       "      <td>0.803631</td>\n",
       "      <td>0.590217</td>\n",
       "      <td>1.675868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RegistrationYear     Power  Kilometer  RegistrationMonth  \\\n",
       "184019          0.639959  0.160845  -0.090133           0.005881   \n",
       "224508         -0.882114 -0.762130  -0.770483           0.840874   \n",
       "328264         -0.882114  0.144363   0.590217          -0.829112   \n",
       "136227          0.944374  0.358625  -1.859043          -0.829112   \n",
       "309930          0.487752  0.803631   0.590217           1.675868   \n",
       "\n",
       "        VehicleType_convertible  VehicleType_coupe  VehicleType_other  \\\n",
       "184019                      0.0                0.0                0.0   \n",
       "224508                      0.0                0.0                0.0   \n",
       "328264                      0.0                0.0                0.0   \n",
       "136227                      1.0                0.0                0.0   \n",
       "309930                      0.0                0.0                0.0   \n",
       "\n",
       "        VehicleType_sedan  VehicleType_small  VehicleType_suv  ...  \\\n",
       "184019                0.0                0.0              0.0  ...   \n",
       "224508                1.0                0.0              0.0  ...   \n",
       "328264                1.0                0.0              0.0  ...   \n",
       "136227                0.0                0.0              0.0  ...   \n",
       "309930                0.0                0.0              0.0  ...   \n",
       "\n",
       "        Brand_smart  Brand_sonstige_autos  Brand_subaru  Brand_suzuki  \\\n",
       "184019          0.0                   0.0           0.0           0.0   \n",
       "224508          0.0                   0.0           0.0           0.0   \n",
       "328264          0.0                   0.0           0.0           0.0   \n",
       "136227          0.0                   0.0           0.0           0.0   \n",
       "309930          0.0                   0.0           0.0           0.0   \n",
       "\n",
       "        Brand_toyota  Brand_trabant  Brand_volkswagen  Brand_volvo  \\\n",
       "184019           0.0            0.0               1.0          0.0   \n",
       "224508           0.0            0.0               0.0          0.0   \n",
       "328264           0.0            0.0               0.0          0.0   \n",
       "136227           0.0            0.0               0.0          0.0   \n",
       "309930           0.0            0.0               1.0          0.0   \n",
       "\n",
       "        Repaired_unknown  Repaired_yes  \n",
       "184019               0.0           0.0  \n",
       "224508               0.0           0.0  \n",
       "328264               0.0           0.0  \n",
       "136227               0.0           0.0  \n",
       "309930               0.0           0.0  \n",
       "\n",
       "[5 rows x 310 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Power</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>VehicleType_convertible</th>\n",
       "      <th>VehicleType_coupe</th>\n",
       "      <th>VehicleType_other</th>\n",
       "      <th>VehicleType_sedan</th>\n",
       "      <th>VehicleType_small</th>\n",
       "      <th>VehicleType_suv</th>\n",
       "      <th>...</th>\n",
       "      <th>Brand_smart</th>\n",
       "      <th>Brand_sonstige_autos</th>\n",
       "      <th>Brand_subaru</th>\n",
       "      <th>Brand_suzuki</th>\n",
       "      <th>Brand_toyota</th>\n",
       "      <th>Brand_trabant</th>\n",
       "      <th>Brand_volkswagen</th>\n",
       "      <th>Brand_volvo</th>\n",
       "      <th>Repaired_unknown</th>\n",
       "      <th>Repaired_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110198</th>\n",
       "      <td>-0.265106</td>\n",
       "      <td>-1.244210</td>\n",
       "      <td>0.591269</td>\n",
       "      <td>-0.269498</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96619</th>\n",
       "      <td>0.639549</td>\n",
       "      <td>-0.261018</td>\n",
       "      <td>0.591269</td>\n",
       "      <td>-0.827991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345457</th>\n",
       "      <td>-0.415881</td>\n",
       "      <td>0.931706</td>\n",
       "      <td>0.591269</td>\n",
       "      <td>-1.665730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142762</th>\n",
       "      <td>-0.868209</td>\n",
       "      <td>1.769837</td>\n",
       "      <td>0.591269</td>\n",
       "      <td>-0.827991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221541</th>\n",
       "      <td>0.790325</td>\n",
       "      <td>-0.809027</td>\n",
       "      <td>-2.121061</td>\n",
       "      <td>0.847488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RegistrationYear     Power  Kilometer  RegistrationMonth  \\\n",
       "110198         -0.265106 -1.244210   0.591269          -0.269498   \n",
       "96619           0.639549 -0.261018   0.591269          -0.827991   \n",
       "345457         -0.415881  0.931706   0.591269          -1.665730   \n",
       "142762         -0.868209  1.769837   0.591269          -0.827991   \n",
       "221541          0.790325 -0.809027  -2.121061           0.847488   \n",
       "\n",
       "        VehicleType_convertible  VehicleType_coupe  VehicleType_other  \\\n",
       "110198                      1.0                0.0                0.0   \n",
       "96619                       0.0                0.0                0.0   \n",
       "345457                      0.0                0.0                0.0   \n",
       "142762                      1.0                0.0                0.0   \n",
       "221541                      0.0                0.0                0.0   \n",
       "\n",
       "        VehicleType_sedan  VehicleType_small  VehicleType_suv  ...  \\\n",
       "110198                0.0                0.0              0.0  ...   \n",
       "96619                 0.0                0.0              0.0  ...   \n",
       "345457                1.0                0.0              0.0  ...   \n",
       "142762                0.0                0.0              0.0  ...   \n",
       "221541                0.0                1.0              0.0  ...   \n",
       "\n",
       "        Brand_smart  Brand_sonstige_autos  Brand_subaru  Brand_suzuki  \\\n",
       "110198          1.0                   0.0           0.0           0.0   \n",
       "96619           0.0                   0.0           0.0           0.0   \n",
       "345457          0.0                   0.0           0.0           0.0   \n",
       "142762          0.0                   0.0           0.0           0.0   \n",
       "221541          1.0                   0.0           0.0           0.0   \n",
       "\n",
       "        Brand_toyota  Brand_trabant  Brand_volkswagen  Brand_volvo  \\\n",
       "110198           0.0            0.0               0.0          0.0   \n",
       "96619            0.0            0.0               1.0          0.0   \n",
       "345457           0.0            0.0               0.0          0.0   \n",
       "142762           0.0            0.0               0.0          0.0   \n",
       "221541           0.0            0.0               0.0          0.0   \n",
       "\n",
       "        Repaired_unknown  Repaired_yes  \n",
       "110198               0.0           0.0  \n",
       "96619                0.0           0.0  \n",
       "345457               0.0           0.0  \n",
       "142762               0.0           0.0  \n",
       "221541               0.0           0.0  \n",
       "\n",
       "[5 rows x 310 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(features_train.head())\n",
    "\n",
    "display(features_valid.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем нужные параметры\n",
    "parameters = {}\n",
    "\n",
    "# Инициализируем модель\n",
    "model = GridSearchCV(LinearRegression(), param_grid = parameters, cv = 5, scoring = 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE TRAIN: 2678.2658313390552\n",
      "TIME TRAIN [s]: 3.88\n",
      "CPU times: total: 26.5 s\n",
      "Wall time: 20.6 s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"4a39e814-a158-4d16-b165-60f601ee2012\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"4a39e814-a158-4d16-b165-60f601ee2012\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"LinearRegression OHE C\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"LinearRegression OHE C\"\n",
    "%%time\n",
    "\n",
    "# Обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "time = model.refit_time_\n",
    "params = model.best_params_\n",
    "\n",
    "# Узнаем RMSE обучающей выборки\n",
    "result_RMSE_t = -model.best_score_\n",
    "print('RMSE TRAIN:', result_RMSE_t)\n",
    "print('TIME TRAIN [s]:', round(time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка на тестовой выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE VALID: 2692.6928922932516\n",
      "Предсказание: 4850.247989100264\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 246 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = timeit.default_timer()\n",
    "# Получим предсказания на тестовой выборки\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "elapsed = round(timeit.default_timer() - start_time, 3)\n",
    "\n",
    "result_RMSE_v = mean_squared_error(target_valid, predictions, squared=False)\n",
    "print('RMSE VALID:', result_RMSE_v)\n",
    "print('Предсказание:', predictions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зафиксируем результаты\n",
    "results[count_model] = pd.Series({\n",
    "    'NAME': 'LinearRegression_OHE_C', \n",
    "    'RMSE TRAIN': result_RMSE_t, \n",
    "    'RMSE VALID': result_RMSE_v, \n",
    "    'PREDICTIONS': predictions.mean(), \n",
    "    'TIME TRAINING [s]': time, \n",
    "    'TIME PREDICTION [s]': elapsed, \n",
    "    'PARAMETRS': params\n",
    "})\n",
    "\n",
    "results[count_model]\n",
    "count_model+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Масштабируем OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Деление на обучающей и валидационной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_clean.drop(['Price'], axis=1)\n",
    "target = df_clean['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим обучающую и валидационную выборку\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=(1 - 0.6), random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Кодируем признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Обучающие признаки\n",
    "features_train = pd.DataFrame(Encoder.fit_transform(features_train[col_type_obj]), columns=col_type_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Валидациоaнные признаки только трансформируем\n",
    "features_valid = pd.DataFrame(Encoder.transform(features_valid[col_type_obj]), columns=col_type_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Масштабируем признаки: обучающую и валидационную выборку\n",
    "scaler.fit(features_train[col_type_obj])\n",
    "\n",
    "# Преобразуем обучающую, валидационную и тестовую выборки функцией transform()\n",
    "features_train[col_type_obj] = scaler.transform(features_train[col_type_obj])\n",
    "features_valid[col_type_obj] = scaler.transform(features_valid[col_type_obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177559, 6)\n",
      "(118374, 6)\n"
     ]
    }
   ],
   "source": [
    "# Проверим\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: 0.6 %\n",
      "Размер валидационной выборки: 0.4 %\n"
     ]
    }
   ],
   "source": [
    "print('Размер обучающей выборки:', round(features_train.shape[0] / features.shape[0], 2), '%')\n",
    "print('Размер валидационной выборки:', round(features_valid.shape[0] / target.shape[0], 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Model</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Repaired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.178426</td>\n",
       "      <td>0.422522</td>\n",
       "      <td>-0.513284</td>\n",
       "      <td>1.157953</td>\n",
       "      <td>0.468488</td>\n",
       "      <td>-0.523308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.237768</td>\n",
       "      <td>0.422522</td>\n",
       "      <td>0.049325</td>\n",
       "      <td>0.626473</td>\n",
       "      <td>1.291481</td>\n",
       "      <td>-0.523308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.427006</td>\n",
       "      <td>0.422522</td>\n",
       "      <td>0.323768</td>\n",
       "      <td>0.626473</td>\n",
       "      <td>0.468488</td>\n",
       "      <td>-0.523308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VehicleType   Gearbox     Model  FuelType     Brand  Repaired\n",
       "0     0.178426  0.422522 -0.513284  1.157953  0.468488 -0.523308\n",
       "1    -0.237768  0.422522  0.049325  0.626473  1.291481 -0.523308\n",
       "2     1.427006  0.422522  0.323768  0.626473  0.468488 -0.523308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Model</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Repaired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.178426</td>\n",
       "      <td>0.422522</td>\n",
       "      <td>-0.513284</td>\n",
       "      <td>1.157953</td>\n",
       "      <td>0.468488</td>\n",
       "      <td>-0.523308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.237768</td>\n",
       "      <td>0.422522</td>\n",
       "      <td>0.049325</td>\n",
       "      <td>0.626473</td>\n",
       "      <td>1.291481</td>\n",
       "      <td>-0.523308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.427006</td>\n",
       "      <td>0.422522</td>\n",
       "      <td>0.323768</td>\n",
       "      <td>0.626473</td>\n",
       "      <td>0.468488</td>\n",
       "      <td>-0.523308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VehicleType   Gearbox     Model  FuelType     Brand  Repaired\n",
       "0     0.178426  0.422522 -0.513284  1.157953  0.468488 -0.523308\n",
       "1    -0.237768  0.422522  0.049325  0.626473  1.291481 -0.523308\n",
       "2     1.427006  0.422522  0.323768  0.626473  0.468488 -0.523308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(features_train.head(3))\n",
    "\n",
    "display(features_train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Матрица гиперпараметров\n",
    "parameters = {'max_depth': range(1, 101, 10), 'min_samples_leaf': [1, 0.5, 2]}\n",
    "\n",
    "# Инициализируем модель c параметрами\n",
    "model = GridSearchCV(DecisionTreeRegressor(random_state = 12345), param_grid = parameters, cv = 5, scoring = 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE TRAIN: 3499.0934747671336\n",
      "TIME TRAIN [s]: 0.16\n",
      "CPU times: total: 14.1 s\n",
      "Wall time: 14.3 s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"1cdc6f1c-085a-4679-8dad-c3529db9637e\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"1cdc6f1c-085a-4679-8dad-c3529db9637e\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"DecisionTreeRegressor OE C\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"DecisionTreeRegressor OE C\"\n",
    "%%time\n",
    "\n",
    "# Обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "time = model.refit_time_\n",
    "params = model.best_params_\n",
    "\n",
    "# Узнаем RMSE обучающей выборки\n",
    "result_RMSE_t = -model.best_score_\n",
    "print('RMSE TRAIN:', result_RMSE_t)\n",
    "print('TIME TRAIN [s]:', round(time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка на тестовой выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=21, min_samples_leaf=2, random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=21, min_samples_leaf=2, random_state=12345)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=21, min_samples_leaf=2, random_state=12345)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализируем модель c лучшими гиперпараметрами\n",
    "model = DecisionTreeRegressor(random_state = 12345).set_params(max_depth = params['max_depth'], min_samples_leaf = params['min_samples_leaf'])\n",
    "\n",
    "# Обучим модель на тренировочной выборке\n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE VALID: 3456.621835386765\n",
      "Предсказание: 4861.513936057213\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = timeit.default_timer()\n",
    "# Получим предсказания на тестовой выборки\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "elapsed = round(timeit.default_timer() - start_time, 3)\n",
    "\n",
    "result_RMSE_v = mean_squared_error(target_valid, predictions, squared=False)\n",
    "print('RMSE VALID:', result_RMSE_v)\n",
    "\n",
    "print('Предсказание:', predictions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зафиксируем результаты\n",
    "results[count_model] = pd.Series({\n",
    "    'NAME': 'DecisionTreeRegressor_OE_C', \n",
    "    'RMSE TRAIN': result_RMSE_t, \n",
    "    'RMSE VALID': result_RMSE_v, \n",
    "    'PREDICTIONS': predictions.mean(), \n",
    "    'TIME TRAINING [s]': time, \n",
    "    'TIME PREDICTION [s]': elapsed, \n",
    "    'PARAMETRS': params\n",
    "})\n",
    "\n",
    "results[count_model]\n",
    "count_model+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрица гиперпараметров для случайного леса\n",
    "parameters = {'bootstrap': [True], 'max_depth': [5, 15], 'max_features': ['auto', 'log2'], 'n_estimators': [25, 50]}\n",
    "\n",
    "# Инициализируем модель c параметрами\n",
    "model = GridSearchCV(RandomForestRegressor(random_state = 12345), parameters, cv = 5, scoring = 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE TRAIN: 3481.2866744037797\n",
      "TIME TRAIN [s]: 6.14\n",
      "CPU times: total: 1min 32s\n",
      "Wall time: 1min 34s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"f13c19de-0c80-490c-89fe-b792000b54df\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"f13c19de-0c80-490c-89fe-b792000b54df\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"RandomForestRegressor OE C\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"RandomForestRegressor OE C\"\n",
    "%%time\n",
    "\n",
    "# Обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "time = model.refit_time_\n",
    "params = model.best_params_\n",
    "\n",
    "# Узнаем RMSE обучающей выборки\n",
    "result_RMSE_t = -model.best_score_\n",
    "print('RMSE TRAIN:', result_RMSE_t)\n",
    "print('TIME TRAIN [s]:', round(time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка на тестовой выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=15, max_features=&#x27;auto&#x27;, n_estimators=50,\n",
       "                      random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=15, max_features=&#x27;auto&#x27;, n_estimators=50,\n",
       "                      random_state=12345)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=15, max_features='auto', n_estimators=50,\n",
       "                      random_state=12345)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализируем модель c лучшими гиперпараметрами\n",
    "model = RandomForestRegressor(random_state = 12345).set_params(\n",
    "    max_depth = params['max_depth'], \n",
    "    max_features = params['max_features'], \n",
    "    n_estimators = params['n_estimators']\n",
    ")\n",
    "\n",
    "# Обучим модель на тренировочной выборке\n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE VALID: 3442.689669205216\n",
      "Предсказание: 4863.122615073646\n",
      "CPU times: total: 641 ms\n",
      "Wall time: 757 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = timeit.default_timer()\n",
    "# Получим предсказания на тестовой выборки\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "elapsed = round(timeit.default_timer() - start_time, 3)\n",
    "\n",
    "result_RMSE_v = mean_squared_error(target_valid, predictions, squared=False)\n",
    "print('RMSE VALID:', result_RMSE_v)\n",
    "print('Предсказание:', predictions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[count_model] = pd.Series({\n",
    "    'NAME': 'RandomForestRegressor_OE_C', \n",
    "    'RMSE TRAIN': result_RMSE_t, \n",
    "    'RMSE VALID': result_RMSE_v, \n",
    "    'PREDICTIONS': predictions.mean(), \n",
    "    'TIME TRAINING [s]': time, \n",
    "    'TIME PREDICTION [s]': elapsed, \n",
    "    'PARAMETRS': params\n",
    "})\n",
    "\n",
    "results[count_model]\n",
    "count_model+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LightGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрица гиперпараметров для LightGBMRegressor\n",
    "parameters = {'num_leaves': [5, 10],\n",
    "              'learning_rate': [0.1, 0.3],\n",
    "              'max_depth': [3, 5],\n",
    "              'n_estimators': [10, 25]}\n",
    "\n",
    "# Инициализируем модель c параметрами\n",
    "model = GridSearchCV(LGBMRegressor(), parameters, cv = 5, scoring = 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE TRAIN: 3716.0189293083263\n",
      "TIME TRAIN [s]: 0.13\n",
      "CPU times: total: 1min 51s\n",
      "Wall time: 7.91 s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"cf88d321-c3df-4c04-940c-65f73a2aecc9\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"cf88d321-c3df-4c04-940c-65f73a2aecc9\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"LightGBMRegressor OE C\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"LightGBMRegressor OE C\"\n",
    "%%time\n",
    "\n",
    "# Обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "time = model.refit_time_\n",
    "params = model.best_params_\n",
    "\n",
    "# Узнаем RMSE обучающей выборки\n",
    "result_RMSE_t = -model.best_score_\n",
    "print('RMSE TRAIN:', result_RMSE_t)\n",
    "print('TIME TRAIN [s]:', round(time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка на тестовой выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(learning_rate=0.3, max_depth=5, n_estimators=25, num_leaves=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(learning_rate=0.3, max_depth=5, n_estimators=25, num_leaves=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(learning_rate=0.3, max_depth=5, n_estimators=25, num_leaves=10)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализируем модель c лучшими гиперпараметрами\n",
    "model = LGBMRegressor().set_params(\n",
    "    max_depth = params['max_depth'], \n",
    "    num_leaves = params['num_leaves'], \n",
    "    learning_rate = params['learning_rate'],\n",
    "    n_estimators = params['n_estimators']\n",
    ")\n",
    "\n",
    "# Обучим модель на тренировочной выборке\n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE VALID: 3689.2139083979214\n",
      "Предсказание: 4874.343228946626\n",
      "CPU times: total: 281 ms\n",
      "Wall time: 26.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = timeit.default_timer()\n",
    "# Получим предсказания на тестовой выборки\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "elapsed = round(timeit.default_timer() - start_time, 3)\n",
    "\n",
    "result_RMSE_v = mean_squared_error(target_valid, predictions, squared=False)\n",
    "print('RMSE VALID:', result_RMSE_v)\n",
    "print('Предсказание:', predictions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зафиксируем результаты\n",
    "results[count_model] = pd.Series({\n",
    "    'NAME': 'LightGBMRegressor_OE_C', \n",
    "    'RMSE TRAIN': result_RMSE_t, \n",
    "    'RMSE VALID': result_RMSE_v, \n",
    "    'PREDICTIONS': predictions.mean(), \n",
    "    'TIME TRAINING [s]': time, \n",
    "    'TIME PREDICTION [s]': elapsed, \n",
    "    'PARAMETRS': params\n",
    "})\n",
    "\n",
    "results[count_model]\n",
    "count_model+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрица гиперпараметров для LightGBMRegressor\n",
    "parameters = {'depth' : [6, 8, 10],\n",
    "              'learning_rate' : [0.01, 0.05, 0.1],\n",
    "              'iterations' : [10, 15, 20]}\n",
    "\n",
    "# Инициализируем модель c параметрами\n",
    "model = GridSearchCV(CatBoostRegressor(), parameters, cv = 5, scoring = 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4614.9702257\ttotal: 10.4ms\tremaining: 93.4ms\n",
      "1:\tlearn: 4603.9181521\ttotal: 19.8ms\tremaining: 79.1ms\n",
      "2:\tlearn: 4592.9956013\ttotal: 28.8ms\tremaining: 67.3ms\n",
      "3:\tlearn: 4582.2639861\ttotal: 37.3ms\tremaining: 56ms\n",
      "4:\tlearn: 4571.7627772\ttotal: 45.8ms\tremaining: 45.8ms\n",
      "5:\tlearn: 4561.4881886\ttotal: 54.9ms\tremaining: 36.6ms\n",
      "6:\tlearn: 4551.3920948\ttotal: 64.2ms\tremaining: 27.5ms\n",
      "7:\tlearn: 4541.3837436\ttotal: 72.2ms\tremaining: 18.1ms\n",
      "8:\tlearn: 4531.6809957\ttotal: 81.1ms\tremaining: 9.01ms\n",
      "9:\tlearn: 4521.9277066\ttotal: 89.8ms\tremaining: 0us\n",
      "0:\tlearn: 4606.1325331\ttotal: 8.75ms\tremaining: 78.8ms\n",
      "1:\tlearn: 4595.0166923\ttotal: 18.4ms\tremaining: 73.4ms\n",
      "2:\tlearn: 4584.1094943\ttotal: 27.6ms\tremaining: 64.4ms\n",
      "3:\tlearn: 4573.4092189\ttotal: 37.1ms\tremaining: 55.7ms\n",
      "4:\tlearn: 4562.9411944\ttotal: 46.6ms\tremaining: 46.6ms\n",
      "5:\tlearn: 4552.7182571\ttotal: 55.5ms\tremaining: 37ms\n",
      "6:\tlearn: 4542.6476872\ttotal: 64.5ms\tremaining: 27.7ms\n",
      "7:\tlearn: 4532.6652104\ttotal: 74.3ms\tremaining: 18.6ms\n",
      "8:\tlearn: 4522.9885759\ttotal: 83.7ms\tremaining: 9.3ms\n",
      "9:\tlearn: 4513.2683897\ttotal: 92.4ms\tremaining: 0us\n",
      "0:\tlearn: 4617.1122664\ttotal: 9.37ms\tremaining: 84.4ms\n",
      "1:\tlearn: 4606.0037914\ttotal: 18.5ms\tremaining: 74ms\n",
      "2:\tlearn: 4595.0861854\ttotal: 28ms\tremaining: 65.3ms\n",
      "3:\tlearn: 4584.3992202\ttotal: 37ms\tremaining: 55.6ms\n",
      "4:\tlearn: 4573.9187737\ttotal: 46.4ms\tremaining: 46.4ms\n",
      "5:\tlearn: 4563.7034685\ttotal: 55ms\tremaining: 36.7ms\n",
      "6:\tlearn: 4553.6409174\ttotal: 63.6ms\tremaining: 27.3ms\n",
      "7:\tlearn: 4543.6688733\ttotal: 72.1ms\tremaining: 18ms\n",
      "8:\tlearn: 4533.9905149\ttotal: 80.7ms\tremaining: 8.96ms\n",
      "9:\tlearn: 4524.3789273\ttotal: 88.9ms\tremaining: 0us\n",
      "0:\tlearn: 4612.7014908\ttotal: 14.5ms\tremaining: 130ms\n",
      "1:\tlearn: 4601.6421867\ttotal: 30.4ms\tremaining: 122ms\n",
      "2:\tlearn: 4590.7726968\ttotal: 40.5ms\tremaining: 94.5ms\n",
      "3:\tlearn: 4580.0967198\ttotal: 50.8ms\tremaining: 76.2ms\n",
      "4:\tlearn: 4569.6918991\ttotal: 65.7ms\tremaining: 65.7ms\n",
      "5:\tlearn: 4559.5210580\ttotal: 74.5ms\tremaining: 49.7ms\n",
      "6:\tlearn: 4549.4998933\ttotal: 91.6ms\tremaining: 39.3ms\n",
      "7:\tlearn: 4539.6154138\ttotal: 105ms\tremaining: 26.3ms\n",
      "8:\tlearn: 4529.9925557\ttotal: 116ms\tremaining: 12.9ms\n",
      "9:\tlearn: 4520.4300992\ttotal: 129ms\tremaining: 0us\n",
      "0:\tlearn: 4607.9914319\ttotal: 8.92ms\tremaining: 80.3ms\n",
      "1:\tlearn: 4596.9279651\ttotal: 17.5ms\tremaining: 70ms\n",
      "2:\tlearn: 4586.0366806\ttotal: 26.5ms\tremaining: 61.9ms\n",
      "3:\tlearn: 4575.3504743\ttotal: 35.4ms\tremaining: 53.1ms\n",
      "4:\tlearn: 4564.9077039\ttotal: 45.3ms\tremaining: 45.3ms\n",
      "5:\tlearn: 4554.7317874\ttotal: 54.5ms\tremaining: 36.3ms\n",
      "6:\tlearn: 4544.7093443\ttotal: 63.2ms\tremaining: 27.1ms\n",
      "7:\tlearn: 4534.7905038\ttotal: 72.2ms\tremaining: 18.1ms\n",
      "8:\tlearn: 4525.1466516\ttotal: 80.9ms\tremaining: 8.98ms\n",
      "9:\tlearn: 4515.5662953\ttotal: 89.8ms\tremaining: 0us\n",
      "0:\tlearn: 4570.6341150\ttotal: 8.98ms\tremaining: 80.8ms\n",
      "1:\tlearn: 4519.9527683\ttotal: 18ms\tremaining: 72.2ms\n",
      "2:\tlearn: 4473.1986005\ttotal: 27.1ms\tremaining: 63.2ms\n",
      "3:\tlearn: 4430.4296288\ttotal: 36.2ms\tremaining: 54.3ms\n",
      "4:\tlearn: 4391.7814816\ttotal: 44.8ms\tremaining: 44.8ms\n",
      "5:\tlearn: 4356.5860792\ttotal: 53.1ms\tremaining: 35.4ms\n",
      "6:\tlearn: 4324.4756461\ttotal: 62.5ms\tremaining: 26.8ms\n",
      "7:\tlearn: 4295.1692439\ttotal: 70.9ms\tremaining: 17.7ms\n",
      "8:\tlearn: 4268.6338529\ttotal: 80.5ms\tremaining: 8.95ms\n",
      "9:\tlearn: 4243.6480376\ttotal: 89.2ms\tremaining: 0us\n",
      "0:\tlearn: 4562.0062229\ttotal: 10.1ms\tremaining: 91.1ms\n",
      "1:\tlearn: 4511.0473621\ttotal: 19.4ms\tremaining: 77.6ms\n",
      "2:\tlearn: 4464.4068918\ttotal: 28.5ms\tremaining: 66.4ms\n",
      "3:\tlearn: 4421.9138520\ttotal: 39.3ms\tremaining: 59ms\n",
      "4:\tlearn: 4383.4194241\ttotal: 47.8ms\tremaining: 47.8ms\n",
      "5:\tlearn: 4348.4362764\ttotal: 56.2ms\tremaining: 37.4ms\n",
      "6:\tlearn: 4316.3176825\ttotal: 65.5ms\tremaining: 28.1ms\n",
      "7:\tlearn: 4286.9855625\ttotal: 73.6ms\tremaining: 18.4ms\n",
      "8:\tlearn: 4260.5197739\ttotal: 81.9ms\tremaining: 9.11ms\n",
      "9:\tlearn: 4235.7342798\ttotal: 90.6ms\tremaining: 0us\n",
      "0:\tlearn: 4572.9458872\ttotal: 9.86ms\tremaining: 88.7ms\n",
      "1:\tlearn: 4522.0387745\ttotal: 18.5ms\tremaining: 73.9ms\n",
      "2:\tlearn: 4475.4481720\ttotal: 28.2ms\tremaining: 65.8ms\n",
      "3:\tlearn: 4433.0062896\ttotal: 36.5ms\tremaining: 54.7ms\n",
      "4:\tlearn: 4394.4786296\ttotal: 45.2ms\tremaining: 45.2ms\n",
      "5:\tlearn: 4359.5387191\ttotal: 54.1ms\tremaining: 36ms\n",
      "6:\tlearn: 4327.4476794\ttotal: 64ms\tremaining: 27.4ms\n",
      "7:\tlearn: 4298.1528006\ttotal: 74ms\tremaining: 18.5ms\n",
      "8:\tlearn: 4271.6684631\ttotal: 84.1ms\tremaining: 9.34ms\n",
      "9:\tlearn: 4246.9142193\ttotal: 94.4ms\tremaining: 0us\n",
      "0:\tlearn: 4568.7747666\ttotal: 9.08ms\tremaining: 81.7ms\n",
      "1:\tlearn: 4518.0917385\ttotal: 17.8ms\tremaining: 71ms\n",
      "2:\tlearn: 4471.7079821\ttotal: 27.1ms\tremaining: 63.2ms\n",
      "3:\tlearn: 4429.4520093\ttotal: 35.8ms\tremaining: 53.7ms\n",
      "4:\tlearn: 4391.2397060\ttotal: 45.2ms\tremaining: 45.2ms\n",
      "5:\tlearn: 4356.4597144\ttotal: 54.8ms\tremaining: 36.5ms\n",
      "6:\tlearn: 4324.5030071\ttotal: 63.5ms\tremaining: 27.2ms\n",
      "7:\tlearn: 4295.3206305\ttotal: 73.9ms\tremaining: 18.5ms\n",
      "8:\tlearn: 4269.0199787\ttotal: 83.2ms\tremaining: 9.25ms\n",
      "9:\tlearn: 4244.3901790\ttotal: 92ms\tremaining: 0us\n",
      "0:\tlearn: 4564.0906121\ttotal: 9.69ms\tremaining: 87.3ms\n",
      "1:\tlearn: 4513.3798903\ttotal: 18.7ms\tremaining: 74.6ms\n",
      "2:\tlearn: 4466.8877844\ttotal: 27.9ms\tremaining: 65.1ms\n",
      "3:\tlearn: 4424.5807839\ttotal: 36.8ms\tremaining: 55.2ms\n",
      "4:\tlearn: 4386.1986075\ttotal: 46.9ms\tremaining: 46.9ms\n",
      "5:\tlearn: 4351.3978057\ttotal: 55.7ms\tremaining: 37.1ms\n",
      "6:\tlearn: 4319.4573072\ttotal: 64.3ms\tremaining: 27.5ms\n",
      "7:\tlearn: 4290.0765247\ttotal: 73.6ms\tremaining: 18.4ms\n",
      "8:\tlearn: 4263.6991164\ttotal: 82.6ms\tremaining: 9.18ms\n",
      "9:\tlearn: 4239.1167832\ttotal: 92.1ms\tremaining: 0us\n",
      "0:\tlearn: 4517.2076857\ttotal: 9.07ms\tremaining: 81.7ms\n",
      "1:\tlearn: 4426.8207368\ttotal: 22.9ms\tremaining: 91.6ms\n",
      "2:\tlearn: 4351.0563959\ttotal: 44.2ms\tremaining: 103ms\n",
      "3:\tlearn: 4288.2352083\ttotal: 56.3ms\tremaining: 84.4ms\n",
      "4:\tlearn: 4237.6395912\ttotal: 71.2ms\tremaining: 71.2ms\n",
      "5:\tlearn: 4194.9615942\ttotal: 80.5ms\tremaining: 53.6ms\n",
      "6:\tlearn: 4159.7053819\ttotal: 93.7ms\tremaining: 40.1ms\n",
      "7:\tlearn: 4127.0193159\ttotal: 110ms\tremaining: 27.6ms\n",
      "8:\tlearn: 4100.8118397\ttotal: 121ms\tremaining: 13.4ms\n",
      "9:\tlearn: 4069.1249168\ttotal: 130ms\tremaining: 0us\n",
      "0:\tlearn: 4508.8340649\ttotal: 11.1ms\tremaining: 99.7ms\n",
      "1:\tlearn: 4417.9933052\ttotal: 21.2ms\tremaining: 84.8ms\n",
      "2:\tlearn: 4342.4463393\ttotal: 31.8ms\tremaining: 74.2ms\n",
      "3:\tlearn: 4280.3418963\ttotal: 41ms\tremaining: 61.5ms\n",
      "4:\tlearn: 4230.2124690\ttotal: 49.4ms\tremaining: 49.4ms\n",
      "5:\tlearn: 4187.8623123\ttotal: 58.2ms\tremaining: 38.8ms\n",
      "6:\tlearn: 4152.3066749\ttotal: 66.2ms\tremaining: 28.4ms\n",
      "7:\tlearn: 4119.9635433\ttotal: 74.9ms\tremaining: 18.7ms\n",
      "8:\tlearn: 4095.1627725\ttotal: 83.3ms\tremaining: 9.26ms\n",
      "9:\tlearn: 4064.0626552\ttotal: 92.7ms\tremaining: 0us\n",
      "0:\tlearn: 4519.7264643\ttotal: 9.14ms\tremaining: 82.3ms\n",
      "1:\tlearn: 4429.7087225\ttotal: 17.4ms\tremaining: 69.5ms\n",
      "2:\tlearn: 4354.1609120\ttotal: 25.6ms\tremaining: 59.8ms\n",
      "3:\tlearn: 4291.6078067\ttotal: 34.5ms\tremaining: 51.7ms\n",
      "4:\tlearn: 4241.1073938\ttotal: 43.3ms\tremaining: 43.3ms\n",
      "5:\tlearn: 4198.8653020\ttotal: 51.8ms\tremaining: 34.5ms\n",
      "6:\tlearn: 4163.8257978\ttotal: 60.9ms\tremaining: 26.1ms\n",
      "7:\tlearn: 4131.3760559\ttotal: 69.9ms\tremaining: 17.5ms\n",
      "8:\tlearn: 4105.2711726\ttotal: 79ms\tremaining: 8.78ms\n",
      "9:\tlearn: 4073.6773944\ttotal: 88.6ms\tremaining: 0us\n",
      "0:\tlearn: 4515.8465441\ttotal: 8.62ms\tremaining: 77.6ms\n",
      "1:\tlearn: 4425.5376851\ttotal: 17.3ms\tremaining: 69.1ms\n",
      "2:\tlearn: 4350.4376436\ttotal: 25.9ms\tremaining: 60.5ms\n",
      "3:\tlearn: 4288.7159466\ttotal: 34.6ms\tremaining: 51.9ms\n",
      "4:\tlearn: 4238.8587822\ttotal: 43.3ms\tremaining: 43.3ms\n",
      "5:\tlearn: 4196.8026053\ttotal: 52ms\tremaining: 34.7ms\n",
      "6:\tlearn: 4161.4192928\ttotal: 60.6ms\tremaining: 26ms\n",
      "7:\tlearn: 4128.9610245\ttotal: 69.3ms\tremaining: 17.3ms\n",
      "8:\tlearn: 4104.3475350\ttotal: 77ms\tremaining: 8.56ms\n",
      "9:\tlearn: 4073.3849216\ttotal: 85.4ms\tremaining: 0us\n",
      "0:\tlearn: 4511.1938071\ttotal: 9.19ms\tremaining: 82.7ms\n",
      "1:\tlearn: 4420.8147629\ttotal: 17.2ms\tremaining: 68.8ms\n",
      "2:\tlearn: 4345.5041615\ttotal: 25.7ms\tremaining: 60ms\n",
      "3:\tlearn: 4283.6866582\ttotal: 34.5ms\tremaining: 51.8ms\n",
      "4:\tlearn: 4233.9298307\ttotal: 43.2ms\tremaining: 43.2ms\n",
      "5:\tlearn: 4191.7934978\ttotal: 51.2ms\tremaining: 34.2ms\n",
      "6:\tlearn: 4156.4989968\ttotal: 60.5ms\tremaining: 25.9ms\n",
      "7:\tlearn: 4124.0638433\ttotal: 68.9ms\tremaining: 17.2ms\n",
      "8:\tlearn: 4099.6873520\ttotal: 76.7ms\tremaining: 8.52ms\n",
      "9:\tlearn: 4068.6471426\ttotal: 84.6ms\tremaining: 0us\n",
      "0:\tlearn: 4614.9702257\ttotal: 9.11ms\tremaining: 128ms\n",
      "1:\tlearn: 4603.9181521\ttotal: 17.3ms\tremaining: 113ms\n",
      "2:\tlearn: 4592.9956013\ttotal: 25.5ms\tremaining: 102ms\n",
      "3:\tlearn: 4582.2639861\ttotal: 33.4ms\tremaining: 91.8ms\n",
      "4:\tlearn: 4571.7627772\ttotal: 42.4ms\tremaining: 84.7ms\n",
      "5:\tlearn: 4561.4881886\ttotal: 50ms\tremaining: 75ms\n",
      "6:\tlearn: 4551.3920948\ttotal: 58.1ms\tremaining: 66.4ms\n",
      "7:\tlearn: 4541.3837436\ttotal: 65.7ms\tremaining: 57.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\tlearn: 4531.6809957\ttotal: 74.9ms\tremaining: 49.9ms\n",
      "9:\tlearn: 4521.9277066\ttotal: 83.5ms\tremaining: 41.8ms\n",
      "10:\tlearn: 4512.4207956\ttotal: 92.3ms\tremaining: 33.6ms\n",
      "11:\tlearn: 4503.2428379\ttotal: 102ms\tremaining: 25.4ms\n",
      "12:\tlearn: 4494.1860730\ttotal: 110ms\tremaining: 16.9ms\n",
      "13:\tlearn: 4485.1796629\ttotal: 118ms\tremaining: 8.42ms\n",
      "14:\tlearn: 4476.3092831\ttotal: 126ms\tremaining: 0us\n",
      "0:\tlearn: 4606.1325331\ttotal: 9.43ms\tremaining: 132ms\n",
      "1:\tlearn: 4595.0166923\ttotal: 18ms\tremaining: 117ms\n",
      "2:\tlearn: 4584.1094943\ttotal: 26.6ms\tremaining: 106ms\n",
      "3:\tlearn: 4573.4092189\ttotal: 34.2ms\tremaining: 94ms\n",
      "4:\tlearn: 4562.9411944\ttotal: 42.4ms\tremaining: 84.9ms\n",
      "5:\tlearn: 4552.7182571\ttotal: 50.3ms\tremaining: 75.5ms\n",
      "6:\tlearn: 4542.6476872\ttotal: 58.4ms\tremaining: 66.8ms\n",
      "7:\tlearn: 4532.6652104\ttotal: 65.8ms\tremaining: 57.6ms\n",
      "8:\tlearn: 4522.9885759\ttotal: 74ms\tremaining: 49.3ms\n",
      "9:\tlearn: 4513.2683897\ttotal: 81.7ms\tremaining: 40.9ms\n",
      "10:\tlearn: 4503.8028749\ttotal: 89.5ms\tremaining: 32.6ms\n",
      "11:\tlearn: 4494.6380821\ttotal: 97.1ms\tremaining: 24.3ms\n",
      "12:\tlearn: 4485.6052864\ttotal: 105ms\tremaining: 16.2ms\n",
      "13:\tlearn: 4476.6460836\ttotal: 114ms\tremaining: 8.13ms\n",
      "14:\tlearn: 4467.8183125\ttotal: 122ms\tremaining: 0us\n",
      "0:\tlearn: 4617.1122664\ttotal: 13.3ms\tremaining: 186ms\n",
      "1:\tlearn: 4606.0037914\ttotal: 22.5ms\tremaining: 146ms\n",
      "2:\tlearn: 4595.0861854\ttotal: 36.1ms\tremaining: 145ms\n",
      "3:\tlearn: 4584.3992202\ttotal: 59.3ms\tremaining: 163ms\n",
      "4:\tlearn: 4573.9187737\ttotal: 68.9ms\tremaining: 138ms\n",
      "5:\tlearn: 4563.7034685\ttotal: 82.2ms\tremaining: 123ms\n",
      "6:\tlearn: 4553.6409174\ttotal: 102ms\tremaining: 117ms\n",
      "7:\tlearn: 4543.6688733\ttotal: 113ms\tremaining: 98.5ms\n",
      "8:\tlearn: 4533.9905149\ttotal: 124ms\tremaining: 83ms\n",
      "9:\tlearn: 4524.3789273\ttotal: 133ms\tremaining: 66.7ms\n",
      "10:\tlearn: 4514.9085141\ttotal: 141ms\tremaining: 51.4ms\n",
      "11:\tlearn: 4505.7563605\ttotal: 149ms\tremaining: 37.3ms\n",
      "12:\tlearn: 4496.7211315\ttotal: 157ms\tremaining: 24.1ms\n",
      "13:\tlearn: 4487.7536614\ttotal: 165ms\tremaining: 11.8ms\n",
      "14:\tlearn: 4478.9177356\ttotal: 173ms\tremaining: 0us\n",
      "0:\tlearn: 4612.7014908\ttotal: 9.63ms\tremaining: 135ms\n",
      "1:\tlearn: 4601.6421867\ttotal: 17.9ms\tremaining: 116ms\n",
      "2:\tlearn: 4590.7726968\ttotal: 25.8ms\tremaining: 103ms\n",
      "3:\tlearn: 4580.0967198\ttotal: 34.1ms\tremaining: 93.9ms\n",
      "4:\tlearn: 4569.6918991\ttotal: 42.5ms\tremaining: 85ms\n",
      "5:\tlearn: 4559.5210580\ttotal: 50.4ms\tremaining: 75.6ms\n",
      "6:\tlearn: 4549.4998933\ttotal: 58.5ms\tremaining: 66.9ms\n",
      "7:\tlearn: 4539.6154138\ttotal: 66.6ms\tremaining: 58.3ms\n",
      "8:\tlearn: 4529.9925557\ttotal: 75.6ms\tremaining: 50.4ms\n",
      "9:\tlearn: 4520.4300992\ttotal: 83.7ms\tremaining: 41.8ms\n",
      "10:\tlearn: 4511.0020272\ttotal: 92.7ms\tremaining: 33.7ms\n",
      "11:\tlearn: 4501.8930276\ttotal: 102ms\tremaining: 25.4ms\n",
      "12:\tlearn: 4492.9068930\ttotal: 110ms\tremaining: 16.9ms\n",
      "13:\tlearn: 4483.9885476\ttotal: 118ms\tremaining: 8.42ms\n",
      "14:\tlearn: 4475.1973305\ttotal: 126ms\tremaining: 0us\n",
      "0:\tlearn: 4607.9914319\ttotal: 8.52ms\tremaining: 119ms\n",
      "1:\tlearn: 4596.9279651\ttotal: 17.1ms\tremaining: 111ms\n",
      "2:\tlearn: 4586.0366806\ttotal: 25ms\tremaining: 99.9ms\n",
      "3:\tlearn: 4575.3504743\ttotal: 33.5ms\tremaining: 92ms\n",
      "4:\tlearn: 4564.9077039\ttotal: 41.6ms\tremaining: 83.3ms\n",
      "5:\tlearn: 4554.7317874\ttotal: 49.4ms\tremaining: 74.1ms\n",
      "6:\tlearn: 4544.7093443\ttotal: 57.3ms\tremaining: 65.5ms\n",
      "7:\tlearn: 4534.7905038\ttotal: 65.5ms\tremaining: 57.3ms\n",
      "8:\tlearn: 4525.1466516\ttotal: 73.6ms\tremaining: 49.1ms\n",
      "9:\tlearn: 4515.5662953\ttotal: 81.5ms\tremaining: 40.8ms\n",
      "10:\tlearn: 4506.1274662\ttotal: 89.5ms\tremaining: 32.5ms\n",
      "11:\tlearn: 4497.0027754\ttotal: 97.4ms\tremaining: 24.4ms\n",
      "12:\tlearn: 4488.0012174\ttotal: 106ms\tremaining: 16.3ms\n",
      "13:\tlearn: 4479.0699577\ttotal: 114ms\tremaining: 8.14ms\n",
      "14:\tlearn: 4470.2878576\ttotal: 123ms\tremaining: 0us\n",
      "0:\tlearn: 4570.6341150\ttotal: 9.43ms\tremaining: 132ms\n",
      "1:\tlearn: 4519.9527683\ttotal: 18ms\tremaining: 117ms\n",
      "2:\tlearn: 4473.1986005\ttotal: 26ms\tremaining: 104ms\n",
      "3:\tlearn: 4430.4296288\ttotal: 34.3ms\tremaining: 94.4ms\n",
      "4:\tlearn: 4391.7814816\ttotal: 42.4ms\tremaining: 84.8ms\n",
      "5:\tlearn: 4356.5860792\ttotal: 50.6ms\tremaining: 75.9ms\n",
      "6:\tlearn: 4324.4756461\ttotal: 58.4ms\tremaining: 66.8ms\n",
      "7:\tlearn: 4295.1692439\ttotal: 66.3ms\tremaining: 58ms\n",
      "8:\tlearn: 4268.6338529\ttotal: 74.4ms\tremaining: 49.6ms\n",
      "9:\tlearn: 4243.6480376\ttotal: 82.6ms\tremaining: 41.3ms\n",
      "10:\tlearn: 4221.1848121\ttotal: 90.7ms\tremaining: 33ms\n",
      "11:\tlearn: 4200.8734512\ttotal: 98.3ms\tremaining: 24.6ms\n",
      "12:\tlearn: 4181.6727934\ttotal: 106ms\tremaining: 16.3ms\n",
      "13:\tlearn: 4163.7146684\ttotal: 114ms\tremaining: 8.16ms\n",
      "14:\tlearn: 4147.7748044\ttotal: 123ms\tremaining: 0us\n",
      "0:\tlearn: 4562.0062229\ttotal: 8.7ms\tremaining: 122ms\n",
      "1:\tlearn: 4511.0473621\ttotal: 16.6ms\tremaining: 108ms\n",
      "2:\tlearn: 4464.4068918\ttotal: 24.9ms\tremaining: 99.4ms\n",
      "3:\tlearn: 4421.9138520\ttotal: 33.1ms\tremaining: 90.9ms\n",
      "4:\tlearn: 4383.4194241\ttotal: 40.8ms\tremaining: 81.5ms\n",
      "5:\tlearn: 4348.4362764\ttotal: 48.9ms\tremaining: 73.4ms\n",
      "6:\tlearn: 4316.3176825\ttotal: 56.9ms\tremaining: 65.1ms\n",
      "7:\tlearn: 4286.9855625\ttotal: 64.8ms\tremaining: 56.7ms\n",
      "8:\tlearn: 4260.5197739\ttotal: 72.6ms\tremaining: 48.4ms\n",
      "9:\tlearn: 4235.7342798\ttotal: 80.6ms\tremaining: 40.3ms\n",
      "10:\tlearn: 4213.3346657\ttotal: 88ms\tremaining: 32ms\n",
      "11:\tlearn: 4193.4173481\ttotal: 95.9ms\tremaining: 24ms\n",
      "12:\tlearn: 4174.3332787\ttotal: 104ms\tremaining: 16ms\n",
      "13:\tlearn: 4157.7552027\ttotal: 112ms\tremaining: 8ms\n",
      "14:\tlearn: 4142.0796807\ttotal: 120ms\tremaining: 0us\n",
      "0:\tlearn: 4572.9458872\ttotal: 9.27ms\tremaining: 130ms\n",
      "1:\tlearn: 4522.0387745\ttotal: 16.9ms\tremaining: 110ms\n",
      "2:\tlearn: 4475.4481720\ttotal: 25.3ms\tremaining: 101ms\n",
      "3:\tlearn: 4433.0062896\ttotal: 33.1ms\tremaining: 91.1ms\n",
      "4:\tlearn: 4394.4786296\ttotal: 41.7ms\tremaining: 83.4ms\n",
      "5:\tlearn: 4359.5387191\ttotal: 50ms\tremaining: 75ms\n",
      "6:\tlearn: 4327.4476794\ttotal: 58.4ms\tremaining: 66.8ms\n",
      "7:\tlearn: 4298.1528006\ttotal: 66.1ms\tremaining: 57.9ms\n",
      "8:\tlearn: 4271.6684631\ttotal: 73.8ms\tremaining: 49.2ms\n",
      "9:\tlearn: 4246.9142193\ttotal: 81.5ms\tremaining: 40.8ms\n",
      "10:\tlearn: 4224.5801269\ttotal: 89.8ms\tremaining: 32.7ms\n",
      "11:\tlearn: 4204.4722205\ttotal: 97.5ms\tremaining: 24.4ms\n",
      "12:\tlearn: 4185.2529885\ttotal: 106ms\tremaining: 16.3ms\n",
      "13:\tlearn: 4168.1052937\ttotal: 114ms\tremaining: 8.14ms\n",
      "14:\tlearn: 4152.3339735\ttotal: 122ms\tremaining: 0us\n",
      "0:\tlearn: 4568.7747666\ttotal: 8.61ms\tremaining: 121ms\n",
      "1:\tlearn: 4518.0917385\ttotal: 17.4ms\tremaining: 113ms\n",
      "2:\tlearn: 4471.7079821\ttotal: 26.8ms\tremaining: 107ms\n",
      "3:\tlearn: 4429.4520093\ttotal: 35.1ms\tremaining: 96.6ms\n",
      "4:\tlearn: 4391.2397060\ttotal: 44.8ms\tremaining: 89.5ms\n",
      "5:\tlearn: 4356.4597144\ttotal: 53.8ms\tremaining: 80.7ms\n",
      "6:\tlearn: 4324.5030071\ttotal: 62.7ms\tremaining: 71.6ms\n",
      "7:\tlearn: 4295.3206305\ttotal: 71ms\tremaining: 62.1ms\n",
      "8:\tlearn: 4269.0199787\ttotal: 79.7ms\tremaining: 53.1ms\n",
      "9:\tlearn: 4244.3901790\ttotal: 88.7ms\tremaining: 44.4ms\n",
      "10:\tlearn: 4222.1299041\ttotal: 97.4ms\tremaining: 35.4ms\n",
      "11:\tlearn: 4202.0140825\ttotal: 106ms\tremaining: 26.5ms\n",
      "12:\tlearn: 4182.8964659\ttotal: 115ms\tremaining: 17.7ms\n",
      "13:\tlearn: 4166.3638786\ttotal: 125ms\tremaining: 8.92ms\n",
      "14:\tlearn: 4150.8095305\ttotal: 134ms\tremaining: 0us\n",
      "0:\tlearn: 4564.0906121\ttotal: 9.13ms\tremaining: 128ms\n",
      "1:\tlearn: 4513.3798903\ttotal: 17ms\tremaining: 111ms\n",
      "2:\tlearn: 4466.8877844\ttotal: 25.7ms\tremaining: 103ms\n",
      "3:\tlearn: 4424.5807839\ttotal: 34.6ms\tremaining: 95.2ms\n",
      "4:\tlearn: 4386.1986075\ttotal: 43.8ms\tremaining: 87.5ms\n",
      "5:\tlearn: 4351.3978057\ttotal: 53.2ms\tremaining: 79.9ms\n",
      "6:\tlearn: 4319.4573072\ttotal: 61.8ms\tremaining: 70.6ms\n",
      "7:\tlearn: 4290.0765247\ttotal: 70.1ms\tremaining: 61.3ms\n",
      "8:\tlearn: 4263.6991164\ttotal: 78.8ms\tremaining: 52.5ms\n",
      "9:\tlearn: 4239.1167832\ttotal: 87.6ms\tremaining: 43.8ms\n",
      "10:\tlearn: 4216.8981591\ttotal: 96.5ms\tremaining: 35.1ms\n",
      "11:\tlearn: 4196.7959542\ttotal: 105ms\tremaining: 26.3ms\n",
      "12:\tlearn: 4177.6580621\ttotal: 114ms\tremaining: 17.5ms\n",
      "13:\tlearn: 4161.1228885\ttotal: 122ms\tremaining: 8.7ms\n",
      "14:\tlearn: 4145.7215229\ttotal: 130ms\tremaining: 0us\n",
      "0:\tlearn: 4517.2076857\ttotal: 8.69ms\tremaining: 122ms\n",
      "1:\tlearn: 4426.8207368\ttotal: 17.5ms\tremaining: 114ms\n",
      "2:\tlearn: 4351.0563959\ttotal: 25.5ms\tremaining: 102ms\n",
      "3:\tlearn: 4288.2352083\ttotal: 34.6ms\tremaining: 95.1ms\n",
      "4:\tlearn: 4237.6395912\ttotal: 43.5ms\tremaining: 87ms\n",
      "5:\tlearn: 4194.9615942\ttotal: 52.1ms\tremaining: 78.1ms\n",
      "6:\tlearn: 4159.7053819\ttotal: 62.6ms\tremaining: 71.6ms\n",
      "7:\tlearn: 4127.0193159\ttotal: 71ms\tremaining: 62.1ms\n",
      "8:\tlearn: 4100.8118397\ttotal: 80.2ms\tremaining: 53.4ms\n",
      "9:\tlearn: 4069.1249168\ttotal: 88.7ms\tremaining: 44.4ms\n",
      "10:\tlearn: 4050.7297716\ttotal: 96.9ms\tremaining: 35.2ms\n",
      "11:\tlearn: 4033.8279861\ttotal: 105ms\tremaining: 26.3ms\n",
      "12:\tlearn: 4017.5854271\ttotal: 115ms\tremaining: 17.7ms\n",
      "13:\tlearn: 3996.6413888\ttotal: 124ms\tremaining: 8.85ms\n",
      "14:\tlearn: 3985.7184519\ttotal: 132ms\tremaining: 0us\n",
      "0:\tlearn: 4508.8340649\ttotal: 9.16ms\tremaining: 128ms\n",
      "1:\tlearn: 4417.9933052\ttotal: 17ms\tremaining: 110ms\n",
      "2:\tlearn: 4342.4463393\ttotal: 25.5ms\tremaining: 102ms\n",
      "3:\tlearn: 4280.3418963\ttotal: 33.5ms\tremaining: 92.1ms\n",
      "4:\tlearn: 4230.2124690\ttotal: 42.1ms\tremaining: 84.2ms\n",
      "5:\tlearn: 4187.8623123\ttotal: 50.2ms\tremaining: 75.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6:\tlearn: 4152.3066749\ttotal: 58.9ms\tremaining: 67.3ms\n",
      "7:\tlearn: 4119.9635433\ttotal: 67.7ms\tremaining: 59.2ms\n",
      "8:\tlearn: 4095.1627725\ttotal: 75.8ms\tremaining: 50.5ms\n",
      "9:\tlearn: 4064.0626552\ttotal: 84.8ms\tremaining: 42.4ms\n",
      "10:\tlearn: 4045.7667873\ttotal: 93.2ms\tremaining: 33.9ms\n",
      "11:\tlearn: 4030.5156198\ttotal: 101ms\tremaining: 25.4ms\n",
      "12:\tlearn: 4014.3341976\ttotal: 110ms\tremaining: 16.9ms\n",
      "13:\tlearn: 3999.5969351\ttotal: 118ms\tremaining: 8.45ms\n",
      "14:\tlearn: 3980.1798188\ttotal: 127ms\tremaining: 0us\n",
      "0:\tlearn: 4519.7264643\ttotal: 9.08ms\tremaining: 127ms\n",
      "1:\tlearn: 4429.7087225\ttotal: 17.3ms\tremaining: 112ms\n",
      "2:\tlearn: 4354.1609120\ttotal: 25.8ms\tremaining: 103ms\n",
      "3:\tlearn: 4291.6078067\ttotal: 34.6ms\tremaining: 95.2ms\n",
      "4:\tlearn: 4241.1073938\ttotal: 42.9ms\tremaining: 85.7ms\n",
      "5:\tlearn: 4198.8653020\ttotal: 51ms\tremaining: 76.5ms\n",
      "6:\tlearn: 4163.8257978\ttotal: 58.9ms\tremaining: 67.3ms\n",
      "7:\tlearn: 4131.3760559\ttotal: 67.5ms\tremaining: 59.1ms\n",
      "8:\tlearn: 4105.2711726\ttotal: 75.7ms\tremaining: 50.5ms\n",
      "9:\tlearn: 4073.6773944\ttotal: 84.4ms\tremaining: 42.2ms\n",
      "10:\tlearn: 4055.3821974\ttotal: 92.5ms\tremaining: 33.6ms\n",
      "11:\tlearn: 4038.3354609\ttotal: 101ms\tremaining: 25.2ms\n",
      "12:\tlearn: 4022.3286314\ttotal: 109ms\tremaining: 16.8ms\n",
      "13:\tlearn: 4009.3327479\ttotal: 117ms\tremaining: 8.38ms\n",
      "14:\tlearn: 3990.0231812\ttotal: 126ms\tremaining: 0us\n",
      "0:\tlearn: 4515.8465441\ttotal: 26.5ms\tremaining: 371ms\n",
      "1:\tlearn: 4425.5376851\ttotal: 34.8ms\tremaining: 226ms\n",
      "2:\tlearn: 4350.4376436\ttotal: 43.3ms\tremaining: 173ms\n",
      "3:\tlearn: 4288.7159466\ttotal: 52ms\tremaining: 143ms\n",
      "4:\tlearn: 4238.8587822\ttotal: 60.3ms\tremaining: 121ms\n",
      "5:\tlearn: 4196.8026053\ttotal: 69.2ms\tremaining: 104ms\n",
      "6:\tlearn: 4161.4192928\ttotal: 77.2ms\tremaining: 88.2ms\n",
      "7:\tlearn: 4128.9610245\ttotal: 85.6ms\tremaining: 74.9ms\n",
      "8:\tlearn: 4104.3475350\ttotal: 93.2ms\tremaining: 62.2ms\n",
      "9:\tlearn: 4073.3849216\ttotal: 101ms\tremaining: 50.7ms\n",
      "10:\tlearn: 4055.3532696\ttotal: 109ms\tremaining: 39.6ms\n",
      "11:\tlearn: 4038.6363955\ttotal: 117ms\tremaining: 29.3ms\n",
      "12:\tlearn: 4022.3071081\ttotal: 126ms\tremaining: 19.4ms\n",
      "13:\tlearn: 4007.4581023\ttotal: 134ms\tremaining: 9.6ms\n",
      "14:\tlearn: 3988.0133171\ttotal: 143ms\tremaining: 0us\n",
      "0:\tlearn: 4511.1938071\ttotal: 9.62ms\tremaining: 135ms\n",
      "1:\tlearn: 4420.8147629\ttotal: 17.6ms\tremaining: 114ms\n",
      "2:\tlearn: 4345.5041615\ttotal: 26.2ms\tremaining: 105ms\n",
      "3:\tlearn: 4283.6866582\ttotal: 34.1ms\tremaining: 93.9ms\n",
      "4:\tlearn: 4233.9298307\ttotal: 42.3ms\tremaining: 84.5ms\n",
      "5:\tlearn: 4191.7934978\ttotal: 50ms\tremaining: 75.1ms\n",
      "6:\tlearn: 4156.4989968\ttotal: 58.3ms\tremaining: 66.7ms\n",
      "7:\tlearn: 4124.0638433\ttotal: 66.9ms\tremaining: 58.6ms\n",
      "8:\tlearn: 4099.6873520\ttotal: 74.9ms\tremaining: 49.9ms\n",
      "9:\tlearn: 4068.6471426\ttotal: 83.5ms\tremaining: 41.8ms\n",
      "10:\tlearn: 4050.4186739\ttotal: 91.5ms\tremaining: 33.3ms\n",
      "11:\tlearn: 4035.8581227\ttotal: 99.2ms\tremaining: 24.8ms\n",
      "12:\tlearn: 4019.6802474\ttotal: 107ms\tremaining: 16.4ms\n",
      "13:\tlearn: 4004.9189631\ttotal: 115ms\tremaining: 8.24ms\n",
      "14:\tlearn: 3985.4599555\ttotal: 123ms\tremaining: 0us\n",
      "0:\tlearn: 4614.9702257\ttotal: 9.44ms\tremaining: 179ms\n",
      "1:\tlearn: 4603.9181521\ttotal: 17.7ms\tremaining: 160ms\n",
      "2:\tlearn: 4592.9956013\ttotal: 27.2ms\tremaining: 154ms\n",
      "3:\tlearn: 4582.2639861\ttotal: 36ms\tremaining: 144ms\n",
      "4:\tlearn: 4571.7627772\ttotal: 44.4ms\tremaining: 133ms\n",
      "5:\tlearn: 4561.4881886\ttotal: 52.3ms\tremaining: 122ms\n",
      "6:\tlearn: 4551.3920948\ttotal: 59.9ms\tremaining: 111ms\n",
      "7:\tlearn: 4541.3837436\ttotal: 68.1ms\tremaining: 102ms\n",
      "8:\tlearn: 4531.6809957\ttotal: 75.7ms\tremaining: 92.5ms\n",
      "9:\tlearn: 4521.9277066\ttotal: 83.8ms\tremaining: 83.8ms\n",
      "10:\tlearn: 4512.4207956\ttotal: 91.5ms\tremaining: 74.9ms\n",
      "11:\tlearn: 4503.2428379\ttotal: 99.7ms\tremaining: 66.5ms\n",
      "12:\tlearn: 4494.1860730\ttotal: 108ms\tremaining: 57.9ms\n",
      "13:\tlearn: 4485.1796629\ttotal: 115ms\tremaining: 49.5ms\n",
      "14:\tlearn: 4476.3092831\ttotal: 123ms\tremaining: 41.2ms\n",
      "15:\tlearn: 4467.7310424\ttotal: 132ms\tremaining: 32.9ms\n",
      "16:\tlearn: 4459.2600366\ttotal: 140ms\tremaining: 24.7ms\n",
      "17:\tlearn: 4450.9985521\ttotal: 149ms\tremaining: 16.5ms\n",
      "18:\tlearn: 4442.7774446\ttotal: 157ms\tremaining: 8.24ms\n",
      "19:\tlearn: 4434.6643497\ttotal: 164ms\tremaining: 0us\n",
      "0:\tlearn: 4606.1325331\ttotal: 8.7ms\tremaining: 165ms\n",
      "1:\tlearn: 4595.0166923\ttotal: 17.3ms\tremaining: 155ms\n",
      "2:\tlearn: 4584.1094943\ttotal: 26.8ms\tremaining: 152ms\n",
      "3:\tlearn: 4573.4092189\ttotal: 34.9ms\tremaining: 140ms\n",
      "4:\tlearn: 4562.9411944\ttotal: 42.9ms\tremaining: 129ms\n",
      "5:\tlearn: 4552.7182571\ttotal: 51.1ms\tremaining: 119ms\n",
      "6:\tlearn: 4542.6476872\ttotal: 59.1ms\tremaining: 110ms\n",
      "7:\tlearn: 4532.6652104\ttotal: 67.7ms\tremaining: 101ms\n",
      "8:\tlearn: 4522.9885759\ttotal: 76.3ms\tremaining: 93.3ms\n",
      "9:\tlearn: 4513.2683897\ttotal: 84.8ms\tremaining: 84.8ms\n",
      "10:\tlearn: 4503.8028749\ttotal: 93.6ms\tremaining: 76.6ms\n",
      "11:\tlearn: 4494.6380821\ttotal: 102ms\tremaining: 67.8ms\n",
      "12:\tlearn: 4485.6052864\ttotal: 110ms\tremaining: 59.2ms\n",
      "13:\tlearn: 4476.6460836\ttotal: 118ms\tremaining: 50.4ms\n",
      "14:\tlearn: 4467.8183125\ttotal: 126ms\tremaining: 42ms\n",
      "15:\tlearn: 4459.2737786\ttotal: 134ms\tremaining: 33.5ms\n",
      "16:\tlearn: 4450.8071534\ttotal: 142ms\tremaining: 25.1ms\n",
      "17:\tlearn: 4442.4717185\ttotal: 151ms\tremaining: 16.8ms\n",
      "18:\tlearn: 4434.2831614\ttotal: 159ms\tremaining: 8.38ms\n",
      "19:\tlearn: 4426.2094882\ttotal: 168ms\tremaining: 0us\n",
      "0:\tlearn: 4617.1122664\ttotal: 20.4ms\tremaining: 387ms\n",
      "1:\tlearn: 4606.0037914\ttotal: 29.5ms\tremaining: 266ms\n",
      "2:\tlearn: 4595.0861854\ttotal: 38ms\tremaining: 216ms\n",
      "3:\tlearn: 4584.3992202\ttotal: 47.1ms\tremaining: 189ms\n",
      "4:\tlearn: 4573.9187737\ttotal: 55.4ms\tremaining: 166ms\n",
      "5:\tlearn: 4563.7034685\ttotal: 64.9ms\tremaining: 151ms\n",
      "6:\tlearn: 4553.6409174\ttotal: 73.2ms\tremaining: 136ms\n",
      "7:\tlearn: 4543.6688733\ttotal: 81.5ms\tremaining: 122ms\n",
      "8:\tlearn: 4533.9905149\ttotal: 89.8ms\tremaining: 110ms\n",
      "9:\tlearn: 4524.3789273\ttotal: 98.2ms\tremaining: 98.2ms\n",
      "10:\tlearn: 4514.9085141\ttotal: 106ms\tremaining: 87ms\n",
      "11:\tlearn: 4505.7563605\ttotal: 115ms\tremaining: 76.4ms\n",
      "12:\tlearn: 4496.7211315\ttotal: 124ms\tremaining: 66.6ms\n",
      "13:\tlearn: 4487.7536614\ttotal: 132ms\tremaining: 56.4ms\n",
      "14:\tlearn: 4478.9177356\ttotal: 140ms\tremaining: 46.8ms\n",
      "15:\tlearn: 4470.3743444\ttotal: 149ms\tremaining: 37.2ms\n",
      "16:\tlearn: 4461.9142575\ttotal: 157ms\tremaining: 27.7ms\n",
      "17:\tlearn: 4453.6764807\ttotal: 165ms\tremaining: 18.4ms\n",
      "18:\tlearn: 4445.4612014\ttotal: 173ms\tremaining: 9.12ms\n",
      "19:\tlearn: 4437.3770392\ttotal: 181ms\tremaining: 0us\n",
      "0:\tlearn: 4612.7014908\ttotal: 9.56ms\tremaining: 182ms\n",
      "1:\tlearn: 4601.6421867\ttotal: 18.8ms\tremaining: 169ms\n",
      "2:\tlearn: 4590.7726968\ttotal: 26.9ms\tremaining: 152ms\n",
      "3:\tlearn: 4580.0967198\ttotal: 35.1ms\tremaining: 141ms\n",
      "4:\tlearn: 4569.6918991\ttotal: 43.2ms\tremaining: 130ms\n",
      "5:\tlearn: 4559.5210580\ttotal: 51.4ms\tremaining: 120ms\n",
      "6:\tlearn: 4549.4998933\ttotal: 59.5ms\tremaining: 110ms\n",
      "7:\tlearn: 4539.6154138\ttotal: 67.5ms\tremaining: 101ms\n",
      "8:\tlearn: 4529.9925557\ttotal: 75.6ms\tremaining: 92.4ms\n",
      "9:\tlearn: 4520.4300992\ttotal: 83.4ms\tremaining: 83.4ms\n",
      "10:\tlearn: 4511.0020272\ttotal: 91.6ms\tremaining: 74.9ms\n",
      "11:\tlearn: 4501.8930276\ttotal: 99.9ms\tremaining: 66.6ms\n",
      "12:\tlearn: 4492.9068930\ttotal: 108ms\tremaining: 57.9ms\n",
      "13:\tlearn: 4483.9885476\ttotal: 115ms\tremaining: 49.5ms\n",
      "14:\tlearn: 4475.1973305\ttotal: 123ms\tremaining: 41ms\n",
      "15:\tlearn: 4466.6615860\ttotal: 131ms\tremaining: 32.8ms\n",
      "16:\tlearn: 4458.2438452\ttotal: 139ms\tremaining: 24.5ms\n",
      "17:\tlearn: 4450.0727051\ttotal: 147ms\tremaining: 16.3ms\n",
      "18:\tlearn: 4441.9142557\ttotal: 155ms\tremaining: 8.15ms\n",
      "19:\tlearn: 4434.0000162\ttotal: 163ms\tremaining: 0us\n",
      "0:\tlearn: 4607.9914319\ttotal: 9.68ms\tremaining: 184ms\n",
      "1:\tlearn: 4596.9279651\ttotal: 18.3ms\tremaining: 164ms\n",
      "2:\tlearn: 4586.0366806\ttotal: 27.3ms\tremaining: 154ms\n",
      "3:\tlearn: 4575.3504743\ttotal: 35.7ms\tremaining: 143ms\n",
      "4:\tlearn: 4564.9077039\ttotal: 44.3ms\tremaining: 133ms\n",
      "5:\tlearn: 4554.7317874\ttotal: 52.6ms\tremaining: 123ms\n",
      "6:\tlearn: 4544.7093443\ttotal: 60.9ms\tremaining: 113ms\n",
      "7:\tlearn: 4534.7905038\ttotal: 69.2ms\tremaining: 104ms\n",
      "8:\tlearn: 4525.1466516\ttotal: 77.2ms\tremaining: 94.4ms\n",
      "9:\tlearn: 4515.5662953\ttotal: 85.7ms\tremaining: 85.7ms\n",
      "10:\tlearn: 4506.1274662\ttotal: 93.1ms\tremaining: 76.2ms\n",
      "11:\tlearn: 4497.0027754\ttotal: 101ms\tremaining: 67.6ms\n",
      "12:\tlearn: 4488.0012174\ttotal: 110ms\tremaining: 59.3ms\n",
      "13:\tlearn: 4479.0699577\ttotal: 119ms\tremaining: 50.9ms\n",
      "14:\tlearn: 4470.2878576\ttotal: 126ms\tremaining: 42.1ms\n",
      "15:\tlearn: 4461.7763013\ttotal: 134ms\tremaining: 33.6ms\n",
      "16:\tlearn: 4453.3512972\ttotal: 142ms\tremaining: 25ms\n",
      "17:\tlearn: 4445.1420599\ttotal: 150ms\tremaining: 16.7ms\n",
      "18:\tlearn: 4436.9575368\ttotal: 157ms\tremaining: 8.28ms\n",
      "19:\tlearn: 4429.0276204\ttotal: 165ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4570.6341150\ttotal: 9.04ms\tremaining: 172ms\n",
      "1:\tlearn: 4519.9527683\ttotal: 17.5ms\tremaining: 158ms\n",
      "2:\tlearn: 4473.1986005\ttotal: 25.9ms\tremaining: 147ms\n",
      "3:\tlearn: 4430.4296288\ttotal: 34.5ms\tremaining: 138ms\n",
      "4:\tlearn: 4391.7814816\ttotal: 43.1ms\tremaining: 129ms\n",
      "5:\tlearn: 4356.5860792\ttotal: 51.5ms\tremaining: 120ms\n",
      "6:\tlearn: 4324.4756461\ttotal: 59.1ms\tremaining: 110ms\n",
      "7:\tlearn: 4295.1692439\ttotal: 67.2ms\tremaining: 101ms\n",
      "8:\tlearn: 4268.6338529\ttotal: 75.3ms\tremaining: 92ms\n",
      "9:\tlearn: 4243.6480376\ttotal: 82.9ms\tremaining: 82.9ms\n",
      "10:\tlearn: 4221.1848121\ttotal: 91ms\tremaining: 74.5ms\n",
      "11:\tlearn: 4200.8734512\ttotal: 99ms\tremaining: 66ms\n",
      "12:\tlearn: 4181.6727934\ttotal: 107ms\tremaining: 57.7ms\n",
      "13:\tlearn: 4163.7146684\ttotal: 116ms\tremaining: 49.8ms\n",
      "14:\tlearn: 4147.7748044\ttotal: 125ms\tremaining: 41.6ms\n",
      "15:\tlearn: 4133.0168443\ttotal: 133ms\tremaining: 33.3ms\n",
      "16:\tlearn: 4115.3985085\ttotal: 142ms\tremaining: 25.1ms\n",
      "17:\tlearn: 4102.9207312\ttotal: 150ms\tremaining: 16.7ms\n",
      "18:\tlearn: 4091.5345577\ttotal: 159ms\tremaining: 8.36ms\n",
      "19:\tlearn: 4080.9617852\ttotal: 167ms\tremaining: 0us\n",
      "0:\tlearn: 4562.0062229\ttotal: 9.84ms\tremaining: 187ms\n",
      "1:\tlearn: 4511.0473621\ttotal: 18ms\tremaining: 162ms\n",
      "2:\tlearn: 4464.4068918\ttotal: 26.3ms\tremaining: 149ms\n",
      "3:\tlearn: 4421.9138520\ttotal: 34.8ms\tremaining: 139ms\n",
      "4:\tlearn: 4383.4194241\ttotal: 43.2ms\tremaining: 130ms\n",
      "5:\tlearn: 4348.4362764\ttotal: 51.6ms\tremaining: 120ms\n",
      "6:\tlearn: 4316.3176825\ttotal: 59.6ms\tremaining: 111ms\n",
      "7:\tlearn: 4286.9855625\ttotal: 67.5ms\tremaining: 101ms\n",
      "8:\tlearn: 4260.5197739\ttotal: 75.3ms\tremaining: 92ms\n",
      "9:\tlearn: 4235.7342798\ttotal: 83.4ms\tremaining: 83.4ms\n",
      "10:\tlearn: 4213.3346657\ttotal: 91.4ms\tremaining: 74.8ms\n",
      "11:\tlearn: 4193.4173481\ttotal: 99.6ms\tremaining: 66.4ms\n",
      "12:\tlearn: 4174.3332787\ttotal: 108ms\tremaining: 58.1ms\n",
      "13:\tlearn: 4157.7552027\ttotal: 116ms\tremaining: 49.5ms\n",
      "14:\tlearn: 4142.0796807\ttotal: 123ms\tremaining: 41.1ms\n",
      "15:\tlearn: 4127.3709182\ttotal: 132ms\tremaining: 32.9ms\n",
      "16:\tlearn: 4109.9471846\ttotal: 140ms\tremaining: 24.7ms\n",
      "17:\tlearn: 4098.1490863\ttotal: 148ms\tremaining: 16.5ms\n",
      "18:\tlearn: 4086.9991744\ttotal: 156ms\tremaining: 8.23ms\n",
      "19:\tlearn: 4076.7312402\ttotal: 165ms\tremaining: 0us\n",
      "0:\tlearn: 4572.9458872\ttotal: 8.53ms\tremaining: 162ms\n",
      "1:\tlearn: 4522.0387745\ttotal: 17.2ms\tremaining: 154ms\n",
      "2:\tlearn: 4475.4481720\ttotal: 26.1ms\tremaining: 148ms\n",
      "3:\tlearn: 4433.0062896\ttotal: 34.4ms\tremaining: 137ms\n",
      "4:\tlearn: 4394.4786296\ttotal: 42.5ms\tremaining: 128ms\n",
      "5:\tlearn: 4359.5387191\ttotal: 51ms\tremaining: 119ms\n",
      "6:\tlearn: 4327.4476794\ttotal: 59.1ms\tremaining: 110ms\n",
      "7:\tlearn: 4298.1528006\ttotal: 66.9ms\tremaining: 100ms\n",
      "8:\tlearn: 4271.6684631\ttotal: 74.9ms\tremaining: 91.6ms\n",
      "9:\tlearn: 4246.9142193\ttotal: 83ms\tremaining: 83ms\n",
      "10:\tlearn: 4224.5801269\ttotal: 91.3ms\tremaining: 74.7ms\n",
      "11:\tlearn: 4204.4722205\ttotal: 99ms\tremaining: 66ms\n",
      "12:\tlearn: 4185.2529885\ttotal: 108ms\tremaining: 57.9ms\n",
      "13:\tlearn: 4168.1052937\ttotal: 116ms\tremaining: 49.8ms\n",
      "14:\tlearn: 4152.3339735\ttotal: 124ms\tremaining: 41.4ms\n",
      "15:\tlearn: 4137.6328519\ttotal: 132ms\tremaining: 33.1ms\n",
      "16:\tlearn: 4119.8491327\ttotal: 141ms\tremaining: 24.9ms\n",
      "17:\tlearn: 4107.9952202\ttotal: 149ms\tremaining: 16.6ms\n",
      "18:\tlearn: 4096.6185432\ttotal: 158ms\tremaining: 8.29ms\n",
      "19:\tlearn: 4086.4049035\ttotal: 166ms\tremaining: 0us\n",
      "0:\tlearn: 4568.7747666\ttotal: 8.99ms\tremaining: 171ms\n",
      "1:\tlearn: 4518.0917385\ttotal: 17.6ms\tremaining: 159ms\n",
      "2:\tlearn: 4471.7079821\ttotal: 26.3ms\tremaining: 149ms\n",
      "3:\tlearn: 4429.4520093\ttotal: 34.1ms\tremaining: 137ms\n",
      "4:\tlearn: 4391.2397060\ttotal: 42.4ms\tremaining: 127ms\n",
      "5:\tlearn: 4356.4597144\ttotal: 51ms\tremaining: 119ms\n",
      "6:\tlearn: 4324.5030071\ttotal: 59.2ms\tremaining: 110ms\n",
      "7:\tlearn: 4295.3206305\ttotal: 67.2ms\tremaining: 101ms\n",
      "8:\tlearn: 4269.0199787\ttotal: 75.5ms\tremaining: 92.2ms\n",
      "9:\tlearn: 4244.3901790\ttotal: 83.5ms\tremaining: 83.5ms\n",
      "10:\tlearn: 4222.1299041\ttotal: 91ms\tremaining: 74.5ms\n",
      "11:\tlearn: 4202.0140825\ttotal: 99.1ms\tremaining: 66ms\n",
      "12:\tlearn: 4182.8964659\ttotal: 107ms\tremaining: 57.7ms\n",
      "13:\tlearn: 4166.3638786\ttotal: 115ms\tremaining: 49.4ms\n",
      "14:\tlearn: 4150.8095305\ttotal: 123ms\tremaining: 41ms\n",
      "15:\tlearn: 4136.1499011\ttotal: 131ms\tremaining: 32.8ms\n",
      "16:\tlearn: 4118.7891980\ttotal: 139ms\tremaining: 24.6ms\n",
      "17:\tlearn: 4107.0902435\ttotal: 147ms\tremaining: 16.4ms\n",
      "18:\tlearn: 4095.7970857\ttotal: 155ms\tremaining: 8.18ms\n",
      "19:\tlearn: 4085.7836705\ttotal: 164ms\tremaining: 0us\n",
      "0:\tlearn: 4564.0906121\ttotal: 9.07ms\tremaining: 172ms\n",
      "1:\tlearn: 4513.3798903\ttotal: 16.9ms\tremaining: 152ms\n",
      "2:\tlearn: 4466.8877844\ttotal: 24.8ms\tremaining: 141ms\n",
      "3:\tlearn: 4424.5807839\ttotal: 33.1ms\tremaining: 132ms\n",
      "4:\tlearn: 4386.1986075\ttotal: 41.4ms\tremaining: 124ms\n",
      "5:\tlearn: 4351.3978057\ttotal: 49.8ms\tremaining: 116ms\n",
      "6:\tlearn: 4319.4573072\ttotal: 57.7ms\tremaining: 107ms\n",
      "7:\tlearn: 4290.0765247\ttotal: 66ms\tremaining: 99ms\n",
      "8:\tlearn: 4263.6991164\ttotal: 73.5ms\tremaining: 89.9ms\n",
      "9:\tlearn: 4239.1167832\ttotal: 81.8ms\tremaining: 81.8ms\n",
      "10:\tlearn: 4216.8981591\ttotal: 89.5ms\tremaining: 73.2ms\n",
      "11:\tlearn: 4196.7959542\ttotal: 97.6ms\tremaining: 65.1ms\n",
      "12:\tlearn: 4177.6580621\ttotal: 106ms\tremaining: 56.9ms\n",
      "13:\tlearn: 4161.1228885\ttotal: 114ms\tremaining: 48.8ms\n",
      "14:\tlearn: 4145.7215229\ttotal: 122ms\tremaining: 40.6ms\n",
      "15:\tlearn: 4131.1039341\ttotal: 130ms\tremaining: 32.5ms\n",
      "16:\tlearn: 4113.3394830\ttotal: 138ms\tremaining: 24.4ms\n",
      "17:\tlearn: 4101.6123959\ttotal: 146ms\tremaining: 16.3ms\n",
      "18:\tlearn: 4090.3031927\ttotal: 155ms\tremaining: 8.14ms\n",
      "19:\tlearn: 4080.2207229\ttotal: 163ms\tremaining: 0us\n",
      "0:\tlearn: 4517.2076857\ttotal: 8.86ms\tremaining: 168ms\n",
      "1:\tlearn: 4426.8207368\ttotal: 17.2ms\tremaining: 155ms\n",
      "2:\tlearn: 4351.0563959\ttotal: 26.2ms\tremaining: 148ms\n",
      "3:\tlearn: 4288.2352083\ttotal: 34.6ms\tremaining: 138ms\n",
      "4:\tlearn: 4237.6395912\ttotal: 43ms\tremaining: 129ms\n",
      "5:\tlearn: 4194.9615942\ttotal: 51.4ms\tremaining: 120ms\n",
      "6:\tlearn: 4159.7053819\ttotal: 59.6ms\tremaining: 111ms\n",
      "7:\tlearn: 4127.0193159\ttotal: 67.8ms\tremaining: 102ms\n",
      "8:\tlearn: 4100.8118397\ttotal: 75.9ms\tremaining: 92.7ms\n",
      "9:\tlearn: 4069.1249168\ttotal: 84.1ms\tremaining: 84.1ms\n",
      "10:\tlearn: 4050.7297716\ttotal: 92.4ms\tremaining: 75.6ms\n",
      "11:\tlearn: 4033.8279861\ttotal: 100ms\tremaining: 66.8ms\n",
      "12:\tlearn: 4017.5854271\ttotal: 109ms\tremaining: 58.6ms\n",
      "13:\tlearn: 3996.6413888\ttotal: 117ms\tremaining: 50.2ms\n",
      "14:\tlearn: 3985.7184519\ttotal: 125ms\tremaining: 41.7ms\n",
      "15:\tlearn: 3972.7915496\ttotal: 134ms\tremaining: 33.4ms\n",
      "16:\tlearn: 3959.5095412\ttotal: 142ms\tremaining: 25.1ms\n",
      "17:\tlearn: 3951.7850424\ttotal: 151ms\tremaining: 16.7ms\n",
      "18:\tlearn: 3943.8847953\ttotal: 159ms\tremaining: 8.35ms\n",
      "19:\tlearn: 3934.6467683\ttotal: 168ms\tremaining: 0us\n",
      "0:\tlearn: 4508.8340649\ttotal: 10ms\tremaining: 190ms\n",
      "1:\tlearn: 4417.9933052\ttotal: 18.5ms\tremaining: 166ms\n",
      "2:\tlearn: 4342.4463393\ttotal: 26.6ms\tremaining: 151ms\n",
      "3:\tlearn: 4280.3418963\ttotal: 35.2ms\tremaining: 141ms\n",
      "4:\tlearn: 4230.2124690\ttotal: 43.7ms\tremaining: 131ms\n",
      "5:\tlearn: 4187.8623123\ttotal: 52.3ms\tremaining: 122ms\n",
      "6:\tlearn: 4152.3066749\ttotal: 61.1ms\tremaining: 114ms\n",
      "7:\tlearn: 4119.9635433\ttotal: 69.5ms\tremaining: 104ms\n",
      "8:\tlearn: 4095.1627725\ttotal: 77.4ms\tremaining: 94.6ms\n",
      "9:\tlearn: 4064.0626552\ttotal: 85.4ms\tremaining: 85.4ms\n",
      "10:\tlearn: 4045.7667873\ttotal: 93.4ms\tremaining: 76.4ms\n",
      "11:\tlearn: 4030.5156198\ttotal: 101ms\tremaining: 67.3ms\n",
      "12:\tlearn: 4014.3341976\ttotal: 109ms\tremaining: 58.9ms\n",
      "13:\tlearn: 3999.5969351\ttotal: 118ms\tremaining: 50.5ms\n",
      "14:\tlearn: 3980.1798188\ttotal: 126ms\tremaining: 42.1ms\n",
      "15:\tlearn: 3968.6536625\ttotal: 134ms\tremaining: 33.6ms\n",
      "16:\tlearn: 3957.7693683\ttotal: 142ms\tremaining: 25.1ms\n",
      "17:\tlearn: 3948.6479875\ttotal: 150ms\tremaining: 16.7ms\n",
      "18:\tlearn: 3940.3888641\ttotal: 159ms\tremaining: 8.35ms\n",
      "19:\tlearn: 3926.6696956\ttotal: 167ms\tremaining: 0us\n",
      "0:\tlearn: 4519.7264643\ttotal: 9.43ms\tremaining: 179ms\n",
      "1:\tlearn: 4429.7087225\ttotal: 19.1ms\tremaining: 172ms\n",
      "2:\tlearn: 4354.1609120\ttotal: 28.5ms\tremaining: 161ms\n",
      "3:\tlearn: 4291.6078067\ttotal: 37.4ms\tremaining: 150ms\n",
      "4:\tlearn: 4241.1073938\ttotal: 46.2ms\tremaining: 138ms\n",
      "5:\tlearn: 4198.8653020\ttotal: 55.1ms\tremaining: 129ms\n",
      "6:\tlearn: 4163.8257978\ttotal: 63.2ms\tremaining: 117ms\n",
      "7:\tlearn: 4131.3760559\ttotal: 71.8ms\tremaining: 108ms\n",
      "8:\tlearn: 4105.2711726\ttotal: 80.2ms\tremaining: 98.1ms\n",
      "9:\tlearn: 4073.6773944\ttotal: 88.6ms\tremaining: 88.6ms\n",
      "10:\tlearn: 4055.3821974\ttotal: 96.5ms\tremaining: 79ms\n",
      "11:\tlearn: 4038.3354609\ttotal: 104ms\tremaining: 69.6ms\n",
      "12:\tlearn: 4022.3286314\ttotal: 113ms\tremaining: 60.8ms\n",
      "13:\tlearn: 4009.3327479\ttotal: 121ms\tremaining: 51.9ms\n",
      "14:\tlearn: 3990.0231812\ttotal: 130ms\tremaining: 43.2ms\n",
      "15:\tlearn: 3979.3962818\ttotal: 138ms\tremaining: 34.4ms\n",
      "16:\tlearn: 3967.6723342\ttotal: 146ms\tremaining: 25.8ms\n",
      "17:\tlearn: 3957.4174630\ttotal: 154ms\tremaining: 17.2ms\n",
      "18:\tlearn: 3948.9759870\ttotal: 163ms\tremaining: 8.56ms\n",
      "19:\tlearn: 3940.0154704\ttotal: 171ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4515.8465441\ttotal: 8.65ms\tremaining: 164ms\n",
      "1:\tlearn: 4425.5376851\ttotal: 17.4ms\tremaining: 157ms\n",
      "2:\tlearn: 4350.4376436\ttotal: 27.3ms\tremaining: 155ms\n",
      "3:\tlearn: 4288.7159466\ttotal: 36.3ms\tremaining: 145ms\n",
      "4:\tlearn: 4238.8587822\ttotal: 44.7ms\tremaining: 134ms\n",
      "5:\tlearn: 4196.8026053\ttotal: 52.6ms\tremaining: 123ms\n",
      "6:\tlearn: 4161.4192928\ttotal: 61.3ms\tremaining: 114ms\n",
      "7:\tlearn: 4128.9610245\ttotal: 70.5ms\tremaining: 106ms\n",
      "8:\tlearn: 4104.3475350\ttotal: 78.7ms\tremaining: 96.2ms\n",
      "9:\tlearn: 4073.3849216\ttotal: 86.9ms\tremaining: 86.9ms\n",
      "10:\tlearn: 4055.3532696\ttotal: 94.8ms\tremaining: 77.6ms\n",
      "11:\tlearn: 4038.6363955\ttotal: 103ms\tremaining: 68.4ms\n",
      "12:\tlearn: 4022.3071081\ttotal: 111ms\tremaining: 59.7ms\n",
      "13:\tlearn: 4007.4581023\ttotal: 120ms\tremaining: 51.2ms\n",
      "14:\tlearn: 3988.0133171\ttotal: 128ms\tremaining: 42.8ms\n",
      "15:\tlearn: 3978.4528488\ttotal: 137ms\tremaining: 34.2ms\n",
      "16:\tlearn: 3965.9978183\ttotal: 146ms\tremaining: 25.8ms\n",
      "17:\tlearn: 3954.5141591\ttotal: 155ms\tremaining: 17.2ms\n",
      "18:\tlearn: 3946.2365892\ttotal: 163ms\tremaining: 8.58ms\n",
      "19:\tlearn: 3932.4799643\ttotal: 171ms\tremaining: 0us\n",
      "0:\tlearn: 4511.1938071\ttotal: 9.64ms\tremaining: 183ms\n",
      "1:\tlearn: 4420.8147629\ttotal: 18.2ms\tremaining: 164ms\n",
      "2:\tlearn: 4345.5041615\ttotal: 26.6ms\tremaining: 151ms\n",
      "3:\tlearn: 4283.6866582\ttotal: 34.3ms\tremaining: 137ms\n",
      "4:\tlearn: 4233.9298307\ttotal: 42.7ms\tremaining: 128ms\n",
      "5:\tlearn: 4191.7934978\ttotal: 51ms\tremaining: 119ms\n",
      "6:\tlearn: 4156.4989968\ttotal: 59.2ms\tremaining: 110ms\n",
      "7:\tlearn: 4124.0638433\ttotal: 67.6ms\tremaining: 101ms\n",
      "8:\tlearn: 4099.6873520\ttotal: 75.6ms\tremaining: 92.5ms\n",
      "9:\tlearn: 4068.6471426\ttotal: 83.9ms\tremaining: 83.9ms\n",
      "10:\tlearn: 4050.4186739\ttotal: 92.1ms\tremaining: 75.4ms\n",
      "11:\tlearn: 4035.8581227\ttotal: 100ms\tremaining: 66.7ms\n",
      "12:\tlearn: 4019.6802474\ttotal: 108ms\tremaining: 58.2ms\n",
      "13:\tlearn: 4004.9189631\ttotal: 116ms\tremaining: 49.9ms\n",
      "14:\tlearn: 3985.4599555\ttotal: 124ms\tremaining: 41.4ms\n",
      "15:\tlearn: 3974.4773562\ttotal: 133ms\tremaining: 33.1ms\n",
      "16:\tlearn: 3962.1384252\ttotal: 141ms\tremaining: 24.9ms\n",
      "17:\tlearn: 3953.4928699\ttotal: 150ms\tremaining: 16.6ms\n",
      "18:\tlearn: 3945.8767414\ttotal: 157ms\tremaining: 8.27ms\n",
      "19:\tlearn: 3936.8149823\ttotal: 166ms\tremaining: 0us\n",
      "0:\tlearn: 4614.2267597\ttotal: 11.9ms\tremaining: 107ms\n",
      "1:\tlearn: 4602.2389917\ttotal: 24ms\tremaining: 96ms\n",
      "2:\tlearn: 4590.6780712\ttotal: 35.5ms\tremaining: 82.9ms\n",
      "3:\tlearn: 4579.3107729\ttotal: 46.5ms\tremaining: 69.8ms\n",
      "4:\tlearn: 4568.0505190\ttotal: 57.9ms\tremaining: 57.9ms\n",
      "5:\tlearn: 4557.1335700\ttotal: 69ms\tremaining: 46ms\n",
      "6:\tlearn: 4546.6171677\ttotal: 79.9ms\tremaining: 34.2ms\n",
      "7:\tlearn: 4536.0863325\ttotal: 90.8ms\tremaining: 22.7ms\n",
      "8:\tlearn: 4525.6886592\ttotal: 101ms\tremaining: 11.2ms\n",
      "9:\tlearn: 4515.7142586\ttotal: 111ms\tremaining: 0us\n",
      "0:\tlearn: 4605.5964364\ttotal: 12.1ms\tremaining: 108ms\n",
      "1:\tlearn: 4593.8869639\ttotal: 23ms\tremaining: 92.1ms\n",
      "2:\tlearn: 4582.3532202\ttotal: 34.9ms\tremaining: 81.5ms\n",
      "3:\tlearn: 4570.4259566\ttotal: 46.8ms\tremaining: 70.1ms\n",
      "4:\tlearn: 4559.1771392\ttotal: 58.1ms\tremaining: 58.1ms\n",
      "5:\tlearn: 4548.2936556\ttotal: 69.7ms\tremaining: 46.4ms\n",
      "6:\tlearn: 4537.7773682\ttotal: 80.6ms\tremaining: 34.5ms\n",
      "7:\tlearn: 4527.2787663\ttotal: 90.9ms\tremaining: 22.7ms\n",
      "8:\tlearn: 4516.8925685\ttotal: 102ms\tremaining: 11.3ms\n",
      "9:\tlearn: 4506.8565943\ttotal: 112ms\tremaining: 0us\n",
      "0:\tlearn: 4616.5010504\ttotal: 11.9ms\tremaining: 107ms\n",
      "1:\tlearn: 4604.7532697\ttotal: 22.1ms\tremaining: 88.3ms\n",
      "2:\tlearn: 4593.3708750\ttotal: 32.8ms\tremaining: 76.4ms\n",
      "3:\tlearn: 4582.2540818\ttotal: 43.8ms\tremaining: 65.6ms\n",
      "4:\tlearn: 4571.0352693\ttotal: 54.5ms\tremaining: 54.5ms\n",
      "5:\tlearn: 4560.2583078\ttotal: 65.5ms\tremaining: 43.6ms\n",
      "6:\tlearn: 4549.7290852\ttotal: 76.5ms\tremaining: 32.8ms\n",
      "7:\tlearn: 4539.2268879\ttotal: 87.5ms\tremaining: 21.9ms\n",
      "8:\tlearn: 4528.8366035\ttotal: 98.8ms\tremaining: 11ms\n",
      "9:\tlearn: 4518.9058206\ttotal: 109ms\tremaining: 0us\n",
      "0:\tlearn: 4612.1597457\ttotal: 17.8ms\tremaining: 161ms\n",
      "1:\tlearn: 4600.4858502\ttotal: 29.1ms\tremaining: 117ms\n",
      "2:\tlearn: 4589.1584858\ttotal: 40.2ms\tremaining: 93.9ms\n",
      "3:\tlearn: 4578.0727004\ttotal: 51.5ms\tremaining: 77.2ms\n",
      "4:\tlearn: 4566.8895558\ttotal: 62.8ms\tremaining: 62.8ms\n",
      "5:\tlearn: 4556.0458911\ttotal: 73.7ms\tremaining: 49.1ms\n",
      "6:\tlearn: 4545.4303625\ttotal: 84.7ms\tremaining: 36.3ms\n",
      "7:\tlearn: 4534.7858288\ttotal: 94.8ms\tremaining: 23.7ms\n",
      "8:\tlearn: 4524.5879806\ttotal: 106ms\tremaining: 11.8ms\n",
      "9:\tlearn: 4514.7114128\ttotal: 117ms\tremaining: 0us\n",
      "0:\tlearn: 4607.3728913\ttotal: 11.7ms\tremaining: 105ms\n",
      "1:\tlearn: 4595.6523212\ttotal: 22.2ms\tremaining: 88.8ms\n",
      "2:\tlearn: 4584.1671346\ttotal: 33.9ms\tremaining: 79.1ms\n",
      "3:\tlearn: 4572.3190838\ttotal: 45.7ms\tremaining: 68.5ms\n",
      "4:\tlearn: 4561.1308626\ttotal: 56.7ms\tremaining: 56.7ms\n",
      "5:\tlearn: 4550.4062567\ttotal: 68ms\tremaining: 45.3ms\n",
      "6:\tlearn: 4539.7847533\ttotal: 79.6ms\tremaining: 34.1ms\n",
      "7:\tlearn: 4529.1091062\ttotal: 90.3ms\tremaining: 22.6ms\n",
      "8:\tlearn: 4518.7488447\ttotal: 101ms\tremaining: 11.3ms\n",
      "9:\tlearn: 4508.8529155\ttotal: 113ms\tremaining: 0us\n",
      "0:\tlearn: 4566.9532639\ttotal: 12.1ms\tremaining: 109ms\n",
      "1:\tlearn: 4512.5890607\ttotal: 22.8ms\tremaining: 91.3ms\n",
      "2:\tlearn: 4462.8720827\ttotal: 34.3ms\tremaining: 79.9ms\n",
      "3:\tlearn: 4417.2576607\ttotal: 45.3ms\tremaining: 67.9ms\n",
      "4:\tlearn: 4375.2018782\ttotal: 57.4ms\tremaining: 57.4ms\n",
      "5:\tlearn: 4337.1352160\ttotal: 68.2ms\tremaining: 45.5ms\n",
      "6:\tlearn: 4298.7927365\ttotal: 79ms\tremaining: 33.8ms\n",
      "7:\tlearn: 4266.6574744\ttotal: 89.7ms\tremaining: 22.4ms\n",
      "8:\tlearn: 4238.3050402\ttotal: 101ms\tremaining: 11.2ms\n",
      "9:\tlearn: 4211.2751036\ttotal: 111ms\tremaining: 0us\n",
      "0:\tlearn: 4559.3518734\ttotal: 20.3ms\tremaining: 182ms\n",
      "1:\tlearn: 4505.3697462\ttotal: 30.5ms\tremaining: 122ms\n",
      "2:\tlearn: 4455.7876810\ttotal: 41.8ms\tremaining: 97.4ms\n",
      "3:\tlearn: 4407.4381912\ttotal: 53.4ms\tremaining: 80.1ms\n",
      "4:\tlearn: 4365.2524589\ttotal: 64.8ms\tremaining: 64.8ms\n",
      "5:\tlearn: 4328.2550665\ttotal: 77.1ms\tremaining: 51.4ms\n",
      "6:\tlearn: 4293.8955546\ttotal: 87.7ms\tremaining: 37.6ms\n",
      "7:\tlearn: 4262.0206525\ttotal: 97.9ms\tremaining: 24.5ms\n",
      "8:\tlearn: 4233.3590644\ttotal: 109ms\tremaining: 12.1ms\n",
      "9:\tlearn: 4206.3136892\ttotal: 119ms\tremaining: 0us\n",
      "0:\tlearn: 4569.9197567\ttotal: 12.3ms\tremaining: 111ms\n",
      "1:\tlearn: 4515.9600609\ttotal: 23.2ms\tremaining: 92.9ms\n",
      "2:\tlearn: 4467.0964160\ttotal: 34ms\tremaining: 79.3ms\n",
      "3:\tlearn: 4422.2502106\ttotal: 45.3ms\tremaining: 68ms\n",
      "4:\tlearn: 4380.4298065\ttotal: 56.4ms\tremaining: 56.4ms\n",
      "5:\tlearn: 4342.7900721\ttotal: 67.7ms\tremaining: 45.1ms\n",
      "6:\tlearn: 4308.8016680\ttotal: 79.2ms\tremaining: 33.9ms\n",
      "7:\tlearn: 4276.7006882\ttotal: 90.3ms\tremaining: 22.6ms\n",
      "8:\tlearn: 4247.2342071\ttotal: 103ms\tremaining: 11.4ms\n",
      "9:\tlearn: 4221.3329355\ttotal: 114ms\tremaining: 0us\n",
      "0:\tlearn: 4566.0926481\ttotal: 10.9ms\tremaining: 97.9ms\n",
      "1:\tlearn: 4512.4658385\ttotal: 21.6ms\tremaining: 86.5ms\n",
      "2:\tlearn: 4463.0659311\ttotal: 32.9ms\tremaining: 76.8ms\n",
      "3:\tlearn: 4415.1708945\ttotal: 43.4ms\tremaining: 65.1ms\n",
      "4:\tlearn: 4373.2717431\ttotal: 55.4ms\tremaining: 55.4ms\n",
      "5:\tlearn: 4335.8592984\ttotal: 65.8ms\tremaining: 43.8ms\n",
      "6:\tlearn: 4300.9914010\ttotal: 76.6ms\tremaining: 32.8ms\n",
      "7:\tlearn: 4269.2090834\ttotal: 88.4ms\tremaining: 22.1ms\n",
      "8:\tlearn: 4241.0448998\ttotal: 99.3ms\tremaining: 11ms\n",
      "9:\tlearn: 4215.1669721\ttotal: 110ms\tremaining: 0us\n",
      "0:\tlearn: 4561.0283361\ttotal: 12ms\tremaining: 108ms\n",
      "1:\tlearn: 4507.0027872\ttotal: 23.7ms\tremaining: 94.9ms\n",
      "2:\tlearn: 4458.3813327\ttotal: 35ms\tremaining: 81.8ms\n",
      "3:\tlearn: 4414.0412016\ttotal: 46.1ms\tremaining: 69.1ms\n",
      "4:\tlearn: 4372.3993501\ttotal: 56.9ms\tremaining: 56.9ms\n",
      "5:\tlearn: 4334.6532826\ttotal: 67.5ms\tremaining: 45ms\n",
      "6:\tlearn: 4300.0994929\ttotal: 78.8ms\tremaining: 33.8ms\n",
      "7:\tlearn: 4268.0567302\ttotal: 89.8ms\tremaining: 22.5ms\n",
      "8:\tlearn: 4239.5903493\ttotal: 100ms\tremaining: 11.1ms\n",
      "9:\tlearn: 4213.7005935\ttotal: 110ms\tremaining: 0us\n",
      "0:\tlearn: 4509.9425451\ttotal: 11.8ms\tremaining: 106ms\n",
      "1:\tlearn: 4412.2365564\ttotal: 22.6ms\tremaining: 90.4ms\n",
      "2:\tlearn: 4330.9114892\ttotal: 33.9ms\tremaining: 79.1ms\n",
      "3:\tlearn: 4266.0989266\ttotal: 44.8ms\tremaining: 67.1ms\n",
      "4:\tlearn: 4208.7094854\ttotal: 55.9ms\tremaining: 55.9ms\n",
      "5:\tlearn: 4161.9707224\ttotal: 67.2ms\tremaining: 44.8ms\n",
      "6:\tlearn: 4115.5774488\ttotal: 78.3ms\tremaining: 33.5ms\n",
      "7:\tlearn: 4076.0618186\ttotal: 88.8ms\tremaining: 22.2ms\n",
      "8:\tlearn: 4046.5485121\ttotal: 99.6ms\tremaining: 11.1ms\n",
      "9:\tlearn: 4022.5514254\ttotal: 110ms\tremaining: 0us\n",
      "0:\tlearn: 4503.5945229\ttotal: 11.9ms\tremaining: 107ms\n",
      "1:\tlearn: 4406.6057191\ttotal: 23.3ms\tremaining: 93.1ms\n",
      "2:\tlearn: 4325.4170103\ttotal: 34.4ms\tremaining: 80.3ms\n",
      "3:\tlearn: 4259.6060887\ttotal: 45.6ms\tremaining: 68.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4:\tlearn: 4202.2621613\ttotal: 58.4ms\tremaining: 58.4ms\n",
      "5:\tlearn: 4154.9964002\ttotal: 70.5ms\tremaining: 47ms\n",
      "6:\tlearn: 4116.6253029\ttotal: 81.7ms\tremaining: 35ms\n",
      "7:\tlearn: 4075.4565122\ttotal: 93.1ms\tremaining: 23.3ms\n",
      "8:\tlearn: 4048.3321599\ttotal: 104ms\tremaining: 11.6ms\n",
      "9:\tlearn: 4024.0398489\ttotal: 115ms\tremaining: 0us\n",
      "0:\tlearn: 4513.7534495\ttotal: 12ms\tremaining: 108ms\n",
      "1:\tlearn: 4416.8382833\ttotal: 22.8ms\tremaining: 91ms\n",
      "2:\tlearn: 4337.0433791\ttotal: 34.5ms\tremaining: 80.5ms\n",
      "3:\tlearn: 4271.4545258\ttotal: 45.8ms\tremaining: 68.7ms\n",
      "4:\tlearn: 4214.2304405\ttotal: 56.5ms\tremaining: 56.5ms\n",
      "5:\tlearn: 4166.8484479\ttotal: 68.1ms\tremaining: 45.4ms\n",
      "6:\tlearn: 4128.4101376\ttotal: 79.1ms\tremaining: 33.9ms\n",
      "7:\tlearn: 4087.3989332\ttotal: 89.8ms\tremaining: 22.5ms\n",
      "8:\tlearn: 4059.5799820\ttotal: 102ms\tremaining: 11.3ms\n",
      "9:\tlearn: 4034.4195441\ttotal: 113ms\tremaining: 0us\n",
      "0:\tlearn: 4510.5526783\ttotal: 12.1ms\tremaining: 109ms\n",
      "1:\tlearn: 4414.2526237\ttotal: 22.2ms\tremaining: 88.9ms\n",
      "2:\tlearn: 4333.4369795\ttotal: 32.6ms\tremaining: 76ms\n",
      "3:\tlearn: 4268.4739326\ttotal: 42.9ms\tremaining: 64.3ms\n",
      "4:\tlearn: 4211.9475248\ttotal: 54.2ms\tremaining: 54.2ms\n",
      "5:\tlearn: 4164.9389080\ttotal: 65.2ms\tremaining: 43.4ms\n",
      "6:\tlearn: 4118.5912874\ttotal: 75.9ms\tremaining: 32.5ms\n",
      "7:\tlearn: 4086.3891410\ttotal: 86.5ms\tremaining: 21.6ms\n",
      "8:\tlearn: 4058.8465165\ttotal: 97.5ms\tremaining: 10.8ms\n",
      "9:\tlearn: 4034.1803578\ttotal: 108ms\tremaining: 0us\n",
      "0:\tlearn: 4505.1497407\ttotal: 11.6ms\tremaining: 105ms\n",
      "1:\tlearn: 4408.1029504\ttotal: 22.2ms\tremaining: 88.8ms\n",
      "2:\tlearn: 4327.2619958\ttotal: 32.9ms\tremaining: 76.9ms\n",
      "3:\tlearn: 4261.0067684\ttotal: 43.7ms\tremaining: 65.6ms\n",
      "4:\tlearn: 4204.3835106\ttotal: 54.5ms\tremaining: 54.5ms\n",
      "5:\tlearn: 4157.2091407\ttotal: 66ms\tremaining: 44ms\n",
      "6:\tlearn: 4110.6486577\ttotal: 76.7ms\tremaining: 32.9ms\n",
      "7:\tlearn: 4077.0556064\ttotal: 87.5ms\tremaining: 21.9ms\n",
      "8:\tlearn: 4050.0711946\ttotal: 98ms\tremaining: 10.9ms\n",
      "9:\tlearn: 4026.2690408\ttotal: 108ms\tremaining: 0us\n",
      "0:\tlearn: 4614.2267597\ttotal: 11.2ms\tremaining: 156ms\n",
      "1:\tlearn: 4602.2389917\ttotal: 22.1ms\tremaining: 144ms\n",
      "2:\tlearn: 4590.6780712\ttotal: 33.6ms\tremaining: 134ms\n",
      "3:\tlearn: 4579.3107729\ttotal: 44.1ms\tremaining: 121ms\n",
      "4:\tlearn: 4568.0505190\ttotal: 56.1ms\tremaining: 112ms\n",
      "5:\tlearn: 4557.1335700\ttotal: 68.5ms\tremaining: 103ms\n",
      "6:\tlearn: 4546.6171677\ttotal: 79.8ms\tremaining: 91.2ms\n",
      "7:\tlearn: 4536.0863325\ttotal: 90ms\tremaining: 78.8ms\n",
      "8:\tlearn: 4525.6886592\ttotal: 101ms\tremaining: 67.4ms\n",
      "9:\tlearn: 4515.7142586\ttotal: 112ms\tremaining: 55.8ms\n",
      "10:\tlearn: 4506.5020971\ttotal: 119ms\tremaining: 43.4ms\n",
      "11:\tlearn: 4495.8960151\ttotal: 131ms\tremaining: 32.7ms\n",
      "12:\tlearn: 4486.2695493\ttotal: 142ms\tremaining: 21.8ms\n",
      "13:\tlearn: 4476.5469915\ttotal: 153ms\tremaining: 11ms\n",
      "14:\tlearn: 4467.1808917\ttotal: 165ms\tremaining: 0us\n",
      "0:\tlearn: 4605.5964364\ttotal: 11.5ms\tremaining: 161ms\n",
      "1:\tlearn: 4593.8869639\ttotal: 21.7ms\tremaining: 141ms\n",
      "2:\tlearn: 4582.3532202\ttotal: 32.7ms\tremaining: 131ms\n",
      "3:\tlearn: 4570.4259566\ttotal: 44.8ms\tremaining: 123ms\n",
      "4:\tlearn: 4559.1771392\ttotal: 56.8ms\tremaining: 114ms\n",
      "5:\tlearn: 4548.2936556\ttotal: 68.9ms\tremaining: 103ms\n",
      "6:\tlearn: 4537.7773682\ttotal: 80.1ms\tremaining: 91.5ms\n",
      "7:\tlearn: 4527.2787663\ttotal: 91.1ms\tremaining: 79.7ms\n",
      "8:\tlearn: 4516.8925685\ttotal: 102ms\tremaining: 68.2ms\n",
      "9:\tlearn: 4506.8565943\ttotal: 113ms\tremaining: 56.3ms\n",
      "10:\tlearn: 4497.6714779\ttotal: 121ms\tremaining: 44ms\n",
      "11:\tlearn: 4487.1256721\ttotal: 131ms\tremaining: 32.9ms\n",
      "12:\tlearn: 4477.5004788\ttotal: 142ms\tremaining: 21.9ms\n",
      "13:\tlearn: 4467.6771185\ttotal: 153ms\tremaining: 10.9ms\n",
      "14:\tlearn: 4457.7015560\ttotal: 163ms\tremaining: 0us\n",
      "0:\tlearn: 4616.5010504\ttotal: 12ms\tremaining: 168ms\n",
      "1:\tlearn: 4604.7532697\ttotal: 23.6ms\tremaining: 153ms\n",
      "2:\tlearn: 4593.3708750\ttotal: 35.6ms\tremaining: 142ms\n",
      "3:\tlearn: 4582.2540818\ttotal: 47.4ms\tremaining: 130ms\n",
      "4:\tlearn: 4571.0352693\ttotal: 60.1ms\tremaining: 120ms\n",
      "5:\tlearn: 4560.2583078\ttotal: 71.4ms\tremaining: 107ms\n",
      "6:\tlearn: 4549.7290852\ttotal: 82.8ms\tremaining: 94.6ms\n",
      "7:\tlearn: 4539.2268879\ttotal: 94ms\tremaining: 82.2ms\n",
      "8:\tlearn: 4528.8366035\ttotal: 105ms\tremaining: 69.7ms\n",
      "9:\tlearn: 4518.9058206\ttotal: 115ms\tremaining: 57.5ms\n",
      "10:\tlearn: 4509.7263096\ttotal: 123ms\tremaining: 44.6ms\n",
      "11:\tlearn: 4499.9284745\ttotal: 133ms\tremaining: 33.3ms\n",
      "12:\tlearn: 4490.1821828\ttotal: 144ms\tremaining: 22.1ms\n",
      "13:\tlearn: 4480.4936802\ttotal: 154ms\tremaining: 11ms\n",
      "14:\tlearn: 4471.1489008\ttotal: 165ms\tremaining: 0us\n",
      "0:\tlearn: 4612.1597457\ttotal: 11.3ms\tremaining: 159ms\n",
      "1:\tlearn: 4600.4858502\ttotal: 22.4ms\tremaining: 146ms\n",
      "2:\tlearn: 4589.1584858\ttotal: 33.7ms\tremaining: 135ms\n",
      "3:\tlearn: 4578.0727004\ttotal: 45.6ms\tremaining: 125ms\n",
      "4:\tlearn: 4566.8895558\ttotal: 56.3ms\tremaining: 113ms\n",
      "5:\tlearn: 4556.0458911\ttotal: 67.4ms\tremaining: 101ms\n",
      "6:\tlearn: 4545.4303625\ttotal: 79ms\tremaining: 90.3ms\n",
      "7:\tlearn: 4534.7858288\ttotal: 89ms\tremaining: 77.9ms\n",
      "8:\tlearn: 4524.5879806\ttotal: 100ms\tremaining: 66.9ms\n",
      "9:\tlearn: 4514.7114128\ttotal: 112ms\tremaining: 56ms\n",
      "10:\tlearn: 4505.5729276\ttotal: 120ms\tremaining: 43.7ms\n",
      "11:\tlearn: 4495.8328063\ttotal: 131ms\tremaining: 32.8ms\n",
      "12:\tlearn: 4486.0641381\ttotal: 142ms\tremaining: 21.9ms\n",
      "13:\tlearn: 4476.3884295\ttotal: 153ms\tremaining: 11ms\n",
      "14:\tlearn: 4467.1022368\ttotal: 165ms\tremaining: 0us\n",
      "0:\tlearn: 4607.3728913\ttotal: 12.8ms\tremaining: 179ms\n",
      "1:\tlearn: 4595.6523212\ttotal: 24.2ms\tremaining: 157ms\n",
      "2:\tlearn: 4584.1671346\ttotal: 35.4ms\tremaining: 142ms\n",
      "3:\tlearn: 4572.3190838\ttotal: 46.7ms\tremaining: 128ms\n",
      "4:\tlearn: 4561.1308626\ttotal: 58.1ms\tremaining: 116ms\n",
      "5:\tlearn: 4550.4062567\ttotal: 69.2ms\tremaining: 104ms\n",
      "6:\tlearn: 4539.7847533\ttotal: 80ms\tremaining: 91.4ms\n",
      "7:\tlearn: 4529.1091062\ttotal: 90.5ms\tremaining: 79.2ms\n",
      "8:\tlearn: 4518.7488447\ttotal: 101ms\tremaining: 67.6ms\n",
      "9:\tlearn: 4508.8529155\ttotal: 112ms\tremaining: 55.9ms\n",
      "10:\tlearn: 4498.7570829\ttotal: 122ms\tremaining: 44.4ms\n",
      "11:\tlearn: 4488.9654725\ttotal: 133ms\tremaining: 33.3ms\n",
      "12:\tlearn: 4478.7568778\ttotal: 144ms\tremaining: 22.1ms\n",
      "13:\tlearn: 4469.2227383\ttotal: 154ms\tremaining: 11ms\n",
      "14:\tlearn: 4459.8553485\ttotal: 165ms\tremaining: 0us\n",
      "0:\tlearn: 4566.9532639\ttotal: 11.5ms\tremaining: 160ms\n",
      "1:\tlearn: 4512.5890607\ttotal: 22.7ms\tremaining: 147ms\n",
      "2:\tlearn: 4462.8720827\ttotal: 35ms\tremaining: 140ms\n",
      "3:\tlearn: 4417.2576607\ttotal: 45.8ms\tremaining: 126ms\n",
      "4:\tlearn: 4375.2018782\ttotal: 56.7ms\tremaining: 113ms\n",
      "5:\tlearn: 4337.1352160\ttotal: 67.7ms\tremaining: 102ms\n",
      "6:\tlearn: 4298.7927365\ttotal: 78.4ms\tremaining: 89.6ms\n",
      "7:\tlearn: 4266.6574744\ttotal: 89.5ms\tremaining: 78.3ms\n",
      "8:\tlearn: 4238.3050402\ttotal: 101ms\tremaining: 67.3ms\n",
      "9:\tlearn: 4211.2751036\ttotal: 112ms\tremaining: 55.9ms\n",
      "10:\tlearn: 4187.1950344\ttotal: 123ms\tremaining: 44.7ms\n",
      "11:\tlearn: 4164.1086630\ttotal: 134ms\tremaining: 33.4ms\n",
      "12:\tlearn: 4140.5176483\ttotal: 144ms\tremaining: 22.2ms\n",
      "13:\tlearn: 4118.9240507\ttotal: 155ms\tremaining: 11.1ms\n",
      "14:\tlearn: 4100.8852619\ttotal: 166ms\tremaining: 0us\n",
      "0:\tlearn: 4559.3518734\ttotal: 11.9ms\tremaining: 166ms\n",
      "1:\tlearn: 4505.3697462\ttotal: 24.4ms\tremaining: 159ms\n",
      "2:\tlearn: 4455.7876810\ttotal: 35.5ms\tremaining: 142ms\n",
      "3:\tlearn: 4407.4381912\ttotal: 47.5ms\tremaining: 131ms\n",
      "4:\tlearn: 4365.2524589\ttotal: 59.3ms\tremaining: 119ms\n",
      "5:\tlearn: 4328.2550665\ttotal: 70.8ms\tremaining: 106ms\n",
      "6:\tlearn: 4293.8955546\ttotal: 81.6ms\tremaining: 93.2ms\n",
      "7:\tlearn: 4262.0206525\ttotal: 92.7ms\tremaining: 81.1ms\n",
      "8:\tlearn: 4233.3590644\ttotal: 104ms\tremaining: 69.2ms\n",
      "9:\tlearn: 4206.3136892\ttotal: 114ms\tremaining: 57.2ms\n",
      "10:\tlearn: 4181.7687693\ttotal: 125ms\tremaining: 45.6ms\n",
      "11:\tlearn: 4158.9392342\ttotal: 136ms\tremaining: 33.9ms\n",
      "12:\tlearn: 4135.2443896\ttotal: 147ms\tremaining: 22.6ms\n",
      "13:\tlearn: 4113.7777796\ttotal: 158ms\tremaining: 11.3ms\n",
      "14:\tlearn: 4095.7094792\ttotal: 169ms\tremaining: 0us\n",
      "0:\tlearn: 4569.9197567\ttotal: 12.3ms\tremaining: 172ms\n",
      "1:\tlearn: 4515.9600609\ttotal: 24.5ms\tremaining: 159ms\n",
      "2:\tlearn: 4467.0964160\ttotal: 35.7ms\tremaining: 143ms\n",
      "3:\tlearn: 4422.2502106\ttotal: 46.5ms\tremaining: 128ms\n",
      "4:\tlearn: 4380.4298065\ttotal: 57.3ms\tremaining: 115ms\n",
      "5:\tlearn: 4342.7900721\ttotal: 67.6ms\tremaining: 101ms\n",
      "6:\tlearn: 4308.8016680\ttotal: 78.4ms\tremaining: 89.6ms\n",
      "7:\tlearn: 4276.7006882\ttotal: 88.8ms\tremaining: 77.7ms\n",
      "8:\tlearn: 4247.2342071\ttotal: 99.1ms\tremaining: 66ms\n",
      "9:\tlearn: 4221.3329355\ttotal: 109ms\tremaining: 54.7ms\n",
      "10:\tlearn: 4197.3450470\ttotal: 120ms\tremaining: 43.8ms\n",
      "11:\tlearn: 4175.0707295\ttotal: 131ms\tremaining: 32.7ms\n",
      "12:\tlearn: 4153.2955572\ttotal: 142ms\tremaining: 21.8ms\n",
      "13:\tlearn: 4131.8218111\ttotal: 152ms\tremaining: 10.9ms\n",
      "14:\tlearn: 4113.3784771\ttotal: 163ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4566.0926481\ttotal: 12.8ms\tremaining: 180ms\n",
      "1:\tlearn: 4512.4658385\ttotal: 24.7ms\tremaining: 160ms\n",
      "2:\tlearn: 4463.0659311\ttotal: 37.2ms\tremaining: 149ms\n",
      "3:\tlearn: 4415.1708945\ttotal: 48.1ms\tremaining: 132ms\n",
      "4:\tlearn: 4373.2717431\ttotal: 58.9ms\tremaining: 118ms\n",
      "5:\tlearn: 4335.8592984\ttotal: 69.5ms\tremaining: 104ms\n",
      "6:\tlearn: 4300.9914010\ttotal: 81ms\tremaining: 92.6ms\n",
      "7:\tlearn: 4269.2090834\ttotal: 91.5ms\tremaining: 80.1ms\n",
      "8:\tlearn: 4241.0448998\ttotal: 103ms\tremaining: 68.5ms\n",
      "9:\tlearn: 4215.1669721\ttotal: 113ms\tremaining: 56.6ms\n",
      "10:\tlearn: 4191.8531338\ttotal: 124ms\tremaining: 44.9ms\n",
      "11:\tlearn: 4169.1151282\ttotal: 134ms\tremaining: 33.6ms\n",
      "12:\tlearn: 4147.1089056\ttotal: 145ms\tremaining: 22.2ms\n",
      "13:\tlearn: 4125.7638097\ttotal: 156ms\tremaining: 11.1ms\n",
      "14:\tlearn: 4107.9223415\ttotal: 166ms\tremaining: 0us\n",
      "0:\tlearn: 4561.0283361\ttotal: 11.8ms\tremaining: 165ms\n",
      "1:\tlearn: 4507.0027872\ttotal: 23.6ms\tremaining: 154ms\n",
      "2:\tlearn: 4458.3813327\ttotal: 34.9ms\tremaining: 140ms\n",
      "3:\tlearn: 4414.0412016\ttotal: 46.4ms\tremaining: 128ms\n",
      "4:\tlearn: 4372.3993501\ttotal: 58ms\tremaining: 116ms\n",
      "5:\tlearn: 4334.6532826\ttotal: 68.6ms\tremaining: 103ms\n",
      "6:\tlearn: 4300.0994929\ttotal: 79.8ms\tremaining: 91.2ms\n",
      "7:\tlearn: 4268.0567302\ttotal: 90.5ms\tremaining: 79.2ms\n",
      "8:\tlearn: 4239.5903493\ttotal: 101ms\tremaining: 67.4ms\n",
      "9:\tlearn: 4213.7005935\ttotal: 111ms\tremaining: 55.7ms\n",
      "10:\tlearn: 4189.7231479\ttotal: 122ms\tremaining: 44.5ms\n",
      "11:\tlearn: 4167.6173277\ttotal: 133ms\tremaining: 33.2ms\n",
      "12:\tlearn: 4145.7403407\ttotal: 143ms\tremaining: 22ms\n",
      "13:\tlearn: 4124.3321595\ttotal: 154ms\tremaining: 11ms\n",
      "14:\tlearn: 4107.3978414\ttotal: 164ms\tremaining: 0us\n",
      "0:\tlearn: 4509.9425451\ttotal: 13.2ms\tremaining: 185ms\n",
      "1:\tlearn: 4412.2365564\ttotal: 24.3ms\tremaining: 158ms\n",
      "2:\tlearn: 4330.9114892\ttotal: 35.7ms\tremaining: 143ms\n",
      "3:\tlearn: 4266.0989266\ttotal: 46.4ms\tremaining: 128ms\n",
      "4:\tlearn: 4208.7094854\ttotal: 57.6ms\tremaining: 115ms\n",
      "5:\tlearn: 4161.9707224\ttotal: 69ms\tremaining: 104ms\n",
      "6:\tlearn: 4115.5774488\ttotal: 79.7ms\tremaining: 91.1ms\n",
      "7:\tlearn: 4076.0618186\ttotal: 90.5ms\tremaining: 79.2ms\n",
      "8:\tlearn: 4046.5485121\ttotal: 101ms\tremaining: 67.2ms\n",
      "9:\tlearn: 4022.5514254\ttotal: 111ms\tremaining: 55.7ms\n",
      "10:\tlearn: 3996.8157828\ttotal: 122ms\tremaining: 44.4ms\n",
      "11:\tlearn: 3975.1578150\ttotal: 133ms\tremaining: 33.3ms\n",
      "12:\tlearn: 3958.6047436\ttotal: 144ms\tremaining: 22.2ms\n",
      "13:\tlearn: 3941.8079888\ttotal: 155ms\tremaining: 11.1ms\n",
      "14:\tlearn: 3921.5556523\ttotal: 166ms\tremaining: 0us\n",
      "0:\tlearn: 4503.5945229\ttotal: 12.5ms\tremaining: 175ms\n",
      "1:\tlearn: 4406.6057191\ttotal: 23.6ms\tremaining: 154ms\n",
      "2:\tlearn: 4325.4170103\ttotal: 35.3ms\tremaining: 141ms\n",
      "3:\tlearn: 4259.6060887\ttotal: 46.4ms\tremaining: 128ms\n",
      "4:\tlearn: 4202.2621613\ttotal: 58.1ms\tremaining: 116ms\n",
      "5:\tlearn: 4154.9964002\ttotal: 69.5ms\tremaining: 104ms\n",
      "6:\tlearn: 4116.6253029\ttotal: 80.5ms\tremaining: 92ms\n",
      "7:\tlearn: 4075.4565122\ttotal: 92ms\tremaining: 80.5ms\n",
      "8:\tlearn: 4048.3321599\ttotal: 102ms\tremaining: 68.3ms\n",
      "9:\tlearn: 4024.0398489\ttotal: 113ms\tremaining: 56.4ms\n",
      "10:\tlearn: 3998.4928102\ttotal: 124ms\tremaining: 45ms\n",
      "11:\tlearn: 3976.4356951\ttotal: 135ms\tremaining: 33.8ms\n",
      "12:\tlearn: 3955.6992438\ttotal: 146ms\tremaining: 22.5ms\n",
      "13:\tlearn: 3938.0792118\ttotal: 157ms\tremaining: 11.2ms\n",
      "14:\tlearn: 3923.6604117\ttotal: 168ms\tremaining: 0us\n",
      "0:\tlearn: 4513.7534495\ttotal: 12.4ms\tremaining: 174ms\n",
      "1:\tlearn: 4416.8382833\ttotal: 23.3ms\tremaining: 151ms\n",
      "2:\tlearn: 4337.0433791\ttotal: 34.6ms\tremaining: 138ms\n",
      "3:\tlearn: 4271.4545258\ttotal: 45.1ms\tremaining: 124ms\n",
      "4:\tlearn: 4214.2304405\ttotal: 56.9ms\tremaining: 114ms\n",
      "5:\tlearn: 4166.8484479\ttotal: 68.5ms\tremaining: 103ms\n",
      "6:\tlearn: 4128.4101376\ttotal: 78.8ms\tremaining: 90ms\n",
      "7:\tlearn: 4087.3989332\ttotal: 89.9ms\tremaining: 78.7ms\n",
      "8:\tlearn: 4059.5799820\ttotal: 101ms\tremaining: 67.2ms\n",
      "9:\tlearn: 4034.4195441\ttotal: 111ms\tremaining: 55.5ms\n",
      "10:\tlearn: 4007.7115554\ttotal: 122ms\tremaining: 44.2ms\n",
      "11:\tlearn: 3985.0365098\ttotal: 133ms\tremaining: 33.2ms\n",
      "12:\tlearn: 3964.1025433\ttotal: 143ms\tremaining: 22.1ms\n",
      "13:\tlearn: 3947.0061251\ttotal: 154ms\tremaining: 11ms\n",
      "14:\tlearn: 3926.3340633\ttotal: 165ms\tremaining: 0us\n",
      "0:\tlearn: 4510.5526783\ttotal: 12.2ms\tremaining: 171ms\n",
      "1:\tlearn: 4414.2526237\ttotal: 23.2ms\tremaining: 151ms\n",
      "2:\tlearn: 4333.4369795\ttotal: 35.5ms\tremaining: 142ms\n",
      "3:\tlearn: 4268.4739326\ttotal: 46ms\tremaining: 126ms\n",
      "4:\tlearn: 4211.9475248\ttotal: 57.5ms\tremaining: 115ms\n",
      "5:\tlearn: 4164.9389080\ttotal: 69.2ms\tremaining: 104ms\n",
      "6:\tlearn: 4118.5912874\ttotal: 80.5ms\tremaining: 92ms\n",
      "7:\tlearn: 4086.3891410\ttotal: 91.5ms\tremaining: 80ms\n",
      "8:\tlearn: 4058.8465165\ttotal: 103ms\tremaining: 68.4ms\n",
      "9:\tlearn: 4034.1803578\ttotal: 113ms\tremaining: 56.4ms\n",
      "10:\tlearn: 4007.6997500\ttotal: 124ms\tremaining: 45ms\n",
      "11:\tlearn: 3988.8482360\ttotal: 134ms\tremaining: 33.4ms\n",
      "12:\tlearn: 3967.7782331\ttotal: 145ms\tremaining: 22.2ms\n",
      "13:\tlearn: 3949.7367794\ttotal: 155ms\tremaining: 11.1ms\n",
      "14:\tlearn: 3934.7603318\ttotal: 166ms\tremaining: 0us\n",
      "0:\tlearn: 4505.1497407\ttotal: 12.2ms\tremaining: 171ms\n",
      "1:\tlearn: 4408.1029504\ttotal: 23.5ms\tremaining: 153ms\n",
      "2:\tlearn: 4327.2619958\ttotal: 35.1ms\tremaining: 140ms\n",
      "3:\tlearn: 4261.0067684\ttotal: 47.1ms\tremaining: 130ms\n",
      "4:\tlearn: 4204.3835106\ttotal: 58.6ms\tremaining: 117ms\n",
      "5:\tlearn: 4157.2091407\ttotal: 70.8ms\tremaining: 106ms\n",
      "6:\tlearn: 4110.6486577\ttotal: 81.9ms\tremaining: 93.6ms\n",
      "7:\tlearn: 4077.0556064\ttotal: 92.5ms\tremaining: 81ms\n",
      "8:\tlearn: 4050.0711946\ttotal: 104ms\tremaining: 69.1ms\n",
      "9:\tlearn: 4026.2690408\ttotal: 114ms\tremaining: 57ms\n",
      "10:\tlearn: 3999.5684157\ttotal: 127ms\tremaining: 46ms\n",
      "11:\tlearn: 3981.2102965\ttotal: 138ms\tremaining: 34.5ms\n",
      "12:\tlearn: 3963.3906278\ttotal: 151ms\tremaining: 23.2ms\n",
      "13:\tlearn: 3947.8911170\ttotal: 163ms\tremaining: 11.6ms\n",
      "14:\tlearn: 3933.5924768\ttotal: 174ms\tremaining: 0us\n",
      "0:\tlearn: 4614.2267597\ttotal: 12.3ms\tremaining: 234ms\n",
      "1:\tlearn: 4602.2389917\ttotal: 23.6ms\tremaining: 213ms\n",
      "2:\tlearn: 4590.6780712\ttotal: 34.7ms\tremaining: 197ms\n",
      "3:\tlearn: 4579.3107729\ttotal: 45.4ms\tremaining: 182ms\n",
      "4:\tlearn: 4568.0505190\ttotal: 56.7ms\tremaining: 170ms\n",
      "5:\tlearn: 4557.1335700\ttotal: 67.3ms\tremaining: 157ms\n",
      "6:\tlearn: 4546.6171677\ttotal: 78.6ms\tremaining: 146ms\n",
      "7:\tlearn: 4536.0863325\ttotal: 89.7ms\tremaining: 134ms\n",
      "8:\tlearn: 4525.6886592\ttotal: 101ms\tremaining: 124ms\n",
      "9:\tlearn: 4515.7142586\ttotal: 112ms\tremaining: 112ms\n",
      "10:\tlearn: 4506.5020971\ttotal: 120ms\tremaining: 97.8ms\n",
      "11:\tlearn: 4495.8960151\ttotal: 131ms\tremaining: 87ms\n",
      "12:\tlearn: 4486.2695493\ttotal: 141ms\tremaining: 75.8ms\n",
      "13:\tlearn: 4476.5469915\ttotal: 152ms\tremaining: 65.2ms\n",
      "14:\tlearn: 4467.1808917\ttotal: 163ms\tremaining: 54.5ms\n",
      "15:\tlearn: 4457.8940941\ttotal: 174ms\tremaining: 43.6ms\n",
      "16:\tlearn: 4448.6266505\ttotal: 186ms\tremaining: 32.8ms\n",
      "17:\tlearn: 4439.5822177\ttotal: 197ms\tremaining: 21.9ms\n",
      "18:\tlearn: 4430.7896573\ttotal: 208ms\tremaining: 10.9ms\n",
      "19:\tlearn: 4421.6388343\ttotal: 218ms\tremaining: 0us\n",
      "0:\tlearn: 4605.5964364\ttotal: 11.7ms\tremaining: 222ms\n",
      "1:\tlearn: 4593.8869639\ttotal: 23ms\tremaining: 207ms\n",
      "2:\tlearn: 4582.3532202\ttotal: 34.6ms\tremaining: 196ms\n",
      "3:\tlearn: 4570.4259566\ttotal: 45.5ms\tremaining: 182ms\n",
      "4:\tlearn: 4559.1771392\ttotal: 56.6ms\tremaining: 170ms\n",
      "5:\tlearn: 4548.2936556\ttotal: 67.6ms\tremaining: 158ms\n",
      "6:\tlearn: 4537.7773682\ttotal: 77.9ms\tremaining: 145ms\n",
      "7:\tlearn: 4527.2787663\ttotal: 88.9ms\tremaining: 133ms\n",
      "8:\tlearn: 4516.8925685\ttotal: 99.6ms\tremaining: 122ms\n",
      "9:\tlearn: 4506.8565943\ttotal: 110ms\tremaining: 110ms\n",
      "10:\tlearn: 4497.6714779\ttotal: 117ms\tremaining: 96ms\n",
      "11:\tlearn: 4487.1256721\ttotal: 127ms\tremaining: 85ms\n",
      "12:\tlearn: 4477.5004788\ttotal: 138ms\tremaining: 74.3ms\n",
      "13:\tlearn: 4467.6771185\ttotal: 148ms\tremaining: 63.6ms\n",
      "14:\tlearn: 4457.7015560\ttotal: 159ms\tremaining: 52.9ms\n",
      "15:\tlearn: 4448.4553668\ttotal: 169ms\tremaining: 42.3ms\n",
      "16:\tlearn: 4439.1929878\ttotal: 180ms\tremaining: 31.8ms\n",
      "17:\tlearn: 4430.1022288\ttotal: 191ms\tremaining: 21.2ms\n",
      "18:\tlearn: 4421.3337998\ttotal: 202ms\tremaining: 10.6ms\n",
      "19:\tlearn: 4412.2291847\ttotal: 213ms\tremaining: 0us\n",
      "0:\tlearn: 4616.5010504\ttotal: 19.9ms\tremaining: 378ms\n",
      "1:\tlearn: 4604.7532697\ttotal: 30.9ms\tremaining: 278ms\n",
      "2:\tlearn: 4593.3708750\ttotal: 41.6ms\tremaining: 236ms\n",
      "3:\tlearn: 4582.2540818\ttotal: 52.2ms\tremaining: 209ms\n",
      "4:\tlearn: 4571.0352693\ttotal: 63.7ms\tremaining: 191ms\n",
      "5:\tlearn: 4560.2583078\ttotal: 75ms\tremaining: 175ms\n",
      "6:\tlearn: 4549.7290852\ttotal: 85.2ms\tremaining: 158ms\n",
      "7:\tlearn: 4539.2268879\ttotal: 95.8ms\tremaining: 144ms\n",
      "8:\tlearn: 4528.8366035\ttotal: 106ms\tremaining: 130ms\n",
      "9:\tlearn: 4518.9058206\ttotal: 116ms\tremaining: 116ms\n",
      "10:\tlearn: 4509.7263096\ttotal: 124ms\tremaining: 102ms\n",
      "11:\tlearn: 4499.9284745\ttotal: 135ms\tremaining: 90.1ms\n",
      "12:\tlearn: 4490.1821828\ttotal: 146ms\tremaining: 78.6ms\n",
      "13:\tlearn: 4480.4936802\ttotal: 158ms\tremaining: 67.6ms\n",
      "14:\tlearn: 4471.1489008\ttotal: 168ms\tremaining: 56.1ms\n",
      "15:\tlearn: 4461.0843936\ttotal: 179ms\tremaining: 44.9ms\n",
      "16:\tlearn: 4451.8455849\ttotal: 191ms\tremaining: 33.7ms\n",
      "17:\tlearn: 4442.8315550\ttotal: 202ms\tremaining: 22.4ms\n",
      "18:\tlearn: 4434.0709026\ttotal: 213ms\tremaining: 11.2ms\n",
      "19:\tlearn: 4425.4545393\ttotal: 223ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4612.1597457\ttotal: 17ms\tremaining: 324ms\n",
      "1:\tlearn: 4600.4858502\ttotal: 28ms\tremaining: 252ms\n",
      "2:\tlearn: 4589.1584858\ttotal: 39.4ms\tremaining: 223ms\n",
      "3:\tlearn: 4578.0727004\ttotal: 50.6ms\tremaining: 202ms\n",
      "4:\tlearn: 4566.8895558\ttotal: 61.3ms\tremaining: 184ms\n",
      "5:\tlearn: 4556.0458911\ttotal: 72.2ms\tremaining: 168ms\n",
      "6:\tlearn: 4545.4303625\ttotal: 83ms\tremaining: 154ms\n",
      "7:\tlearn: 4534.7858288\ttotal: 93.7ms\tremaining: 141ms\n",
      "8:\tlearn: 4524.5879806\ttotal: 104ms\tremaining: 128ms\n",
      "9:\tlearn: 4514.7114128\ttotal: 115ms\tremaining: 115ms\n",
      "10:\tlearn: 4505.5729276\ttotal: 122ms\tremaining: 100ms\n",
      "11:\tlearn: 4495.8328063\ttotal: 133ms\tremaining: 88.7ms\n",
      "12:\tlearn: 4486.0641381\ttotal: 143ms\tremaining: 77.2ms\n",
      "13:\tlearn: 4476.3884295\ttotal: 154ms\tremaining: 66.2ms\n",
      "14:\tlearn: 4467.1022368\ttotal: 165ms\tremaining: 55.1ms\n",
      "15:\tlearn: 4457.0972045\ttotal: 176ms\tremaining: 43.9ms\n",
      "16:\tlearn: 4447.8734057\ttotal: 187ms\tremaining: 33ms\n",
      "17:\tlearn: 4438.8774831\ttotal: 198ms\tremaining: 22ms\n",
      "18:\tlearn: 4430.1176905\ttotal: 209ms\tremaining: 11ms\n",
      "19:\tlearn: 4421.5331436\ttotal: 221ms\tremaining: 0us\n",
      "0:\tlearn: 4607.3728913\ttotal: 11.8ms\tremaining: 224ms\n",
      "1:\tlearn: 4595.6523212\ttotal: 21.9ms\tremaining: 197ms\n",
      "2:\tlearn: 4584.1671346\ttotal: 32.8ms\tremaining: 186ms\n",
      "3:\tlearn: 4572.3190838\ttotal: 44ms\tremaining: 176ms\n",
      "4:\tlearn: 4561.1308626\ttotal: 55.5ms\tremaining: 167ms\n",
      "5:\tlearn: 4550.4062567\ttotal: 66.4ms\tremaining: 155ms\n",
      "6:\tlearn: 4539.7847533\ttotal: 77.7ms\tremaining: 144ms\n",
      "7:\tlearn: 4529.1091062\ttotal: 89.1ms\tremaining: 134ms\n",
      "8:\tlearn: 4518.7488447\ttotal: 101ms\tremaining: 123ms\n",
      "9:\tlearn: 4508.8529155\ttotal: 112ms\tremaining: 112ms\n",
      "10:\tlearn: 4498.7570829\ttotal: 124ms\tremaining: 101ms\n",
      "11:\tlearn: 4488.9654725\ttotal: 135ms\tremaining: 89.9ms\n",
      "12:\tlearn: 4478.7568778\ttotal: 146ms\tremaining: 78.7ms\n",
      "13:\tlearn: 4469.2227383\ttotal: 158ms\tremaining: 67.6ms\n",
      "14:\tlearn: 4459.8553485\ttotal: 169ms\tremaining: 56.3ms\n",
      "15:\tlearn: 4450.8201530\ttotal: 180ms\tremaining: 45ms\n",
      "16:\tlearn: 4441.8922754\ttotal: 191ms\tremaining: 33.8ms\n",
      "17:\tlearn: 4433.8568935\ttotal: 200ms\tremaining: 22.2ms\n",
      "18:\tlearn: 4424.6534000\ttotal: 211ms\tremaining: 11.1ms\n",
      "19:\tlearn: 4416.0413820\ttotal: 223ms\tremaining: 0us\n",
      "0:\tlearn: 4566.9532639\ttotal: 11.8ms\tremaining: 224ms\n",
      "1:\tlearn: 4512.5890607\ttotal: 23ms\tremaining: 207ms\n",
      "2:\tlearn: 4462.8720827\ttotal: 34.7ms\tremaining: 197ms\n",
      "3:\tlearn: 4417.2576607\ttotal: 46.3ms\tremaining: 185ms\n",
      "4:\tlearn: 4375.2018782\ttotal: 58.3ms\tremaining: 175ms\n",
      "5:\tlearn: 4337.1352160\ttotal: 69.9ms\tremaining: 163ms\n",
      "6:\tlearn: 4298.7927365\ttotal: 81.7ms\tremaining: 152ms\n",
      "7:\tlearn: 4266.6574744\ttotal: 92.7ms\tremaining: 139ms\n",
      "8:\tlearn: 4238.3050402\ttotal: 104ms\tremaining: 127ms\n",
      "9:\tlearn: 4211.2751036\ttotal: 116ms\tremaining: 116ms\n",
      "10:\tlearn: 4187.1950344\ttotal: 127ms\tremaining: 104ms\n",
      "11:\tlearn: 4164.1086630\ttotal: 139ms\tremaining: 92.4ms\n",
      "12:\tlearn: 4140.5176483\ttotal: 150ms\tremaining: 80.9ms\n",
      "13:\tlearn: 4118.9240507\ttotal: 163ms\tremaining: 69.8ms\n",
      "14:\tlearn: 4100.8852619\ttotal: 175ms\tremaining: 58.4ms\n",
      "15:\tlearn: 4084.3179092\ttotal: 187ms\tremaining: 46.7ms\n",
      "16:\tlearn: 4069.5578096\ttotal: 199ms\tremaining: 35.1ms\n",
      "17:\tlearn: 4053.4953334\ttotal: 211ms\tremaining: 23.4ms\n",
      "18:\tlearn: 4040.2269661\ttotal: 222ms\tremaining: 11.7ms\n",
      "19:\tlearn: 4023.3897218\ttotal: 234ms\tremaining: 0us\n",
      "0:\tlearn: 4559.3518734\ttotal: 12.2ms\tremaining: 232ms\n",
      "1:\tlearn: 4505.3697462\ttotal: 23.2ms\tremaining: 209ms\n",
      "2:\tlearn: 4455.7876810\ttotal: 35ms\tremaining: 198ms\n",
      "3:\tlearn: 4407.4381912\ttotal: 46ms\tremaining: 184ms\n",
      "4:\tlearn: 4365.2524589\ttotal: 57.4ms\tremaining: 172ms\n",
      "5:\tlearn: 4328.2550665\ttotal: 69.2ms\tremaining: 161ms\n",
      "6:\tlearn: 4293.8955546\ttotal: 81.3ms\tremaining: 151ms\n",
      "7:\tlearn: 4262.0206525\ttotal: 93.2ms\tremaining: 140ms\n",
      "8:\tlearn: 4233.3590644\ttotal: 104ms\tremaining: 128ms\n",
      "9:\tlearn: 4206.3136892\ttotal: 117ms\tremaining: 117ms\n",
      "10:\tlearn: 4181.7687693\ttotal: 129ms\tremaining: 105ms\n",
      "11:\tlearn: 4158.9392342\ttotal: 140ms\tremaining: 93.4ms\n",
      "12:\tlearn: 4135.2443896\ttotal: 152ms\tremaining: 81.7ms\n",
      "13:\tlearn: 4113.7777796\ttotal: 163ms\tremaining: 69.9ms\n",
      "14:\tlearn: 4095.7094792\ttotal: 175ms\tremaining: 58.4ms\n",
      "15:\tlearn: 4078.9363448\ttotal: 187ms\tremaining: 46.7ms\n",
      "16:\tlearn: 4064.1780330\ttotal: 199ms\tremaining: 35.1ms\n",
      "17:\tlearn: 4048.3772497\ttotal: 211ms\tremaining: 23.5ms\n",
      "18:\tlearn: 4034.8591392\ttotal: 223ms\tremaining: 11.7ms\n",
      "19:\tlearn: 4021.1240029\ttotal: 234ms\tremaining: 0us\n",
      "0:\tlearn: 4569.9197567\ttotal: 11.8ms\tremaining: 223ms\n",
      "1:\tlearn: 4515.9600609\ttotal: 23ms\tremaining: 207ms\n",
      "2:\tlearn: 4467.0964160\ttotal: 34.4ms\tremaining: 195ms\n",
      "3:\tlearn: 4422.2502106\ttotal: 45.8ms\tremaining: 183ms\n",
      "4:\tlearn: 4380.4298065\ttotal: 57.5ms\tremaining: 173ms\n",
      "5:\tlearn: 4342.7900721\ttotal: 69.2ms\tremaining: 162ms\n",
      "6:\tlearn: 4308.8016680\ttotal: 80.4ms\tremaining: 149ms\n",
      "7:\tlearn: 4276.7006882\ttotal: 91.5ms\tremaining: 137ms\n",
      "8:\tlearn: 4247.2342071\ttotal: 103ms\tremaining: 126ms\n",
      "9:\tlearn: 4221.3329355\ttotal: 113ms\tremaining: 113ms\n",
      "10:\tlearn: 4197.3450470\ttotal: 125ms\tremaining: 102ms\n",
      "11:\tlearn: 4175.0707295\ttotal: 136ms\tremaining: 90.7ms\n",
      "12:\tlearn: 4153.2955572\ttotal: 147ms\tremaining: 79.3ms\n",
      "13:\tlearn: 4131.8218111\ttotal: 159ms\tremaining: 68.1ms\n",
      "14:\tlearn: 4113.3784771\ttotal: 170ms\tremaining: 56.8ms\n",
      "15:\tlearn: 4095.8807077\ttotal: 181ms\tremaining: 45.3ms\n",
      "16:\tlearn: 4081.3661865\ttotal: 194ms\tremaining: 34.1ms\n",
      "17:\tlearn: 4065.5570312\ttotal: 205ms\tremaining: 22.8ms\n",
      "18:\tlearn: 4052.5612181\ttotal: 216ms\tremaining: 11.4ms\n",
      "19:\tlearn: 4034.8394496\ttotal: 228ms\tremaining: 0us\n",
      "0:\tlearn: 4566.0926481\ttotal: 12.7ms\tremaining: 241ms\n",
      "1:\tlearn: 4512.4658385\ttotal: 24ms\tremaining: 216ms\n",
      "2:\tlearn: 4463.0659311\ttotal: 35.7ms\tremaining: 202ms\n",
      "3:\tlearn: 4415.1708945\ttotal: 47.1ms\tremaining: 188ms\n",
      "4:\tlearn: 4373.2717431\ttotal: 58.7ms\tremaining: 176ms\n",
      "5:\tlearn: 4335.8592984\ttotal: 69.4ms\tremaining: 162ms\n",
      "6:\tlearn: 4300.9914010\ttotal: 81.4ms\tremaining: 151ms\n",
      "7:\tlearn: 4269.2090834\ttotal: 93.2ms\tremaining: 140ms\n",
      "8:\tlearn: 4241.0448998\ttotal: 105ms\tremaining: 128ms\n",
      "9:\tlearn: 4215.1669721\ttotal: 116ms\tremaining: 116ms\n",
      "10:\tlearn: 4191.8531338\ttotal: 127ms\tremaining: 104ms\n",
      "11:\tlearn: 4169.1151282\ttotal: 138ms\tremaining: 92.3ms\n",
      "12:\tlearn: 4147.1089056\ttotal: 150ms\tremaining: 80.6ms\n",
      "13:\tlearn: 4125.7638097\ttotal: 162ms\tremaining: 69.6ms\n",
      "14:\tlearn: 4107.9223415\ttotal: 175ms\tremaining: 58.2ms\n",
      "15:\tlearn: 4090.7263422\ttotal: 187ms\tremaining: 46.7ms\n",
      "16:\tlearn: 4075.8080723\ttotal: 199ms\tremaining: 35ms\n",
      "17:\tlearn: 4060.6791329\ttotal: 210ms\tremaining: 23.3ms\n",
      "18:\tlearn: 4047.4529781\ttotal: 221ms\tremaining: 11.6ms\n",
      "19:\tlearn: 4033.8108547\ttotal: 233ms\tremaining: 0us\n",
      "0:\tlearn: 4561.0283361\ttotal: 12.7ms\tremaining: 241ms\n",
      "1:\tlearn: 4507.0027872\ttotal: 23.4ms\tremaining: 211ms\n",
      "2:\tlearn: 4458.3813327\ttotal: 34.5ms\tremaining: 196ms\n",
      "3:\tlearn: 4414.0412016\ttotal: 45.7ms\tremaining: 183ms\n",
      "4:\tlearn: 4372.3993501\ttotal: 57.4ms\tremaining: 172ms\n",
      "5:\tlearn: 4334.6532826\ttotal: 68.2ms\tremaining: 159ms\n",
      "6:\tlearn: 4300.0994929\ttotal: 80.9ms\tremaining: 150ms\n",
      "7:\tlearn: 4268.0567302\ttotal: 93.3ms\tremaining: 140ms\n",
      "8:\tlearn: 4239.5903493\ttotal: 105ms\tremaining: 128ms\n",
      "9:\tlearn: 4213.7005935\ttotal: 115ms\tremaining: 115ms\n",
      "10:\tlearn: 4189.7231479\ttotal: 127ms\tremaining: 104ms\n",
      "11:\tlearn: 4167.6173277\ttotal: 138ms\tremaining: 92ms\n",
      "12:\tlearn: 4145.7403407\ttotal: 149ms\tremaining: 80.5ms\n",
      "13:\tlearn: 4124.3321595\ttotal: 161ms\tremaining: 68.8ms\n",
      "14:\tlearn: 4107.3978414\ttotal: 171ms\tremaining: 57.2ms\n",
      "15:\tlearn: 4090.5790828\ttotal: 183ms\tremaining: 45.7ms\n",
      "16:\tlearn: 4075.9915388\ttotal: 193ms\tremaining: 34.1ms\n",
      "17:\tlearn: 4060.1354086\ttotal: 205ms\tremaining: 22.8ms\n",
      "18:\tlearn: 4046.7860621\ttotal: 216ms\tremaining: 11.4ms\n",
      "19:\tlearn: 4033.1758386\ttotal: 228ms\tremaining: 0us\n",
      "0:\tlearn: 4509.9425451\ttotal: 11.9ms\tremaining: 226ms\n",
      "1:\tlearn: 4412.2365564\ttotal: 22.8ms\tremaining: 205ms\n",
      "2:\tlearn: 4330.9114892\ttotal: 34.2ms\tremaining: 194ms\n",
      "3:\tlearn: 4266.0989266\ttotal: 44.7ms\tremaining: 179ms\n",
      "4:\tlearn: 4208.7094854\ttotal: 56.4ms\tremaining: 169ms\n",
      "5:\tlearn: 4161.9707224\ttotal: 67.6ms\tremaining: 158ms\n",
      "6:\tlearn: 4115.5774488\ttotal: 78.8ms\tremaining: 146ms\n",
      "7:\tlearn: 4076.0618186\ttotal: 90.1ms\tremaining: 135ms\n",
      "8:\tlearn: 4046.5485121\ttotal: 101ms\tremaining: 123ms\n",
      "9:\tlearn: 4022.5514254\ttotal: 113ms\tremaining: 113ms\n",
      "10:\tlearn: 3996.8157828\ttotal: 125ms\tremaining: 102ms\n",
      "11:\tlearn: 3975.1578150\ttotal: 137ms\tremaining: 91.5ms\n",
      "12:\tlearn: 3958.6047436\ttotal: 148ms\tremaining: 79.9ms\n",
      "13:\tlearn: 3941.8079888\ttotal: 160ms\tremaining: 68.5ms\n",
      "14:\tlearn: 3921.5556523\ttotal: 171ms\tremaining: 57.1ms\n",
      "15:\tlearn: 3908.2993589\ttotal: 183ms\tremaining: 45.8ms\n",
      "16:\tlearn: 3896.9863269\ttotal: 195ms\tremaining: 34.4ms\n",
      "17:\tlearn: 3882.2975604\ttotal: 207ms\tremaining: 23ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:\tlearn: 3874.0801067\ttotal: 218ms\tremaining: 11.5ms\n",
      "19:\tlearn: 3860.8326416\ttotal: 230ms\tremaining: 0us\n",
      "0:\tlearn: 4503.5945229\ttotal: 12.1ms\tremaining: 230ms\n",
      "1:\tlearn: 4406.6057191\ttotal: 23.2ms\tremaining: 209ms\n",
      "2:\tlearn: 4325.4170103\ttotal: 35.2ms\tremaining: 200ms\n",
      "3:\tlearn: 4259.6060887\ttotal: 46.5ms\tremaining: 186ms\n",
      "4:\tlearn: 4202.2621613\ttotal: 57.7ms\tremaining: 173ms\n",
      "5:\tlearn: 4154.9964002\ttotal: 68.5ms\tremaining: 160ms\n",
      "6:\tlearn: 4116.6253029\ttotal: 79.6ms\tremaining: 148ms\n",
      "7:\tlearn: 4075.4565122\ttotal: 91.1ms\tremaining: 137ms\n",
      "8:\tlearn: 4048.3321599\ttotal: 102ms\tremaining: 125ms\n",
      "9:\tlearn: 4024.0398489\ttotal: 114ms\tremaining: 114ms\n",
      "10:\tlearn: 3998.4928102\ttotal: 126ms\tremaining: 103ms\n",
      "11:\tlearn: 3976.4356951\ttotal: 139ms\tremaining: 92.7ms\n",
      "12:\tlearn: 3955.6992438\ttotal: 150ms\tremaining: 80.9ms\n",
      "13:\tlearn: 3938.0792118\ttotal: 162ms\tremaining: 69.4ms\n",
      "14:\tlearn: 3923.6604117\ttotal: 174ms\tremaining: 58.1ms\n",
      "15:\tlearn: 3910.1838184\ttotal: 186ms\tremaining: 46.5ms\n",
      "16:\tlearn: 3898.6071554\ttotal: 197ms\tremaining: 34.8ms\n",
      "17:\tlearn: 3888.2365933\ttotal: 209ms\tremaining: 23.2ms\n",
      "18:\tlearn: 3873.2384897\ttotal: 221ms\tremaining: 11.6ms\n",
      "19:\tlearn: 3862.5762932\ttotal: 231ms\tremaining: 0us\n",
      "0:\tlearn: 4513.7534495\ttotal: 12ms\tremaining: 229ms\n",
      "1:\tlearn: 4416.8382833\ttotal: 23ms\tremaining: 207ms\n",
      "2:\tlearn: 4337.0433791\ttotal: 34.3ms\tremaining: 195ms\n",
      "3:\tlearn: 4271.4545258\ttotal: 44.8ms\tremaining: 179ms\n",
      "4:\tlearn: 4214.2304405\ttotal: 56.9ms\tremaining: 171ms\n",
      "5:\tlearn: 4166.8484479\ttotal: 68.6ms\tremaining: 160ms\n",
      "6:\tlearn: 4128.4101376\ttotal: 80.6ms\tremaining: 150ms\n",
      "7:\tlearn: 4087.3989332\ttotal: 91.2ms\tremaining: 137ms\n",
      "8:\tlearn: 4059.5799820\ttotal: 103ms\tremaining: 126ms\n",
      "9:\tlearn: 4034.4195441\ttotal: 113ms\tremaining: 113ms\n",
      "10:\tlearn: 4007.7115554\ttotal: 124ms\tremaining: 102ms\n",
      "11:\tlearn: 3985.0365098\ttotal: 135ms\tremaining: 90.3ms\n",
      "12:\tlearn: 3964.1025433\ttotal: 146ms\tremaining: 78.5ms\n",
      "13:\tlearn: 3947.0061251\ttotal: 157ms\tremaining: 67.3ms\n",
      "14:\tlearn: 3926.3340633\ttotal: 167ms\tremaining: 55.8ms\n",
      "15:\tlearn: 3910.6229799\ttotal: 178ms\tremaining: 44.6ms\n",
      "16:\tlearn: 3898.5096137\ttotal: 189ms\tremaining: 33.4ms\n",
      "17:\tlearn: 3884.6681846\ttotal: 200ms\tremaining: 22.2ms\n",
      "18:\tlearn: 3875.4664575\ttotal: 210ms\tremaining: 11ms\n",
      "19:\tlearn: 3862.8334793\ttotal: 221ms\tremaining: 0us\n",
      "0:\tlearn: 4510.5526783\ttotal: 12.1ms\tremaining: 230ms\n",
      "1:\tlearn: 4414.2526237\ttotal: 23ms\tremaining: 207ms\n",
      "2:\tlearn: 4333.4369795\ttotal: 34ms\tremaining: 192ms\n",
      "3:\tlearn: 4268.4739326\ttotal: 44.1ms\tremaining: 176ms\n",
      "4:\tlearn: 4211.9475248\ttotal: 54.9ms\tremaining: 165ms\n",
      "5:\tlearn: 4164.9389080\ttotal: 66.4ms\tremaining: 155ms\n",
      "6:\tlearn: 4118.5912874\ttotal: 77.6ms\tremaining: 144ms\n",
      "7:\tlearn: 4086.3891410\ttotal: 88.2ms\tremaining: 132ms\n",
      "8:\tlearn: 4058.8465165\ttotal: 99.5ms\tremaining: 122ms\n",
      "9:\tlearn: 4034.1803578\ttotal: 110ms\tremaining: 110ms\n",
      "10:\tlearn: 4007.6997500\ttotal: 122ms\tremaining: 99.8ms\n",
      "11:\tlearn: 3988.8482360\ttotal: 133ms\tremaining: 88.7ms\n",
      "12:\tlearn: 3967.7782331\ttotal: 144ms\tremaining: 77.7ms\n",
      "13:\tlearn: 3949.7367794\ttotal: 155ms\tremaining: 66.5ms\n",
      "14:\tlearn: 3934.7603318\ttotal: 166ms\tremaining: 55.3ms\n",
      "15:\tlearn: 3918.0880211\ttotal: 177ms\tremaining: 44.3ms\n",
      "16:\tlearn: 3907.1958992\ttotal: 188ms\tremaining: 33.1ms\n",
      "17:\tlearn: 3892.9968217\ttotal: 199ms\tremaining: 22.1ms\n",
      "18:\tlearn: 3884.3567568\ttotal: 209ms\tremaining: 11ms\n",
      "19:\tlearn: 3875.8237431\ttotal: 220ms\tremaining: 0us\n",
      "0:\tlearn: 4505.1497407\ttotal: 12.4ms\tremaining: 236ms\n",
      "1:\tlearn: 4408.1029504\ttotal: 23.5ms\tremaining: 211ms\n",
      "2:\tlearn: 4327.2619958\ttotal: 35.2ms\tremaining: 200ms\n",
      "3:\tlearn: 4261.0067684\ttotal: 46.9ms\tremaining: 188ms\n",
      "4:\tlearn: 4204.3835106\ttotal: 58.8ms\tremaining: 176ms\n",
      "5:\tlearn: 4157.2091407\ttotal: 69.9ms\tremaining: 163ms\n",
      "6:\tlearn: 4110.6486577\ttotal: 82ms\tremaining: 152ms\n",
      "7:\tlearn: 4077.0556064\ttotal: 93.3ms\tremaining: 140ms\n",
      "8:\tlearn: 4050.0711946\ttotal: 105ms\tremaining: 128ms\n",
      "9:\tlearn: 4026.2690408\ttotal: 115ms\tremaining: 115ms\n",
      "10:\tlearn: 3999.5684157\ttotal: 127ms\tremaining: 104ms\n",
      "11:\tlearn: 3981.2102965\ttotal: 139ms\tremaining: 92.9ms\n",
      "12:\tlearn: 3963.3906278\ttotal: 151ms\tremaining: 81.1ms\n",
      "13:\tlearn: 3947.8911170\ttotal: 162ms\tremaining: 69.4ms\n",
      "14:\tlearn: 3933.5924768\ttotal: 174ms\tremaining: 58.1ms\n",
      "15:\tlearn: 3916.2593817\ttotal: 186ms\tremaining: 46.4ms\n",
      "16:\tlearn: 3904.8448790\ttotal: 196ms\tremaining: 34.6ms\n",
      "17:\tlearn: 3892.6502047\ttotal: 208ms\tremaining: 23.1ms\n",
      "18:\tlearn: 3884.8770509\ttotal: 218ms\tremaining: 11.4ms\n",
      "19:\tlearn: 3873.9260469\ttotal: 228ms\tremaining: 0us\n",
      "0:\tlearn: 4613.6122908\ttotal: 22ms\tremaining: 198ms\n",
      "1:\tlearn: 4600.8342954\ttotal: 41.7ms\tremaining: 167ms\n",
      "2:\tlearn: 4588.1463201\ttotal: 60.7ms\tremaining: 142ms\n",
      "3:\tlearn: 4576.7305281\ttotal: 80.9ms\tremaining: 121ms\n",
      "4:\tlearn: 4564.6579499\ttotal: 101ms\tremaining: 101ms\n",
      "5:\tlearn: 4552.4527351\ttotal: 119ms\tremaining: 79.6ms\n",
      "6:\tlearn: 4540.4256741\ttotal: 139ms\tremaining: 59.5ms\n",
      "7:\tlearn: 4528.7062222\ttotal: 158ms\tremaining: 39.6ms\n",
      "8:\tlearn: 4517.2579614\ttotal: 178ms\tremaining: 19.8ms\n",
      "9:\tlearn: 4506.3083267\ttotal: 198ms\tremaining: 0us\n",
      "0:\tlearn: 4604.7800388\ttotal: 22.5ms\tremaining: 203ms\n",
      "1:\tlearn: 4592.1774971\ttotal: 45.4ms\tremaining: 182ms\n",
      "2:\tlearn: 4580.2931459\ttotal: 67.5ms\tremaining: 158ms\n",
      "3:\tlearn: 4568.9002428\ttotal: 88.7ms\tremaining: 133ms\n",
      "4:\tlearn: 4556.8511509\ttotal: 110ms\tremaining: 110ms\n",
      "5:\tlearn: 4544.9733678\ttotal: 131ms\tremaining: 87.1ms\n",
      "6:\tlearn: 4533.5574676\ttotal: 150ms\tremaining: 64.3ms\n",
      "7:\tlearn: 4521.7246287\ttotal: 171ms\tremaining: 42.6ms\n",
      "8:\tlearn: 4510.4217434\ttotal: 191ms\tremaining: 21.2ms\n",
      "9:\tlearn: 4499.5120679\ttotal: 210ms\tremaining: 0us\n",
      "0:\tlearn: 4615.6723384\ttotal: 22.1ms\tremaining: 199ms\n",
      "1:\tlearn: 4602.6050718\ttotal: 41.7ms\tremaining: 167ms\n",
      "2:\tlearn: 4590.2312006\ttotal: 61.5ms\tremaining: 143ms\n",
      "3:\tlearn: 4578.6246034\ttotal: 81.1ms\tremaining: 122ms\n",
      "4:\tlearn: 4567.2175105\ttotal: 100ms\tremaining: 100ms\n",
      "5:\tlearn: 4555.0123814\ttotal: 121ms\tremaining: 80.8ms\n",
      "6:\tlearn: 4543.4095176\ttotal: 142ms\tremaining: 60.7ms\n",
      "7:\tlearn: 4531.6723034\ttotal: 162ms\tremaining: 40.4ms\n",
      "8:\tlearn: 4520.6254826\ttotal: 181ms\tremaining: 20.1ms\n",
      "9:\tlearn: 4509.7174931\ttotal: 202ms\tremaining: 0us\n",
      "0:\tlearn: 4611.4260480\ttotal: 23.7ms\tremaining: 213ms\n",
      "1:\tlearn: 4598.4030884\ttotal: 43.1ms\tremaining: 172ms\n",
      "2:\tlearn: 4587.7180721\ttotal: 53ms\tremaining: 124ms\n",
      "3:\tlearn: 4575.8502737\ttotal: 73.4ms\tremaining: 110ms\n",
      "4:\tlearn: 4563.9391954\ttotal: 93.3ms\tremaining: 93.3ms\n",
      "5:\tlearn: 4552.4419587\ttotal: 113ms\tremaining: 75.2ms\n",
      "6:\tlearn: 4540.8457261\ttotal: 133ms\tremaining: 56.9ms\n",
      "7:\tlearn: 4529.2425589\ttotal: 153ms\tremaining: 38.2ms\n",
      "8:\tlearn: 4518.1798658\ttotal: 172ms\tremaining: 19.2ms\n",
      "9:\tlearn: 4507.7120477\ttotal: 194ms\tremaining: 0us\n",
      "0:\tlearn: 4606.5259155\ttotal: 21.7ms\tremaining: 196ms\n",
      "1:\tlearn: 4593.9952048\ttotal: 41.6ms\tremaining: 167ms\n",
      "2:\tlearn: 4583.2509350\ttotal: 51.5ms\tremaining: 120ms\n",
      "3:\tlearn: 4571.3370425\ttotal: 72.7ms\tremaining: 109ms\n",
      "4:\tlearn: 4559.3807644\ttotal: 94ms\tremaining: 94ms\n",
      "5:\tlearn: 4547.4047259\ttotal: 114ms\tremaining: 76.2ms\n",
      "6:\tlearn: 4535.8279255\ttotal: 135ms\tremaining: 57.8ms\n",
      "7:\tlearn: 4524.2250003\ttotal: 155ms\tremaining: 38.6ms\n",
      "8:\tlearn: 4513.4990821\ttotal: 175ms\tremaining: 19.5ms\n",
      "9:\tlearn: 4503.0519792\ttotal: 196ms\tremaining: 0us\n",
      "0:\tlearn: 4563.9054494\ttotal: 23.7ms\tremaining: 213ms\n",
      "1:\tlearn: 4504.7130098\ttotal: 43.3ms\tremaining: 173ms\n",
      "2:\tlearn: 4453.4292411\ttotal: 62.5ms\tremaining: 146ms\n",
      "3:\tlearn: 4406.4974654\ttotal: 82.2ms\tremaining: 123ms\n",
      "4:\tlearn: 4361.3811481\ttotal: 102ms\tremaining: 102ms\n",
      "5:\tlearn: 4317.2970250\ttotal: 121ms\tremaining: 80.8ms\n",
      "6:\tlearn: 4277.2037724\ttotal: 141ms\tremaining: 60.6ms\n",
      "7:\tlearn: 4239.9490117\ttotal: 161ms\tremaining: 40.3ms\n",
      "8:\tlearn: 4208.7424629\ttotal: 182ms\tremaining: 20.2ms\n",
      "9:\tlearn: 4178.2331183\ttotal: 201ms\tremaining: 0us\n",
      "0:\tlearn: 4555.3038989\ttotal: 21.3ms\tremaining: 192ms\n",
      "1:\tlearn: 4494.5192945\ttotal: 43.1ms\tremaining: 173ms\n",
      "2:\tlearn: 4448.5484526\ttotal: 52.7ms\tremaining: 123ms\n",
      "3:\tlearn: 4400.3759868\ttotal: 73.6ms\tremaining: 110ms\n",
      "4:\tlearn: 4353.4593894\ttotal: 95.3ms\tremaining: 95.3ms\n",
      "5:\tlearn: 4312.1193666\ttotal: 118ms\tremaining: 78.4ms\n",
      "6:\tlearn: 4274.1994854\ttotal: 137ms\tremaining: 58.8ms\n",
      "7:\tlearn: 4237.5963272\ttotal: 157ms\tremaining: 39.2ms\n",
      "8:\tlearn: 4205.0484755\ttotal: 177ms\tremaining: 19.7ms\n",
      "9:\tlearn: 4175.6661400\ttotal: 198ms\tremaining: 0us\n",
      "0:\tlearn: 4565.8109162\ttotal: 21.2ms\tremaining: 191ms\n",
      "1:\tlearn: 4505.2342935\ttotal: 41.2ms\tremaining: 165ms\n",
      "2:\tlearn: 4454.4274219\ttotal: 60.6ms\tremaining: 141ms\n",
      "3:\tlearn: 4407.8064975\ttotal: 81.5ms\tremaining: 122ms\n",
      "4:\tlearn: 4362.1855208\ttotal: 101ms\tremaining: 101ms\n",
      "5:\tlearn: 4318.2492303\ttotal: 120ms\tremaining: 79.8ms\n",
      "6:\tlearn: 4280.9590941\ttotal: 140ms\tremaining: 59.9ms\n",
      "7:\tlearn: 4243.5691230\ttotal: 160ms\tremaining: 40ms\n",
      "8:\tlearn: 4211.3083347\ttotal: 181ms\tremaining: 20.1ms\n",
      "9:\tlearn: 4181.7179590\ttotal: 201ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4562.4550000\ttotal: 21.7ms\tremaining: 195ms\n",
      "1:\tlearn: 4502.0197965\ttotal: 42.1ms\tremaining: 168ms\n",
      "2:\tlearn: 4456.3842517\ttotal: 51.4ms\tremaining: 120ms\n",
      "3:\tlearn: 4408.2955653\ttotal: 71.5ms\tremaining: 107ms\n",
      "4:\tlearn: 4361.7292385\ttotal: 91.8ms\tremaining: 91.8ms\n",
      "5:\tlearn: 4319.8329055\ttotal: 114ms\tremaining: 75.8ms\n",
      "6:\tlearn: 4282.9781647\ttotal: 135ms\tremaining: 57.7ms\n",
      "7:\tlearn: 4246.1758973\ttotal: 155ms\tremaining: 38.6ms\n",
      "8:\tlearn: 4214.4122215\ttotal: 174ms\tremaining: 19.3ms\n",
      "9:\tlearn: 4185.1930260\ttotal: 193ms\tremaining: 0us\n",
      "0:\tlearn: 4556.8288986\ttotal: 24ms\tremaining: 216ms\n",
      "1:\tlearn: 4498.7985919\ttotal: 44.4ms\tremaining: 178ms\n",
      "2:\tlearn: 4452.8724774\ttotal: 54.2ms\tremaining: 126ms\n",
      "3:\tlearn: 4404.5798968\ttotal: 74.5ms\tremaining: 112ms\n",
      "4:\tlearn: 4357.9168808\ttotal: 93.5ms\tremaining: 93.5ms\n",
      "5:\tlearn: 4315.2842651\ttotal: 114ms\tremaining: 75.8ms\n",
      "6:\tlearn: 4277.3967059\ttotal: 134ms\tremaining: 57.3ms\n",
      "7:\tlearn: 4240.6104349\ttotal: 153ms\tremaining: 38.4ms\n",
      "8:\tlearn: 4208.8879741\ttotal: 173ms\tremaining: 19.2ms\n",
      "9:\tlearn: 4179.8799963\ttotal: 195ms\tremaining: 0us\n",
      "0:\tlearn: 4503.9125523\ttotal: 23ms\tremaining: 207ms\n",
      "1:\tlearn: 4396.8573569\ttotal: 44.1ms\tremaining: 176ms\n",
      "2:\tlearn: 4305.8580382\ttotal: 63.6ms\tremaining: 149ms\n",
      "3:\tlearn: 4235.5961384\ttotal: 83ms\tremaining: 125ms\n",
      "4:\tlearn: 4175.3215995\ttotal: 103ms\tremaining: 103ms\n",
      "5:\tlearn: 4119.3780405\ttotal: 124ms\tremaining: 82.8ms\n",
      "6:\tlearn: 4072.8867465\ttotal: 145ms\tremaining: 62.2ms\n",
      "7:\tlearn: 4031.9322334\ttotal: 165ms\tremaining: 41.4ms\n",
      "8:\tlearn: 3996.9545586\ttotal: 185ms\tremaining: 20.6ms\n",
      "9:\tlearn: 3967.0394240\ttotal: 205ms\tremaining: 0us\n",
      "0:\tlearn: 4495.5893626\ttotal: 22.5ms\tremaining: 203ms\n",
      "1:\tlearn: 4385.4591995\ttotal: 43.1ms\tremaining: 172ms\n",
      "2:\tlearn: 4310.9390216\ttotal: 52.5ms\tremaining: 123ms\n",
      "3:\tlearn: 4238.9999614\ttotal: 72.5ms\tremaining: 109ms\n",
      "4:\tlearn: 4172.9042800\ttotal: 91.7ms\tremaining: 91.7ms\n",
      "5:\tlearn: 4119.1256758\ttotal: 111ms\tremaining: 74.1ms\n",
      "6:\tlearn: 4075.5826735\ttotal: 131ms\tremaining: 56.3ms\n",
      "7:\tlearn: 4034.0023787\ttotal: 153ms\tremaining: 38.4ms\n",
      "8:\tlearn: 3999.0906576\ttotal: 173ms\tremaining: 19.3ms\n",
      "9:\tlearn: 3966.8498584\ttotal: 193ms\tremaining: 0us\n",
      "0:\tlearn: 4505.6284457\ttotal: 21.9ms\tremaining: 197ms\n",
      "1:\tlearn: 4395.7106289\ttotal: 41.8ms\tremaining: 167ms\n",
      "2:\tlearn: 4321.3380185\ttotal: 51.3ms\tremaining: 120ms\n",
      "3:\tlearn: 4249.3140417\ttotal: 72.3ms\tremaining: 108ms\n",
      "4:\tlearn: 4183.1909667\ttotal: 91.9ms\tremaining: 91.9ms\n",
      "5:\tlearn: 4130.5405112\ttotal: 112ms\tremaining: 74.4ms\n",
      "6:\tlearn: 4086.9119505\ttotal: 132ms\tremaining: 56.4ms\n",
      "7:\tlearn: 4044.9323452\ttotal: 152ms\tremaining: 38.1ms\n",
      "8:\tlearn: 4009.9872741\ttotal: 173ms\tremaining: 19.3ms\n",
      "9:\tlearn: 3979.5126401\ttotal: 193ms\tremaining: 0us\n",
      "0:\tlearn: 4503.3596361\ttotal: 23.1ms\tremaining: 208ms\n",
      "1:\tlearn: 4393.9195120\ttotal: 43.4ms\tremaining: 174ms\n",
      "2:\tlearn: 4319.9964127\ttotal: 53.4ms\tremaining: 125ms\n",
      "3:\tlearn: 4247.5181380\ttotal: 73.2ms\tremaining: 110ms\n",
      "4:\tlearn: 4181.6349768\ttotal: 94.3ms\tremaining: 94.3ms\n",
      "5:\tlearn: 4128.5784288\ttotal: 114ms\tremaining: 76.2ms\n",
      "6:\tlearn: 4085.3429805\ttotal: 135ms\tremaining: 57.9ms\n",
      "7:\tlearn: 4038.3811411\ttotal: 155ms\tremaining: 38.8ms\n",
      "8:\tlearn: 4003.5667305\ttotal: 175ms\tremaining: 19.4ms\n",
      "9:\tlearn: 3970.8228580\ttotal: 195ms\tremaining: 0us\n",
      "0:\tlearn: 4496.8454647\ttotal: 20.5ms\tremaining: 185ms\n",
      "1:\tlearn: 4387.4435628\ttotal: 40.5ms\tremaining: 162ms\n",
      "2:\tlearn: 4313.2203195\ttotal: 50ms\tremaining: 117ms\n",
      "3:\tlearn: 4240.5752475\ttotal: 70.1ms\tremaining: 105ms\n",
      "4:\tlearn: 4172.5173969\ttotal: 90ms\tremaining: 90ms\n",
      "5:\tlearn: 4120.0018029\ttotal: 110ms\tremaining: 73.2ms\n",
      "6:\tlearn: 4076.2804730\ttotal: 131ms\tremaining: 56ms\n",
      "7:\tlearn: 4032.1053393\ttotal: 151ms\tremaining: 37.7ms\n",
      "8:\tlearn: 3999.6983532\ttotal: 170ms\tremaining: 18.9ms\n",
      "9:\tlearn: 3967.2035886\ttotal: 191ms\tremaining: 0us\n",
      "0:\tlearn: 4613.6122908\ttotal: 21.3ms\tremaining: 299ms\n",
      "1:\tlearn: 4600.8342954\ttotal: 41.5ms\tremaining: 270ms\n",
      "2:\tlearn: 4588.1463201\ttotal: 60.9ms\tremaining: 244ms\n",
      "3:\tlearn: 4576.7305281\ttotal: 81.2ms\tremaining: 223ms\n",
      "4:\tlearn: 4564.6579499\ttotal: 101ms\tremaining: 202ms\n",
      "5:\tlearn: 4552.4527351\ttotal: 121ms\tremaining: 182ms\n",
      "6:\tlearn: 4540.4256741\ttotal: 140ms\tremaining: 161ms\n",
      "7:\tlearn: 4528.7062222\ttotal: 160ms\tremaining: 140ms\n",
      "8:\tlearn: 4517.2579614\ttotal: 180ms\tremaining: 120ms\n",
      "9:\tlearn: 4506.3083267\ttotal: 201ms\tremaining: 100ms\n",
      "10:\tlearn: 4495.5942088\ttotal: 220ms\tremaining: 80ms\n",
      "11:\tlearn: 4484.3935937\ttotal: 242ms\tremaining: 60.5ms\n",
      "12:\tlearn: 4475.0715519\ttotal: 253ms\tremaining: 39ms\n",
      "13:\tlearn: 4464.9531871\ttotal: 275ms\tremaining: 19.6ms\n",
      "14:\tlearn: 4454.3002914\ttotal: 295ms\tremaining: 0us\n",
      "0:\tlearn: 4604.7800388\ttotal: 23ms\tremaining: 322ms\n",
      "1:\tlearn: 4592.1774971\ttotal: 43.8ms\tremaining: 285ms\n",
      "2:\tlearn: 4580.2931459\ttotal: 63.9ms\tremaining: 256ms\n",
      "3:\tlearn: 4568.9002428\ttotal: 83.6ms\tremaining: 230ms\n",
      "4:\tlearn: 4556.8511509\ttotal: 104ms\tremaining: 209ms\n",
      "5:\tlearn: 4544.9733678\ttotal: 126ms\tremaining: 190ms\n",
      "6:\tlearn: 4533.5574676\ttotal: 147ms\tremaining: 168ms\n",
      "7:\tlearn: 4521.7246287\ttotal: 167ms\tremaining: 147ms\n",
      "8:\tlearn: 4510.4217434\ttotal: 188ms\tremaining: 125ms\n",
      "9:\tlearn: 4499.5120679\ttotal: 207ms\tremaining: 104ms\n",
      "10:\tlearn: 4489.2071642\ttotal: 227ms\tremaining: 82.6ms\n",
      "11:\tlearn: 4477.9158099\ttotal: 248ms\tremaining: 62ms\n",
      "12:\tlearn: 4468.6404938\ttotal: 260ms\tremaining: 40ms\n",
      "13:\tlearn: 4457.8220211\ttotal: 279ms\tremaining: 19.9ms\n",
      "14:\tlearn: 4447.4196957\ttotal: 299ms\tremaining: 0us\n",
      "0:\tlearn: 4615.6723384\ttotal: 22.6ms\tremaining: 316ms\n",
      "1:\tlearn: 4602.6050718\ttotal: 42.1ms\tremaining: 273ms\n",
      "2:\tlearn: 4590.2312006\ttotal: 62.8ms\tremaining: 251ms\n",
      "3:\tlearn: 4578.6246034\ttotal: 83.7ms\tremaining: 230ms\n",
      "4:\tlearn: 4567.2175105\ttotal: 104ms\tremaining: 208ms\n",
      "5:\tlearn: 4555.0123814\ttotal: 124ms\tremaining: 187ms\n",
      "6:\tlearn: 4543.4095176\ttotal: 144ms\tremaining: 165ms\n",
      "7:\tlearn: 4531.6723034\ttotal: 165ms\tremaining: 144ms\n",
      "8:\tlearn: 4520.6254826\ttotal: 184ms\tremaining: 123ms\n",
      "9:\tlearn: 4509.7174931\ttotal: 205ms\tremaining: 102ms\n",
      "10:\tlearn: 4499.0399721\ttotal: 226ms\tremaining: 82ms\n",
      "11:\tlearn: 4488.5122777\ttotal: 247ms\tremaining: 61.7ms\n",
      "12:\tlearn: 4479.2283417\ttotal: 260ms\tremaining: 39.9ms\n",
      "13:\tlearn: 4468.9595131\ttotal: 280ms\tremaining: 20ms\n",
      "14:\tlearn: 4458.5613534\ttotal: 302ms\tremaining: 0us\n",
      "0:\tlearn: 4611.4260480\ttotal: 23.2ms\tremaining: 325ms\n",
      "1:\tlearn: 4598.4030884\ttotal: 43.4ms\tremaining: 282ms\n",
      "2:\tlearn: 4587.7180721\ttotal: 53.8ms\tremaining: 215ms\n",
      "3:\tlearn: 4575.8502737\ttotal: 74.4ms\tremaining: 205ms\n",
      "4:\tlearn: 4563.9391954\ttotal: 103ms\tremaining: 207ms\n",
      "5:\tlearn: 4552.4419587\ttotal: 124ms\tremaining: 186ms\n",
      "6:\tlearn: 4540.8457261\ttotal: 144ms\tremaining: 164ms\n",
      "7:\tlearn: 4529.2425589\ttotal: 164ms\tremaining: 144ms\n",
      "8:\tlearn: 4518.1798658\ttotal: 184ms\tremaining: 122ms\n",
      "9:\tlearn: 4507.7120477\ttotal: 203ms\tremaining: 101ms\n",
      "10:\tlearn: 4496.8125516\ttotal: 223ms\tremaining: 81.2ms\n",
      "11:\tlearn: 4485.9942051\ttotal: 243ms\tremaining: 60.7ms\n",
      "12:\tlearn: 4475.6228689\ttotal: 262ms\tremaining: 40.4ms\n",
      "13:\tlearn: 4465.4288292\ttotal: 282ms\tremaining: 20.2ms\n",
      "14:\tlearn: 4455.5710031\ttotal: 302ms\tremaining: 0us\n",
      "0:\tlearn: 4606.5259155\ttotal: 21.6ms\tremaining: 302ms\n",
      "1:\tlearn: 4593.9952048\ttotal: 40.9ms\tremaining: 266ms\n",
      "2:\tlearn: 4583.2509350\ttotal: 51.5ms\tremaining: 206ms\n",
      "3:\tlearn: 4571.3370425\ttotal: 71.8ms\tremaining: 197ms\n",
      "4:\tlearn: 4559.3807644\ttotal: 91.7ms\tremaining: 183ms\n",
      "5:\tlearn: 4547.4047259\ttotal: 112ms\tremaining: 167ms\n",
      "6:\tlearn: 4535.8279255\ttotal: 131ms\tremaining: 149ms\n",
      "7:\tlearn: 4524.2250003\ttotal: 154ms\tremaining: 134ms\n",
      "8:\tlearn: 4513.4990821\ttotal: 174ms\tremaining: 116ms\n",
      "9:\tlearn: 4503.0519792\ttotal: 193ms\tremaining: 96.7ms\n",
      "10:\tlearn: 4492.1424933\ttotal: 213ms\tremaining: 77.6ms\n",
      "11:\tlearn: 4481.8135602\ttotal: 234ms\tremaining: 58.6ms\n",
      "12:\tlearn: 4471.4417921\ttotal: 254ms\tremaining: 39ms\n",
      "13:\tlearn: 4461.2803292\ttotal: 273ms\tremaining: 19.5ms\n",
      "14:\tlearn: 4452.7562681\ttotal: 282ms\tremaining: 0us\n",
      "0:\tlearn: 4563.9054494\ttotal: 22.4ms\tremaining: 314ms\n",
      "1:\tlearn: 4504.7130098\ttotal: 44.3ms\tremaining: 288ms\n",
      "2:\tlearn: 4453.4292411\ttotal: 63.3ms\tremaining: 253ms\n",
      "3:\tlearn: 4406.4974654\ttotal: 84.1ms\tremaining: 231ms\n",
      "4:\tlearn: 4361.3811481\ttotal: 103ms\tremaining: 207ms\n",
      "5:\tlearn: 4317.2970250\ttotal: 125ms\tremaining: 187ms\n",
      "6:\tlearn: 4277.2037724\ttotal: 144ms\tremaining: 165ms\n",
      "7:\tlearn: 4239.9490117\ttotal: 164ms\tremaining: 143ms\n",
      "8:\tlearn: 4208.7424629\ttotal: 183ms\tremaining: 122ms\n",
      "9:\tlearn: 4178.2331183\ttotal: 203ms\tremaining: 102ms\n",
      "10:\tlearn: 4148.9309273\ttotal: 223ms\tremaining: 81.1ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:\tlearn: 4121.0012319\ttotal: 244ms\tremaining: 60.9ms\n",
      "12:\tlearn: 4101.6072152\ttotal: 256ms\tremaining: 39.4ms\n",
      "13:\tlearn: 4081.2173017\ttotal: 277ms\tremaining: 19.8ms\n",
      "14:\tlearn: 4058.8300414\ttotal: 297ms\tremaining: 0us\n",
      "0:\tlearn: 4555.3038989\ttotal: 22.4ms\tremaining: 314ms\n",
      "1:\tlearn: 4494.5192945\ttotal: 43.5ms\tremaining: 283ms\n",
      "2:\tlearn: 4448.5484526\ttotal: 53.8ms\tremaining: 215ms\n",
      "3:\tlearn: 4400.3759868\ttotal: 74.1ms\tremaining: 204ms\n",
      "4:\tlearn: 4353.4593894\ttotal: 95.5ms\tremaining: 191ms\n",
      "5:\tlearn: 4312.1193666\ttotal: 116ms\tremaining: 174ms\n",
      "6:\tlearn: 4274.1994854\ttotal: 136ms\tremaining: 156ms\n",
      "7:\tlearn: 4237.5963272\ttotal: 157ms\tremaining: 137ms\n",
      "8:\tlearn: 4205.0484755\ttotal: 176ms\tremaining: 117ms\n",
      "9:\tlearn: 4175.6661400\ttotal: 196ms\tremaining: 97.8ms\n",
      "10:\tlearn: 4147.1527490\ttotal: 216ms\tremaining: 78.5ms\n",
      "11:\tlearn: 4122.3027329\ttotal: 235ms\tremaining: 58.8ms\n",
      "12:\tlearn: 4099.3302081\ttotal: 255ms\tremaining: 39.2ms\n",
      "13:\tlearn: 4079.7073742\ttotal: 275ms\tremaining: 19.7ms\n",
      "14:\tlearn: 4065.1100307\ttotal: 283ms\tremaining: 0us\n",
      "0:\tlearn: 4565.8109162\ttotal: 22.9ms\tremaining: 320ms\n",
      "1:\tlearn: 4505.2342935\ttotal: 42.6ms\tremaining: 277ms\n",
      "2:\tlearn: 4454.4274219\ttotal: 62ms\tremaining: 248ms\n",
      "3:\tlearn: 4407.8064975\ttotal: 81.5ms\tremaining: 224ms\n",
      "4:\tlearn: 4362.1855208\ttotal: 102ms\tremaining: 204ms\n",
      "5:\tlearn: 4318.2492303\ttotal: 122ms\tremaining: 182ms\n",
      "6:\tlearn: 4280.9590941\ttotal: 143ms\tremaining: 163ms\n",
      "7:\tlearn: 4243.5691230\ttotal: 162ms\tremaining: 142ms\n",
      "8:\tlearn: 4211.3083347\ttotal: 182ms\tremaining: 121ms\n",
      "9:\tlearn: 4181.7179590\ttotal: 203ms\tremaining: 101ms\n",
      "10:\tlearn: 4153.6525379\ttotal: 222ms\tremaining: 80.8ms\n",
      "11:\tlearn: 4125.8095384\ttotal: 242ms\tremaining: 60.5ms\n",
      "12:\tlearn: 4106.4785791\ttotal: 254ms\tremaining: 39.1ms\n",
      "13:\tlearn: 4085.0729028\ttotal: 275ms\tremaining: 19.6ms\n",
      "14:\tlearn: 4062.7166450\ttotal: 294ms\tremaining: 0us\n",
      "0:\tlearn: 4562.4550000\ttotal: 22.1ms\tremaining: 310ms\n",
      "1:\tlearn: 4502.0197965\ttotal: 41.6ms\tremaining: 271ms\n",
      "2:\tlearn: 4456.3842517\ttotal: 51.5ms\tremaining: 206ms\n",
      "3:\tlearn: 4408.2955653\ttotal: 70.9ms\tremaining: 195ms\n",
      "4:\tlearn: 4361.7292385\ttotal: 90.8ms\tremaining: 182ms\n",
      "5:\tlearn: 4319.8329055\ttotal: 112ms\tremaining: 169ms\n",
      "6:\tlearn: 4282.9781647\ttotal: 133ms\tremaining: 152ms\n",
      "7:\tlearn: 4246.1758973\ttotal: 154ms\tremaining: 135ms\n",
      "8:\tlearn: 4214.4122215\ttotal: 175ms\tremaining: 117ms\n",
      "9:\tlearn: 4185.1930260\ttotal: 196ms\tremaining: 97.8ms\n",
      "10:\tlearn: 4156.1160096\ttotal: 215ms\tremaining: 78.3ms\n",
      "11:\tlearn: 4131.5902804\ttotal: 235ms\tremaining: 58.8ms\n",
      "12:\tlearn: 4108.7952249\ttotal: 255ms\tremaining: 39.2ms\n",
      "13:\tlearn: 4085.7187000\ttotal: 275ms\tremaining: 19.6ms\n",
      "14:\tlearn: 4071.1990713\ttotal: 284ms\tremaining: 0us\n",
      "0:\tlearn: 4556.8288986\ttotal: 22.1ms\tremaining: 309ms\n",
      "1:\tlearn: 4498.7985919\ttotal: 42.8ms\tremaining: 278ms\n",
      "2:\tlearn: 4452.8724774\ttotal: 52.9ms\tremaining: 212ms\n",
      "3:\tlearn: 4404.5798968\ttotal: 73.9ms\tremaining: 203ms\n",
      "4:\tlearn: 4357.9168808\ttotal: 94.1ms\tremaining: 188ms\n",
      "5:\tlearn: 4315.2842651\ttotal: 114ms\tremaining: 171ms\n",
      "6:\tlearn: 4277.3967059\ttotal: 135ms\tremaining: 154ms\n",
      "7:\tlearn: 4240.6104349\ttotal: 155ms\tremaining: 135ms\n",
      "8:\tlearn: 4208.8879741\ttotal: 175ms\tremaining: 117ms\n",
      "9:\tlearn: 4179.8799963\ttotal: 196ms\tremaining: 97.8ms\n",
      "10:\tlearn: 4150.8557887\ttotal: 215ms\tremaining: 78.1ms\n",
      "11:\tlearn: 4126.2981448\ttotal: 235ms\tremaining: 58.8ms\n",
      "12:\tlearn: 4099.7284488\ttotal: 257ms\tremaining: 39.5ms\n",
      "13:\tlearn: 4079.6914067\ttotal: 277ms\tremaining: 19.8ms\n",
      "14:\tlearn: 4065.1462705\ttotal: 285ms\tremaining: 0us\n",
      "0:\tlearn: 4503.9125523\ttotal: 20.6ms\tremaining: 289ms\n",
      "1:\tlearn: 4396.8573569\ttotal: 41.7ms\tremaining: 271ms\n",
      "2:\tlearn: 4305.8580382\ttotal: 61.9ms\tremaining: 248ms\n",
      "3:\tlearn: 4235.5961384\ttotal: 82ms\tremaining: 226ms\n",
      "4:\tlearn: 4175.3215995\ttotal: 102ms\tremaining: 203ms\n",
      "5:\tlearn: 4119.3780405\ttotal: 122ms\tremaining: 183ms\n",
      "6:\tlearn: 4072.8867465\ttotal: 142ms\tremaining: 162ms\n",
      "7:\tlearn: 4031.9322334\ttotal: 162ms\tremaining: 142ms\n",
      "8:\tlearn: 3996.9545586\ttotal: 182ms\tremaining: 121ms\n",
      "9:\tlearn: 3967.0394240\ttotal: 202ms\tremaining: 101ms\n",
      "10:\tlearn: 3939.2446071\ttotal: 222ms\tremaining: 80.6ms\n",
      "11:\tlearn: 3912.9443106\ttotal: 241ms\tremaining: 60.3ms\n",
      "12:\tlearn: 3894.6321103\ttotal: 261ms\tremaining: 40.2ms\n",
      "13:\tlearn: 3872.4018145\ttotal: 280ms\tremaining: 20ms\n",
      "14:\tlearn: 3853.1928499\ttotal: 301ms\tremaining: 0us\n",
      "0:\tlearn: 4495.5893626\ttotal: 22.1ms\tremaining: 309ms\n",
      "1:\tlearn: 4385.4591995\ttotal: 43.2ms\tremaining: 281ms\n",
      "2:\tlearn: 4310.9390216\ttotal: 52.2ms\tremaining: 209ms\n",
      "3:\tlearn: 4238.9999614\ttotal: 72.9ms\tremaining: 200ms\n",
      "4:\tlearn: 4172.9042800\ttotal: 93.3ms\tremaining: 187ms\n",
      "5:\tlearn: 4119.1256758\ttotal: 113ms\tremaining: 170ms\n",
      "6:\tlearn: 4075.5826735\ttotal: 133ms\tremaining: 152ms\n",
      "7:\tlearn: 4034.0023787\ttotal: 153ms\tremaining: 134ms\n",
      "8:\tlearn: 3999.0906576\ttotal: 173ms\tremaining: 115ms\n",
      "9:\tlearn: 3966.8498584\ttotal: 194ms\tremaining: 97ms\n",
      "10:\tlearn: 3938.1578118\ttotal: 215ms\tremaining: 78.1ms\n",
      "11:\tlearn: 3915.9309414\ttotal: 234ms\tremaining: 58.6ms\n",
      "12:\tlearn: 3897.3151708\ttotal: 255ms\tremaining: 39.2ms\n",
      "13:\tlearn: 3876.9152733\ttotal: 276ms\tremaining: 19.7ms\n",
      "14:\tlearn: 3861.1998144\ttotal: 295ms\tremaining: 0us\n",
      "0:\tlearn: 4505.6284457\ttotal: 23.5ms\tremaining: 328ms\n",
      "1:\tlearn: 4395.7106289\ttotal: 44.6ms\tremaining: 290ms\n",
      "2:\tlearn: 4321.3380185\ttotal: 54.2ms\tremaining: 217ms\n",
      "3:\tlearn: 4249.3140417\ttotal: 74.4ms\tremaining: 205ms\n",
      "4:\tlearn: 4183.1909667\ttotal: 93.8ms\tremaining: 188ms\n",
      "5:\tlearn: 4130.5405112\ttotal: 114ms\tremaining: 172ms\n",
      "6:\tlearn: 4086.9119505\ttotal: 135ms\tremaining: 154ms\n",
      "7:\tlearn: 4044.9323452\ttotal: 155ms\tremaining: 136ms\n",
      "8:\tlearn: 4009.9872741\ttotal: 174ms\tremaining: 116ms\n",
      "9:\tlearn: 3979.5126401\ttotal: 194ms\tremaining: 97ms\n",
      "10:\tlearn: 3950.8382203\ttotal: 214ms\tremaining: 77.9ms\n",
      "11:\tlearn: 3929.6193229\ttotal: 235ms\tremaining: 58.7ms\n",
      "12:\tlearn: 3906.0569113\ttotal: 253ms\tremaining: 39ms\n",
      "13:\tlearn: 3883.1688563\ttotal: 274ms\tremaining: 19.6ms\n",
      "14:\tlearn: 3865.4186219\ttotal: 295ms\tremaining: 0us\n",
      "0:\tlearn: 4503.3596361\ttotal: 21.3ms\tremaining: 298ms\n",
      "1:\tlearn: 4393.9195120\ttotal: 41ms\tremaining: 266ms\n",
      "2:\tlearn: 4319.9964127\ttotal: 50.6ms\tremaining: 202ms\n",
      "3:\tlearn: 4247.5181380\ttotal: 70.2ms\tremaining: 193ms\n",
      "4:\tlearn: 4181.6349768\ttotal: 90.6ms\tremaining: 181ms\n",
      "5:\tlearn: 4128.5784288\ttotal: 111ms\tremaining: 166ms\n",
      "6:\tlearn: 4085.3429805\ttotal: 130ms\tremaining: 149ms\n",
      "7:\tlearn: 4038.3811411\ttotal: 150ms\tremaining: 131ms\n",
      "8:\tlearn: 4003.5667305\ttotal: 170ms\tremaining: 113ms\n",
      "9:\tlearn: 3970.8228580\ttotal: 189ms\tremaining: 94.5ms\n",
      "10:\tlearn: 3942.9245021\ttotal: 209ms\tremaining: 76ms\n",
      "11:\tlearn: 3920.8479576\ttotal: 232ms\tremaining: 57.9ms\n",
      "12:\tlearn: 3902.8147646\ttotal: 252ms\tremaining: 38.7ms\n",
      "13:\tlearn: 3882.4482014\ttotal: 273ms\tremaining: 19.5ms\n",
      "14:\tlearn: 3864.4966468\ttotal: 292ms\tremaining: 0us\n",
      "0:\tlearn: 4496.8454647\ttotal: 22.1ms\tremaining: 309ms\n",
      "1:\tlearn: 4387.4435628\ttotal: 41.4ms\tremaining: 269ms\n",
      "2:\tlearn: 4313.2203195\ttotal: 51.3ms\tremaining: 205ms\n",
      "3:\tlearn: 4240.5752475\ttotal: 71.9ms\tremaining: 198ms\n",
      "4:\tlearn: 4172.5173969\ttotal: 93.5ms\tremaining: 187ms\n",
      "5:\tlearn: 4120.0018029\ttotal: 116ms\tremaining: 174ms\n",
      "6:\tlearn: 4076.2804730\ttotal: 136ms\tremaining: 156ms\n",
      "7:\tlearn: 4032.1053393\ttotal: 156ms\tremaining: 136ms\n",
      "8:\tlearn: 3999.6983532\ttotal: 175ms\tremaining: 117ms\n",
      "9:\tlearn: 3967.2035886\ttotal: 196ms\tremaining: 97.9ms\n",
      "10:\tlearn: 3938.7767882\ttotal: 216ms\tremaining: 78.4ms\n",
      "11:\tlearn: 3916.9317790\ttotal: 236ms\tremaining: 58.9ms\n",
      "12:\tlearn: 3893.3648722\ttotal: 254ms\tremaining: 39.2ms\n",
      "13:\tlearn: 3871.8860843\ttotal: 274ms\tremaining: 19.6ms\n",
      "14:\tlearn: 3853.2977739\ttotal: 295ms\tremaining: 0us\n",
      "0:\tlearn: 4613.6122908\ttotal: 22.6ms\tremaining: 429ms\n",
      "1:\tlearn: 4600.8342954\ttotal: 43.6ms\tremaining: 392ms\n",
      "2:\tlearn: 4588.1463201\ttotal: 63.2ms\tremaining: 358ms\n",
      "3:\tlearn: 4576.7305281\ttotal: 84.6ms\tremaining: 338ms\n",
      "4:\tlearn: 4564.6579499\ttotal: 104ms\tremaining: 313ms\n",
      "5:\tlearn: 4552.4527351\ttotal: 124ms\tremaining: 288ms\n",
      "6:\tlearn: 4540.4256741\ttotal: 144ms\tremaining: 267ms\n",
      "7:\tlearn: 4528.7062222\ttotal: 165ms\tremaining: 247ms\n",
      "8:\tlearn: 4517.2579614\ttotal: 185ms\tremaining: 226ms\n",
      "9:\tlearn: 4506.3083267\ttotal: 205ms\tremaining: 205ms\n",
      "10:\tlearn: 4495.5942088\ttotal: 224ms\tremaining: 184ms\n",
      "11:\tlearn: 4484.3935937\ttotal: 244ms\tremaining: 163ms\n",
      "12:\tlearn: 4475.0715519\ttotal: 255ms\tremaining: 137ms\n",
      "13:\tlearn: 4464.9531871\ttotal: 275ms\tremaining: 118ms\n",
      "14:\tlearn: 4454.3002914\ttotal: 297ms\tremaining: 98.9ms\n",
      "15:\tlearn: 4443.9283603\ttotal: 316ms\tremaining: 79.1ms\n",
      "16:\tlearn: 4433.9819266\ttotal: 337ms\tremaining: 59.5ms\n",
      "17:\tlearn: 4424.2445137\ttotal: 357ms\tremaining: 39.6ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:\tlearn: 4414.7029022\ttotal: 376ms\tremaining: 19.8ms\n",
      "19:\tlearn: 4405.3172247\ttotal: 396ms\tremaining: 0us\n",
      "0:\tlearn: 4604.7800388\ttotal: 23ms\tremaining: 437ms\n",
      "1:\tlearn: 4592.1774971\ttotal: 43.4ms\tremaining: 390ms\n",
      "2:\tlearn: 4580.2931459\ttotal: 63.4ms\tremaining: 359ms\n",
      "3:\tlearn: 4568.9002428\ttotal: 82.8ms\tremaining: 331ms\n",
      "4:\tlearn: 4556.8511509\ttotal: 102ms\tremaining: 306ms\n",
      "5:\tlearn: 4544.9733678\ttotal: 121ms\tremaining: 283ms\n",
      "6:\tlearn: 4533.5574676\ttotal: 141ms\tremaining: 262ms\n",
      "7:\tlearn: 4521.7246287\ttotal: 161ms\tremaining: 242ms\n",
      "8:\tlearn: 4510.4217434\ttotal: 181ms\tremaining: 222ms\n",
      "9:\tlearn: 4499.5120679\ttotal: 200ms\tremaining: 200ms\n",
      "10:\tlearn: 4489.2071642\ttotal: 220ms\tremaining: 180ms\n",
      "11:\tlearn: 4477.9158099\ttotal: 240ms\tremaining: 160ms\n",
      "12:\tlearn: 4468.6404938\ttotal: 251ms\tremaining: 135ms\n",
      "13:\tlearn: 4457.8220211\ttotal: 271ms\tremaining: 116ms\n",
      "14:\tlearn: 4447.4196957\ttotal: 290ms\tremaining: 96.5ms\n",
      "15:\tlearn: 4437.0639030\ttotal: 310ms\tremaining: 77.5ms\n",
      "16:\tlearn: 4427.1398652\ttotal: 330ms\tremaining: 58.2ms\n",
      "17:\tlearn: 4417.5370862\ttotal: 350ms\tremaining: 38.9ms\n",
      "18:\tlearn: 4408.1400829\ttotal: 371ms\tremaining: 19.5ms\n",
      "19:\tlearn: 4398.9799782\ttotal: 392ms\tremaining: 0us\n",
      "0:\tlearn: 4615.6723384\ttotal: 22.8ms\tremaining: 433ms\n",
      "1:\tlearn: 4602.6050718\ttotal: 42.6ms\tremaining: 383ms\n",
      "2:\tlearn: 4590.2312006\ttotal: 62.5ms\tremaining: 354ms\n",
      "3:\tlearn: 4578.6246034\ttotal: 83.3ms\tremaining: 333ms\n",
      "4:\tlearn: 4567.2175105\ttotal: 103ms\tremaining: 310ms\n",
      "5:\tlearn: 4555.0123814\ttotal: 124ms\tremaining: 290ms\n",
      "6:\tlearn: 4543.4095176\ttotal: 144ms\tremaining: 267ms\n",
      "7:\tlearn: 4531.6723034\ttotal: 165ms\tremaining: 248ms\n",
      "8:\tlearn: 4520.6254826\ttotal: 187ms\tremaining: 228ms\n",
      "9:\tlearn: 4509.7174931\ttotal: 207ms\tremaining: 207ms\n",
      "10:\tlearn: 4499.0399721\ttotal: 228ms\tremaining: 186ms\n",
      "11:\tlearn: 4488.5122777\ttotal: 248ms\tremaining: 165ms\n",
      "12:\tlearn: 4479.2283417\ttotal: 261ms\tremaining: 141ms\n",
      "13:\tlearn: 4468.9595131\ttotal: 281ms\tremaining: 120ms\n",
      "14:\tlearn: 4458.5613534\ttotal: 301ms\tremaining: 100ms\n",
      "15:\tlearn: 4448.1595771\ttotal: 321ms\tremaining: 80.3ms\n",
      "16:\tlearn: 4438.6122739\ttotal: 341ms\tremaining: 60.2ms\n",
      "17:\tlearn: 4428.8539415\ttotal: 361ms\tremaining: 40.1ms\n",
      "18:\tlearn: 4419.5711113\ttotal: 381ms\tremaining: 20ms\n",
      "19:\tlearn: 4410.3181902\ttotal: 401ms\tremaining: 0us\n",
      "0:\tlearn: 4611.4260480\ttotal: 22.3ms\tremaining: 424ms\n",
      "1:\tlearn: 4598.4030884\ttotal: 43.1ms\tremaining: 388ms\n",
      "2:\tlearn: 4587.7180721\ttotal: 52.8ms\tremaining: 299ms\n",
      "3:\tlearn: 4575.8502737\ttotal: 72.5ms\tremaining: 290ms\n",
      "4:\tlearn: 4563.9391954\ttotal: 93.9ms\tremaining: 282ms\n",
      "5:\tlearn: 4552.4419587\ttotal: 115ms\tremaining: 268ms\n",
      "6:\tlearn: 4540.8457261\ttotal: 135ms\tremaining: 251ms\n",
      "7:\tlearn: 4529.2425589\ttotal: 155ms\tremaining: 233ms\n",
      "8:\tlearn: 4518.1798658\ttotal: 176ms\tremaining: 215ms\n",
      "9:\tlearn: 4507.7120477\ttotal: 195ms\tremaining: 195ms\n",
      "10:\tlearn: 4496.8125516\ttotal: 213ms\tremaining: 174ms\n",
      "11:\tlearn: 4485.9942051\ttotal: 233ms\tremaining: 155ms\n",
      "12:\tlearn: 4475.6228689\ttotal: 252ms\tremaining: 136ms\n",
      "13:\tlearn: 4465.4288292\ttotal: 272ms\tremaining: 116ms\n",
      "14:\tlearn: 4455.5710031\ttotal: 293ms\tremaining: 97.8ms\n",
      "15:\tlearn: 4445.5469290\ttotal: 313ms\tremaining: 78.2ms\n",
      "16:\tlearn: 4435.1156713\ttotal: 334ms\tremaining: 58.9ms\n",
      "17:\tlearn: 4425.4764771\ttotal: 352ms\tremaining: 39.2ms\n",
      "18:\tlearn: 4415.9271752\ttotal: 372ms\tremaining: 19.6ms\n",
      "19:\tlearn: 4407.4257367\ttotal: 392ms\tremaining: 0us\n",
      "0:\tlearn: 4606.5259155\ttotal: 22.1ms\tremaining: 420ms\n",
      "1:\tlearn: 4593.9952048\ttotal: 41.5ms\tremaining: 373ms\n",
      "2:\tlearn: 4583.2509350\ttotal: 52ms\tremaining: 294ms\n",
      "3:\tlearn: 4571.3370425\ttotal: 72.7ms\tremaining: 291ms\n",
      "4:\tlearn: 4559.3807644\ttotal: 93.8ms\tremaining: 281ms\n",
      "5:\tlearn: 4547.4047259\ttotal: 115ms\tremaining: 268ms\n",
      "6:\tlearn: 4535.8279255\ttotal: 137ms\tremaining: 254ms\n",
      "7:\tlearn: 4524.2250003\ttotal: 158ms\tremaining: 237ms\n",
      "8:\tlearn: 4513.4990821\ttotal: 179ms\tremaining: 218ms\n",
      "9:\tlearn: 4503.0519792\ttotal: 200ms\tremaining: 200ms\n",
      "10:\tlearn: 4492.1424933\ttotal: 221ms\tremaining: 181ms\n",
      "11:\tlearn: 4481.8135602\ttotal: 241ms\tremaining: 161ms\n",
      "12:\tlearn: 4471.4417921\ttotal: 261ms\tremaining: 141ms\n",
      "13:\tlearn: 4461.2803292\ttotal: 281ms\tremaining: 120ms\n",
      "14:\tlearn: 4452.7562681\ttotal: 290ms\tremaining: 96.7ms\n",
      "15:\tlearn: 4442.4629102\ttotal: 310ms\tremaining: 77.5ms\n",
      "16:\tlearn: 4432.7864899\ttotal: 330ms\tremaining: 58.3ms\n",
      "17:\tlearn: 4423.1960369\ttotal: 350ms\tremaining: 38.9ms\n",
      "18:\tlearn: 4413.4078636\ttotal: 369ms\tremaining: 19.4ms\n",
      "19:\tlearn: 4403.4267911\ttotal: 388ms\tremaining: 0us\n",
      "0:\tlearn: 4563.9054494\ttotal: 21.7ms\tremaining: 412ms\n",
      "1:\tlearn: 4504.7130098\ttotal: 41.9ms\tremaining: 377ms\n",
      "2:\tlearn: 4453.4292411\ttotal: 61.8ms\tremaining: 350ms\n",
      "3:\tlearn: 4406.4974654\ttotal: 83.3ms\tremaining: 333ms\n",
      "4:\tlearn: 4361.3811481\ttotal: 102ms\tremaining: 307ms\n",
      "5:\tlearn: 4317.2970250\ttotal: 123ms\tremaining: 288ms\n",
      "6:\tlearn: 4277.2037724\ttotal: 144ms\tremaining: 267ms\n",
      "7:\tlearn: 4239.9490117\ttotal: 163ms\tremaining: 244ms\n",
      "8:\tlearn: 4208.7424629\ttotal: 184ms\tremaining: 224ms\n",
      "9:\tlearn: 4178.2331183\ttotal: 203ms\tremaining: 203ms\n",
      "10:\tlearn: 4148.9309273\ttotal: 222ms\tremaining: 182ms\n",
      "11:\tlearn: 4121.0012319\ttotal: 241ms\tremaining: 161ms\n",
      "12:\tlearn: 4101.6072152\ttotal: 252ms\tremaining: 136ms\n",
      "13:\tlearn: 4081.2173017\ttotal: 272ms\tremaining: 117ms\n",
      "14:\tlearn: 4058.8300414\ttotal: 293ms\tremaining: 97.5ms\n",
      "15:\tlearn: 4041.1504002\ttotal: 312ms\tremaining: 77.9ms\n",
      "16:\tlearn: 4025.2468817\ttotal: 332ms\tremaining: 58.6ms\n",
      "17:\tlearn: 4007.9287354\ttotal: 353ms\tremaining: 39.2ms\n",
      "18:\tlearn: 3992.7656063\ttotal: 373ms\tremaining: 19.6ms\n",
      "19:\tlearn: 3979.4051762\ttotal: 394ms\tremaining: 0us\n",
      "0:\tlearn: 4555.3038989\ttotal: 22.3ms\tremaining: 423ms\n",
      "1:\tlearn: 4494.5192945\ttotal: 42.6ms\tremaining: 383ms\n",
      "2:\tlearn: 4448.5484526\ttotal: 52.8ms\tremaining: 299ms\n",
      "3:\tlearn: 4400.3759868\ttotal: 73.3ms\tremaining: 293ms\n",
      "4:\tlearn: 4353.4593894\ttotal: 93ms\tremaining: 279ms\n",
      "5:\tlearn: 4312.1193666\ttotal: 113ms\tremaining: 263ms\n",
      "6:\tlearn: 4274.1994854\ttotal: 132ms\tremaining: 245ms\n",
      "7:\tlearn: 4237.5963272\ttotal: 153ms\tremaining: 229ms\n",
      "8:\tlearn: 4205.0484755\ttotal: 173ms\tremaining: 211ms\n",
      "9:\tlearn: 4175.6661400\ttotal: 192ms\tremaining: 192ms\n",
      "10:\tlearn: 4147.1527490\ttotal: 212ms\tremaining: 174ms\n",
      "11:\tlearn: 4122.3027329\ttotal: 232ms\tremaining: 155ms\n",
      "12:\tlearn: 4099.3302081\ttotal: 251ms\tremaining: 135ms\n",
      "13:\tlearn: 4079.7073742\ttotal: 271ms\tremaining: 116ms\n",
      "14:\tlearn: 4065.1100307\ttotal: 282ms\tremaining: 93.8ms\n",
      "15:\tlearn: 4047.0850343\ttotal: 302ms\tremaining: 75.4ms\n",
      "16:\tlearn: 4030.9271564\ttotal: 321ms\tremaining: 56.7ms\n",
      "17:\tlearn: 4013.4879412\ttotal: 341ms\tremaining: 37.9ms\n",
      "18:\tlearn: 3996.1639178\ttotal: 361ms\tremaining: 19ms\n",
      "19:\tlearn: 3980.0584728\ttotal: 382ms\tremaining: 0us\n",
      "0:\tlearn: 4565.8109162\ttotal: 21.6ms\tremaining: 410ms\n",
      "1:\tlearn: 4505.2342935\ttotal: 41ms\tremaining: 369ms\n",
      "2:\tlearn: 4454.4274219\ttotal: 60.8ms\tremaining: 344ms\n",
      "3:\tlearn: 4407.8064975\ttotal: 81ms\tremaining: 324ms\n",
      "4:\tlearn: 4362.1855208\ttotal: 102ms\tremaining: 305ms\n",
      "5:\tlearn: 4318.2492303\ttotal: 121ms\tremaining: 283ms\n",
      "6:\tlearn: 4280.9590941\ttotal: 142ms\tremaining: 263ms\n",
      "7:\tlearn: 4243.5691230\ttotal: 162ms\tremaining: 242ms\n",
      "8:\tlearn: 4211.3083347\ttotal: 182ms\tremaining: 222ms\n",
      "9:\tlearn: 4181.7179590\ttotal: 201ms\tremaining: 201ms\n",
      "10:\tlearn: 4153.6525379\ttotal: 221ms\tremaining: 181ms\n",
      "11:\tlearn: 4125.8095384\ttotal: 241ms\tremaining: 160ms\n",
      "12:\tlearn: 4106.4785791\ttotal: 253ms\tremaining: 136ms\n",
      "13:\tlearn: 4085.0729028\ttotal: 274ms\tremaining: 117ms\n",
      "14:\tlearn: 4062.7166450\ttotal: 294ms\tremaining: 98.2ms\n",
      "15:\tlearn: 4043.2819206\ttotal: 315ms\tremaining: 78.8ms\n",
      "16:\tlearn: 4026.7399599\ttotal: 335ms\tremaining: 59.2ms\n",
      "17:\tlearn: 4009.0939410\ttotal: 355ms\tremaining: 39.5ms\n",
      "18:\tlearn: 3993.9724491\ttotal: 376ms\tremaining: 19.8ms\n",
      "19:\tlearn: 3979.8629154\ttotal: 396ms\tremaining: 0us\n",
      "0:\tlearn: 4562.4550000\ttotal: 24.4ms\tremaining: 464ms\n",
      "1:\tlearn: 4502.0197965\ttotal: 44.4ms\tremaining: 400ms\n",
      "2:\tlearn: 4456.3842517\ttotal: 53.9ms\tremaining: 305ms\n",
      "3:\tlearn: 4408.2955653\ttotal: 73.9ms\tremaining: 296ms\n",
      "4:\tlearn: 4361.7292385\ttotal: 93.2ms\tremaining: 280ms\n",
      "5:\tlearn: 4319.8329055\ttotal: 112ms\tremaining: 261ms\n",
      "6:\tlearn: 4282.9781647\ttotal: 131ms\tremaining: 244ms\n",
      "7:\tlearn: 4246.1758973\ttotal: 151ms\tremaining: 227ms\n",
      "8:\tlearn: 4214.4122215\ttotal: 172ms\tremaining: 210ms\n",
      "9:\tlearn: 4185.1930260\ttotal: 192ms\tremaining: 192ms\n",
      "10:\tlearn: 4156.1160096\ttotal: 212ms\tremaining: 174ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:\tlearn: 4131.5902804\ttotal: 233ms\tremaining: 156ms\n",
      "12:\tlearn: 4108.7952249\ttotal: 254ms\tremaining: 137ms\n",
      "13:\tlearn: 4085.7187000\ttotal: 274ms\tremaining: 118ms\n",
      "14:\tlearn: 4071.1990713\ttotal: 283ms\tremaining: 94.4ms\n",
      "15:\tlearn: 4052.7916249\ttotal: 304ms\tremaining: 76ms\n",
      "16:\tlearn: 4032.8865522\ttotal: 325ms\tremaining: 57.4ms\n",
      "17:\tlearn: 4017.3741351\ttotal: 345ms\tremaining: 38.3ms\n",
      "18:\tlearn: 4003.2097572\ttotal: 365ms\tremaining: 19.2ms\n",
      "19:\tlearn: 3986.5788180\ttotal: 385ms\tremaining: 0us\n",
      "0:\tlearn: 4556.8288986\ttotal: 24.3ms\tremaining: 462ms\n",
      "1:\tlearn: 4498.7985919\ttotal: 44.6ms\tremaining: 401ms\n",
      "2:\tlearn: 4452.8724774\ttotal: 54.2ms\tremaining: 307ms\n",
      "3:\tlearn: 4404.5798968\ttotal: 74.2ms\tremaining: 297ms\n",
      "4:\tlearn: 4357.9168808\ttotal: 94.6ms\tremaining: 284ms\n",
      "5:\tlearn: 4315.2842651\ttotal: 116ms\tremaining: 271ms\n",
      "6:\tlearn: 4277.3967059\ttotal: 137ms\tremaining: 254ms\n",
      "7:\tlearn: 4240.6104349\ttotal: 156ms\tremaining: 234ms\n",
      "8:\tlearn: 4208.8879741\ttotal: 176ms\tremaining: 215ms\n",
      "9:\tlearn: 4179.8799963\ttotal: 196ms\tremaining: 196ms\n",
      "10:\tlearn: 4150.8557887\ttotal: 216ms\tremaining: 177ms\n",
      "11:\tlearn: 4126.2981448\ttotal: 236ms\tremaining: 157ms\n",
      "12:\tlearn: 4099.7284488\ttotal: 257ms\tremaining: 138ms\n",
      "13:\tlearn: 4079.6914067\ttotal: 278ms\tremaining: 119ms\n",
      "14:\tlearn: 4065.1462705\ttotal: 287ms\tremaining: 95.7ms\n",
      "15:\tlearn: 4046.4336608\ttotal: 307ms\tremaining: 76.7ms\n",
      "16:\tlearn: 4029.7230570\ttotal: 327ms\tremaining: 57.7ms\n",
      "17:\tlearn: 4011.7028444\ttotal: 347ms\tremaining: 38.6ms\n",
      "18:\tlearn: 3993.6391945\ttotal: 366ms\tremaining: 19.3ms\n",
      "19:\tlearn: 3979.8795130\ttotal: 386ms\tremaining: 0us\n",
      "0:\tlearn: 4503.9125523\ttotal: 22.3ms\tremaining: 424ms\n",
      "1:\tlearn: 4396.8573569\ttotal: 42.6ms\tremaining: 384ms\n",
      "2:\tlearn: 4305.8580382\ttotal: 62.5ms\tremaining: 354ms\n",
      "3:\tlearn: 4235.5961384\ttotal: 82.2ms\tremaining: 329ms\n",
      "4:\tlearn: 4175.3215995\ttotal: 102ms\tremaining: 305ms\n",
      "5:\tlearn: 4119.3780405\ttotal: 122ms\tremaining: 284ms\n",
      "6:\tlearn: 4072.8867465\ttotal: 143ms\tremaining: 266ms\n",
      "7:\tlearn: 4031.9322334\ttotal: 163ms\tremaining: 245ms\n",
      "8:\tlearn: 3996.9545586\ttotal: 182ms\tremaining: 223ms\n",
      "9:\tlearn: 3967.0394240\ttotal: 202ms\tremaining: 202ms\n",
      "10:\tlearn: 3939.2446071\ttotal: 222ms\tremaining: 181ms\n",
      "11:\tlearn: 3912.9443106\ttotal: 242ms\tremaining: 161ms\n",
      "12:\tlearn: 3894.6321103\ttotal: 263ms\tremaining: 142ms\n",
      "13:\tlearn: 3872.4018145\ttotal: 283ms\tremaining: 121ms\n",
      "14:\tlearn: 3853.1928499\ttotal: 302ms\tremaining: 101ms\n",
      "15:\tlearn: 3840.3918076\ttotal: 321ms\tremaining: 80.3ms\n",
      "16:\tlearn: 3825.5179560\ttotal: 343ms\tremaining: 60.5ms\n",
      "17:\tlearn: 3810.5595510\ttotal: 362ms\tremaining: 40.2ms\n",
      "18:\tlearn: 3798.7134242\ttotal: 381ms\tremaining: 20.1ms\n",
      "19:\tlearn: 3787.6587880\ttotal: 401ms\tremaining: 0us\n",
      "0:\tlearn: 4495.5893626\ttotal: 21.8ms\tremaining: 414ms\n",
      "1:\tlearn: 4385.4591995\ttotal: 42.5ms\tremaining: 382ms\n",
      "2:\tlearn: 4310.9390216\ttotal: 52.5ms\tremaining: 298ms\n",
      "3:\tlearn: 4238.9999614\ttotal: 72.3ms\tremaining: 289ms\n",
      "4:\tlearn: 4172.9042800\ttotal: 92.2ms\tremaining: 277ms\n",
      "5:\tlearn: 4119.1256758\ttotal: 113ms\tremaining: 263ms\n",
      "6:\tlearn: 4075.5826735\ttotal: 134ms\tremaining: 248ms\n",
      "7:\tlearn: 4034.0023787\ttotal: 155ms\tremaining: 232ms\n",
      "8:\tlearn: 3999.0906576\ttotal: 175ms\tremaining: 214ms\n",
      "9:\tlearn: 3966.8498584\ttotal: 194ms\tremaining: 194ms\n",
      "10:\tlearn: 3938.1578118\ttotal: 213ms\tremaining: 174ms\n",
      "11:\tlearn: 3915.9309414\ttotal: 233ms\tremaining: 155ms\n",
      "12:\tlearn: 3897.3151708\ttotal: 253ms\tremaining: 136ms\n",
      "13:\tlearn: 3876.9152733\ttotal: 273ms\tremaining: 117ms\n",
      "14:\tlearn: 3861.1998144\ttotal: 293ms\tremaining: 97.7ms\n",
      "15:\tlearn: 3847.1557275\ttotal: 313ms\tremaining: 78.2ms\n",
      "16:\tlearn: 3831.6408925\ttotal: 332ms\tremaining: 58.6ms\n",
      "17:\tlearn: 3817.0359504\ttotal: 352ms\tremaining: 39.1ms\n",
      "18:\tlearn: 3802.9457142\ttotal: 371ms\tremaining: 19.5ms\n",
      "19:\tlearn: 3794.1342459\ttotal: 391ms\tremaining: 0us\n",
      "0:\tlearn: 4505.6284457\ttotal: 22.3ms\tremaining: 424ms\n",
      "1:\tlearn: 4395.7106289\ttotal: 43.2ms\tremaining: 389ms\n",
      "2:\tlearn: 4321.3380185\ttotal: 53.2ms\tremaining: 301ms\n",
      "3:\tlearn: 4249.3140417\ttotal: 73.5ms\tremaining: 294ms\n",
      "4:\tlearn: 4183.1909667\ttotal: 92.3ms\tremaining: 277ms\n",
      "5:\tlearn: 4130.5405112\ttotal: 111ms\tremaining: 260ms\n",
      "6:\tlearn: 4086.9119505\ttotal: 133ms\tremaining: 246ms\n",
      "7:\tlearn: 4044.9323452\ttotal: 152ms\tremaining: 228ms\n",
      "8:\tlearn: 4009.9872741\ttotal: 171ms\tremaining: 210ms\n",
      "9:\tlearn: 3979.5126401\ttotal: 191ms\tremaining: 191ms\n",
      "10:\tlearn: 3950.8382203\ttotal: 210ms\tremaining: 171ms\n",
      "11:\tlearn: 3929.6193229\ttotal: 230ms\tremaining: 153ms\n",
      "12:\tlearn: 3906.0569113\ttotal: 251ms\tremaining: 135ms\n",
      "13:\tlearn: 3883.1688563\ttotal: 271ms\tremaining: 116ms\n",
      "14:\tlearn: 3865.4186219\ttotal: 290ms\tremaining: 96.8ms\n",
      "15:\tlearn: 3853.0065647\ttotal: 311ms\tremaining: 77.7ms\n",
      "16:\tlearn: 3835.9212051\ttotal: 331ms\tremaining: 58.4ms\n",
      "17:\tlearn: 3822.0920791\ttotal: 350ms\tremaining: 38.9ms\n",
      "18:\tlearn: 3809.7783288\ttotal: 369ms\tremaining: 19.4ms\n",
      "19:\tlearn: 3797.0547742\ttotal: 389ms\tremaining: 0us\n",
      "0:\tlearn: 4503.3596361\ttotal: 22.5ms\tremaining: 427ms\n",
      "1:\tlearn: 4393.9195120\ttotal: 42.3ms\tremaining: 381ms\n",
      "2:\tlearn: 4319.9964127\ttotal: 51.4ms\tremaining: 291ms\n",
      "3:\tlearn: 4247.5181380\ttotal: 71.4ms\tremaining: 286ms\n",
      "4:\tlearn: 4181.6349768\ttotal: 90.8ms\tremaining: 272ms\n",
      "5:\tlearn: 4128.5784288\ttotal: 111ms\tremaining: 260ms\n",
      "6:\tlearn: 4085.3429805\ttotal: 131ms\tremaining: 243ms\n",
      "7:\tlearn: 4038.3811411\ttotal: 151ms\tremaining: 226ms\n",
      "8:\tlearn: 4003.5667305\ttotal: 170ms\tremaining: 207ms\n",
      "9:\tlearn: 3970.8228580\ttotal: 189ms\tremaining: 189ms\n",
      "10:\tlearn: 3942.9245021\ttotal: 209ms\tremaining: 171ms\n",
      "11:\tlearn: 3920.8479576\ttotal: 230ms\tremaining: 153ms\n",
      "12:\tlearn: 3902.8147646\ttotal: 251ms\tremaining: 135ms\n",
      "13:\tlearn: 3882.4482014\ttotal: 271ms\tremaining: 116ms\n",
      "14:\tlearn: 3864.4966468\ttotal: 291ms\tremaining: 96.9ms\n",
      "15:\tlearn: 3851.1483046\ttotal: 310ms\tremaining: 77.5ms\n",
      "16:\tlearn: 3835.3610695\ttotal: 329ms\tremaining: 58.1ms\n",
      "17:\tlearn: 3822.5509445\ttotal: 349ms\tremaining: 38.8ms\n",
      "18:\tlearn: 3812.5239441\ttotal: 370ms\tremaining: 19.5ms\n",
      "19:\tlearn: 3800.0060597\ttotal: 390ms\tremaining: 0us\n",
      "0:\tlearn: 4496.8454647\ttotal: 23ms\tremaining: 438ms\n",
      "1:\tlearn: 4387.4435628\ttotal: 44ms\tremaining: 396ms\n",
      "2:\tlearn: 4313.2203195\ttotal: 53.1ms\tremaining: 301ms\n",
      "3:\tlearn: 4240.5752475\ttotal: 73.2ms\tremaining: 293ms\n",
      "4:\tlearn: 4172.5173969\ttotal: 93.3ms\tremaining: 280ms\n",
      "5:\tlearn: 4120.0018029\ttotal: 113ms\tremaining: 263ms\n",
      "6:\tlearn: 4076.2804730\ttotal: 132ms\tremaining: 245ms\n",
      "7:\tlearn: 4032.1053393\ttotal: 151ms\tremaining: 227ms\n",
      "8:\tlearn: 3999.6983532\ttotal: 172ms\tremaining: 210ms\n",
      "9:\tlearn: 3967.2035886\ttotal: 192ms\tremaining: 192ms\n",
      "10:\tlearn: 3938.7767882\ttotal: 212ms\tremaining: 173ms\n",
      "11:\tlearn: 3916.9317790\ttotal: 232ms\tremaining: 154ms\n",
      "12:\tlearn: 3893.3648722\ttotal: 253ms\tremaining: 136ms\n",
      "13:\tlearn: 3871.8860843\ttotal: 273ms\tremaining: 117ms\n",
      "14:\tlearn: 3853.2977739\ttotal: 293ms\tremaining: 97.6ms\n",
      "15:\tlearn: 3842.8188904\ttotal: 312ms\tremaining: 78ms\n",
      "16:\tlearn: 3826.9127124\ttotal: 331ms\tremaining: 58.5ms\n",
      "17:\tlearn: 3813.9745066\ttotal: 351ms\tremaining: 39ms\n",
      "18:\tlearn: 3803.2906653\ttotal: 370ms\tremaining: 19.5ms\n",
      "19:\tlearn: 3792.1236747\ttotal: 389ms\tremaining: 0us\n",
      "0:\tlearn: 4501.2028071\ttotal: 24.6ms\tremaining: 468ms\n",
      "1:\tlearn: 4391.3600266\ttotal: 48.7ms\tremaining: 438ms\n",
      "2:\tlearn: 4307.3637860\ttotal: 70.6ms\tremaining: 400ms\n",
      "3:\tlearn: 4237.8104867\ttotal: 93.3ms\tremaining: 373ms\n",
      "4:\tlearn: 4177.8587967\ttotal: 116ms\tremaining: 347ms\n",
      "5:\tlearn: 4118.8198652\ttotal: 139ms\tremaining: 324ms\n",
      "6:\tlearn: 4073.7695439\ttotal: 162ms\tremaining: 300ms\n",
      "7:\tlearn: 4032.8472099\ttotal: 185ms\tremaining: 277ms\n",
      "8:\tlearn: 3997.5539611\ttotal: 207ms\tremaining: 253ms\n",
      "9:\tlearn: 3968.4488166\ttotal: 229ms\tremaining: 229ms\n",
      "10:\tlearn: 3940.3062810\ttotal: 252ms\tremaining: 206ms\n",
      "11:\tlearn: 3915.6652362\ttotal: 274ms\tremaining: 183ms\n",
      "12:\tlearn: 3899.0126034\ttotal: 297ms\tremaining: 160ms\n",
      "13:\tlearn: 3877.5804030\ttotal: 319ms\tremaining: 137ms\n",
      "14:\tlearn: 3860.2262357\ttotal: 341ms\tremaining: 114ms\n",
      "15:\tlearn: 3842.3313367\ttotal: 363ms\tremaining: 90.7ms\n",
      "16:\tlearn: 3829.3171365\ttotal: 386ms\tremaining: 68ms\n",
      "17:\tlearn: 3816.5275196\ttotal: 408ms\tremaining: 45.3ms\n",
      "18:\tlearn: 3804.9531128\ttotal: 430ms\tremaining: 22.6ms\n",
      "19:\tlearn: 3796.9526907\ttotal: 452ms\tremaining: 0us\n",
      "RMSE: 3804.2430737249742\n",
      "CPU times: total: 19 s\n",
      "Wall time: 36.1 s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"82dab4b2-0fe1-4206-9b9a-3e76d5175476\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"82dab4b2-0fe1-4206-9b9a-3e76d5175476\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"CatBoostRegressor OHE C\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"CatBoostRegressor OHE C\"\n",
    "%%time\n",
    "\n",
    "# Обучим модель на тренировочной выборке\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Узнаем RMSE\n",
    "result_RMSE = -model.best_score_\n",
    "print('RMSE:', result_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка на тестовой выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 25, 'num_leaves': 10}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4333.9809410\ttotal: 10.2ms\tremaining: 244ms\n",
      "1:\tlearn: 4184.1263784\ttotal: 18.5ms\tremaining: 213ms\n",
      "2:\tlearn: 4108.7130409\ttotal: 27.6ms\tremaining: 203ms\n",
      "3:\tlearn: 4063.5860962\ttotal: 35.9ms\tremaining: 188ms\n",
      "4:\tlearn: 4022.0495829\ttotal: 45ms\tremaining: 180ms\n",
      "5:\tlearn: 4001.4928016\ttotal: 53.2ms\tremaining: 168ms\n",
      "6:\tlearn: 3944.0381703\ttotal: 63.1ms\tremaining: 162ms\n",
      "7:\tlearn: 3919.9997541\ttotal: 71.4ms\tremaining: 152ms\n",
      "8:\tlearn: 3906.4631905\ttotal: 79ms\tremaining: 140ms\n",
      "9:\tlearn: 3888.9074157\ttotal: 87.1ms\tremaining: 131ms\n",
      "10:\tlearn: 3866.7771799\ttotal: 95.4ms\tremaining: 121ms\n",
      "11:\tlearn: 3850.4109946\ttotal: 104ms\tremaining: 112ms\n",
      "12:\tlearn: 3838.3821374\ttotal: 113ms\tremaining: 105ms\n",
      "13:\tlearn: 3826.1180663\ttotal: 122ms\tremaining: 95.9ms\n",
      "14:\tlearn: 3820.9527074\ttotal: 130ms\tremaining: 86.6ms\n",
      "15:\tlearn: 3813.3471474\ttotal: 138ms\tremaining: 77.7ms\n",
      "16:\tlearn: 3806.1802215\ttotal: 146ms\tremaining: 68.7ms\n",
      "17:\tlearn: 3793.0671494\ttotal: 154ms\tremaining: 59.7ms\n",
      "18:\tlearn: 3787.7685760\ttotal: 162ms\tremaining: 51.1ms\n",
      "19:\tlearn: 3779.3958265\ttotal: 171ms\tremaining: 42.8ms\n",
      "20:\tlearn: 3772.0551466\ttotal: 180ms\tremaining: 34.2ms\n",
      "21:\tlearn: 3768.1782614\ttotal: 193ms\tremaining: 26.4ms\n",
      "22:\tlearn: 3762.4239855\ttotal: 202ms\tremaining: 17.6ms\n",
      "23:\tlearn: 3757.3966402\ttotal: 225ms\tremaining: 9.36ms\n",
      "24:\tlearn: 3750.4759373\ttotal: 235ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1ec9824e250>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализируем модель c лучшими гиперпараметрами\n",
    "model = CatBoostRegressor().set_params(\n",
    "    max_depth = params['max_depth'], \n",
    "    n_estimators = params['n_estimators'], \n",
    "    learning_rate = params['learning_rate']\n",
    ")\n",
    "\n",
    "# Обучим модель на тренировочной выборке\n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE VALID: 3729.837835517173\n",
      "Предсказание: 4872.838132491546\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = timeit.default_timer()\n",
    "# Получим предсказания на тестовой выборки\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "elapsed = round(timeit.default_timer() - start_time, 3)\n",
    "\n",
    "result_RMSE_v = mean_squared_error(target_valid, predictions, squared=False)\n",
    "print('RMSE VALID:', result_RMSE_v)\n",
    "print('Предсказание:', predictions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зафиксируем результаты\n",
    "results[count_model] = pd.Series({\n",
    "    'NAME': 'CatBoostRegressor_OE_C', \n",
    "    'RMSE TRAIN': result_RMSE_t, \n",
    "    'RMSE VALID': result_RMSE_v, \n",
    "    'PREDICTIONS': predictions.mean(), \n",
    "    'TIME TRAINING [s]': time, \n",
    "    'TIME PREDICTION [s]': elapsed, \n",
    "    'PARAMETRS': params\n",
    "})\n",
    "\n",
    "results[count_model]\n",
    "count_model+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"08646930-e4d5-41c9-937b-3a7755b497ad\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"08646930-e4d5-41c9-937b-3a7755b497ad\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Total result\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Total result\"\n",
    "results = pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>RMSE TRAIN</th>\n",
       "      <th>RMSE VALID</th>\n",
       "      <th>PREDICTIONS</th>\n",
       "      <th>TIME TRAINING [s]</th>\n",
       "      <th>TIME PREDICTION [s]</th>\n",
       "      <th>PARAMETRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression_OHE</td>\n",
       "      <td>2678.265831</td>\n",
       "      <td>2693.317059</td>\n",
       "      <td>4844.076334</td>\n",
       "      <td>3.710571</td>\n",
       "      <td>0.374</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor_OE</td>\n",
       "      <td>1946.632082</td>\n",
       "      <td>1911.429629</td>\n",
       "      <td>4855.46556</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.023</td>\n",
       "      <td>{'max_depth': 11, 'min_samples_leaf': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor_OE</td>\n",
       "      <td>1635.406597</td>\n",
       "      <td>1606.647976</td>\n",
       "      <td>4854.598315</td>\n",
       "      <td>6.378552</td>\n",
       "      <td>0.904</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 15, 'max_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMRegressor_OE_C</td>\n",
       "      <td>1887.950836</td>\n",
       "      <td>1858.723461</td>\n",
       "      <td>4861.04697</td>\n",
       "      <td>0.126526</td>\n",
       "      <td>0.033</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 5, 'n_esti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoostRegressor_OE</td>\n",
       "      <td>2080.358649</td>\n",
       "      <td>2058.262133</td>\n",
       "      <td>4856.601989</td>\n",
       "      <td>0.566164</td>\n",
       "      <td>0.013</td>\n",
       "      <td>{'depth': 10, 'iterations': 20, 'learning_rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearRegression_OHE_C</td>\n",
       "      <td>2678.265831</td>\n",
       "      <td>2692.692892</td>\n",
       "      <td>4850.247989</td>\n",
       "      <td>3.883029</td>\n",
       "      <td>0.243</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeRegressor_OE_C</td>\n",
       "      <td>3499.093475</td>\n",
       "      <td>3456.621835</td>\n",
       "      <td>4861.513936</td>\n",
       "      <td>0.161952</td>\n",
       "      <td>0.024</td>\n",
       "      <td>{'max_depth': 21, 'min_samples_leaf': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestRegressor_OE_C</td>\n",
       "      <td>3481.286674</td>\n",
       "      <td>3442.689669</td>\n",
       "      <td>4863.122615</td>\n",
       "      <td>6.141539</td>\n",
       "      <td>0.755</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 15, 'max_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMRegressor_OE_C</td>\n",
       "      <td>3716.018929</td>\n",
       "      <td>3689.213908</td>\n",
       "      <td>4874.343229</td>\n",
       "      <td>0.126124</td>\n",
       "      <td>0.024</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 5, 'n_esti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoostRegressor_OE_C</td>\n",
       "      <td>3716.018929</td>\n",
       "      <td>3729.837836</td>\n",
       "      <td>4872.838132</td>\n",
       "      <td>0.126124</td>\n",
       "      <td>0.011</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 5, 'n_esti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         NAME   RMSE TRAIN   RMSE VALID  PREDICTIONS  \\\n",
       "0        LinearRegression_OHE  2678.265831  2693.317059  4844.076334   \n",
       "1    DecisionTreeRegressor_OE  1946.632082  1911.429629   4855.46556   \n",
       "2    RandomForestRegressor_OE  1635.406597  1606.647976  4854.598315   \n",
       "3      LightGBMRegressor_OE_C  1887.950836  1858.723461   4861.04697   \n",
       "4        CatBoostRegressor_OE  2080.358649  2058.262133  4856.601989   \n",
       "5      LinearRegression_OHE_C  2678.265831  2692.692892  4850.247989   \n",
       "6  DecisionTreeRegressor_OE_C  3499.093475  3456.621835  4861.513936   \n",
       "7  RandomForestRegressor_OE_C  3481.286674  3442.689669  4863.122615   \n",
       "8      LightGBMRegressor_OE_C  3716.018929  3689.213908  4874.343229   \n",
       "9      CatBoostRegressor_OE_C  3716.018929  3729.837836  4872.838132   \n",
       "\n",
       "  TIME TRAINING [s] TIME PREDICTION [s]  \\\n",
       "0          3.710571               0.374   \n",
       "1              0.37               0.023   \n",
       "2          6.378552               0.904   \n",
       "3          0.126526               0.033   \n",
       "4          0.566164               0.013   \n",
       "5          3.883029               0.243   \n",
       "6          0.161952               0.024   \n",
       "7          6.141539               0.755   \n",
       "8          0.126124               0.024   \n",
       "9          0.126124               0.011   \n",
       "\n",
       "                                           PARAMETRS  \n",
       "0                                                 {}  \n",
       "1           {'max_depth': 11, 'min_samples_leaf': 2}  \n",
       "2  {'bootstrap': True, 'max_depth': 15, 'max_feat...  \n",
       "3  {'learning_rate': 0.3, 'max_depth': 5, 'n_esti...  \n",
       "4  {'depth': 10, 'iterations': 20, 'learning_rate...  \n",
       "5                                                 {}  \n",
       "6           {'max_depth': 21, 'min_samples_leaf': 2}  \n",
       "7  {'bootstrap': True, 'max_depth': 15, 'max_feat...  \n",
       "8  {'learning_rate': 0.3, 'max_depth': 5, 'n_esti...  \n",
       "9  {'learning_rate': 0.3, 'max_depth': 5, 'n_esti...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем устанавливать рейтинг. Критерии, которые важны заказчику: качество предсказания `RMSE`, время обучения модели `TIME TRAINING [s]` и время предсказания модели `TIME PREDICTION [s]`. Три параметры, значит будем рассматривать их вместе как 100%. Но качество предсказания будем устанавливать как 40%, а остальные по 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нам интересует RMSE не более 2500, тогда\n",
    "results = results[results['RMSE VALID'] < 2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Papin\\AppData\\Local\\Temp\\ipykernel_28692\\562859168.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RATING'] = results['RMSE VALID'] * 0.4 * results['TIME TRAINING [s]'] * 0.3 * results['TIME PREDICTION [s]'] * 0.3\n"
     ]
    }
   ],
   "source": [
    "# Устанавливаем рейтинги\n",
    "results['RATING'] = results['RMSE VALID'] * 0.4 * results['TIME TRAINING [s]'] * 0.3 * results['TIME PREDICTION [s]'] * 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>RMSE TRAIN</th>\n",
       "      <th>RMSE VALID</th>\n",
       "      <th>PREDICTIONS</th>\n",
       "      <th>TIME TRAINING [s]</th>\n",
       "      <th>TIME PREDICTION [s]</th>\n",
       "      <th>PARAMETRS</th>\n",
       "      <th>RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor_OE</td>\n",
       "      <td>1635.406597</td>\n",
       "      <td>1606.647976</td>\n",
       "      <td>4854.598315</td>\n",
       "      <td>6.378552</td>\n",
       "      <td>0.904</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 15, 'max_feat...</td>\n",
       "      <td>333.51375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor_OE</td>\n",
       "      <td>1946.632082</td>\n",
       "      <td>1911.429629</td>\n",
       "      <td>4855.46556</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.023</td>\n",
       "      <td>{'max_depth': 11, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.585586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoostRegressor_OE</td>\n",
       "      <td>2080.358649</td>\n",
       "      <td>2058.262133</td>\n",
       "      <td>4856.601989</td>\n",
       "      <td>0.566164</td>\n",
       "      <td>0.013</td>\n",
       "      <td>{'depth': 10, 'iterations': 20, 'learning_rate...</td>\n",
       "      <td>0.545367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMRegressor_OE_C</td>\n",
       "      <td>1887.950836</td>\n",
       "      <td>1858.723461</td>\n",
       "      <td>4861.04697</td>\n",
       "      <td>0.126526</td>\n",
       "      <td>0.033</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.279389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       NAME   RMSE TRAIN   RMSE VALID  PREDICTIONS  \\\n",
       "2  RandomForestRegressor_OE  1635.406597  1606.647976  4854.598315   \n",
       "1  DecisionTreeRegressor_OE  1946.632082  1911.429629   4855.46556   \n",
       "4      CatBoostRegressor_OE  2080.358649  2058.262133  4856.601989   \n",
       "3    LightGBMRegressor_OE_C  1887.950836  1858.723461   4861.04697   \n",
       "\n",
       "  TIME TRAINING [s] TIME PREDICTION [s]  \\\n",
       "2          6.378552               0.904   \n",
       "1              0.37               0.023   \n",
       "4          0.566164               0.013   \n",
       "3          0.126526               0.033   \n",
       "\n",
       "                                           PARAMETRS     RATING  \n",
       "2  {'bootstrap': True, 'max_depth': 15, 'max_feat...  333.51375  \n",
       "1           {'max_depth': 11, 'min_samples_leaf': 2}   0.585586  \n",
       "4  {'depth': 10, 'iterations': 20, 'learning_rate...   0.545367  \n",
       "3  {'learning_rate': 0.3, 'max_depth': 5, 'n_esti...   0.279389  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сортируем по порядке убывания и смотрим\n",
    "results.sort_values(by='RATING', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем `тройку лучших` моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>RMSE TRAIN</th>\n",
       "      <th>RMSE VALID</th>\n",
       "      <th>PREDICTIONS</th>\n",
       "      <th>TIME TRAINING [s]</th>\n",
       "      <th>TIME PREDICTION [s]</th>\n",
       "      <th>PARAMETRS</th>\n",
       "      <th>RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor_OE</td>\n",
       "      <td>1635.406597</td>\n",
       "      <td>1606.647976</td>\n",
       "      <td>4854.598315</td>\n",
       "      <td>6.378552</td>\n",
       "      <td>0.904</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 15, 'max_feat...</td>\n",
       "      <td>333.51375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor_OE</td>\n",
       "      <td>1946.632082</td>\n",
       "      <td>1911.429629</td>\n",
       "      <td>4855.46556</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.023</td>\n",
       "      <td>{'max_depth': 11, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.585586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoostRegressor_OE</td>\n",
       "      <td>2080.358649</td>\n",
       "      <td>2058.262133</td>\n",
       "      <td>4856.601989</td>\n",
       "      <td>0.566164</td>\n",
       "      <td>0.013</td>\n",
       "      <td>{'depth': 10, 'iterations': 20, 'learning_rate...</td>\n",
       "      <td>0.545367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       NAME   RMSE TRAIN   RMSE VALID  PREDICTIONS  \\\n",
       "2  RandomForestRegressor_OE  1635.406597  1606.647976  4854.598315   \n",
       "1  DecisionTreeRegressor_OE  1946.632082  1911.429629   4855.46556   \n",
       "4      CatBoostRegressor_OE  2080.358649  2058.262133  4856.601989   \n",
       "\n",
       "  TIME TRAINING [s] TIME PREDICTION [s]  \\\n",
       "2          6.378552               0.904   \n",
       "1              0.37               0.023   \n",
       "4          0.566164               0.013   \n",
       "\n",
       "                                           PARAMETRS     RATING  \n",
       "2  {'bootstrap': True, 'max_depth': 15, 'max_feat...  333.51375  \n",
       "1           {'max_depth': 11, 'min_samples_leaf': 2}   0.585586  \n",
       "4  {'depth': 10, 'iterations': 20, 'learning_rate...   0.545367  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by='RATING', ascending=False)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самой лучшей модели является `RandomForestRegressor_OE` - RMSE составляет **1606**, а скорость обучения составляет 6 секунда, время предсказания - 0,9 секунда. Вполне акдеватный результат, чтобы выбрать эту модель для реализации. Есть другая модель - `DecisionTreeRegressor_OE`, результаты неплохие, преимущества у нее - скорость обучения и предсказания. А третье место заслужила модель - `CatBoostRegressor_OE`, однако эта модель может похвастаться скоростью предсказания"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 460,
    "start_time": "2023-03-14T17:13:35.764Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-14T17:13:42.868Z"
   },
   {
    "duration": 1284,
    "start_time": "2023-03-14T17:14:46.591Z"
   },
   {
    "duration": 1196,
    "start_time": "2023-03-14T17:15:00.256Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-14T17:18:00.473Z"
   },
   {
    "duration": 106,
    "start_time": "2023-03-14T17:18:07.393Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-14T17:18:10.414Z"
   },
   {
    "duration": 99,
    "start_time": "2023-03-14T17:18:12.897Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-14T17:18:47.563Z"
   },
   {
    "duration": 2940,
    "start_time": "2023-03-14T17:22:50.259Z"
   },
   {
    "duration": 100,
    "start_time": "2023-03-14T17:23:00.648Z"
   },
   {
    "duration": 2401,
    "start_time": "2023-03-14T17:23:05.391Z"
   },
   {
    "duration": 572,
    "start_time": "2023-03-14T17:23:14.015Z"
   },
   {
    "duration": 658,
    "start_time": "2023-03-14T17:23:49.172Z"
   },
   {
    "duration": 561,
    "start_time": "2023-03-14T17:23:58.672Z"
   },
   {
    "duration": 497,
    "start_time": "2023-03-14T17:24:19.891Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-14T17:24:36.172Z"
   },
   {
    "duration": 945,
    "start_time": "2023-03-14T17:24:50.009Z"
   },
   {
    "duration": 816,
    "start_time": "2023-03-14T17:24:53.817Z"
   },
   {
    "duration": 583,
    "start_time": "2023-03-14T17:25:02.692Z"
   },
   {
    "duration": 588,
    "start_time": "2023-03-14T17:25:05.495Z"
   },
   {
    "duration": 604,
    "start_time": "2023-03-14T17:25:09.801Z"
   },
   {
    "duration": 636,
    "start_time": "2023-03-14T17:25:18.698Z"
   },
   {
    "duration": 610,
    "start_time": "2023-03-14T17:25:23.329Z"
   },
   {
    "duration": 352,
    "start_time": "2023-03-14T17:25:52.758Z"
   },
   {
    "duration": 221,
    "start_time": "2023-03-14T17:26:30.992Z"
   },
   {
    "duration": 630,
    "start_time": "2023-03-14T17:26:34.323Z"
   },
   {
    "duration": 1081,
    "start_time": "2023-03-14T17:26:38.952Z"
   },
   {
    "duration": 629,
    "start_time": "2023-03-14T17:26:43.395Z"
   },
   {
    "duration": 210,
    "start_time": "2023-03-14T17:28:15.608Z"
   },
   {
    "duration": 230,
    "start_time": "2023-03-14T17:28:44.118Z"
   },
   {
    "duration": 223,
    "start_time": "2023-03-14T17:28:51.388Z"
   },
   {
    "duration": 222,
    "start_time": "2023-03-14T17:28:54.029Z"
   },
   {
    "duration": 390,
    "start_time": "2023-03-14T17:28:56.344Z"
   },
   {
    "duration": 570,
    "start_time": "2023-03-14T17:29:00.509Z"
   },
   {
    "duration": 391,
    "start_time": "2023-03-14T17:29:02.407Z"
   },
   {
    "duration": 377,
    "start_time": "2023-03-14T17:29:06.304Z"
   },
   {
    "duration": 383,
    "start_time": "2023-03-14T17:29:14.392Z"
   },
   {
    "duration": 214,
    "start_time": "2023-03-14T17:29:17.112Z"
   },
   {
    "duration": 203,
    "start_time": "2023-03-14T17:29:20.092Z"
   },
   {
    "duration": 221,
    "start_time": "2023-03-14T17:29:27.533Z"
   },
   {
    "duration": 253,
    "start_time": "2023-03-14T17:29:39.668Z"
   },
   {
    "duration": 404,
    "start_time": "2023-03-14T17:30:12.564Z"
   },
   {
    "duration": 276,
    "start_time": "2023-03-14T17:30:20.572Z"
   },
   {
    "duration": 280,
    "start_time": "2023-03-14T17:30:24.046Z"
   },
   {
    "duration": 261,
    "start_time": "2023-03-14T17:31:03.608Z"
   },
   {
    "duration": 107,
    "start_time": "2023-03-14T17:31:34.896Z"
   },
   {
    "duration": 1225,
    "start_time": "2023-03-14T17:31:44.896Z"
   },
   {
    "duration": 92,
    "start_time": "2023-03-14T17:31:48.168Z"
   },
   {
    "duration": 93,
    "start_time": "2023-03-14T17:31:52.599Z"
   },
   {
    "duration": 91,
    "start_time": "2023-03-14T17:31:58.033Z"
   },
   {
    "duration": 91,
    "start_time": "2023-03-14T17:32:34.452Z"
   },
   {
    "duration": 66,
    "start_time": "2023-03-14T17:33:07.194Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-14T17:33:09.634Z"
   },
   {
    "duration": 109,
    "start_time": "2023-03-14T17:33:16.285Z"
   },
   {
    "duration": 218,
    "start_time": "2023-03-14T17:35:04.400Z"
   },
   {
    "duration": 102,
    "start_time": "2023-03-14T17:35:05.436Z"
   },
   {
    "duration": 105,
    "start_time": "2023-03-14T17:35:23.465Z"
   },
   {
    "duration": 185,
    "start_time": "2023-03-14T17:35:42.605Z"
   },
   {
    "duration": 100,
    "start_time": "2023-03-14T17:35:43.756Z"
   },
   {
    "duration": 102,
    "start_time": "2023-03-14T17:35:48.615Z"
   },
   {
    "duration": 99,
    "start_time": "2023-03-14T17:35:58.190Z"
   },
   {
    "duration": 93,
    "start_time": "2023-03-14T17:36:03.491Z"
   },
   {
    "duration": 92,
    "start_time": "2023-03-14T17:36:07.976Z"
   },
   {
    "duration": 721,
    "start_time": "2023-03-14T17:36:47.492Z"
   },
   {
    "duration": 179,
    "start_time": "2023-03-14T17:36:54.492Z"
   },
   {
    "duration": 255,
    "start_time": "2023-03-14T17:37:05.076Z"
   },
   {
    "duration": 98,
    "start_time": "2023-03-14T17:37:06.000Z"
   },
   {
    "duration": 249,
    "start_time": "2023-03-14T17:40:55.592Z"
   },
   {
    "duration": 265,
    "start_time": "2023-03-14T17:40:57.099Z"
   },
   {
    "duration": 240,
    "start_time": "2023-03-14T17:42:43.561Z"
   },
   {
    "duration": 96,
    "start_time": "2023-03-14T17:43:10.792Z"
   },
   {
    "duration": 219,
    "start_time": "2023-03-14T17:43:32.904Z"
   },
   {
    "duration": 93,
    "start_time": "2023-03-14T17:43:34.424Z"
   },
   {
    "duration": 173,
    "start_time": "2023-03-14T17:43:44.895Z"
   },
   {
    "duration": 213,
    "start_time": "2023-03-14T17:44:01.401Z"
   },
   {
    "duration": 72,
    "start_time": "2023-03-14T17:44:06.295Z"
   },
   {
    "duration": 181,
    "start_time": "2023-03-14T17:44:30.874Z"
   },
   {
    "duration": 184,
    "start_time": "2023-03-14T17:44:48.968Z"
   },
   {
    "duration": 177,
    "start_time": "2023-03-14T17:44:56.973Z"
   },
   {
    "duration": 178,
    "start_time": "2023-03-14T17:45:08.214Z"
   },
   {
    "duration": 218,
    "start_time": "2023-03-14T17:45:17.375Z"
   },
   {
    "duration": 72,
    "start_time": "2023-03-14T17:45:18.997Z"
   },
   {
    "duration": 73,
    "start_time": "2023-03-14T17:45:31.292Z"
   },
   {
    "duration": 33,
    "start_time": "2023-03-14T17:47:14.908Z"
   },
   {
    "duration": 76,
    "start_time": "2023-03-14T17:47:16.564Z"
   },
   {
    "duration": 156,
    "start_time": "2023-03-14T17:47:39.364Z"
   },
   {
    "duration": 64,
    "start_time": "2023-03-14T17:47:42.078Z"
   },
   {
    "duration": 397,
    "start_time": "2023-03-14T17:48:19.993Z"
   },
   {
    "duration": 431,
    "start_time": "2023-03-14T17:48:23.969Z"
   },
   {
    "duration": 410,
    "start_time": "2023-03-14T17:48:27.798Z"
   },
   {
    "duration": 393,
    "start_time": "2023-03-14T17:48:35.793Z"
   },
   {
    "duration": 561,
    "start_time": "2023-03-14T17:49:17.868Z"
   },
   {
    "duration": 67,
    "start_time": "2023-03-14T17:52:35.796Z"
   },
   {
    "duration": 279,
    "start_time": "2023-03-14T17:52:40.821Z"
   },
   {
    "duration": 100,
    "start_time": "2023-03-14T17:52:42.416Z"
   },
   {
    "duration": 412,
    "start_time": "2023-03-14T17:52:46.403Z"
   },
   {
    "duration": 422,
    "start_time": "2023-03-14T17:53:00.905Z"
   },
   {
    "duration": 149,
    "start_time": "2023-03-14T17:53:01.897Z"
   },
   {
    "duration": 65,
    "start_time": "2023-03-14T17:53:03.223Z"
   },
   {
    "duration": 299,
    "start_time": "2023-03-14T17:53:20.471Z"
   },
   {
    "duration": 354,
    "start_time": "2023-03-14T17:53:21.468Z"
   },
   {
    "duration": 153,
    "start_time": "2023-03-14T17:53:22.228Z"
   },
   {
    "duration": 67,
    "start_time": "2023-03-14T17:53:22.919Z"
   },
   {
    "duration": 426,
    "start_time": "2023-03-14T17:53:23.991Z"
   },
   {
    "duration": 410,
    "start_time": "2023-03-14T17:54:06.375Z"
   },
   {
    "duration": 81,
    "start_time": "2023-03-14T17:54:44.814Z"
   },
   {
    "duration": 94,
    "start_time": "2023-03-14T17:56:37.821Z"
   },
   {
    "duration": 61,
    "start_time": "2023-03-14T17:56:41.471Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-14T17:58:13.302Z"
   },
   {
    "duration": 62,
    "start_time": "2023-03-14T18:00:23.047Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-14T18:01:06.697Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-14T18:01:10.300Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-14T18:06:28.375Z"
   },
   {
    "duration": 27,
    "start_time": "2023-03-14T18:06:38.918Z"
   },
   {
    "duration": 84,
    "start_time": "2023-03-14T18:06:43.195Z"
   },
   {
    "duration": 26,
    "start_time": "2023-03-14T18:06:50.830Z"
   },
   {
    "duration": 82,
    "start_time": "2023-03-14T18:06:52.416Z"
   },
   {
    "duration": 17,
    "start_time": "2023-03-14T18:06:59.296Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-14T18:07:37.197Z"
   },
   {
    "duration": 83,
    "start_time": "2023-03-14T18:07:38.696Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-14T18:07:56.601Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-14T18:08:34.351Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-14T18:08:38.573Z"
   },
   {
    "duration": 44,
    "start_time": "2023-03-14T18:08:50.577Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-14T18:08:52.419Z"
   },
   {
    "duration": 113,
    "start_time": "2023-03-14T18:09:00.467Z"
   },
   {
    "duration": 189,
    "start_time": "2023-03-14T18:09:56.891Z"
   },
   {
    "duration": 85,
    "start_time": "2023-03-14T18:10:00.363Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-14T18:10:05.323Z"
   },
   {
    "duration": 73,
    "start_time": "2023-03-14T18:10:40.270Z"
   },
   {
    "duration": 139,
    "start_time": "2023-03-14T18:12:43.621Z"
   },
   {
    "duration": 64,
    "start_time": "2023-03-14T18:13:58.629Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-14T18:31:16.966Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-14T18:32:51.870Z"
   },
   {
    "duration": 77,
    "start_time": "2023-03-14T18:32:58.418Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-14T18:33:04.816Z"
   },
   {
    "duration": 69,
    "start_time": "2023-03-14T18:53:06.139Z"
   },
   {
    "duration": 133,
    "start_time": "2023-03-14T18:58:58.132Z"
   },
   {
    "duration": 78,
    "start_time": "2023-03-14T18:59:18.345Z"
   },
   {
    "duration": 414,
    "start_time": "2023-03-14T19:00:31.022Z"
   },
   {
    "duration": 120,
    "start_time": "2023-03-14T19:00:44.507Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-14T19:01:03.094Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-14T19:01:13.620Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-14T19:01:17.695Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-14T19:01:20.628Z"
   },
   {
    "duration": 20,
    "start_time": "2023-03-14T19:01:23.792Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-14T19:01:26.230Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-14T19:02:30.621Z"
   },
   {
    "duration": 45,
    "start_time": "2023-03-14T19:02:31.523Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-14T19:02:32.211Z"
   },
   {
    "duration": 96,
    "start_time": "2023-03-14T19:02:37.409Z"
   },
   {
    "duration": 48,
    "start_time": "2023-03-14T19:05:08.120Z"
   },
   {
    "duration": 51,
    "start_time": "2023-03-20T19:23:37.028Z"
   },
   {
    "duration": 1734,
    "start_time": "2023-03-20T19:23:39.775Z"
   },
   {
    "duration": 3043,
    "start_time": "2023-03-20T19:23:41.511Z"
   },
   {
    "duration": 135,
    "start_time": "2023-03-20T19:23:44.556Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-20T19:23:44.693Z"
   },
   {
    "duration": 111,
    "start_time": "2023-03-20T19:23:44.711Z"
   },
   {
    "duration": 407,
    "start_time": "2023-03-20T19:23:44.824Z"
   },
   {
    "duration": 286,
    "start_time": "2023-03-20T19:23:45.232Z"
   },
   {
    "duration": 330,
    "start_time": "2023-03-20T19:23:45.520Z"
   },
   {
    "duration": 144,
    "start_time": "2023-03-20T19:23:45.851Z"
   },
   {
    "duration": 60,
    "start_time": "2023-03-20T19:23:45.996Z"
   },
   {
    "duration": 409,
    "start_time": "2023-03-20T19:23:46.058Z"
   },
   {
    "duration": 84,
    "start_time": "2023-03-20T19:23:46.468Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-20T19:23:46.554Z"
   },
   {
    "duration": 184,
    "start_time": "2023-03-20T19:23:46.559Z"
   },
   {
    "duration": 75,
    "start_time": "2023-03-20T19:23:46.745Z"
   },
   {
    "duration": 79,
    "start_time": "2023-03-20T19:23:46.821Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-20T19:28:28.150Z"
   },
   {
    "duration": 68,
    "start_time": "2023-03-20T19:28:29.562Z"
   },
   {
    "duration": 219,
    "start_time": "2023-03-20T19:28:31.884Z"
   },
   {
    "duration": 47,
    "start_time": "2023-03-21T17:13:45.903Z"
   },
   {
    "duration": 1704,
    "start_time": "2023-03-21T17:13:48.900Z"
   },
   {
    "duration": 3165,
    "start_time": "2023-03-21T17:13:50.606Z"
   },
   {
    "duration": 109,
    "start_time": "2023-03-21T17:13:53.773Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-21T17:13:53.884Z"
   },
   {
    "duration": 131,
    "start_time": "2023-03-21T17:13:53.902Z"
   },
   {
    "duration": 389,
    "start_time": "2023-03-21T17:13:54.035Z"
   },
   {
    "duration": 257,
    "start_time": "2023-03-21T17:13:54.426Z"
   },
   {
    "duration": 347,
    "start_time": "2023-03-21T17:13:54.685Z"
   },
   {
    "duration": 141,
    "start_time": "2023-03-21T17:13:55.033Z"
   },
   {
    "duration": 66,
    "start_time": "2023-03-21T17:13:55.176Z"
   },
   {
    "duration": 345,
    "start_time": "2023-03-21T17:13:55.244Z"
   },
   {
    "duration": 66,
    "start_time": "2023-03-21T17:13:55.591Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-21T17:13:55.659Z"
   },
   {
    "duration": 158,
    "start_time": "2023-03-21T17:13:55.665Z"
   },
   {
    "duration": 56,
    "start_time": "2023-03-21T17:13:55.825Z"
   },
   {
    "duration": 68,
    "start_time": "2023-03-21T17:13:55.883Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-21T17:14:01.487Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-21T17:14:25.920Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-21T17:14:38.787Z"
   },
   {
    "duration": 39,
    "start_time": "2023-03-21T17:15:45.969Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-21T17:15:50.899Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-21T17:15:56.520Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-21T17:15:59.144Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-21T17:16:00.240Z"
   },
   {
    "duration": 67,
    "start_time": "2023-03-21T17:16:00.859Z"
   },
   {
    "duration": 249,
    "start_time": "2023-03-21T17:16:01.603Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-21T17:16:26.291Z"
   },
   {
    "duration": 63,
    "start_time": "2023-03-21T17:19:24.042Z"
   },
   {
    "duration": 98,
    "start_time": "2023-03-21T17:19:31.228Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-21T17:19:44.938Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-21T17:19:55.624Z"
   },
   {
    "duration": 54,
    "start_time": "2023-03-21T17:20:22.212Z"
   },
   {
    "duration": 86,
    "start_time": "2023-03-21T17:20:34.046Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-21T17:20:34.899Z"
   },
   {
    "duration": 56,
    "start_time": "2023-03-21T17:20:40.508Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-21T17:42:51.198Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-21T17:43:03.249Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-21T17:43:06.598Z"
   },
   {
    "duration": 34,
    "start_time": "2023-03-21T17:43:07.547Z"
   },
   {
    "duration": 1053,
    "start_time": "2023-03-21T17:43:08.609Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-21T17:45:10.293Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-21T17:45:13.442Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-21T17:45:23.798Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-21T17:45:40.724Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-21T17:45:55.910Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-21T17:45:57.927Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-21T17:46:18.384Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-21T17:46:20.011Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-21T17:46:20.649Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-21T17:46:50.995Z"
   },
   {
    "duration": 1113,
    "start_time": "2023-03-21T17:47:43.813Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-21T17:47:51.404Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-21T17:48:08.268Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-21T17:48:09.798Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-21T17:48:18.901Z"
   },
   {
    "duration": 105,
    "start_time": "2023-03-21T17:48:19.866Z"
   },
   {
    "duration": 39,
    "start_time": "2023-03-21T18:06:26.981Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-21T18:06:34.430Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-21T18:06:35.494Z"
   },
   {
    "duration": 20,
    "start_time": "2023-03-21T18:07:01.435Z"
   },
   {
    "duration": 136,
    "start_time": "2023-03-21T18:07:02.417Z"
   },
   {
    "duration": 280,
    "start_time": "2023-03-21T18:07:48.137Z"
   },
   {
    "duration": 55,
    "start_time": "2023-03-21T18:07:52.223Z"
   },
   {
    "duration": 104,
    "start_time": "2023-03-21T18:08:15.384Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-21T18:08:16.443Z"
   },
   {
    "duration": 117,
    "start_time": "2023-03-21T18:08:20.234Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-21T18:29:39.600Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-21T18:29:53.115Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-21T18:30:01.628Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-21T18:30:36.834Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-21T18:30:41.537Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-21T18:30:44.417Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-21T18:31:18.204Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-21T18:31:25.499Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-21T18:32:01.640Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-21T18:32:18.745Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-21T18:32:25.820Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-21T18:32:28.429Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-21T18:32:36.093Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-21T18:33:22.043Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-21T18:33:33.576Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-21T18:33:40.343Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-21T18:36:12.628Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-21T18:36:22.676Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-21T18:37:18.278Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-21T18:37:20.555Z"
   },
   {
    "duration": 499,
    "start_time": "2023-03-21T18:37:24.394Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-21T18:37:59.771Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-21T18:38:02.701Z"
   },
   {
    "duration": 230,
    "start_time": "2023-03-21T18:38:06.900Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-21T18:38:10.883Z"
   },
   {
    "duration": 229,
    "start_time": "2023-03-21T18:40:33.182Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-21T18:40:36.110Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-21T18:42:02.856Z"
   },
   {
    "duration": 235,
    "start_time": "2023-03-21T18:42:08.304Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-21T18:43:39.025Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-21T18:43:42.233Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-21T18:44:03.608Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-21T18:44:18.873Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-21T18:44:26.891Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-21T18:44:40.600Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-21T18:46:14.655Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-21T18:46:47.304Z"
   },
   {
    "duration": 17,
    "start_time": "2023-03-21T18:46:48.242Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-21T18:51:17.825Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-21T18:51:19.257Z"
   },
   {
    "duration": 27,
    "start_time": "2023-03-21T18:52:13.419Z"
   },
   {
    "duration": 32,
    "start_time": "2023-03-21T18:53:25.519Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-21T18:53:28.864Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-21T18:54:21.195Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-21T18:54:35.623Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-21T18:54:44.423Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-21T18:55:03.793Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-21T18:55:06.023Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-21T18:55:08.326Z"
   },
   {
    "duration": 40,
    "start_time": "2023-03-21T18:55:10.645Z"
   },
   {
    "duration": 169,
    "start_time": "2023-03-21T18:55:11.317Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-21T18:55:33.584Z"
   },
   {
    "duration": 43,
    "start_time": "2023-03-21T18:55:34.423Z"
   },
   {
    "duration": 209,
    "start_time": "2023-03-21T18:55:35.215Z"
   },
   {
    "duration": 432,
    "start_time": "2023-03-21T18:55:45.903Z"
   },
   {
    "duration": 424,
    "start_time": "2023-03-21T18:55:52.721Z"
   },
   {
    "duration": 77,
    "start_time": "2023-03-21T18:56:56.251Z"
   },
   {
    "duration": 67,
    "start_time": "2023-03-21T18:57:00.263Z"
   },
   {
    "duration": 230,
    "start_time": "2023-03-21T18:58:57.694Z"
   },
   {
    "duration": 207,
    "start_time": "2023-03-21T18:59:01.220Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-21T19:00:51.604Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-21T19:02:27.024Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-21T19:02:29.367Z"
   },
   {
    "duration": 91,
    "start_time": "2023-03-21T19:02:51.135Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-21T19:02:56.527Z"
   },
   {
    "duration": 119,
    "start_time": "2023-03-21T19:03:32.114Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-21T19:03:33.253Z"
   },
   {
    "duration": 181,
    "start_time": "2023-03-21T19:03:47.544Z"
   },
   {
    "duration": 485,
    "start_time": "2023-03-21T20:01:02.695Z"
   },
   {
    "duration": 12366,
    "start_time": "2023-03-21T20:01:45.640Z"
   },
   {
    "duration": 474,
    "start_time": "2023-03-21T20:03:24.890Z"
   },
   {
    "duration": 6120,
    "start_time": "2023-03-21T20:03:36.053Z"
   },
   {
    "duration": 6020,
    "start_time": "2023-03-21T20:03:52.726Z"
   },
   {
    "duration": 12198,
    "start_time": "2023-03-21T20:05:24.421Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-21T20:07:50.161Z"
   },
   {
    "duration": 53,
    "start_time": "2023-03-21T20:08:02.517Z"
   },
   {
    "duration": 51,
    "start_time": "2023-03-21T20:08:14.457Z"
   },
   {
    "duration": 54,
    "start_time": "2023-03-21T20:08:30.023Z"
   },
   {
    "duration": 63,
    "start_time": "2023-03-21T20:08:40.219Z"
   },
   {
    "duration": 3298,
    "start_time": "2023-03-21T20:08:51.044Z"
   },
   {
    "duration": 3345,
    "start_time": "2023-03-21T20:09:18.295Z"
   },
   {
    "duration": 3290,
    "start_time": "2023-03-21T20:09:25.515Z"
   },
   {
    "duration": 3421,
    "start_time": "2023-03-21T20:09:37.746Z"
   },
   {
    "duration": 3548,
    "start_time": "2023-03-21T20:09:58.334Z"
   },
   {
    "duration": 3489,
    "start_time": "2023-03-21T20:10:20.001Z"
   },
   {
    "duration": 3336,
    "start_time": "2023-03-21T20:10:43.288Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-21T20:10:58.961Z"
   },
   {
    "duration": 12300,
    "start_time": "2023-03-21T20:11:17.952Z"
   },
   {
    "duration": 30562,
    "start_time": "2023-03-21T20:14:46.061Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-21T20:20:42.254Z"
   },
   {
    "duration": 1508,
    "start_time": "2023-03-23T13:19:27.680Z"
   },
   {
    "duration": 3231,
    "start_time": "2023-03-23T13:19:29.189Z"
   },
   {
    "duration": 119,
    "start_time": "2023-03-23T13:19:32.421Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-23T13:19:32.542Z"
   },
   {
    "duration": 96,
    "start_time": "2023-03-23T13:19:32.559Z"
   },
   {
    "duration": 353,
    "start_time": "2023-03-23T13:19:32.656Z"
   },
   {
    "duration": 246,
    "start_time": "2023-03-23T13:19:33.011Z"
   },
   {
    "duration": 318,
    "start_time": "2023-03-23T13:19:33.259Z"
   },
   {
    "duration": 125,
    "start_time": "2023-03-23T13:19:33.579Z"
   },
   {
    "duration": 69,
    "start_time": "2023-03-23T13:19:33.707Z"
   },
   {
    "duration": 329,
    "start_time": "2023-03-23T13:19:33.778Z"
   },
   {
    "duration": 65,
    "start_time": "2023-03-23T13:19:34.109Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T13:19:34.176Z"
   },
   {
    "duration": 155,
    "start_time": "2023-03-23T13:19:34.180Z"
   },
   {
    "duration": 54,
    "start_time": "2023-03-23T13:19:34.337Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-23T13:19:34.392Z"
   },
   {
    "duration": 118,
    "start_time": "2023-03-23T13:19:34.408Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-23T13:19:34.527Z"
   },
   {
    "duration": 48,
    "start_time": "2023-03-23T13:19:34.546Z"
   },
   {
    "duration": 77,
    "start_time": "2023-03-23T13:19:34.597Z"
   },
   {
    "duration": 236,
    "start_time": "2023-03-23T13:19:34.675Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-23T13:19:34.913Z"
   },
   {
    "duration": 29,
    "start_time": "2023-03-23T13:19:34.928Z"
   },
   {
    "duration": 281,
    "start_time": "2023-03-23T13:21:35.147Z"
   },
   {
    "duration": 50,
    "start_time": "2023-03-23T13:21:38.815Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-23T13:25:02.836Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-23T13:25:08.362Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-23T13:25:11.394Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-23T13:25:15.576Z"
   },
   {
    "duration": 43,
    "start_time": "2023-03-23T13:25:30.234Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T13:26:04.657Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-23T13:26:05.172Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-23T13:26:05.651Z"
   },
   {
    "duration": 78,
    "start_time": "2023-03-23T13:26:06.369Z"
   },
   {
    "duration": 166,
    "start_time": "2023-03-23T13:26:10.408Z"
   },
   {
    "duration": 3850,
    "start_time": "2023-03-23T13:26:20.263Z"
   },
   {
    "duration": 33840,
    "start_time": "2023-03-23T13:26:25.066Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T13:27:30.862Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-23T13:27:33.541Z"
   },
   {
    "duration": 29,
    "start_time": "2023-03-23T13:27:44.522Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T13:27:49.277Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-23T13:27:51.997Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-23T13:28:07.302Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-23T13:28:25.874Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-23T13:28:45.308Z"
   },
   {
    "duration": 45,
    "start_time": "2023-03-23T13:32:24.617Z"
   },
   {
    "duration": 60,
    "start_time": "2023-03-23T13:32:33.132Z"
   },
   {
    "duration": 214,
    "start_time": "2023-03-23T13:32:41.177Z"
   },
   {
    "duration": 50,
    "start_time": "2023-03-23T13:32:45.107Z"
   },
   {
    "duration": 83,
    "start_time": "2023-03-23T13:32:48.348Z"
   },
   {
    "duration": 192,
    "start_time": "2023-03-23T13:32:49.653Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T13:34:34.740Z"
   },
   {
    "duration": 181,
    "start_time": "2023-03-23T13:35:07.359Z"
   },
   {
    "duration": 131,
    "start_time": "2023-03-23T13:35:16.516Z"
   },
   {
    "duration": 91,
    "start_time": "2023-03-23T13:35:29.350Z"
   },
   {
    "duration": 55,
    "start_time": "2023-03-23T13:35:33.897Z"
   },
   {
    "duration": 110,
    "start_time": "2023-03-23T13:35:38.132Z"
   },
   {
    "duration": 49,
    "start_time": "2023-03-23T13:36:36.992Z"
   },
   {
    "duration": 198,
    "start_time": "2023-03-23T13:36:46.646Z"
   },
   {
    "duration": 104,
    "start_time": "2023-03-23T13:36:51.944Z"
   },
   {
    "duration": 82,
    "start_time": "2023-03-23T13:36:55.361Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-23T13:36:58.735Z"
   },
   {
    "duration": 74,
    "start_time": "2023-03-23T13:37:04.368Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-23T13:37:06.357Z"
   },
   {
    "duration": 193,
    "start_time": "2023-03-23T13:37:07.451Z"
   },
   {
    "duration": 135,
    "start_time": "2023-03-23T13:37:08.815Z"
   },
   {
    "duration": 165,
    "start_time": "2023-03-23T13:37:10.087Z"
   },
   {
    "duration": 33,
    "start_time": "2023-03-23T13:37:11.333Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-23T13:37:12.470Z"
   },
   {
    "duration": 81,
    "start_time": "2023-03-23T13:37:20.863Z"
   },
   {
    "duration": 85,
    "start_time": "2023-03-23T13:37:23.364Z"
   },
   {
    "duration": 142,
    "start_time": "2023-03-23T13:37:26.607Z"
   },
   {
    "duration": 114,
    "start_time": "2023-03-23T13:37:27.926Z"
   },
   {
    "duration": 106,
    "start_time": "2023-03-23T13:37:30.339Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T13:38:36.013Z"
   },
   {
    "duration": 32,
    "start_time": "2023-03-23T13:38:45.551Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T13:38:46.650Z"
   },
   {
    "duration": 79,
    "start_time": "2023-03-23T13:38:55.969Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T13:38:57.175Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T13:39:58.855Z"
   },
   {
    "duration": 748,
    "start_time": "2023-03-23T13:39:58.862Z"
   },
   {
    "duration": 111,
    "start_time": "2023-03-23T13:39:59.612Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-23T13:39:59.724Z"
   },
   {
    "duration": 100,
    "start_time": "2023-03-23T13:39:59.744Z"
   },
   {
    "duration": 385,
    "start_time": "2023-03-23T13:39:59.846Z"
   },
   {
    "duration": 255,
    "start_time": "2023-03-23T13:40:00.232Z"
   },
   {
    "duration": 332,
    "start_time": "2023-03-23T13:40:00.489Z"
   },
   {
    "duration": 144,
    "start_time": "2023-03-23T13:40:00.823Z"
   },
   {
    "duration": 61,
    "start_time": "2023-03-23T13:40:00.969Z"
   },
   {
    "duration": 330,
    "start_time": "2023-03-23T13:40:01.040Z"
   },
   {
    "duration": 80,
    "start_time": "2023-03-23T13:40:01.371Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-23T13:40:01.453Z"
   },
   {
    "duration": 179,
    "start_time": "2023-03-23T13:40:01.478Z"
   },
   {
    "duration": 56,
    "start_time": "2023-03-23T13:40:01.659Z"
   },
   {
    "duration": 49,
    "start_time": "2023-03-23T13:40:01.717Z"
   },
   {
    "duration": 118,
    "start_time": "2023-03-23T13:40:01.768Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-23T13:40:01.888Z"
   },
   {
    "duration": 77,
    "start_time": "2023-03-23T13:40:01.903Z"
   },
   {
    "duration": 42,
    "start_time": "2023-03-23T13:40:01.982Z"
   },
   {
    "duration": 259,
    "start_time": "2023-03-23T13:40:02.026Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-23T13:40:02.286Z"
   },
   {
    "duration": 74,
    "start_time": "2023-03-23T13:40:02.301Z"
   },
   {
    "duration": 59,
    "start_time": "2023-03-23T13:40:02.376Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-23T13:40:02.437Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-23T13:40:02.458Z"
   },
   {
    "duration": 55,
    "start_time": "2023-03-23T13:40:02.491Z"
   },
   {
    "duration": 4077,
    "start_time": "2023-03-23T13:40:02.547Z"
   },
   {
    "duration": 34116,
    "start_time": "2023-03-23T13:40:06.625Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-23T13:40:40.743Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-23T13:40:50.735Z"
   },
   {
    "duration": 165,
    "start_time": "2023-03-23T13:41:06.476Z"
   },
   {
    "duration": 4042,
    "start_time": "2023-03-23T13:41:07.282Z"
   },
   {
    "duration": 33480,
    "start_time": "2023-03-23T13:41:15.829Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-23T13:41:57.967Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T13:42:05.368Z"
   },
   {
    "duration": 748,
    "start_time": "2023-03-23T13:42:05.375Z"
   },
   {
    "duration": 134,
    "start_time": "2023-03-23T13:42:06.124Z"
   },
   {
    "duration": 17,
    "start_time": "2023-03-23T13:42:06.260Z"
   },
   {
    "duration": 107,
    "start_time": "2023-03-23T13:42:06.280Z"
   },
   {
    "duration": 376,
    "start_time": "2023-03-23T13:42:06.389Z"
   },
   {
    "duration": 261,
    "start_time": "2023-03-23T13:42:06.767Z"
   },
   {
    "duration": 416,
    "start_time": "2023-03-23T13:42:07.030Z"
   },
   {
    "duration": 148,
    "start_time": "2023-03-23T13:42:07.448Z"
   },
   {
    "duration": 83,
    "start_time": "2023-03-23T13:42:07.598Z"
   },
   {
    "duration": 415,
    "start_time": "2023-03-23T13:42:07.683Z"
   },
   {
    "duration": 70,
    "start_time": "2023-03-23T13:42:08.100Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T13:42:08.172Z"
   },
   {
    "duration": 182,
    "start_time": "2023-03-23T13:42:08.179Z"
   },
   {
    "duration": 53,
    "start_time": "2023-03-23T13:42:08.363Z"
   },
   {
    "duration": 33,
    "start_time": "2023-03-23T13:42:08.418Z"
   },
   {
    "duration": 127,
    "start_time": "2023-03-23T13:42:08.452Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-23T13:42:08.581Z"
   },
   {
    "duration": 48,
    "start_time": "2023-03-23T13:42:08.598Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T13:42:08.648Z"
   },
   {
    "duration": 254,
    "start_time": "2023-03-23T13:42:08.655Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-23T13:42:08.910Z"
   },
   {
    "duration": 26,
    "start_time": "2023-03-23T13:42:08.926Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T13:42:08.954Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-23T13:42:08.958Z"
   },
   {
    "duration": 20,
    "start_time": "2023-03-23T13:42:08.975Z"
   },
   {
    "duration": 77,
    "start_time": "2023-03-23T13:42:08.997Z"
   },
   {
    "duration": 3874,
    "start_time": "2023-03-23T13:42:09.157Z"
   },
   {
    "duration": 34022,
    "start_time": "2023-03-23T13:42:13.033Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-23T13:42:50.204Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-23T13:43:35.236Z"
   },
   {
    "duration": 755,
    "start_time": "2023-03-23T13:43:35.246Z"
   },
   {
    "duration": 113,
    "start_time": "2023-03-23T13:43:36.003Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-23T13:43:36.118Z"
   },
   {
    "duration": 129,
    "start_time": "2023-03-23T13:43:36.146Z"
   },
   {
    "duration": 367,
    "start_time": "2023-03-23T13:43:36.278Z"
   },
   {
    "duration": 269,
    "start_time": "2023-03-23T13:43:36.648Z"
   },
   {
    "duration": 403,
    "start_time": "2023-03-23T13:43:36.919Z"
   },
   {
    "duration": 139,
    "start_time": "2023-03-23T13:43:37.324Z"
   },
   {
    "duration": 75,
    "start_time": "2023-03-23T13:43:37.465Z"
   },
   {
    "duration": 477,
    "start_time": "2023-03-23T13:43:37.542Z"
   },
   {
    "duration": 86,
    "start_time": "2023-03-23T13:43:38.021Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T13:43:38.110Z"
   },
   {
    "duration": 164,
    "start_time": "2023-03-23T13:43:38.118Z"
   },
   {
    "duration": 64,
    "start_time": "2023-03-23T13:43:38.284Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-23T13:43:38.350Z"
   },
   {
    "duration": 128,
    "start_time": "2023-03-23T13:43:38.372Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-23T13:43:38.502Z"
   },
   {
    "duration": 91,
    "start_time": "2023-03-23T13:43:38.522Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-23T13:43:38.616Z"
   },
   {
    "duration": 253,
    "start_time": "2023-03-23T13:43:38.625Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-23T13:43:38.880Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-23T13:43:38.898Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T13:43:38.913Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-23T13:43:38.940Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-23T13:43:38.953Z"
   },
   {
    "duration": 69,
    "start_time": "2023-03-23T13:43:38.983Z"
   },
   {
    "duration": 4026,
    "start_time": "2023-03-23T13:43:39.054Z"
   },
   {
    "duration": 34615,
    "start_time": "2023-03-23T13:43:43.081Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-23T13:44:17.698Z"
   },
   {
    "duration": 33,
    "start_time": "2023-03-23T13:46:02.560Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T14:12:21.788Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-23T14:13:48.299Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-23T14:14:02.079Z"
   },
   {
    "duration": 632,
    "start_time": "2023-03-23T14:14:06.829Z"
   },
   {
    "duration": 45,
    "start_time": "2023-03-23T14:14:10.315Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-23T14:14:19.778Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-23T14:14:43.903Z"
   },
   {
    "duration": 27,
    "start_time": "2023-03-23T14:14:54.806Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-23T14:14:57.888Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T14:21:47.480Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T14:26:14.861Z"
   },
   {
    "duration": 78,
    "start_time": "2023-03-23T14:26:18.472Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T14:26:22.359Z"
   },
   {
    "duration": 81,
    "start_time": "2023-03-23T14:26:30.367Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T14:26:31.924Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T14:26:35.061Z"
   },
   {
    "duration": 39,
    "start_time": "2023-03-23T14:26:38.812Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T14:26:40.266Z"
   },
   {
    "duration": 58,
    "start_time": "2023-03-23T14:26:52.404Z"
   },
   {
    "duration": 73,
    "start_time": "2023-03-23T14:26:55.285Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-23T14:26:56.501Z"
   },
   {
    "duration": 125,
    "start_time": "2023-03-23T14:27:06.734Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-23T14:27:07.966Z"
   },
   {
    "duration": 123,
    "start_time": "2023-03-23T14:27:10.928Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-23T14:27:11.941Z"
   },
   {
    "duration": 210,
    "start_time": "2023-03-23T14:27:28.439Z"
   },
   {
    "duration": 69,
    "start_time": "2023-03-23T14:27:31.586Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-23T14:27:32.734Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-23T14:28:37.208Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T14:28:59.094Z"
   },
   {
    "duration": 800,
    "start_time": "2023-03-23T14:28:59.101Z"
   },
   {
    "duration": 121,
    "start_time": "2023-03-23T14:28:59.903Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-23T14:29:00.025Z"
   },
   {
    "duration": 96,
    "start_time": "2023-03-23T14:29:00.063Z"
   },
   {
    "duration": 389,
    "start_time": "2023-03-23T14:29:00.161Z"
   },
   {
    "duration": 262,
    "start_time": "2023-03-23T14:29:00.552Z"
   },
   {
    "duration": 341,
    "start_time": "2023-03-23T14:29:00.816Z"
   },
   {
    "duration": 136,
    "start_time": "2023-03-23T14:29:01.159Z"
   },
   {
    "duration": 70,
    "start_time": "2023-03-23T14:29:01.296Z"
   },
   {
    "duration": 347,
    "start_time": "2023-03-23T14:29:01.367Z"
   },
   {
    "duration": 81,
    "start_time": "2023-03-23T14:29:01.716Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-23T14:29:01.798Z"
   },
   {
    "duration": 170,
    "start_time": "2023-03-23T14:29:01.824Z"
   },
   {
    "duration": 63,
    "start_time": "2023-03-23T14:29:01.995Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-23T14:29:02.060Z"
   },
   {
    "duration": 167,
    "start_time": "2023-03-23T14:29:02.087Z"
   },
   {
    "duration": 20,
    "start_time": "2023-03-23T14:29:02.256Z"
   },
   {
    "duration": 43,
    "start_time": "2023-03-23T14:29:02.277Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-23T14:29:02.322Z"
   },
   {
    "duration": 33,
    "start_time": "2023-03-23T14:29:02.326Z"
   },
   {
    "duration": 570,
    "start_time": "2023-03-23T14:29:02.360Z"
   },
   {
    "duration": 29,
    "start_time": "2023-03-23T14:29:02.932Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-23T14:29:02.962Z"
   },
   {
    "duration": 264,
    "start_time": "2023-03-23T14:29:02.973Z"
   },
   {
    "duration": 132,
    "start_time": "2023-03-23T14:29:03.245Z"
   },
   {
    "duration": 17,
    "start_time": "2023-03-23T14:29:03.381Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-23T14:29:03.399Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-23T14:29:03.416Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-23T14:29:03.417Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-23T14:29:03.417Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-23T14:29:03.418Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-23T14:29:03.419Z"
   },
   {
    "duration": 87,
    "start_time": "2023-03-23T14:29:21.602Z"
   },
   {
    "duration": 264,
    "start_time": "2023-03-23T14:29:23.473Z"
   },
   {
    "duration": 39466,
    "start_time": "2023-03-23T14:29:24.595Z"
   },
   {
    "duration": 45926,
    "start_time": "2023-03-23T14:30:04.139Z"
   },
   {
    "duration": 307291,
    "start_time": "2023-03-23T14:30:50.066Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T14:35:57.359Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-23T14:35:57.365Z"
   },
   {
    "duration": 30,
    "start_time": "2023-03-23T14:35:57.379Z"
   },
   {
    "duration": 107,
    "start_time": "2023-03-23T14:35:57.410Z"
   },
   {
    "duration": 261,
    "start_time": "2023-03-23T14:35:57.519Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T14:41:40.007Z"
   },
   {
    "duration": 775,
    "start_time": "2023-03-23T14:41:40.014Z"
   },
   {
    "duration": 117,
    "start_time": "2023-03-23T14:41:40.791Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-23T14:41:40.910Z"
   },
   {
    "duration": 103,
    "start_time": "2023-03-23T14:41:40.923Z"
   },
   {
    "duration": 365,
    "start_time": "2023-03-23T14:41:41.028Z"
   },
   {
    "duration": 262,
    "start_time": "2023-03-23T14:41:41.395Z"
   },
   {
    "duration": 339,
    "start_time": "2023-03-23T14:41:41.659Z"
   },
   {
    "duration": 134,
    "start_time": "2023-03-23T14:41:42.001Z"
   },
   {
    "duration": 61,
    "start_time": "2023-03-23T14:41:42.136Z"
   },
   {
    "duration": 329,
    "start_time": "2023-03-23T14:41:42.199Z"
   },
   {
    "duration": 95,
    "start_time": "2023-03-23T14:41:42.529Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T14:41:42.625Z"
   },
   {
    "duration": 158,
    "start_time": "2023-03-23T14:41:42.630Z"
   },
   {
    "duration": 63,
    "start_time": "2023-03-23T14:41:42.790Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-23T14:41:42.854Z"
   },
   {
    "duration": 116,
    "start_time": "2023-03-23T14:41:42.870Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-23T14:41:42.988Z"
   },
   {
    "duration": 48,
    "start_time": "2023-03-23T14:41:45.024Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T14:41:46.115Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-23T14:41:47.575Z"
   },
   {
    "duration": 580,
    "start_time": "2023-03-23T14:41:48.176Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-23T14:41:49.312Z"
   },
   {
    "duration": 157,
    "start_time": "2023-03-23T14:41:51.081Z"
   },
   {
    "duration": 244,
    "start_time": "2023-03-23T14:41:52.974Z"
   },
   {
    "duration": 47563,
    "start_time": "2023-03-23T14:41:53.993Z"
   },
   {
    "duration": 43854,
    "start_time": "2023-03-23T14:42:49.159Z"
   },
   {
    "duration": 350549,
    "start_time": "2023-03-23T14:44:05.349Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T14:49:55.900Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-23T14:50:05.785Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T14:50:13.452Z"
   },
   {
    "duration": 236,
    "start_time": "2023-03-23T14:50:15.355Z"
   },
   {
    "duration": 71,
    "start_time": "2023-03-23T14:50:16.996Z"
   },
   {
    "duration": 17,
    "start_time": "2023-03-23T14:50:18.203Z"
   },
   {
    "duration": 89,
    "start_time": "2023-03-23T14:50:20.081Z"
   },
   {
    "duration": 96,
    "start_time": "2023-03-23T14:50:23.888Z"
   },
   {
    "duration": 275,
    "start_time": "2023-03-23T14:50:24.936Z"
   },
   {
    "duration": 352,
    "start_time": "2023-03-23T14:50:26.435Z"
   },
   {
    "duration": 43,
    "start_time": "2023-03-23T14:50:55.393Z"
   },
   {
    "duration": 96,
    "start_time": "2023-03-23T14:51:04.338Z"
   },
   {
    "duration": 286,
    "start_time": "2023-03-23T14:51:04.922Z"
   },
   {
    "duration": 69,
    "start_time": "2023-03-23T14:51:05.693Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-23T14:51:27.691Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T14:51:34.020Z"
   },
   {
    "duration": 254,
    "start_time": "2023-03-23T14:51:35.272Z"
   },
   {
    "duration": 17,
    "start_time": "2023-03-23T14:51:41.835Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-23T14:51:43.508Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-23T14:51:48.171Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-23T14:51:48.882Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-23T14:51:49.380Z"
   },
   {
    "duration": 195,
    "start_time": "2023-03-23T14:51:58.557Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T14:52:17.155Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-23T14:52:54.650Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-23T14:52:55.254Z"
   },
   {
    "duration": 93,
    "start_time": "2023-03-23T14:52:56.155Z"
   },
   {
    "duration": 4065,
    "start_time": "2023-03-23T14:53:02.384Z"
   },
   {
    "duration": 34804,
    "start_time": "2023-03-23T14:53:08.158Z"
   },
   {
    "duration": 97,
    "start_time": "2023-03-23T14:53:46.864Z"
   },
   {
    "duration": 276,
    "start_time": "2023-03-23T14:53:48.995Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-23T14:53:49.967Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-23T14:54:07.425Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T14:54:11.014Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-23T14:54:12.093Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-23T14:55:06.998Z"
   },
   {
    "duration": 207,
    "start_time": "2023-03-23T14:56:00.378Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-23T14:56:09.785Z"
   },
   {
    "duration": 193,
    "start_time": "2023-03-23T14:56:12.533Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T14:56:14.965Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-23T14:56:16.017Z"
   },
   {
    "duration": 15543,
    "start_time": "2023-03-23T14:56:32.098Z"
   },
   {
    "duration": 41939,
    "start_time": "2023-03-23T14:56:51.193Z"
   },
   {
    "duration": 324080,
    "start_time": "2023-03-23T14:57:33.133Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T15:02:57.256Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-23T15:02:57.264Z"
   },
   {
    "duration": 255,
    "start_time": "2023-03-23T15:03:29.866Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-23T15:03:31.372Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T15:03:33.439Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-23T15:03:36.784Z"
   },
   {
    "duration": 57,
    "start_time": "2023-03-23T15:03:40.792Z"
   },
   {
    "duration": 3757,
    "start_time": "2023-03-23T15:03:45.457Z"
   },
   {
    "duration": 33214,
    "start_time": "2023-03-23T15:03:49.216Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-23T15:04:22.432Z"
   },
   {
    "duration": 92,
    "start_time": "2023-03-23T15:09:14.199Z"
   },
   {
    "duration": 258,
    "start_time": "2023-03-23T15:09:14.989Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-23T15:09:31.641Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T15:18:58.253Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T15:19:07.758Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T15:19:20.941Z"
   },
   {
    "duration": 78,
    "start_time": "2023-03-23T15:19:33.160Z"
   },
   {
    "duration": 135,
    "start_time": "2023-03-23T15:20:14.500Z"
   },
   {
    "duration": 83,
    "start_time": "2023-03-23T15:20:22.654Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-23T15:20:24.670Z"
   },
   {
    "duration": 1496,
    "start_time": "2023-03-23T15:20:31.065Z"
   },
   {
    "duration": 3110,
    "start_time": "2023-03-23T15:20:32.563Z"
   },
   {
    "duration": 118,
    "start_time": "2023-03-23T15:20:35.674Z"
   },
   {
    "duration": 17,
    "start_time": "2023-03-23T15:20:35.795Z"
   },
   {
    "duration": 104,
    "start_time": "2023-03-23T15:20:35.813Z"
   },
   {
    "duration": 404,
    "start_time": "2023-03-23T15:20:35.919Z"
   },
   {
    "duration": 259,
    "start_time": "2023-03-23T15:20:36.324Z"
   },
   {
    "duration": 360,
    "start_time": "2023-03-23T15:20:36.585Z"
   },
   {
    "duration": 144,
    "start_time": "2023-03-23T15:20:36.947Z"
   },
   {
    "duration": 68,
    "start_time": "2023-03-23T15:20:37.094Z"
   },
   {
    "duration": 340,
    "start_time": "2023-03-23T15:20:37.164Z"
   },
   {
    "duration": 99,
    "start_time": "2023-03-23T15:20:37.506Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T15:20:37.607Z"
   },
   {
    "duration": 168,
    "start_time": "2023-03-23T15:20:37.613Z"
   },
   {
    "duration": 62,
    "start_time": "2023-03-23T15:20:37.783Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-23T15:20:37.846Z"
   },
   {
    "duration": 127,
    "start_time": "2023-03-23T15:20:37.863Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-23T15:20:37.992Z"
   },
   {
    "duration": 57,
    "start_time": "2023-03-23T15:20:38.007Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T15:20:38.067Z"
   },
   {
    "duration": 95,
    "start_time": "2023-03-23T15:20:38.072Z"
   },
   {
    "duration": 572,
    "start_time": "2023-03-23T15:20:38.168Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-23T15:20:38.741Z"
   },
   {
    "duration": 166,
    "start_time": "2023-03-23T15:20:38.758Z"
   },
   {
    "duration": 258,
    "start_time": "2023-03-23T15:20:38.926Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T15:20:39.185Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T15:20:39.190Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T15:20:40.548Z"
   },
   {
    "duration": 30272,
    "start_time": "2023-03-23T15:20:41.826Z"
   },
   {
    "duration": 32511,
    "start_time": "2023-03-23T15:21:39.436Z"
   },
   {
    "duration": 98,
    "start_time": "2023-03-23T15:22:11.949Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-23T15:22:32.117Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-23T15:22:37.901Z"
   },
   {
    "duration": 31594,
    "start_time": "2023-03-23T15:22:43.146Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T15:23:14.745Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T15:23:17.145Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T15:23:17.874Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T15:23:18.685Z"
   },
   {
    "duration": 29713,
    "start_time": "2023-03-23T15:23:23.329Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T15:24:23.063Z"
   },
   {
    "duration": 230511,
    "start_time": "2023-03-23T15:24:27.136Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T15:28:17.649Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T15:28:17.655Z"
   },
   {
    "duration": 201494,
    "start_time": "2023-03-23T15:32:45.691Z"
   },
   {
    "duration": 96887,
    "start_time": "2023-03-23T15:44:15.153Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-23T15:45:52.047Z"
   },
   {
    "duration": 307,
    "start_time": "2023-03-23T15:45:55.134Z"
   },
   {
    "duration": 353,
    "start_time": "2023-03-23T15:46:03.288Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T15:46:12.095Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T15:46:16.476Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T15:46:23.137Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T15:46:24.054Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T15:46:24.816Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T15:46:35.005Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T15:46:37.309Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T15:46:48.302Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-23T15:46:49.442Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-23T15:46:52.199Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-23T15:47:04.940Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T15:47:14.904Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T15:47:16.235Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-23T15:47:21.036Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-23T15:47:36.154Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-23T15:47:45.441Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-23T15:48:00.603Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-23T15:48:06.567Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-23T15:48:08.819Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-23T15:48:23.283Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-23T15:48:25.973Z"
   },
   {
    "duration": 81,
    "start_time": "2023-03-23T15:48:27.576Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-23T15:48:28.846Z"
   },
   {
    "duration": 317,
    "start_time": "2023-03-23T15:48:46.631Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T15:50:37.932Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T15:50:38.826Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T15:51:48.900Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T15:51:49.390Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T15:52:01.852Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T15:52:03.890Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T15:52:04.809Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-23T15:52:05.300Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T15:52:39.485Z"
   },
   {
    "duration": 27544,
    "start_time": "2023-03-23T15:53:04.118Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T15:56:37.658Z"
   },
   {
    "duration": 75,
    "start_time": "2023-03-23T15:56:41.203Z"
   },
   {
    "duration": 84,
    "start_time": "2023-03-23T15:58:16.178Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T15:58:36.142Z"
   },
   {
    "duration": 74,
    "start_time": "2023-03-23T15:58:37.023Z"
   },
   {
    "duration": 70,
    "start_time": "2023-03-23T15:58:46.140Z"
   },
   {
    "duration": 76,
    "start_time": "2023-03-23T15:59:41.389Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T15:59:44.228Z"
   },
   {
    "duration": 80,
    "start_time": "2023-03-23T15:59:44.824Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T16:00:24.999Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:00:58.747Z"
   },
   {
    "duration": 8473,
    "start_time": "2023-03-23T16:01:01.763Z"
   },
   {
    "duration": 273,
    "start_time": "2023-03-23T16:01:29.672Z"
   },
   {
    "duration": 187,
    "start_time": "2023-03-23T16:01:49.707Z"
   },
   {
    "duration": 270,
    "start_time": "2023-03-23T16:01:51.783Z"
   },
   {
    "duration": 286,
    "start_time": "2023-03-23T16:03:09.384Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:03:14.795Z"
   },
   {
    "duration": 76463,
    "start_time": "2023-03-23T16:03:15.677Z"
   },
   {
    "duration": 540,
    "start_time": "2023-03-23T16:04:32.142Z"
   },
   {
    "duration": 312,
    "start_time": "2023-03-23T16:05:58.728Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T16:06:00.633Z"
   },
   {
    "duration": 272,
    "start_time": "2023-03-23T16:06:05.477Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T16:06:12.549Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:06:22.037Z"
   },
   {
    "duration": 8557,
    "start_time": "2023-03-23T16:06:22.694Z"
   },
   {
    "duration": 205,
    "start_time": "2023-03-23T16:06:31.253Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T16:06:31.459Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-23T16:13:49.755Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-23T16:13:55.838Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-23T16:13:59.480Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-23T16:14:05.680Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:14:18.271Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-23T16:14:27.930Z"
   },
   {
    "duration": 94,
    "start_time": "2023-03-23T16:14:31.000Z"
   },
   {
    "duration": 263,
    "start_time": "2023-03-23T16:14:31.579Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:14:32.594Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:14:55.474Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:15:02.543Z"
   },
   {
    "duration": 92255,
    "start_time": "2023-03-23T16:15:03.592Z"
   },
   {
    "duration": 401,
    "start_time": "2023-03-23T16:16:35.849Z"
   },
   {
    "duration": 89,
    "start_time": "2023-03-23T16:16:36.253Z"
   },
   {
    "duration": 20,
    "start_time": "2023-03-23T16:16:36.345Z"
   },
   {
    "duration": 101804,
    "start_time": "2023-03-23T16:16:47.745Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:18:46.910Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:18:53.659Z"
   },
   {
    "duration": 112,
    "start_time": "2023-03-23T16:19:00.142Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-23T16:19:05.789Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:19:06.771Z"
   },
   {
    "duration": 29992,
    "start_time": "2023-03-23T16:19:07.155Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:19:46.039Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:19:56.838Z"
   },
   {
    "duration": 74052,
    "start_time": "2023-03-23T16:19:58.392Z"
   },
   {
    "duration": 292,
    "start_time": "2023-03-23T16:25:27.549Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T16:25:28.814Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:25:42.997Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-23T16:25:55.921Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T16:26:48.456Z"
   },
   {
    "duration": 8257,
    "start_time": "2023-03-23T16:26:51.230Z"
   },
   {
    "duration": 193,
    "start_time": "2023-03-23T16:26:59.489Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T16:26:59.684Z"
   },
   {
    "duration": 71,
    "start_time": "2023-03-23T16:29:58.291Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-23T16:30:25.924Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:30:27.428Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-23T16:30:28.627Z"
   },
   {
    "duration": 39,
    "start_time": "2023-03-23T16:30:32.662Z"
   },
   {
    "duration": 29676,
    "start_time": "2023-03-23T16:30:36.870Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-23T16:31:20.260Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:34:07.966Z"
   },
   {
    "duration": 149,
    "start_time": "2023-03-23T16:35:08.844Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T16:37:24.150Z"
   },
   {
    "duration": 703,
    "start_time": "2023-03-23T16:37:24.157Z"
   },
   {
    "duration": 106,
    "start_time": "2023-03-23T16:37:24.862Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-23T16:37:24.970Z"
   },
   {
    "duration": 99,
    "start_time": "2023-03-23T16:37:24.984Z"
   },
   {
    "duration": 339,
    "start_time": "2023-03-23T16:37:25.085Z"
   },
   {
    "duration": 231,
    "start_time": "2023-03-23T16:37:25.426Z"
   },
   {
    "duration": 301,
    "start_time": "2023-03-23T16:37:25.658Z"
   },
   {
    "duration": 131,
    "start_time": "2023-03-23T16:37:25.960Z"
   },
   {
    "duration": 63,
    "start_time": "2023-03-23T16:37:26.093Z"
   },
   {
    "duration": 342,
    "start_time": "2023-03-23T16:37:26.157Z"
   },
   {
    "duration": 69,
    "start_time": "2023-03-23T16:37:26.501Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T16:37:26.571Z"
   },
   {
    "duration": 164,
    "start_time": "2023-03-23T16:37:26.577Z"
   },
   {
    "duration": 53,
    "start_time": "2023-03-23T16:37:26.742Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-23T16:37:26.797Z"
   },
   {
    "duration": 102,
    "start_time": "2023-03-23T16:37:26.827Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-23T16:37:26.931Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-23T16:37:26.951Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:37:26.993Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-23T16:37:26.997Z"
   },
   {
    "duration": 573,
    "start_time": "2023-03-23T16:37:27.022Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-23T16:37:27.596Z"
   },
   {
    "duration": 161,
    "start_time": "2023-03-23T16:37:27.610Z"
   },
   {
    "duration": 232,
    "start_time": "2023-03-23T16:37:27.773Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:37:28.006Z"
   },
   {
    "duration": 98537,
    "start_time": "2023-03-23T16:37:28.011Z"
   },
   {
    "duration": 405,
    "start_time": "2023-03-23T16:39:06.550Z"
   },
   {
    "duration": 88,
    "start_time": "2023-03-23T16:39:06.957Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-23T16:39:07.047Z"
   },
   {
    "duration": 8755,
    "start_time": "2023-03-23T16:39:07.057Z"
   },
   {
    "duration": 193,
    "start_time": "2023-03-23T16:39:15.814Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-23T16:39:16.009Z"
   },
   {
    "duration": 39,
    "start_time": "2023-03-23T16:39:16.018Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-23T16:39:16.058Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-23T16:39:16.060Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-23T16:39:16.061Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-23T16:39:16.062Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T16:40:05.021Z"
   },
   {
    "duration": 1286539,
    "start_time": "2023-03-23T16:40:06.293Z"
   },
   {
    "duration": 1313,
    "start_time": "2023-03-23T17:01:32.834Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T17:01:34.149Z"
   },
   {
    "duration": 27,
    "start_time": "2023-03-23T17:01:34.157Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-23T17:01:58.942Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-23T17:07:24.876Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T17:07:45.685Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T17:08:21.405Z"
   },
   {
    "duration": 217,
    "start_time": "2023-03-23T17:09:10.857Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-23T18:01:32.184Z"
   },
   {
    "duration": 1824,
    "start_time": "2023-03-23T18:01:32.197Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-23T18:01:34.023Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-23T18:01:34.024Z"
   },
   {
    "duration": 1,
    "start_time": "2023-03-23T18:01:34.025Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T18:17:09.221Z"
   },
   {
    "duration": 82,
    "start_time": "2023-03-27T07:23:02.548Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.634Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.637Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.638Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.640Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.642Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.643Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.644Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.646Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.648Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.650Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.652Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.654Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.655Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.656Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.657Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.658Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.659Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.661Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.663Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.664Z"
   },
   {
    "duration": 1,
    "start_time": "2023-03-27T07:23:02.665Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.667Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.668Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.670Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.671Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.672Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.674Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.735Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.737Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.739Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.741Z"
   },
   {
    "duration": 51,
    "start_time": "2023-03-27T07:23:02.783Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.839Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.842Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.843Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.845Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.847Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.849Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.853Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.855Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.856Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.859Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.860Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.862Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.864Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.866Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.867Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.870Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.871Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.873Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.875Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.876Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.934Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.936Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.937Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.939Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.940Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.941Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.942Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.944Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.945Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.946Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.947Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.948Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.950Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.951Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.952Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.954Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.955Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.956Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.957Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.959Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.960Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.961Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.964Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.965Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.966Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.968Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.970Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.970Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:02.971Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.034Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.035Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.037Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.038Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.040Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.042Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.044Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.045Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.047Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.049Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.050Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.052Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.053Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.055Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.056Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.058Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.060Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.062Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.063Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T07:23:03.141Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.153Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.155Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.157Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.159Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.162Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.164Z"
   },
   {
    "duration": 1,
    "start_time": "2023-03-27T07:23:03.167Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.169Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.170Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.172Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.174Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.175Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.177Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.178Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.179Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.181Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.235Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.237Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.239Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.240Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.242Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.244Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.246Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.247Z"
   },
   {
    "duration": 1,
    "start_time": "2023-03-27T07:23:03.248Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.250Z"
   },
   {
    "duration": 1,
    "start_time": "2023-03-27T07:23:03.251Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.253Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.254Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.255Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.257Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.258Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.260Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.262Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.263Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.266Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.267Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.269Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.271Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.272Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.334Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.336Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.338Z"
   },
   {
    "duration": 1,
    "start_time": "2023-03-27T07:23:03.339Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.341Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.343Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.344Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.346Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.347Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.349Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.355Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.356Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.358Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.359Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.361Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.363Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.364Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.365Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.366Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-27T07:23:03.487Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.499Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.501Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.502Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.504Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.534Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.536Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.538Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.539Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.541Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.543Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.546Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.548Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.549Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.551Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.552Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.554Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.556Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.557Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.558Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.559Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.561Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.563Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.565Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.566Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.567Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.569Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.570Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.571Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.634Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.635Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.637Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.638Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.640Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.641Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.643Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.644Z"
   },
   {
    "duration": 1,
    "start_time": "2023-03-27T07:23:03.645Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.647Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.648Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.650Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.651Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-27T07:23:03.655Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.666Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.667Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.669Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.671Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.672Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.734Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.735Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.737Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.738Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.739Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.741Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.742Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.744Z"
   },
   {
    "duration": 131,
    "start_time": "2023-03-27T07:23:03.748Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-27T07:23:03.881Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.896Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.897Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.899Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.901Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.935Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.937Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.939Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:03.941Z"
   },
   {
    "duration": 5155,
    "start_time": "2023-03-27T07:23:40.628Z"
   },
   {
    "duration": 94,
    "start_time": "2023-03-27T07:23:45.787Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:45.884Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:45.886Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:45.893Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:45.894Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:45.895Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:45.896Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:45.898Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:45.899Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:45.900Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:45.902Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:45.903Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:45.904Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:45.905Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:45.906Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-27T07:23:45.907Z"
   },
   {
    "duration": 4715,
    "start_time": "2023-03-27T07:25:22.322Z"
   },
   {
    "duration": 77,
    "start_time": "2023-03-27T07:25:27.041Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T07:25:27.121Z"
   },
   {
    "duration": 1618,
    "start_time": "2023-03-27T07:25:27.129Z"
   },
   {
    "duration": 209,
    "start_time": "2023-03-27T07:25:28.751Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-27T07:25:28.962Z"
   },
   {
    "duration": 166,
    "start_time": "2023-03-27T07:25:28.993Z"
   },
   {
    "duration": 520,
    "start_time": "2023-03-27T07:25:29.162Z"
   },
   {
    "duration": 83,
    "start_time": "2023-03-27T07:25:29.685Z"
   },
   {
    "duration": 391,
    "start_time": "2023-03-27T07:25:29.771Z"
   },
   {
    "duration": 533,
    "start_time": "2023-03-27T07:25:30.165Z"
   },
   {
    "duration": 214,
    "start_time": "2023-03-27T07:25:30.700Z"
   },
   {
    "duration": 105,
    "start_time": "2023-03-27T07:25:30.916Z"
   },
   {
    "duration": 411,
    "start_time": "2023-03-27T07:25:31.034Z"
   },
   {
    "duration": 161,
    "start_time": "2023-03-27T07:25:31.447Z"
   },
   {
    "duration": 81,
    "start_time": "2023-03-27T07:25:31.610Z"
   },
   {
    "duration": 79,
    "start_time": "2023-03-27T07:25:31.694Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T07:25:31.774Z"
   },
   {
    "duration": 44,
    "start_time": "2023-03-27T07:25:31.782Z"
   },
   {
    "duration": 193,
    "start_time": "2023-03-27T07:25:31.829Z"
   },
   {
    "duration": 79,
    "start_time": "2023-03-27T07:25:32.025Z"
   },
   {
    "duration": 51,
    "start_time": "2023-03-27T07:25:32.108Z"
   },
   {
    "duration": 56,
    "start_time": "2023-03-27T07:25:32.162Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-27T07:25:32.220Z"
   },
   {
    "duration": 26,
    "start_time": "2023-03-27T07:25:32.245Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-27T07:25:32.273Z"
   },
   {
    "duration": 75,
    "start_time": "2023-03-27T07:25:32.303Z"
   },
   {
    "duration": 69,
    "start_time": "2023-03-27T07:25:32.380Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-27T07:25:32.450Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-27T07:25:32.478Z"
   },
   {
    "duration": 89,
    "start_time": "2023-03-27T07:25:32.498Z"
   },
   {
    "duration": 75,
    "start_time": "2023-03-27T07:26:02.489Z"
   },
   {
    "duration": 131,
    "start_time": "2023-03-27T07:26:14.449Z"
   },
   {
    "duration": 75,
    "start_time": "2023-03-27T07:26:59.390Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T07:28:00.169Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T07:34:07.046Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-27T07:34:13.670Z"
   },
   {
    "duration": 335,
    "start_time": "2023-03-27T07:34:16.158Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-27T07:34:18.052Z"
   },
   {
    "duration": 120,
    "start_time": "2023-03-27T07:35:46.339Z"
   },
   {
    "duration": 186,
    "start_time": "2023-03-27T07:35:46.859Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-27T07:35:49.466Z"
   },
   {
    "duration": 34680,
    "start_time": "2023-03-27T07:36:45.805Z"
   },
   {
    "duration": 278,
    "start_time": "2023-03-27T07:37:23.059Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T07:38:39.271Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T07:38:40.271Z"
   },
   {
    "duration": 4509,
    "start_time": "2023-03-27T07:38:40.963Z"
   },
   {
    "duration": 131,
    "start_time": "2023-03-27T07:42:41.032Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T07:42:42.643Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T07:43:53.845Z"
   },
   {
    "duration": 858770,
    "start_time": "2023-03-27T07:43:54.617Z"
   },
   {
    "duration": 154,
    "start_time": "2023-03-27T07:58:13.389Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T07:58:13.545Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T07:58:13.553Z"
   },
   {
    "duration": 94236,
    "start_time": "2023-03-27T07:58:13.565Z"
   },
   {
    "duration": 147,
    "start_time": "2023-03-27T07:59:47.803Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-27T07:59:47.952Z"
   },
   {
    "duration": 3706,
    "start_time": "2023-03-28T15:41:30.662Z"
   },
   {
    "duration": 260,
    "start_time": "2023-03-28T15:41:34.371Z"
   },
   {
    "duration": 1456,
    "start_time": "2023-03-28T15:41:34.632Z"
   },
   {
    "duration": 1124,
    "start_time": "2023-03-28T15:41:36.091Z"
   },
   {
    "duration": 145,
    "start_time": "2023-03-28T15:41:37.217Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-28T15:41:37.364Z"
   },
   {
    "duration": 106,
    "start_time": "2023-03-28T15:41:37.380Z"
   },
   {
    "duration": 383,
    "start_time": "2023-03-28T15:41:37.487Z"
   },
   {
    "duration": 49,
    "start_time": "2023-03-28T15:41:37.872Z"
   },
   {
    "duration": 30,
    "start_time": "2023-03-28T15:41:37.924Z"
   },
   {
    "duration": 341,
    "start_time": "2023-03-28T15:41:37.956Z"
   },
   {
    "duration": 89,
    "start_time": "2023-03-28T15:41:38.299Z"
   },
   {
    "duration": 36,
    "start_time": "2023-03-28T15:41:38.389Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-28T15:41:38.427Z"
   },
   {
    "duration": 91,
    "start_time": "2023-03-28T15:41:38.451Z"
   },
   {
    "duration": 368,
    "start_time": "2023-03-28T15:41:38.544Z"
   },
   {
    "duration": 213,
    "start_time": "2023-03-28T15:41:38.913Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-28T15:41:39.127Z"
   },
   {
    "duration": 70,
    "start_time": "2023-03-28T15:41:39.132Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-28T15:41:39.204Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-28T15:41:39.208Z"
   },
   {
    "duration": 161,
    "start_time": "2023-03-28T15:41:39.251Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-28T15:41:39.414Z"
   },
   {
    "duration": 84,
    "start_time": "2023-03-28T15:41:39.419Z"
   },
   {
    "duration": 65,
    "start_time": "2023-03-28T15:41:39.505Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-28T15:41:39.572Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-28T15:41:39.587Z"
   },
   {
    "duration": 46,
    "start_time": "2023-03-28T15:41:39.595Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-28T15:41:39.643Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-28T15:41:39.652Z"
   },
   {
    "duration": 20,
    "start_time": "2023-03-28T15:41:39.665Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-28T15:41:39.686Z"
   },
   {
    "duration": 45,
    "start_time": "2023-03-28T15:41:39.696Z"
   },
   {
    "duration": 218,
    "start_time": "2023-03-28T15:41:39.743Z"
   },
   {
    "duration": 217,
    "start_time": "2023-03-28T15:41:39.963Z"
   },
   {
    "duration": 215,
    "start_time": "2023-03-28T15:41:40.182Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-28T15:41:40.399Z"
   },
   {
    "duration": 80,
    "start_time": "2023-03-28T15:41:40.404Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-28T15:41:40.485Z"
   },
   {
    "duration": 17,
    "start_time": "2023-03-28T15:41:40.490Z"
   },
   {
    "duration": 32,
    "start_time": "2023-03-28T15:41:40.509Z"
   },
   {
    "duration": 69,
    "start_time": "2023-03-28T15:41:40.543Z"
   },
   {
    "duration": 29,
    "start_time": "2023-03-28T15:41:40.613Z"
   },
   {
    "duration": 147,
    "start_time": "2023-03-28T15:41:40.643Z"
   },
   {
    "duration": 159,
    "start_time": "2023-03-28T15:41:40.791Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-28T15:41:40.952Z"
   },
   {
    "duration": 46,
    "start_time": "2023-03-28T15:41:40.967Z"
   },
   {
    "duration": 141,
    "start_time": "2023-03-28T15:41:41.015Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-28T15:41:41.158Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-28T15:41:41.159Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-28T15:41:41.160Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-28T15:41:41.161Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-28T15:41:41.162Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-28T15:41:41.163Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-28T15:41:41.163Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-28T15:41:41.165Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-28T15:41:41.165Z"
   },
   {
    "duration": 3885,
    "start_time": "2023-03-29T14:18:58.912Z"
   },
   {
    "duration": 6024,
    "start_time": "2023-03-29T14:19:02.800Z"
   },
   {
    "duration": 1641,
    "start_time": "2023-03-29T14:19:08.826Z"
   },
   {
    "duration": 1271,
    "start_time": "2023-03-29T14:19:10.474Z"
   },
   {
    "duration": 115,
    "start_time": "2023-03-29T14:19:11.747Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-29T14:19:11.864Z"
   },
   {
    "duration": 105,
    "start_time": "2023-03-29T14:19:11.880Z"
   },
   {
    "duration": 550,
    "start_time": "2023-03-29T14:19:11.987Z"
   },
   {
    "duration": 53,
    "start_time": "2023-03-29T14:19:12.539Z"
   },
   {
    "duration": 32,
    "start_time": "2023-03-29T14:19:12.594Z"
   },
   {
    "duration": 588,
    "start_time": "2023-03-29T14:19:12.628Z"
   },
   {
    "duration": 85,
    "start_time": "2023-03-29T14:19:13.218Z"
   },
   {
    "duration": 46,
    "start_time": "2023-03-29T14:19:13.305Z"
   },
   {
    "duration": 99,
    "start_time": "2023-03-29T14:19:13.354Z"
   },
   {
    "duration": 89,
    "start_time": "2023-03-29T14:19:13.455Z"
   },
   {
    "duration": 381,
    "start_time": "2023-03-29T14:19:13.545Z"
   },
   {
    "duration": 215,
    "start_time": "2023-03-29T14:19:13.928Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-29T14:19:14.145Z"
   },
   {
    "duration": 75,
    "start_time": "2023-03-29T14:19:14.149Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T14:19:14.226Z"
   },
   {
    "duration": 36,
    "start_time": "2023-03-29T14:19:14.231Z"
   },
   {
    "duration": 175,
    "start_time": "2023-03-29T14:19:14.269Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T14:19:14.446Z"
   },
   {
    "duration": 77,
    "start_time": "2023-03-29T14:19:14.452Z"
   },
   {
    "duration": 65,
    "start_time": "2023-03-29T14:19:14.531Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-29T14:19:14.597Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-29T14:19:14.627Z"
   },
   {
    "duration": 26,
    "start_time": "2023-03-29T14:19:14.638Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-29T14:19:14.666Z"
   },
   {
    "duration": 27,
    "start_time": "2023-03-29T14:19:14.675Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-29T14:19:14.703Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-29T14:19:14.730Z"
   },
   {
    "duration": 29,
    "start_time": "2023-03-29T14:19:14.742Z"
   },
   {
    "duration": 243,
    "start_time": "2023-03-29T14:19:14.773Z"
   },
   {
    "duration": 228,
    "start_time": "2023-03-29T14:19:15.019Z"
   },
   {
    "duration": 249,
    "start_time": "2023-03-29T14:19:15.248Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T14:19:15.499Z"
   },
   {
    "duration": 96,
    "start_time": "2023-03-29T14:19:15.504Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T14:19:15.601Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-29T14:19:15.606Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-29T14:19:15.631Z"
   },
   {
    "duration": 79,
    "start_time": "2023-03-29T14:19:15.653Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-29T14:19:15.733Z"
   },
   {
    "duration": 137,
    "start_time": "2023-03-29T14:19:15.750Z"
   },
   {
    "duration": 150,
    "start_time": "2023-03-29T14:19:15.889Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-29T14:19:16.041Z"
   },
   {
    "duration": 73,
    "start_time": "2023-03-29T14:19:16.057Z"
   },
   {
    "duration": 47,
    "start_time": "2023-03-29T14:19:26.466Z"
   },
   {
    "duration": 215,
    "start_time": "2023-03-29T14:19:26.992Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-29T14:19:27.588Z"
   },
   {
    "duration": 588,
    "start_time": "2023-03-29T14:19:28.255Z"
   },
   {
    "duration": 388,
    "start_time": "2023-03-29T14:19:30.020Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-29T14:19:35.262Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T14:19:36.123Z"
   },
   {
    "duration": 26,
    "start_time": "2023-03-29T14:19:37.056Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-29T14:22:09.912Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-29T14:22:10.501Z"
   },
   {
    "duration": 62,
    "start_time": "2023-03-29T14:22:11.165Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-29T14:22:11.709Z"
   },
   {
    "duration": 508,
    "start_time": "2023-03-29T14:22:12.215Z"
   },
   {
    "duration": 304,
    "start_time": "2023-03-29T14:22:12.733Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T14:22:16.274Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-29T14:22:17.293Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-29T14:22:18.253Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T14:22:24.548Z"
   },
   {
    "duration": 54875,
    "start_time": "2023-03-29T14:22:26.709Z"
   },
   {
    "duration": 420,
    "start_time": "2023-03-29T14:28:26.012Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-29T14:28:27.641Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-29T14:28:29.439Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T14:28:30.458Z"
   },
   {
    "duration": 211919,
    "start_time": "2023-03-29T14:28:30.928Z"
   },
   {
    "duration": 6638,
    "start_time": "2023-03-29T14:32:02.850Z"
   },
   {
    "duration": 1095,
    "start_time": "2023-03-29T14:32:09.490Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-29T14:32:10.588Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-29T14:32:10.598Z"
   },
   {
    "duration": 92982,
    "start_time": "2023-03-29T14:32:10.611Z"
   },
   {
    "duration": 1036,
    "start_time": "2023-03-29T14:33:43.595Z"
   },
   {
    "duration": 201,
    "start_time": "2023-03-29T14:33:44.632Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-29T14:33:44.835Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-29T14:36:54.859Z"
   },
   {
    "duration": 213878,
    "start_time": "2023-03-29T14:36:55.700Z"
   },
   {
    "duration": 2043,
    "start_time": "2023-03-29T14:40:29.580Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-29T14:40:31.625Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-29T14:40:31.650Z"
   },
   {
    "duration": 112,
    "start_time": "2023-03-29T14:41:53.195Z"
   },
   {
    "duration": 1669,
    "start_time": "2023-03-29T14:42:35.827Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-29T14:42:42.780Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-29T14:42:45.662Z"
   },
   {
    "duration": 57,
    "start_time": "2023-03-29T14:43:11.370Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-29T14:43:12.479Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-29T14:43:30.326Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-29T14:43:31.233Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-29T14:44:03.740Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "374.388px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
